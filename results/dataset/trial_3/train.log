*************************** Fold #: 1 ***************************
Model: "sequential_20"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_220 (Dense)            (None, 30)                150       
_________________________________________________________________
dense_221 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_222 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_223 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_224 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_225 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_226 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_227 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_228 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_229 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_230 (Dense)            (None, 1)                 31        
=================================================================
Total params: 8,551
Trainable params: 8,551
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
4/4 - 0s - loss: 29.6460 - val_loss: 46.3590

Epoch 00001: val_loss improved from inf to 46.35904, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 2/10000
4/4 - 0s - loss: 29.6118 - val_loss: 46.3192

Epoch 00002: val_loss improved from 46.35904 to 46.31925, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 3/10000
4/4 - 0s - loss: 29.5743 - val_loss: 46.2752

Epoch 00003: val_loss improved from 46.31925 to 46.27522, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 4/10000
4/4 - 0s - loss: 29.5322 - val_loss: 46.2258

Epoch 00004: val_loss improved from 46.27522 to 46.22583, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 5/10000
4/4 - 0s - loss: 29.4847 - val_loss: 46.1697

Epoch 00005: val_loss improved from 46.22583 to 46.16971, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 6/10000
4/4 - 0s - loss: 29.4315 - val_loss: 46.1048

Epoch 00006: val_loss improved from 46.16971 to 46.10480, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 7/10000
4/4 - 0s - loss: 29.3687 - val_loss: 46.0288

Epoch 00007: val_loss improved from 46.10480 to 46.02878, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 8/10000
4/4 - 0s - loss: 29.2950 - val_loss: 45.9380

Epoch 00008: val_loss improved from 46.02878 to 45.93798, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 9/10000
4/4 - 0s - loss: 29.2047 - val_loss: 45.8274

Epoch 00009: val_loss improved from 45.93798 to 45.82744, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 10/10000
4/4 - 0s - loss: 29.0975 - val_loss: 45.6891

Epoch 00010: val_loss improved from 45.82744 to 45.68910, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 11/10000
4/4 - 0s - loss: 28.9587 - val_loss: 45.5115

Epoch 00011: val_loss improved from 45.68910 to 45.51154, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 12/10000
4/4 - 0s - loss: 28.7797 - val_loss: 45.2734

Epoch 00012: val_loss improved from 45.51154 to 45.27343, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 13/10000
4/4 - 0s - loss: 28.5356 - val_loss: 44.9429

Epoch 00013: val_loss improved from 45.27343 to 44.94289, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 14/10000
4/4 - 0s - loss: 28.2040 - val_loss: 44.4633

Epoch 00014: val_loss improved from 44.94289 to 44.46327, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 15/10000
4/4 - 0s - loss: 27.6988 - val_loss: 43.7363

Epoch 00015: val_loss improved from 44.46327 to 43.73626, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 16/10000
4/4 - 0s - loss: 26.9254 - val_loss: 42.5898

Epoch 00016: val_loss improved from 43.73626 to 42.58976, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 17/10000
4/4 - 0s - loss: 25.7147 - val_loss: 40.7844

Epoch 00017: val_loss improved from 42.58976 to 40.78444, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 18/10000
4/4 - 0s - loss: 23.9460 - val_loss: 38.2598

Epoch 00018: val_loss improved from 40.78444 to 38.25982, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 19/10000
4/4 - 0s - loss: 21.9268 - val_loss: 36.6187

Epoch 00019: val_loss improved from 38.25982 to 36.61869, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 20/10000
4/4 - 0s - loss: 21.8635 - val_loss: 36.8498

Epoch 00020: val_loss did not improve from 36.61869
Epoch 21/10000
4/4 - 0s - loss: 21.7442 - val_loss: 36.4743

Epoch 00021: val_loss improved from 36.61869 to 36.47427, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 22/10000
4/4 - 0s - loss: 21.2714 - val_loss: 36.7689

Epoch 00022: val_loss did not improve from 36.47427
Epoch 23/10000
4/4 - 0s - loss: 21.3830 - val_loss: 36.7966

Epoch 00023: val_loss did not improve from 36.47427
Epoch 24/10000
4/4 - 0s - loss: 21.2819 - val_loss: 36.4485

Epoch 00024: val_loss improved from 36.47427 to 36.44852, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 25/10000
4/4 - 0s - loss: 21.0814 - val_loss: 36.1584

Epoch 00025: val_loss improved from 36.44852 to 36.15839, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 26/10000
4/4 - 0s - loss: 21.0129 - val_loss: 36.0574

Epoch 00026: val_loss improved from 36.15839 to 36.05737, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 27/10000
4/4 - 0s - loss: 20.9865 - val_loss: 35.9889

Epoch 00027: val_loss improved from 36.05737 to 35.98891, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 28/10000
4/4 - 0s - loss: 20.8775 - val_loss: 35.9614

Epoch 00028: val_loss improved from 35.98891 to 35.96140, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 29/10000
4/4 - 0s - loss: 20.7956 - val_loss: 35.9681

Epoch 00029: val_loss did not improve from 35.96140
Epoch 30/10000
4/4 - 0s - loss: 20.7484 - val_loss: 35.9041

Epoch 00030: val_loss improved from 35.96140 to 35.90413, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 31/10000
4/4 - 0s - loss: 20.6885 - val_loss: 35.7633

Epoch 00031: val_loss improved from 35.90413 to 35.76330, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 32/10000
4/4 - 0s - loss: 20.6339 - val_loss: 35.7065

Epoch 00032: val_loss improved from 35.76330 to 35.70655, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 33/10000
4/4 - 0s - loss: 20.5958 - val_loss: 35.6731

Epoch 00033: val_loss improved from 35.70655 to 35.67307, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 34/10000
4/4 - 0s - loss: 20.5450 - val_loss: 35.7033

Epoch 00034: val_loss did not improve from 35.67307
Epoch 35/10000
4/4 - 0s - loss: 20.5232 - val_loss: 35.6848

Epoch 00035: val_loss did not improve from 35.67307
Epoch 36/10000
4/4 - 0s - loss: 20.4767 - val_loss: 35.5875

Epoch 00036: val_loss improved from 35.67307 to 35.58754, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 37/10000
4/4 - 0s - loss: 20.4512 - val_loss: 35.5405

Epoch 00037: val_loss improved from 35.58754 to 35.54054, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 38/10000
4/4 - 0s - loss: 20.4310 - val_loss: 35.5279

Epoch 00038: val_loss improved from 35.54054 to 35.52794, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 39/10000
4/4 - 0s - loss: 20.4062 - val_loss: 35.5797

Epoch 00039: val_loss did not improve from 35.52794
Epoch 40/10000
4/4 - 0s - loss: 20.3800 - val_loss: 35.5522

Epoch 00040: val_loss did not improve from 35.52794
Epoch 41/10000
4/4 - 0s - loss: 20.3541 - val_loss: 35.4994

Epoch 00041: val_loss improved from 35.52794 to 35.49936, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 42/10000
4/4 - 0s - loss: 20.3360 - val_loss: 35.4781

Epoch 00042: val_loss improved from 35.49936 to 35.47812, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 43/10000
4/4 - 0s - loss: 20.3199 - val_loss: 35.4883

Epoch 00043: val_loss did not improve from 35.47812
Epoch 44/10000
4/4 - 0s - loss: 20.3020 - val_loss: 35.4921

Epoch 00044: val_loss did not improve from 35.47812
Epoch 45/10000
4/4 - 0s - loss: 20.2859 - val_loss: 35.4723

Epoch 00045: val_loss improved from 35.47812 to 35.47231, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 46/10000
4/4 - 0s - loss: 20.2714 - val_loss: 35.4461

Epoch 00046: val_loss improved from 35.47231 to 35.44613, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 47/10000
4/4 - 0s - loss: 20.2627 - val_loss: 35.4643

Epoch 00047: val_loss did not improve from 35.44613
Epoch 48/10000
4/4 - 0s - loss: 20.2578 - val_loss: 35.4169

Epoch 00048: val_loss improved from 35.44613 to 35.41686, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 49/10000
4/4 - 0s - loss: 20.2435 - val_loss: 35.4236

Epoch 00049: val_loss did not improve from 35.41686
Epoch 50/10000
4/4 - 0s - loss: 20.2403 - val_loss: 35.5056

Epoch 00050: val_loss did not improve from 35.41686
Epoch 51/10000
4/4 - 0s - loss: 20.2267 - val_loss: 35.4264

Epoch 00051: val_loss did not improve from 35.41686
Epoch 52/10000
4/4 - 0s - loss: 20.2124 - val_loss: 35.3896

Epoch 00052: val_loss improved from 35.41686 to 35.38960, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 53/10000
4/4 - 0s - loss: 20.2101 - val_loss: 35.3978

Epoch 00053: val_loss did not improve from 35.38960
Epoch 54/10000
4/4 - 0s - loss: 20.1955 - val_loss: 35.4524

Epoch 00054: val_loss did not improve from 35.38960
Epoch 55/10000
4/4 - 0s - loss: 20.2075 - val_loss: 35.4926

Epoch 00055: val_loss did not improve from 35.38960
Epoch 56/10000
4/4 - 0s - loss: 20.1900 - val_loss: 35.4186

Epoch 00056: val_loss did not improve from 35.38960
Epoch 57/10000
4/4 - 0s - loss: 20.1903 - val_loss: 35.3732

Epoch 00057: val_loss improved from 35.38960 to 35.37322, saving model to ./results/dataset/trial_3/ckpt_1
Epoch 58/10000
4/4 - 0s - loss: 20.2004 - val_loss: 35.3931

Epoch 00058: val_loss did not improve from 35.37322
Epoch 59/10000
4/4 - 0s - loss: 20.1742 - val_loss: 35.4584

Epoch 00059: val_loss did not improve from 35.37322
Epoch 60/10000
4/4 - 0s - loss: 20.1986 - val_loss: 35.5296

Epoch 00060: val_loss did not improve from 35.37322
Epoch 61/10000
4/4 - 0s - loss: 20.1959 - val_loss: 35.4175

Epoch 00061: val_loss did not improve from 35.37322
Epoch 62/10000
4/4 - 0s - loss: 20.1771 - val_loss: 35.4075

Epoch 00062: val_loss did not improve from 35.37322
Epoch 63/10000
4/4 - 0s - loss: 20.1719 - val_loss: 35.4326

Epoch 00063: val_loss did not improve from 35.37322
Epoch 64/10000
4/4 - 0s - loss: 20.1756 - val_loss: 35.4622

Epoch 00064: val_loss did not improve from 35.37322
Epoch 65/10000
4/4 - 0s - loss: 20.1725 - val_loss: 35.4171

Epoch 00065: val_loss did not improve from 35.37322
Epoch 66/10000
4/4 - 0s - loss: 20.1710 - val_loss: 35.4164

Epoch 00066: val_loss did not improve from 35.37322
Epoch 67/10000
4/4 - 0s - loss: 20.1686 - val_loss: 35.4417

Epoch 00067: val_loss did not improve from 35.37322
Epoch 68/10000
4/4 - 0s - loss: 20.1662 - val_loss: 35.4544

Epoch 00068: val_loss did not improve from 35.37322
Epoch 69/10000
4/4 - 0s - loss: 20.1721 - val_loss: 35.4520

Epoch 00069: val_loss did not improve from 35.37322
Epoch 70/10000
4/4 - 0s - loss: 20.1681 - val_loss: 35.4227

Epoch 00070: val_loss did not improve from 35.37322
Epoch 71/10000
4/4 - 0s - loss: 20.1693 - val_loss: 35.4189

Epoch 00071: val_loss did not improve from 35.37322
Epoch 72/10000
4/4 - 0s - loss: 20.1658 - val_loss: 35.4607

Epoch 00072: val_loss did not improve from 35.37322
Epoch 73/10000
4/4 - 0s - loss: 20.1646 - val_loss: 35.4729

Epoch 00073: val_loss did not improve from 35.37322
Epoch 74/10000
4/4 - 0s - loss: 20.1760 - val_loss: 35.4784

Epoch 00074: val_loss did not improve from 35.37322
Epoch 75/10000
4/4 - 0s - loss: 20.1577 - val_loss: 35.4118

Epoch 00075: val_loss did not improve from 35.37322
Epoch 76/10000
4/4 - 0s - loss: 20.1801 - val_loss: 35.4016

Epoch 00076: val_loss did not improve from 35.37322
Epoch 77/10000
4/4 - 0s - loss: 20.1739 - val_loss: 35.4502

Epoch 00077: val_loss did not improve from 35.37322
Epoch 78/10000
4/4 - 0s - loss: 20.1565 - val_loss: 35.5636

Epoch 00078: val_loss did not improve from 35.37322
Epoch 79/10000
4/4 - 0s - loss: 20.1954 - val_loss: 35.5126

Epoch 00079: val_loss did not improve from 35.37322
Epoch 80/10000
4/4 - 0s - loss: 20.1773 - val_loss: 35.4677

Epoch 00080: val_loss did not improve from 35.37322
Epoch 81/10000
4/4 - 0s - loss: 20.1644 - val_loss: 35.4630

Epoch 00081: val_loss did not improve from 35.37322
Epoch 82/10000
4/4 - 0s - loss: 20.1663 - val_loss: 35.4507

Epoch 00082: val_loss did not improve from 35.37322
Epoch 83/10000
4/4 - 0s - loss: 20.1631 - val_loss: 35.4670

Epoch 00083: val_loss did not improve from 35.37322
Epoch 84/10000
4/4 - 0s - loss: 20.1758 - val_loss: 35.4800

Epoch 00084: val_loss did not improve from 35.37322
Epoch 85/10000
4/4 - 0s - loss: 20.1718 - val_loss: 35.5035

Epoch 00085: val_loss did not improve from 35.37322
Epoch 86/10000
4/4 - 0s - loss: 20.1830 - val_loss: 35.4466

Epoch 00086: val_loss did not improve from 35.37322
Epoch 87/10000
4/4 - 0s - loss: 20.1641 - val_loss: 35.4673

Epoch 00087: val_loss did not improve from 35.37322
Epoch 88/10000
4/4 - 0s - loss: 20.1638 - val_loss: 35.4900

Epoch 00088: val_loss did not improve from 35.37322
Epoch 89/10000
4/4 - 0s - loss: 20.1690 - val_loss: 35.4701

Epoch 00089: val_loss did not improve from 35.37322
Epoch 90/10000
4/4 - 0s - loss: 20.1640 - val_loss: 35.4208

Epoch 00090: val_loss did not improve from 35.37322
Epoch 91/10000
4/4 - 0s - loss: 20.1704 - val_loss: 35.4409

Epoch 00091: val_loss did not improve from 35.37322
Epoch 92/10000
4/4 - 0s - loss: 20.1806 - val_loss: 35.4953

Epoch 00092: val_loss did not improve from 35.37322
Epoch 93/10000
4/4 - 0s - loss: 20.1685 - val_loss: 35.4523

Epoch 00093: val_loss did not improve from 35.37322
Epoch 94/10000
4/4 - 0s - loss: 20.1752 - val_loss: 35.4365

Epoch 00094: val_loss did not improve from 35.37322
Epoch 95/10000
4/4 - 0s - loss: 20.1642 - val_loss: 35.4680

Epoch 00095: val_loss did not improve from 35.37322
Epoch 96/10000
4/4 - 0s - loss: 20.1750 - val_loss: 35.4897

Epoch 00096: val_loss did not improve from 35.37322
Epoch 97/10000
4/4 - 0s - loss: 20.1630 - val_loss: 35.4338

Epoch 00097: val_loss did not improve from 35.37322
Epoch 98/10000
4/4 - 0s - loss: 20.1728 - val_loss: 35.4217

Epoch 00098: val_loss did not improve from 35.37322
Epoch 99/10000
4/4 - 0s - loss: 20.1789 - val_loss: 35.4741

Epoch 00099: val_loss did not improve from 35.37322
Epoch 100/10000
4/4 - 0s - loss: 20.1630 - val_loss: 35.4583

Epoch 00100: val_loss did not improve from 35.37322
Epoch 101/10000
4/4 - 0s - loss: 20.1783 - val_loss: 35.4384

Epoch 00101: val_loss did not improve from 35.37322
Epoch 102/10000
4/4 - 0s - loss: 20.1780 - val_loss: 35.5338

Epoch 00102: val_loss did not improve from 35.37322
Epoch 103/10000
4/4 - 0s - loss: 20.1774 - val_loss: 35.4813

Epoch 00103: val_loss did not improve from 35.37322
Epoch 104/10000
4/4 - 0s - loss: 20.1683 - val_loss: 35.4420

Epoch 00104: val_loss did not improve from 35.37322
Epoch 105/10000
4/4 - 0s - loss: 20.1705 - val_loss: 35.4714

Epoch 00105: val_loss did not improve from 35.37322
Epoch 106/10000
4/4 - 0s - loss: 20.1642 - val_loss: 35.4643

Epoch 00106: val_loss did not improve from 35.37322
Epoch 107/10000
4/4 - 0s - loss: 20.1665 - val_loss: 35.4400

Epoch 00107: val_loss did not improve from 35.37322
Epoch 108/10000
4/4 - 0s - loss: 20.1626 - val_loss: 35.4779

Epoch 00108: val_loss did not improve from 35.37322
Epoch 109/10000
4/4 - 0s - loss: 20.1643 - val_loss: 35.4940

Epoch 00109: val_loss did not improve from 35.37322
Epoch 110/10000
4/4 - 0s - loss: 20.1756 - val_loss: 35.4519

Epoch 00110: val_loss did not improve from 35.37322
Epoch 111/10000
4/4 - 0s - loss: 20.1647 - val_loss: 35.4797

Epoch 00111: val_loss did not improve from 35.37322
Epoch 112/10000
4/4 - 0s - loss: 20.1675 - val_loss: 35.4559

Epoch 00112: val_loss did not improve from 35.37322
Epoch 113/10000
4/4 - 0s - loss: 20.1671 - val_loss: 35.4727

Epoch 00113: val_loss did not improve from 35.37322
Epoch 114/10000
4/4 - 0s - loss: 20.1609 - val_loss: 35.4413

Epoch 00114: val_loss did not improve from 35.37322
Epoch 115/10000
4/4 - 0s - loss: 20.1670 - val_loss: 35.4420

Epoch 00115: val_loss did not improve from 35.37322
Epoch 116/10000
4/4 - 0s - loss: 20.1667 - val_loss: 35.4579

Epoch 00116: val_loss did not improve from 35.37322
Epoch 117/10000
4/4 - 0s - loss: 20.1632 - val_loss: 35.4711

Epoch 00117: val_loss did not improve from 35.37322
Epoch 118/10000
4/4 - 0s - loss: 20.1686 - val_loss: 35.4736

Epoch 00118: val_loss did not improve from 35.37322
Epoch 119/10000
4/4 - 0s - loss: 20.1672 - val_loss: 35.4579

Epoch 00119: val_loss did not improve from 35.37322
Epoch 120/10000
4/4 - 0s - loss: 20.1630 - val_loss: 35.4383

Epoch 00120: val_loss did not improve from 35.37322
Epoch 121/10000
4/4 - 0s - loss: 20.1800 - val_loss: 35.4250

Epoch 00121: val_loss did not improve from 35.37322
Epoch 122/10000
4/4 - 0s - loss: 20.1781 - val_loss: 35.5036

Epoch 00122: val_loss did not improve from 35.37322
Epoch 123/10000
4/4 - 0s - loss: 20.1721 - val_loss: 35.4875

Epoch 00123: val_loss did not improve from 35.37322
Epoch 124/10000
4/4 - 0s - loss: 20.1696 - val_loss: 35.4402

Epoch 00124: val_loss did not improve from 35.37322
Epoch 125/10000
4/4 - 0s - loss: 20.1844 - val_loss: 35.4361

Epoch 00125: val_loss did not improve from 35.37322
Epoch 126/10000
4/4 - 0s - loss: 20.1669 - val_loss: 35.4819

Epoch 00126: val_loss did not improve from 35.37322
Epoch 127/10000
4/4 - 0s - loss: 20.1667 - val_loss: 35.4855

Epoch 00127: val_loss did not improve from 35.37322
Epoch 128/10000
4/4 - 0s - loss: 20.1728 - val_loss: 35.4510

Epoch 00128: val_loss did not improve from 35.37322
Epoch 129/10000
4/4 - 0s - loss: 20.1789 - val_loss: 35.4253

Epoch 00129: val_loss did not improve from 35.37322
Epoch 130/10000
4/4 - 0s - loss: 20.1777 - val_loss: 35.4232

Epoch 00130: val_loss did not improve from 35.37322
Epoch 131/10000
4/4 - 0s - loss: 20.1719 - val_loss: 35.5307

Epoch 00131: val_loss did not improve from 35.37322
Epoch 132/10000
4/4 - 0s - loss: 20.1865 - val_loss: 35.4874

Epoch 00132: val_loss did not improve from 35.37322
Epoch 133/10000
4/4 - 0s - loss: 20.1670 - val_loss: 35.4884

Epoch 00133: val_loss did not improve from 35.37322
Epoch 134/10000
4/4 - 0s - loss: 20.1620 - val_loss: 35.4532

Epoch 00134: val_loss did not improve from 35.37322
Epoch 135/10000
4/4 - 0s - loss: 20.1656 - val_loss: 35.4293

Epoch 00135: val_loss did not improve from 35.37322
Epoch 136/10000
4/4 - 0s - loss: 20.1777 - val_loss: 35.4721

Epoch 00136: val_loss did not improve from 35.37322
Epoch 137/10000
4/4 - 0s - loss: 20.1641 - val_loss: 35.4844

Epoch 00137: val_loss did not improve from 35.37322
Epoch 138/10000
4/4 - 0s - loss: 20.1644 - val_loss: 35.4469

Epoch 00138: val_loss did not improve from 35.37322
Epoch 139/10000
4/4 - 0s - loss: 20.1639 - val_loss: 35.4479

Epoch 00139: val_loss did not improve from 35.37322
Epoch 140/10000
4/4 - 0s - loss: 20.1675 - val_loss: 35.4594

Epoch 00140: val_loss did not improve from 35.37322
Epoch 141/10000
4/4 - 0s - loss: 20.1707 - val_loss: 35.4397

Epoch 00141: val_loss did not improve from 35.37322
Epoch 142/10000
4/4 - 0s - loss: 20.1671 - val_loss: 35.4623

Epoch 00142: val_loss did not improve from 35.37322
Epoch 143/10000
4/4 - 0s - loss: 20.1628 - val_loss: 35.4585

Epoch 00143: val_loss did not improve from 35.37322
Epoch 144/10000
4/4 - 0s - loss: 20.1627 - val_loss: 35.4693

Epoch 00144: val_loss did not improve from 35.37322
Epoch 145/10000
4/4 - 0s - loss: 20.1675 - val_loss: 35.4689

Epoch 00145: val_loss did not improve from 35.37322
Epoch 146/10000
4/4 - 0s - loss: 20.1631 - val_loss: 35.4665

Epoch 00146: val_loss did not improve from 35.37322
Epoch 147/10000
4/4 - 0s - loss: 20.1671 - val_loss: 35.4680

Epoch 00147: val_loss did not improve from 35.37322
Epoch 148/10000
4/4 - 0s - loss: 20.1833 - val_loss: 35.4215

Epoch 00148: val_loss did not improve from 35.37322
Epoch 149/10000
4/4 - 0s - loss: 20.1755 - val_loss: 35.4740

Epoch 00149: val_loss did not improve from 35.37322
Epoch 150/10000
4/4 - 0s - loss: 20.1761 - val_loss: 35.4764

Epoch 00150: val_loss did not improve from 35.37322
Epoch 151/10000
4/4 - 0s - loss: 20.1652 - val_loss: 35.4169

Epoch 00151: val_loss did not improve from 35.37322
Epoch 152/10000
4/4 - 0s - loss: 20.1720 - val_loss: 35.4549

Epoch 00152: val_loss did not improve from 35.37322
Epoch 153/10000
4/4 - 0s - loss: 20.1686 - val_loss: 35.4999

Epoch 00153: val_loss did not improve from 35.37322
Epoch 154/10000
4/4 - 0s - loss: 20.2018 - val_loss: 35.4438

Epoch 00154: val_loss did not improve from 35.37322
Epoch 155/10000
4/4 - 0s - loss: 20.1545 - val_loss: 35.5110

Epoch 00155: val_loss did not improve from 35.37322
Epoch 156/10000
4/4 - 0s - loss: 20.1879 - val_loss: 35.5616

Epoch 00156: val_loss did not improve from 35.37322
Epoch 157/10000
4/4 - 0s - loss: 20.1774 - val_loss: 35.4518

Epoch 00157: val_loss did not improve from 35.37322
Epoch 158/10000
4/4 - 0s - loss: 20.1684 - val_loss: 35.4208

Epoch 00158: val_loss did not improve from 35.37322
Epoch 159/10000
4/4 - 0s - loss: 20.1748 - val_loss: 35.4155

Epoch 00159: val_loss did not improve from 35.37322
Epoch 160/10000
4/4 - 0s - loss: 20.1762 - val_loss: 35.4568

Epoch 00160: val_loss did not improve from 35.37322
Epoch 161/10000
4/4 - 0s - loss: 20.1901 - val_loss: 35.5725

Epoch 00161: val_loss did not improve from 35.37322
Epoch 162/10000
4/4 - 0s - loss: 20.1822 - val_loss: 35.4829

Epoch 00162: val_loss did not improve from 35.37322
Epoch 163/10000
4/4 - 0s - loss: 20.1711 - val_loss: 35.4027

Epoch 00163: val_loss did not improve from 35.37322
Epoch 164/10000
4/4 - 0s - loss: 20.2023 - val_loss: 35.4182

Epoch 00164: val_loss did not improve from 35.37322
Epoch 165/10000
4/4 - 0s - loss: 20.1858 - val_loss: 35.5642

Epoch 00165: val_loss did not improve from 35.37322
Epoch 166/10000
4/4 - 0s - loss: 20.1855 - val_loss: 35.5100

Epoch 00166: val_loss did not improve from 35.37322
Epoch 167/10000
4/4 - 0s - loss: 20.1742 - val_loss: 35.4371

Epoch 00167: val_loss did not improve from 35.37322
Epoch 168/10000
4/4 - 0s - loss: 20.1667 - val_loss: 35.4524

Epoch 00168: val_loss did not improve from 35.37322
Epoch 169/10000
4/4 - 0s - loss: 20.1674 - val_loss: 35.4979

Epoch 00169: val_loss did not improve from 35.37322
Epoch 170/10000
4/4 - 0s - loss: 20.1711 - val_loss: 35.4617

Epoch 00170: val_loss did not improve from 35.37322
Epoch 171/10000
4/4 - 0s - loss: 20.1638 - val_loss: 35.4501

Epoch 00171: val_loss did not improve from 35.37322
Epoch 172/10000
4/4 - 0s - loss: 20.1749 - val_loss: 35.4180

Epoch 00172: val_loss did not improve from 35.37322
Epoch 173/10000
4/4 - 0s - loss: 20.1801 - val_loss: 35.4732

Epoch 00173: val_loss did not improve from 35.37322
Epoch 174/10000
4/4 - 0s - loss: 20.1812 - val_loss: 35.5209

Epoch 00174: val_loss did not improve from 35.37322
Epoch 175/10000
4/4 - 0s - loss: 20.1689 - val_loss: 35.4467

Epoch 00175: val_loss did not improve from 35.37322
Epoch 176/10000
4/4 - 0s - loss: 20.1656 - val_loss: 35.4323

Epoch 00176: val_loss did not improve from 35.37322
Epoch 177/10000
4/4 - 0s - loss: 20.1670 - val_loss: 35.4340

Epoch 00177: val_loss did not improve from 35.37322
Epoch 178/10000
4/4 - 0s - loss: 20.1607 - val_loss: 35.4769

Epoch 00178: val_loss did not improve from 35.37322
Epoch 179/10000
4/4 - 0s - loss: 20.1635 - val_loss: 35.5100

Epoch 00179: val_loss did not improve from 35.37322
Epoch 180/10000
4/4 - 0s - loss: 20.1710 - val_loss: 35.4752

Epoch 00180: val_loss did not improve from 35.37322
Epoch 181/10000
4/4 - 0s - loss: 20.1625 - val_loss: 35.4237

Epoch 00181: val_loss did not improve from 35.37322
Epoch 182/10000
4/4 - 0s - loss: 20.1705 - val_loss: 35.4417

Epoch 00182: val_loss did not improve from 35.37322
Epoch 183/10000
4/4 - 0s - loss: 20.1637 - val_loss: 35.4750

Epoch 00183: val_loss did not improve from 35.37322
Epoch 184/10000
4/4 - 0s - loss: 20.1686 - val_loss: 35.4703

Epoch 00184: val_loss did not improve from 35.37322
Epoch 185/10000
4/4 - 0s - loss: 20.1737 - val_loss: 35.4367

Epoch 00185: val_loss did not improve from 35.37322
Epoch 186/10000
4/4 - 0s - loss: 20.1746 - val_loss: 35.4939

Epoch 00186: val_loss did not improve from 35.37322
Epoch 187/10000
4/4 - 0s - loss: 20.1671 - val_loss: 35.4521

Epoch 00187: val_loss did not improve from 35.37322
Epoch 188/10000
4/4 - 0s - loss: 20.1667 - val_loss: 35.4493

Epoch 00188: val_loss did not improve from 35.37322
Epoch 189/10000
4/4 - 0s - loss: 20.1670 - val_loss: 35.4834

Epoch 00189: val_loss did not improve from 35.37322
Epoch 190/10000
4/4 - 0s - loss: 20.1669 - val_loss: 35.4430

Epoch 00190: val_loss did not improve from 35.37322
Epoch 191/10000
4/4 - 0s - loss: 20.1696 - val_loss: 35.4612

Epoch 00191: val_loss did not improve from 35.37322
Epoch 192/10000
4/4 - 0s - loss: 20.1647 - val_loss: 35.4461

Epoch 00192: val_loss did not improve from 35.37322
Epoch 193/10000
4/4 - 0s - loss: 20.1646 - val_loss: 35.4662

Epoch 00193: val_loss did not improve from 35.37322
Epoch 194/10000
4/4 - 0s - loss: 20.1704 - val_loss: 35.5001

Epoch 00194: val_loss did not improve from 35.37322
Epoch 195/10000
4/4 - 0s - loss: 20.1634 - val_loss: 35.4481

Epoch 00195: val_loss did not improve from 35.37322
Epoch 196/10000
4/4 - 0s - loss: 20.1651 - val_loss: 35.4236

Epoch 00196: val_loss did not improve from 35.37322
Epoch 197/10000
4/4 - 0s - loss: 20.1784 - val_loss: 35.4169

Epoch 00197: val_loss did not improve from 35.37322
Epoch 198/10000
4/4 - 0s - loss: 20.1818 - val_loss: 35.4835

Epoch 00198: val_loss did not improve from 35.37322
Epoch 199/10000
4/4 - 0s - loss: 20.1638 - val_loss: 35.4778

Epoch 00199: val_loss did not improve from 35.37322
Epoch 200/10000
4/4 - 0s - loss: 20.1651 - val_loss: 35.4604

Epoch 00200: val_loss did not improve from 35.37322
Epoch 201/10000
4/4 - 0s - loss: 20.1653 - val_loss: 35.4484

Epoch 00201: val_loss did not improve from 35.37322
Epoch 202/10000
4/4 - 0s - loss: 20.1723 - val_loss: 35.4967

Epoch 00202: val_loss did not improve from 35.37322
Epoch 203/10000
4/4 - 0s - loss: 20.1686 - val_loss: 35.4662

Epoch 00203: val_loss did not improve from 35.37322
Epoch 204/10000
4/4 - 0s - loss: 20.1588 - val_loss: 35.4198

Epoch 00204: val_loss did not improve from 35.37322
Epoch 205/10000
4/4 - 0s - loss: 20.1790 - val_loss: 35.4304

Epoch 00205: val_loss did not improve from 35.37322
Epoch 206/10000
4/4 - 0s - loss: 20.1771 - val_loss: 35.5488

Epoch 00206: val_loss did not improve from 35.37322
Epoch 207/10000
4/4 - 0s - loss: 20.1929 - val_loss: 35.5190

Epoch 00207: val_loss did not improve from 35.37322
Epoch 208/10000
4/4 - 0s - loss: 20.1702 - val_loss: 35.4084

Epoch 00208: val_loss did not improve from 35.37322
Epoch 209/10000
4/4 - 0s - loss: 20.1810 - val_loss: 35.4322

Epoch 00209: val_loss did not improve from 35.37322
Epoch 210/10000
4/4 - 0s - loss: 20.1968 - val_loss: 35.5037

Epoch 00210: val_loss did not improve from 35.37322
Epoch 211/10000
4/4 - 0s - loss: 20.1668 - val_loss: 35.4470

Epoch 00211: val_loss did not improve from 35.37322
Epoch 212/10000
4/4 - 0s - loss: 20.1625 - val_loss: 35.4406

Epoch 00212: val_loss did not improve from 35.37322
Epoch 213/10000
4/4 - 0s - loss: 20.1662 - val_loss: 35.4532

Epoch 00213: val_loss did not improve from 35.37322
Epoch 214/10000
4/4 - 0s - loss: 20.1637 - val_loss: 35.4554

Epoch 00214: val_loss did not improve from 35.37322
Epoch 215/10000
4/4 - 0s - loss: 20.1683 - val_loss: 35.4684

Epoch 00215: val_loss did not improve from 35.37322
Epoch 216/10000
4/4 - 0s - loss: 20.1626 - val_loss: 35.4395

Epoch 00216: val_loss did not improve from 35.37322
Epoch 217/10000
4/4 - 0s - loss: 20.1638 - val_loss: 35.4552

Epoch 00217: val_loss did not improve from 35.37322
Epoch 218/10000
4/4 - 0s - loss: 20.1604 - val_loss: 35.4840

Epoch 00218: val_loss did not improve from 35.37322
Epoch 219/10000
4/4 - 0s - loss: 20.1719 - val_loss: 35.5218

Epoch 00219: val_loss did not improve from 35.37322
Epoch 220/10000
4/4 - 0s - loss: 20.1648 - val_loss: 35.4426

Epoch 00220: val_loss did not improve from 35.37322
Epoch 221/10000
4/4 - 0s - loss: 20.1837 - val_loss: 35.4103

Epoch 00221: val_loss did not improve from 35.37322
Epoch 222/10000
4/4 - 0s - loss: 20.1788 - val_loss: 35.4385

Epoch 00222: val_loss did not improve from 35.37322
Epoch 223/10000
4/4 - 0s - loss: 20.1652 - val_loss: 35.5292

Epoch 00223: val_loss did not improve from 35.37322
Epoch 224/10000
4/4 - 0s - loss: 20.1747 - val_loss: 35.4793

Epoch 00224: val_loss did not improve from 35.37322
Epoch 225/10000
4/4 - 0s - loss: 20.1906 - val_loss: 35.4049

Epoch 00225: val_loss did not improve from 35.37322
Epoch 226/10000
4/4 - 0s - loss: 20.1726 - val_loss: 35.4676

Epoch 00226: val_loss did not improve from 35.37322
Epoch 227/10000
4/4 - 0s - loss: 20.1934 - val_loss: 35.5878

Epoch 00227: val_loss did not improve from 35.37322
Epoch 228/10000
4/4 - 0s - loss: 20.2010 - val_loss: 35.4692

Epoch 00228: val_loss did not improve from 35.37322
Epoch 229/10000
4/4 - 0s - loss: 20.1708 - val_loss: 35.4418

Epoch 00229: val_loss did not improve from 35.37322
Epoch 230/10000
4/4 - 0s - loss: 20.1793 - val_loss: 35.5024

Epoch 00230: val_loss did not improve from 35.37322
Epoch 231/10000
4/4 - 0s - loss: 20.1673 - val_loss: 35.4506

Epoch 00231: val_loss did not improve from 35.37322
Epoch 232/10000
4/4 - 0s - loss: 20.1651 - val_loss: 35.4489

Epoch 00232: val_loss did not improve from 35.37322
Epoch 233/10000
4/4 - 0s - loss: 20.1746 - val_loss: 35.4285

Epoch 00233: val_loss did not improve from 35.37322
Epoch 234/10000
4/4 - 0s - loss: 20.1730 - val_loss: 35.5120

Epoch 00234: val_loss did not improve from 35.37322
Epoch 235/10000
4/4 - 0s - loss: 20.1717 - val_loss: 35.4841

Epoch 00235: val_loss did not improve from 35.37322
Epoch 236/10000
4/4 - 0s - loss: 20.1662 - val_loss: 35.4380

Epoch 00236: val_loss did not improve from 35.37322
Epoch 237/10000
4/4 - 0s - loss: 20.1660 - val_loss: 35.4535

Epoch 00237: val_loss did not improve from 35.37322
Epoch 238/10000
4/4 - 0s - loss: 20.1632 - val_loss: 35.4443

Epoch 00238: val_loss did not improve from 35.37322
Epoch 239/10000
4/4 - 0s - loss: 20.1636 - val_loss: 35.4641

Epoch 00239: val_loss did not improve from 35.37322
Epoch 240/10000
4/4 - 0s - loss: 20.1713 - val_loss: 35.4759

Epoch 00240: val_loss did not improve from 35.37322
Epoch 241/10000
4/4 - 0s - loss: 20.1644 - val_loss: 35.4174

Epoch 00241: val_loss did not improve from 35.37322
Epoch 242/10000
4/4 - 0s - loss: 20.1772 - val_loss: 35.4319

Epoch 00242: val_loss did not improve from 35.37322
Epoch 243/10000
4/4 - 0s - loss: 20.1745 - val_loss: 35.5127

Epoch 00243: val_loss did not improve from 35.37322
Epoch 244/10000
4/4 - 0s - loss: 20.1727 - val_loss: 35.4719

Epoch 00244: val_loss did not improve from 35.37322
Epoch 245/10000
4/4 - 0s - loss: 20.1650 - val_loss: 35.4566

Epoch 00245: val_loss did not improve from 35.37322
Epoch 246/10000
4/4 - 0s - loss: 20.1630 - val_loss: 35.4701

Epoch 00246: val_loss did not improve from 35.37322
Epoch 247/10000
4/4 - 0s - loss: 20.1662 - val_loss: 35.4730

Epoch 00247: val_loss did not improve from 35.37322
Epoch 248/10000
4/4 - 0s - loss: 20.1664 - val_loss: 35.4678

Epoch 00248: val_loss did not improve from 35.37322
Epoch 249/10000
4/4 - 0s - loss: 20.1661 - val_loss: 35.4733

Epoch 00249: val_loss did not improve from 35.37322
Epoch 250/10000
4/4 - 0s - loss: 20.1717 - val_loss: 35.4271

Epoch 00250: val_loss did not improve from 35.37322
Epoch 251/10000
4/4 - 0s - loss: 20.1717 - val_loss: 35.4757

Epoch 00251: val_loss did not improve from 35.37322
Epoch 252/10000
4/4 - 0s - loss: 20.1699 - val_loss: 35.4619

Epoch 00252: val_loss did not improve from 35.37322
Epoch 253/10000
4/4 - 0s - loss: 20.1627 - val_loss: 35.4467

Epoch 00253: val_loss did not improve from 35.37322
Epoch 254/10000
4/4 - 0s - loss: 20.1775 - val_loss: 35.4583

Epoch 00254: val_loss did not improve from 35.37322
Epoch 255/10000
4/4 - 0s - loss: 20.1781 - val_loss: 35.4133

Epoch 00255: val_loss did not improve from 35.37322
Epoch 256/10000
4/4 - 0s - loss: 20.1736 - val_loss: 35.5003

Epoch 00256: val_loss did not improve from 35.37322
Epoch 257/10000
4/4 - 0s - loss: 20.1693 - val_loss: 35.4895

Epoch 00257: val_loss did not improve from 35.37322
Epoch 00257: early stopping
*************************** Fold #: 2 ***************************
Model: "sequential_21"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_231 (Dense)            (None, 30)                150       
_________________________________________________________________
dense_232 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_233 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_234 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_235 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_236 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_237 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_238 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_239 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_240 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_241 (Dense)            (None, 1)                 31        
=================================================================
Total params: 8,551
Trainable params: 8,551
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
4/4 - 0s - loss: 31.6862 - val_loss: 27.9803

Epoch 00001: val_loss improved from inf to 27.98025, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 2/10000
4/4 - 0s - loss: 31.6466 - val_loss: 27.9348

Epoch 00002: val_loss improved from 27.98025 to 27.93483, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 3/10000
4/4 - 0s - loss: 31.6009 - val_loss: 27.8835

Epoch 00003: val_loss improved from 27.93483 to 27.88352, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 4/10000
4/4 - 0s - loss: 31.5496 - val_loss: 27.8248

Epoch 00004: val_loss improved from 27.88352 to 27.82476, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 5/10000
4/4 - 0s - loss: 31.4895 - val_loss: 27.7563

Epoch 00005: val_loss improved from 27.82476 to 27.75630, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 6/10000
4/4 - 0s - loss: 31.4206 - val_loss: 27.6750

Epoch 00006: val_loss improved from 27.75630 to 27.67500, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 7/10000
4/4 - 0s - loss: 31.3375 - val_loss: 27.5767

Epoch 00007: val_loss improved from 27.67500 to 27.57671, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 8/10000
4/4 - 0s - loss: 31.2355 - val_loss: 27.4557

Epoch 00008: val_loss improved from 27.57671 to 27.45572, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 9/10000
4/4 - 0s - loss: 31.1107 - val_loss: 27.3022

Epoch 00009: val_loss improved from 27.45572 to 27.30218, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 10/10000
4/4 - 0s - loss: 30.9537 - val_loss: 27.0998

Epoch 00010: val_loss improved from 27.30218 to 27.09981, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 11/10000
4/4 - 0s - loss: 30.7377 - val_loss: 26.8215

Epoch 00011: val_loss improved from 27.09981 to 26.82147, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 12/10000
4/4 - 0s - loss: 30.4310 - val_loss: 26.4184

Epoch 00012: val_loss improved from 26.82147 to 26.41843, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 13/10000
4/4 - 0s - loss: 29.9856 - val_loss: 25.8039

Epoch 00013: val_loss improved from 26.41843 to 25.80388, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 14/10000
4/4 - 0s - loss: 29.2940 - val_loss: 24.8277

Epoch 00014: val_loss improved from 25.80388 to 24.82770, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 15/10000
4/4 - 0s - loss: 28.2493 - val_loss: 23.2664

Epoch 00015: val_loss improved from 24.82770 to 23.26640, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 16/10000
4/4 - 0s - loss: 26.5471 - val_loss: 20.9762

Epoch 00016: val_loss improved from 23.26640 to 20.97623, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 17/10000
4/4 - 0s - loss: 24.3953 - val_loss: 18.9990

Epoch 00017: val_loss improved from 20.97623 to 18.99897, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 18/10000
4/4 - 0s - loss: 23.5477 - val_loss: 19.4543

Epoch 00018: val_loss did not improve from 18.99897
Epoch 19/10000
4/4 - 0s - loss: 23.8666 - val_loss: 18.7874

Epoch 00019: val_loss improved from 18.99897 to 18.78744, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 20/10000
4/4 - 0s - loss: 23.2568 - val_loss: 18.9220

Epoch 00020: val_loss did not improve from 18.78744
Epoch 21/10000
4/4 - 0s - loss: 23.3349 - val_loss: 18.9955

Epoch 00021: val_loss did not improve from 18.78744
Epoch 22/10000
4/4 - 0s - loss: 23.2903 - val_loss: 18.6643

Epoch 00022: val_loss improved from 18.78744 to 18.66431, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 23/10000
4/4 - 0s - loss: 23.0640 - val_loss: 18.3499

Epoch 00023: val_loss improved from 18.66431 to 18.34993, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 24/10000
4/4 - 0s - loss: 22.9914 - val_loss: 18.2321

Epoch 00024: val_loss improved from 18.34993 to 18.23212, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 25/10000
4/4 - 0s - loss: 22.9531 - val_loss: 18.1241

Epoch 00025: val_loss improved from 18.23212 to 18.12412, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 26/10000
4/4 - 0s - loss: 22.8523 - val_loss: 18.1217

Epoch 00026: val_loss improved from 18.12412 to 18.12168, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 27/10000
4/4 - 0s - loss: 22.8028 - val_loss: 18.0312

Epoch 00027: val_loss improved from 18.12168 to 18.03123, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 28/10000
4/4 - 0s - loss: 22.7494 - val_loss: 17.8644

Epoch 00028: val_loss improved from 18.03123 to 17.86440, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 29/10000
4/4 - 0s - loss: 22.6885 - val_loss: 17.7143

Epoch 00029: val_loss improved from 17.86440 to 17.71433, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 30/10000
4/4 - 0s - loss: 22.6492 - val_loss: 17.6392

Epoch 00030: val_loss improved from 17.71433 to 17.63924, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 31/10000
4/4 - 0s - loss: 22.6134 - val_loss: 17.5633

Epoch 00031: val_loss improved from 17.63924 to 17.56329, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 32/10000
4/4 - 0s - loss: 22.5727 - val_loss: 17.5289

Epoch 00032: val_loss improved from 17.56329 to 17.52886, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 33/10000
4/4 - 0s - loss: 22.5529 - val_loss: 17.4818

Epoch 00033: val_loss improved from 17.52886 to 17.48183, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 34/10000
4/4 - 0s - loss: 22.5331 - val_loss: 17.3706

Epoch 00034: val_loss improved from 17.48183 to 17.37061, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 35/10000
4/4 - 0s - loss: 22.5039 - val_loss: 17.3287

Epoch 00035: val_loss improved from 17.37061 to 17.32873, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 36/10000
4/4 - 0s - loss: 22.4844 - val_loss: 17.2902

Epoch 00036: val_loss improved from 17.32873 to 17.29021, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 37/10000
4/4 - 0s - loss: 22.4625 - val_loss: 17.2885

Epoch 00037: val_loss improved from 17.29021 to 17.28852, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 38/10000
4/4 - 0s - loss: 22.4476 - val_loss: 17.2486

Epoch 00038: val_loss improved from 17.28852 to 17.24863, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 39/10000
4/4 - 0s - loss: 22.4327 - val_loss: 17.1310

Epoch 00039: val_loss improved from 17.24863 to 17.13103, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 40/10000
4/4 - 0s - loss: 22.4080 - val_loss: 17.0990

Epoch 00040: val_loss improved from 17.13103 to 17.09897, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 41/10000
4/4 - 0s - loss: 22.3934 - val_loss: 17.0802

Epoch 00041: val_loss improved from 17.09897 to 17.08022, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 42/10000
4/4 - 0s - loss: 22.3788 - val_loss: 17.0423

Epoch 00042: val_loss improved from 17.08022 to 17.04229, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 43/10000
4/4 - 0s - loss: 22.3631 - val_loss: 16.9670

Epoch 00043: val_loss improved from 17.04229 to 16.96704, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 44/10000
4/4 - 0s - loss: 22.3555 - val_loss: 16.9466

Epoch 00044: val_loss improved from 16.96704 to 16.94658, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 45/10000
4/4 - 0s - loss: 22.3394 - val_loss: 16.9611

Epoch 00045: val_loss did not improve from 16.94658
Epoch 46/10000
4/4 - 0s - loss: 22.3281 - val_loss: 17.0001

Epoch 00046: val_loss did not improve from 16.94658
Epoch 47/10000
4/4 - 0s - loss: 22.3338 - val_loss: 16.9572

Epoch 00047: val_loss did not improve from 16.94658
Epoch 48/10000
4/4 - 0s - loss: 22.3106 - val_loss: 16.8458

Epoch 00048: val_loss improved from 16.94658 to 16.84576, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 49/10000
4/4 - 0s - loss: 22.3065 - val_loss: 16.7634

Epoch 00049: val_loss improved from 16.84576 to 16.76340, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 50/10000
4/4 - 0s - loss: 22.3192 - val_loss: 16.7584

Epoch 00050: val_loss improved from 16.76340 to 16.75844, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 51/10000
4/4 - 0s - loss: 22.2905 - val_loss: 16.8563

Epoch 00051: val_loss did not improve from 16.75844
Epoch 52/10000
4/4 - 0s - loss: 22.3033 - val_loss: 16.8664

Epoch 00052: val_loss did not improve from 16.75844
Epoch 53/10000
4/4 - 0s - loss: 22.2988 - val_loss: 16.7146

Epoch 00053: val_loss improved from 16.75844 to 16.71456, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 54/10000
4/4 - 0s - loss: 22.2829 - val_loss: 16.7305

Epoch 00054: val_loss did not improve from 16.71456
Epoch 55/10000
4/4 - 0s - loss: 22.2770 - val_loss: 16.7760

Epoch 00055: val_loss did not improve from 16.71456
Epoch 56/10000
4/4 - 0s - loss: 22.2804 - val_loss: 16.7394

Epoch 00056: val_loss did not improve from 16.71456
Epoch 57/10000
4/4 - 0s - loss: 22.2791 - val_loss: 16.6187

Epoch 00057: val_loss improved from 16.71456 to 16.61871, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 58/10000
4/4 - 0s - loss: 22.2791 - val_loss: 16.6717

Epoch 00058: val_loss did not improve from 16.61871
Epoch 59/10000
4/4 - 0s - loss: 22.2645 - val_loss: 16.8098

Epoch 00059: val_loss did not improve from 16.61871
Epoch 60/10000
4/4 - 0s - loss: 22.2941 - val_loss: 16.7917

Epoch 00060: val_loss did not improve from 16.61871
Epoch 61/10000
4/4 - 0s - loss: 22.2662 - val_loss: 16.6624

Epoch 00061: val_loss did not improve from 16.61871
Epoch 62/10000
4/4 - 0s - loss: 22.2764 - val_loss: 16.5904

Epoch 00062: val_loss improved from 16.61871 to 16.59041, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 63/10000
4/4 - 0s - loss: 22.2810 - val_loss: 16.6655

Epoch 00063: val_loss did not improve from 16.59041
Epoch 64/10000
4/4 - 0s - loss: 22.2615 - val_loss: 16.7244

Epoch 00064: val_loss did not improve from 16.59041
Epoch 65/10000
4/4 - 0s - loss: 22.2820 - val_loss: 16.7609

Epoch 00065: val_loss did not improve from 16.59041
Epoch 66/10000
4/4 - 0s - loss: 22.2591 - val_loss: 16.6166

Epoch 00066: val_loss did not improve from 16.59041
Epoch 67/10000
4/4 - 0s - loss: 22.3480 - val_loss: 16.5392

Epoch 00067: val_loss improved from 16.59041 to 16.53920, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 68/10000
4/4 - 0s - loss: 22.3035 - val_loss: 16.7903

Epoch 00068: val_loss did not improve from 16.53920
Epoch 69/10000
4/4 - 0s - loss: 22.2957 - val_loss: 16.8115

Epoch 00069: val_loss did not improve from 16.53920
Epoch 70/10000
4/4 - 0s - loss: 22.2696 - val_loss: 16.6511

Epoch 00070: val_loss did not improve from 16.53920
Epoch 71/10000
4/4 - 0s - loss: 22.2970 - val_loss: 16.5764

Epoch 00071: val_loss did not improve from 16.53920
Epoch 72/10000
4/4 - 0s - loss: 22.2619 - val_loss: 16.6917

Epoch 00072: val_loss did not improve from 16.53920
Epoch 73/10000
4/4 - 0s - loss: 22.2642 - val_loss: 16.7888

Epoch 00073: val_loss did not improve from 16.53920
Epoch 74/10000
4/4 - 0s - loss: 22.2810 - val_loss: 16.6927

Epoch 00074: val_loss did not improve from 16.53920
Epoch 75/10000
4/4 - 0s - loss: 22.2633 - val_loss: 16.6117

Epoch 00075: val_loss did not improve from 16.53920
Epoch 76/10000
4/4 - 0s - loss: 22.2647 - val_loss: 16.5993

Epoch 00076: val_loss did not improve from 16.53920
Epoch 77/10000
4/4 - 0s - loss: 22.2674 - val_loss: 16.6299

Epoch 00077: val_loss did not improve from 16.53920
Epoch 78/10000
4/4 - 0s - loss: 22.2609 - val_loss: 16.7797

Epoch 00078: val_loss did not improve from 16.53920
Epoch 79/10000
4/4 - 0s - loss: 22.2833 - val_loss: 16.6753

Epoch 00079: val_loss did not improve from 16.53920
Epoch 80/10000
4/4 - 0s - loss: 22.2588 - val_loss: 16.6755

Epoch 00080: val_loss did not improve from 16.53920
Epoch 81/10000
4/4 - 0s - loss: 22.2590 - val_loss: 16.6503

Epoch 00081: val_loss did not improve from 16.53920
Epoch 82/10000
4/4 - 0s - loss: 22.2598 - val_loss: 16.5873

Epoch 00082: val_loss did not improve from 16.53920
Epoch 83/10000
4/4 - 0s - loss: 22.2645 - val_loss: 16.6183

Epoch 00083: val_loss did not improve from 16.53920
Epoch 84/10000
4/4 - 0s - loss: 22.2589 - val_loss: 16.6374

Epoch 00084: val_loss did not improve from 16.53920
Epoch 85/10000
4/4 - 0s - loss: 22.2599 - val_loss: 16.6374

Epoch 00085: val_loss did not improve from 16.53920
Epoch 86/10000
4/4 - 0s - loss: 22.2741 - val_loss: 16.5690

Epoch 00086: val_loss did not improve from 16.53920
Epoch 87/10000
4/4 - 0s - loss: 22.2620 - val_loss: 16.6601

Epoch 00087: val_loss did not improve from 16.53920
Epoch 88/10000
4/4 - 0s - loss: 22.2692 - val_loss: 16.6838

Epoch 00088: val_loss did not improve from 16.53920
Epoch 89/10000
4/4 - 0s - loss: 22.2555 - val_loss: 16.5902

Epoch 00089: val_loss did not improve from 16.53920
Epoch 90/10000
4/4 - 0s - loss: 22.2919 - val_loss: 16.5284

Epoch 00090: val_loss improved from 16.53920 to 16.52838, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 91/10000
4/4 - 0s - loss: 22.3023 - val_loss: 16.7179

Epoch 00091: val_loss did not improve from 16.52838
Epoch 92/10000
4/4 - 0s - loss: 22.2818 - val_loss: 16.7510

Epoch 00092: val_loss did not improve from 16.52838
Epoch 93/10000
4/4 - 0s - loss: 22.2644 - val_loss: 16.5879

Epoch 00093: val_loss did not improve from 16.52838
Epoch 94/10000
4/4 - 0s - loss: 22.2679 - val_loss: 16.5778

Epoch 00094: val_loss did not improve from 16.52838
Epoch 95/10000
4/4 - 0s - loss: 22.2782 - val_loss: 16.6314

Epoch 00095: val_loss did not improve from 16.52838
Epoch 96/10000
4/4 - 0s - loss: 22.2652 - val_loss: 16.6114

Epoch 00096: val_loss did not improve from 16.52838
Epoch 97/10000
4/4 - 0s - loss: 22.2655 - val_loss: 16.6854

Epoch 00097: val_loss did not improve from 16.52838
Epoch 98/10000
4/4 - 0s - loss: 22.2602 - val_loss: 16.6225

Epoch 00098: val_loss did not improve from 16.52838
Epoch 99/10000
4/4 - 0s - loss: 22.2561 - val_loss: 16.5759

Epoch 00099: val_loss did not improve from 16.52838
Epoch 100/10000
4/4 - 0s - loss: 22.2727 - val_loss: 16.6048

Epoch 00100: val_loss did not improve from 16.52838
Epoch 101/10000
4/4 - 0s - loss: 22.2624 - val_loss: 16.5628

Epoch 00101: val_loss did not improve from 16.52838
Epoch 102/10000
4/4 - 0s - loss: 22.2636 - val_loss: 16.5942

Epoch 00102: val_loss did not improve from 16.52838
Epoch 103/10000
4/4 - 0s - loss: 22.2629 - val_loss: 16.6702

Epoch 00103: val_loss did not improve from 16.52838
Epoch 104/10000
4/4 - 0s - loss: 22.2598 - val_loss: 16.6244

Epoch 00104: val_loss did not improve from 16.52838
Epoch 105/10000
4/4 - 0s - loss: 22.2598 - val_loss: 16.5678

Epoch 00105: val_loss did not improve from 16.52838
Epoch 106/10000
4/4 - 0s - loss: 22.2660 - val_loss: 16.5951

Epoch 00106: val_loss did not improve from 16.52838
Epoch 107/10000
4/4 - 0s - loss: 22.2553 - val_loss: 16.6840

Epoch 00107: val_loss did not improve from 16.52838
Epoch 108/10000
4/4 - 0s - loss: 22.2618 - val_loss: 16.6706

Epoch 00108: val_loss did not improve from 16.52838
Epoch 109/10000
4/4 - 0s - loss: 22.2590 - val_loss: 16.6356

Epoch 00109: val_loss did not improve from 16.52838
Epoch 110/10000
4/4 - 0s - loss: 22.2607 - val_loss: 16.6132

Epoch 00110: val_loss did not improve from 16.52838
Epoch 111/10000
4/4 - 0s - loss: 22.2647 - val_loss: 16.6561

Epoch 00111: val_loss did not improve from 16.52838
Epoch 112/10000
4/4 - 0s - loss: 22.2632 - val_loss: 16.6337

Epoch 00112: val_loss did not improve from 16.52838
Epoch 113/10000
4/4 - 0s - loss: 22.2592 - val_loss: 16.6035

Epoch 00113: val_loss did not improve from 16.52838
Epoch 114/10000
4/4 - 0s - loss: 22.2623 - val_loss: 16.5684

Epoch 00114: val_loss did not improve from 16.52838
Epoch 115/10000
4/4 - 0s - loss: 22.2617 - val_loss: 16.6298

Epoch 00115: val_loss did not improve from 16.52838
Epoch 116/10000
4/4 - 0s - loss: 22.2566 - val_loss: 16.6645

Epoch 00116: val_loss did not improve from 16.52838
Epoch 117/10000
4/4 - 0s - loss: 22.2626 - val_loss: 16.6863

Epoch 00117: val_loss did not improve from 16.52838
Epoch 118/10000
4/4 - 0s - loss: 22.2630 - val_loss: 16.6787

Epoch 00118: val_loss did not improve from 16.52838
Epoch 119/10000
4/4 - 0s - loss: 22.2693 - val_loss: 16.6837

Epoch 00119: val_loss did not improve from 16.52838
Epoch 120/10000
4/4 - 0s - loss: 22.2613 - val_loss: 16.5969

Epoch 00120: val_loss did not improve from 16.52838
Epoch 121/10000
4/4 - 0s - loss: 22.2612 - val_loss: 16.6055

Epoch 00121: val_loss did not improve from 16.52838
Epoch 122/10000
4/4 - 0s - loss: 22.2581 - val_loss: 16.6347

Epoch 00122: val_loss did not improve from 16.52838
Epoch 123/10000
4/4 - 0s - loss: 22.2581 - val_loss: 16.6600

Epoch 00123: val_loss did not improve from 16.52838
Epoch 124/10000
4/4 - 0s - loss: 22.2586 - val_loss: 16.6557

Epoch 00124: val_loss did not improve from 16.52838
Epoch 125/10000
4/4 - 0s - loss: 22.2594 - val_loss: 16.6537

Epoch 00125: val_loss did not improve from 16.52838
Epoch 126/10000
4/4 - 0s - loss: 22.2641 - val_loss: 16.6542

Epoch 00126: val_loss did not improve from 16.52838
Epoch 127/10000
4/4 - 0s - loss: 22.2758 - val_loss: 16.5734

Epoch 00127: val_loss did not improve from 16.52838
Epoch 128/10000
4/4 - 0s - loss: 22.2693 - val_loss: 16.6650

Epoch 00128: val_loss did not improve from 16.52838
Epoch 129/10000
4/4 - 0s - loss: 22.2599 - val_loss: 16.6881

Epoch 00129: val_loss did not improve from 16.52838
Epoch 130/10000
4/4 - 0s - loss: 22.2601 - val_loss: 16.6569

Epoch 00130: val_loss did not improve from 16.52838
Epoch 131/10000
4/4 - 0s - loss: 22.2609 - val_loss: 16.6047

Epoch 00131: val_loss did not improve from 16.52838
Epoch 132/10000
4/4 - 0s - loss: 22.2606 - val_loss: 16.6530

Epoch 00132: val_loss did not improve from 16.52838
Epoch 133/10000
4/4 - 0s - loss: 22.2652 - val_loss: 16.6761

Epoch 00133: val_loss did not improve from 16.52838
Epoch 134/10000
4/4 - 0s - loss: 22.2567 - val_loss: 16.6011

Epoch 00134: val_loss did not improve from 16.52838
Epoch 135/10000
4/4 - 0s - loss: 22.2647 - val_loss: 16.5903

Epoch 00135: val_loss did not improve from 16.52838
Epoch 136/10000
4/4 - 0s - loss: 22.2689 - val_loss: 16.6898

Epoch 00136: val_loss did not improve from 16.52838
Epoch 137/10000
4/4 - 0s - loss: 22.2643 - val_loss: 16.6482

Epoch 00137: val_loss did not improve from 16.52838
Epoch 138/10000
4/4 - 0s - loss: 22.2667 - val_loss: 16.5614

Epoch 00138: val_loss did not improve from 16.52838
Epoch 139/10000
4/4 - 0s - loss: 22.2677 - val_loss: 16.6337

Epoch 00139: val_loss did not improve from 16.52838
Epoch 140/10000
4/4 - 0s - loss: 22.2547 - val_loss: 16.7005

Epoch 00140: val_loss did not improve from 16.52838
Epoch 141/10000
4/4 - 0s - loss: 22.2689 - val_loss: 16.6966

Epoch 00141: val_loss did not improve from 16.52838
Epoch 142/10000
4/4 - 0s - loss: 22.2718 - val_loss: 16.6862

Epoch 00142: val_loss did not improve from 16.52838
Epoch 143/10000
4/4 - 0s - loss: 22.2572 - val_loss: 16.5815

Epoch 00143: val_loss did not improve from 16.52838
Epoch 144/10000
4/4 - 0s - loss: 22.2761 - val_loss: 16.5458

Epoch 00144: val_loss did not improve from 16.52838
Epoch 145/10000
4/4 - 0s - loss: 22.2587 - val_loss: 16.6559

Epoch 00145: val_loss did not improve from 16.52838
Epoch 146/10000
4/4 - 0s - loss: 22.3065 - val_loss: 16.8330

Epoch 00146: val_loss did not improve from 16.52838
Epoch 147/10000
4/4 - 0s - loss: 22.2831 - val_loss: 16.6278

Epoch 00147: val_loss did not improve from 16.52838
Epoch 148/10000
4/4 - 0s - loss: 22.2818 - val_loss: 16.5208

Epoch 00148: val_loss improved from 16.52838 to 16.52083, saving model to ./results/dataset/trial_3/ckpt_2
Epoch 149/10000
4/4 - 0s - loss: 22.2820 - val_loss: 16.6250

Epoch 00149: val_loss did not improve from 16.52083
Epoch 150/10000
4/4 - 0s - loss: 22.2629 - val_loss: 16.6935

Epoch 00150: val_loss did not improve from 16.52083
Epoch 151/10000
4/4 - 0s - loss: 22.2625 - val_loss: 16.6370

Epoch 00151: val_loss did not improve from 16.52083
Epoch 152/10000
4/4 - 0s - loss: 22.2623 - val_loss: 16.6119

Epoch 00152: val_loss did not improve from 16.52083
Epoch 153/10000
4/4 - 0s - loss: 22.2580 - val_loss: 16.5653

Epoch 00153: val_loss did not improve from 16.52083
Epoch 154/10000
4/4 - 0s - loss: 22.2646 - val_loss: 16.6204

Epoch 00154: val_loss did not improve from 16.52083
Epoch 155/10000
4/4 - 0s - loss: 22.2719 - val_loss: 16.7181

Epoch 00155: val_loss did not improve from 16.52083
Epoch 156/10000
4/4 - 0s - loss: 22.2641 - val_loss: 16.6184

Epoch 00156: val_loss did not improve from 16.52083
Epoch 157/10000
4/4 - 0s - loss: 22.2586 - val_loss: 16.5852

Epoch 00157: val_loss did not improve from 16.52083
Epoch 158/10000
4/4 - 0s - loss: 22.2650 - val_loss: 16.5645

Epoch 00158: val_loss did not improve from 16.52083
Epoch 159/10000
4/4 - 0s - loss: 22.2591 - val_loss: 16.6568

Epoch 00159: val_loss did not improve from 16.52083
Epoch 160/10000
4/4 - 0s - loss: 22.2602 - val_loss: 16.7218

Epoch 00160: val_loss did not improve from 16.52083
Epoch 161/10000
4/4 - 0s - loss: 22.2618 - val_loss: 16.6427

Epoch 00161: val_loss did not improve from 16.52083
Epoch 162/10000
4/4 - 0s - loss: 22.2557 - val_loss: 16.5731

Epoch 00162: val_loss did not improve from 16.52083
Epoch 163/10000
4/4 - 0s - loss: 22.2818 - val_loss: 16.5722

Epoch 00163: val_loss did not improve from 16.52083
Epoch 164/10000
4/4 - 0s - loss: 22.2642 - val_loss: 16.6228

Epoch 00164: val_loss did not improve from 16.52083
Epoch 165/10000
4/4 - 0s - loss: 22.2583 - val_loss: 16.7107

Epoch 00165: val_loss did not improve from 16.52083
Epoch 166/10000
4/4 - 0s - loss: 22.2727 - val_loss: 16.6686

Epoch 00166: val_loss did not improve from 16.52083
Epoch 167/10000
4/4 - 0s - loss: 22.2689 - val_loss: 16.6399

Epoch 00167: val_loss did not improve from 16.52083
Epoch 168/10000
4/4 - 0s - loss: 22.2652 - val_loss: 16.6871

Epoch 00168: val_loss did not improve from 16.52083
Epoch 169/10000
4/4 - 0s - loss: 22.2601 - val_loss: 16.6128

Epoch 00169: val_loss did not improve from 16.52083
Epoch 170/10000
4/4 - 0s - loss: 22.2598 - val_loss: 16.5846

Epoch 00170: val_loss did not improve from 16.52083
Epoch 171/10000
4/4 - 0s - loss: 22.2667 - val_loss: 16.6262

Epoch 00171: val_loss did not improve from 16.52083
Epoch 172/10000
4/4 - 0s - loss: 22.2559 - val_loss: 16.7399

Epoch 00172: val_loss did not improve from 16.52083
Epoch 173/10000
4/4 - 0s - loss: 22.2694 - val_loss: 16.6865

Epoch 00173: val_loss did not improve from 16.52083
Epoch 174/10000
4/4 - 0s - loss: 22.2565 - val_loss: 16.6153

Epoch 00174: val_loss did not improve from 16.52083
Epoch 175/10000
4/4 - 0s - loss: 22.2617 - val_loss: 16.6049

Epoch 00175: val_loss did not improve from 16.52083
Epoch 176/10000
4/4 - 0s - loss: 22.2600 - val_loss: 16.5989

Epoch 00176: val_loss did not improve from 16.52083
Epoch 177/10000
4/4 - 0s - loss: 22.2732 - val_loss: 16.6295

Epoch 00177: val_loss did not improve from 16.52083
Epoch 178/10000
4/4 - 0s - loss: 22.2600 - val_loss: 16.8255

Epoch 00178: val_loss did not improve from 16.52083
Epoch 179/10000
4/4 - 0s - loss: 22.3065 - val_loss: 16.7617

Epoch 00179: val_loss did not improve from 16.52083
Epoch 180/10000
4/4 - 0s - loss: 22.2469 - val_loss: 16.5735

Epoch 00180: val_loss did not improve from 16.52083
Epoch 181/10000
4/4 - 0s - loss: 22.2794 - val_loss: 16.5391

Epoch 00181: val_loss did not improve from 16.52083
Epoch 182/10000
4/4 - 0s - loss: 22.2749 - val_loss: 16.6517

Epoch 00182: val_loss did not improve from 16.52083
Epoch 183/10000
4/4 - 0s - loss: 22.2646 - val_loss: 16.7766

Epoch 00183: val_loss did not improve from 16.52083
Epoch 184/10000
4/4 - 0s - loss: 22.2832 - val_loss: 16.6987

Epoch 00184: val_loss did not improve from 16.52083
Epoch 185/10000
4/4 - 0s - loss: 22.2526 - val_loss: 16.5977

Epoch 00185: val_loss did not improve from 16.52083
Epoch 186/10000
4/4 - 0s - loss: 22.2851 - val_loss: 16.5415

Epoch 00186: val_loss did not improve from 16.52083
Epoch 187/10000
4/4 - 0s - loss: 22.2771 - val_loss: 16.7167

Epoch 00187: val_loss did not improve from 16.52083
Epoch 188/10000
4/4 - 0s - loss: 22.2681 - val_loss: 16.6861

Epoch 00188: val_loss did not improve from 16.52083
Epoch 189/10000
4/4 - 0s - loss: 22.2670 - val_loss: 16.6486

Epoch 00189: val_loss did not improve from 16.52083
Epoch 190/10000
4/4 - 0s - loss: 22.2614 - val_loss: 16.6408

Epoch 00190: val_loss did not improve from 16.52083
Epoch 191/10000
4/4 - 0s - loss: 22.2695 - val_loss: 16.6681

Epoch 00191: val_loss did not improve from 16.52083
Epoch 192/10000
4/4 - 0s - loss: 22.2565 - val_loss: 16.5629

Epoch 00192: val_loss did not improve from 16.52083
Epoch 193/10000
4/4 - 0s - loss: 22.2797 - val_loss: 16.5882

Epoch 00193: val_loss did not improve from 16.52083
Epoch 194/10000
4/4 - 0s - loss: 22.2602 - val_loss: 16.7318

Epoch 00194: val_loss did not improve from 16.52083
Epoch 195/10000
4/4 - 0s - loss: 22.2673 - val_loss: 16.7033

Epoch 00195: val_loss did not improve from 16.52083
Epoch 196/10000
4/4 - 0s - loss: 22.2576 - val_loss: 16.6019

Epoch 00196: val_loss did not improve from 16.52083
Epoch 197/10000
4/4 - 0s - loss: 22.2603 - val_loss: 16.5760

Epoch 00197: val_loss did not improve from 16.52083
Epoch 198/10000
4/4 - 0s - loss: 22.2641 - val_loss: 16.6546

Epoch 00198: val_loss did not improve from 16.52083
Epoch 199/10000
4/4 - 0s - loss: 22.2685 - val_loss: 16.7135

Epoch 00199: val_loss did not improve from 16.52083
Epoch 200/10000
4/4 - 0s - loss: 22.2752 - val_loss: 16.5963

Epoch 00200: val_loss did not improve from 16.52083
Epoch 201/10000
4/4 - 0s - loss: 22.2600 - val_loss: 16.6428

Epoch 00201: val_loss did not improve from 16.52083
Epoch 202/10000
4/4 - 0s - loss: 22.2697 - val_loss: 16.6856

Epoch 00202: val_loss did not improve from 16.52083
Epoch 203/10000
4/4 - 0s - loss: 22.2702 - val_loss: 16.6096

Epoch 00203: val_loss did not improve from 16.52083
Epoch 204/10000
4/4 - 0s - loss: 22.2586 - val_loss: 16.6751

Epoch 00204: val_loss did not improve from 16.52083
Epoch 205/10000
4/4 - 0s - loss: 22.2792 - val_loss: 16.7029

Epoch 00205: val_loss did not improve from 16.52083
Epoch 206/10000
4/4 - 0s - loss: 22.2638 - val_loss: 16.5344

Epoch 00206: val_loss did not improve from 16.52083
Epoch 207/10000
4/4 - 0s - loss: 22.2841 - val_loss: 16.5776

Epoch 00207: val_loss did not improve from 16.52083
Epoch 208/10000
4/4 - 0s - loss: 22.2763 - val_loss: 16.7629

Epoch 00208: val_loss did not improve from 16.52083
Epoch 209/10000
4/4 - 0s - loss: 22.2801 - val_loss: 16.6599

Epoch 00209: val_loss did not improve from 16.52083
Epoch 210/10000
4/4 - 0s - loss: 22.2645 - val_loss: 16.5719

Epoch 00210: val_loss did not improve from 16.52083
Epoch 211/10000
4/4 - 0s - loss: 22.2631 - val_loss: 16.6385

Epoch 00211: val_loss did not improve from 16.52083
Epoch 212/10000
4/4 - 0s - loss: 22.2710 - val_loss: 16.7450

Epoch 00212: val_loss did not improve from 16.52083
Epoch 213/10000
4/4 - 0s - loss: 22.2655 - val_loss: 16.6098

Epoch 00213: val_loss did not improve from 16.52083
Epoch 214/10000
4/4 - 0s - loss: 22.2601 - val_loss: 16.5859

Epoch 00214: val_loss did not improve from 16.52083
Epoch 215/10000
4/4 - 0s - loss: 22.2658 - val_loss: 16.6478

Epoch 00215: val_loss did not improve from 16.52083
Epoch 216/10000
4/4 - 0s - loss: 22.2613 - val_loss: 16.6282

Epoch 00216: val_loss did not improve from 16.52083
Epoch 217/10000
4/4 - 0s - loss: 22.2622 - val_loss: 16.6183

Epoch 00217: val_loss did not improve from 16.52083
Epoch 218/10000
4/4 - 0s - loss: 22.2710 - val_loss: 16.6869

Epoch 00218: val_loss did not improve from 16.52083
Epoch 219/10000
4/4 - 0s - loss: 22.2541 - val_loss: 16.5899

Epoch 00219: val_loss did not improve from 16.52083
Epoch 220/10000
4/4 - 0s - loss: 22.2638 - val_loss: 16.5409

Epoch 00220: val_loss did not improve from 16.52083
Epoch 221/10000
4/4 - 0s - loss: 22.2732 - val_loss: 16.6267

Epoch 00221: val_loss did not improve from 16.52083
Epoch 222/10000
4/4 - 0s - loss: 22.2694 - val_loss: 16.6338

Epoch 00222: val_loss did not improve from 16.52083
Epoch 223/10000
4/4 - 0s - loss: 22.2542 - val_loss: 16.7014

Epoch 00223: val_loss did not improve from 16.52083
Epoch 224/10000
4/4 - 0s - loss: 22.2675 - val_loss: 16.6851

Epoch 00224: val_loss did not improve from 16.52083
Epoch 225/10000
4/4 - 0s - loss: 22.2690 - val_loss: 16.6382

Epoch 00225: val_loss did not improve from 16.52083
Epoch 226/10000
4/4 - 0s - loss: 22.2584 - val_loss: 16.6513

Epoch 00226: val_loss did not improve from 16.52083
Epoch 227/10000
4/4 - 0s - loss: 22.2653 - val_loss: 16.6818

Epoch 00227: val_loss did not improve from 16.52083
Epoch 228/10000
4/4 - 0s - loss: 22.2575 - val_loss: 16.6196

Epoch 00228: val_loss did not improve from 16.52083
Epoch 229/10000
4/4 - 0s - loss: 22.2651 - val_loss: 16.5796

Epoch 00229: val_loss did not improve from 16.52083
Epoch 230/10000
4/4 - 0s - loss: 22.2647 - val_loss: 16.6140

Epoch 00230: val_loss did not improve from 16.52083
Epoch 231/10000
4/4 - 0s - loss: 22.2601 - val_loss: 16.6252

Epoch 00231: val_loss did not improve from 16.52083
Epoch 232/10000
4/4 - 0s - loss: 22.2574 - val_loss: 16.7123

Epoch 00232: val_loss did not improve from 16.52083
Epoch 233/10000
4/4 - 0s - loss: 22.2670 - val_loss: 16.6566

Epoch 00233: val_loss did not improve from 16.52083
Epoch 234/10000
4/4 - 0s - loss: 22.2659 - val_loss: 16.5375

Epoch 00234: val_loss did not improve from 16.52083
Epoch 235/10000
4/4 - 0s - loss: 22.2754 - val_loss: 16.5983

Epoch 00235: val_loss did not improve from 16.52083
Epoch 236/10000
4/4 - 0s - loss: 22.2578 - val_loss: 16.6513

Epoch 00236: val_loss did not improve from 16.52083
Epoch 237/10000
4/4 - 0s - loss: 22.2748 - val_loss: 16.7329

Epoch 00237: val_loss did not improve from 16.52083
Epoch 238/10000
4/4 - 0s - loss: 22.2659 - val_loss: 16.6356

Epoch 00238: val_loss did not improve from 16.52083
Epoch 239/10000
4/4 - 0s - loss: 22.2966 - val_loss: 16.5462

Epoch 00239: val_loss did not improve from 16.52083
Epoch 240/10000
4/4 - 0s - loss: 22.2543 - val_loss: 16.6903

Epoch 00240: val_loss did not improve from 16.52083
Epoch 241/10000
4/4 - 0s - loss: 22.2850 - val_loss: 16.8007

Epoch 00241: val_loss did not improve from 16.52083
Epoch 242/10000
4/4 - 0s - loss: 22.2729 - val_loss: 16.6302

Epoch 00242: val_loss did not improve from 16.52083
Epoch 243/10000
4/4 - 0s - loss: 22.2841 - val_loss: 16.5585

Epoch 00243: val_loss did not improve from 16.52083
Epoch 244/10000
4/4 - 0s - loss: 22.2560 - val_loss: 16.6856

Epoch 00244: val_loss did not improve from 16.52083
Epoch 245/10000
4/4 - 0s - loss: 22.3070 - val_loss: 16.8714

Epoch 00245: val_loss did not improve from 16.52083
Epoch 246/10000
4/4 - 0s - loss: 22.2881 - val_loss: 16.6565

Epoch 00246: val_loss did not improve from 16.52083
Epoch 247/10000
4/4 - 0s - loss: 22.2608 - val_loss: 16.5595

Epoch 00247: val_loss did not improve from 16.52083
Epoch 248/10000
4/4 - 0s - loss: 22.2734 - val_loss: 16.6294

Epoch 00248: val_loss did not improve from 16.52083
Epoch 249/10000
4/4 - 0s - loss: 22.2559 - val_loss: 16.7376

Epoch 00249: val_loss did not improve from 16.52083
Epoch 250/10000
4/4 - 0s - loss: 22.2756 - val_loss: 16.7217

Epoch 00250: val_loss did not improve from 16.52083
Epoch 251/10000
4/4 - 0s - loss: 22.2743 - val_loss: 16.6224

Epoch 00251: val_loss did not improve from 16.52083
Epoch 252/10000
4/4 - 0s - loss: 22.2592 - val_loss: 16.6587

Epoch 00252: val_loss did not improve from 16.52083
Epoch 253/10000
4/4 - 0s - loss: 22.2598 - val_loss: 16.6695

Epoch 00253: val_loss did not improve from 16.52083
Epoch 254/10000
4/4 - 0s - loss: 22.2616 - val_loss: 16.7213

Epoch 00254: val_loss did not improve from 16.52083
Epoch 255/10000
4/4 - 0s - loss: 22.2657 - val_loss: 16.6656

Epoch 00255: val_loss did not improve from 16.52083
Epoch 256/10000
4/4 - 0s - loss: 22.2665 - val_loss: 16.5811

Epoch 00256: val_loss did not improve from 16.52083
Epoch 257/10000
4/4 - 0s - loss: 22.2616 - val_loss: 16.6448

Epoch 00257: val_loss did not improve from 16.52083
Epoch 258/10000
4/4 - 0s - loss: 22.2674 - val_loss: 16.7207

Epoch 00258: val_loss did not improve from 16.52083
Epoch 259/10000
4/4 - 0s - loss: 22.2637 - val_loss: 16.6099

Epoch 00259: val_loss did not improve from 16.52083
Epoch 260/10000
4/4 - 0s - loss: 22.2688 - val_loss: 16.5768

Epoch 00260: val_loss did not improve from 16.52083
Epoch 261/10000
4/4 - 0s - loss: 22.2669 - val_loss: 16.6333

Epoch 00261: val_loss did not improve from 16.52083
Epoch 262/10000
4/4 - 0s - loss: 22.2637 - val_loss: 16.6206

Epoch 00262: val_loss did not improve from 16.52083
Epoch 263/10000
4/4 - 0s - loss: 22.2574 - val_loss: 16.5851

Epoch 00263: val_loss did not improve from 16.52083
Epoch 264/10000
4/4 - 0s - loss: 22.2634 - val_loss: 16.5937

Epoch 00264: val_loss did not improve from 16.52083
Epoch 265/10000
4/4 - 0s - loss: 22.2591 - val_loss: 16.6562

Epoch 00265: val_loss did not improve from 16.52083
Epoch 266/10000
4/4 - 0s - loss: 22.2603 - val_loss: 16.6399

Epoch 00266: val_loss did not improve from 16.52083
Epoch 267/10000
4/4 - 0s - loss: 22.2571 - val_loss: 16.5848

Epoch 00267: val_loss did not improve from 16.52083
Epoch 268/10000
4/4 - 0s - loss: 22.2804 - val_loss: 16.5604

Epoch 00268: val_loss did not improve from 16.52083
Epoch 269/10000
4/4 - 0s - loss: 22.2609 - val_loss: 16.6866

Epoch 00269: val_loss did not improve from 16.52083
Epoch 270/10000
4/4 - 0s - loss: 22.2627 - val_loss: 16.6975

Epoch 00270: val_loss did not improve from 16.52083
Epoch 271/10000
4/4 - 0s - loss: 22.2654 - val_loss: 16.6446

Epoch 00271: val_loss did not improve from 16.52083
Epoch 272/10000
4/4 - 0s - loss: 22.2584 - val_loss: 16.6275

Epoch 00272: val_loss did not improve from 16.52083
Epoch 273/10000
4/4 - 0s - loss: 22.2594 - val_loss: 16.6482

Epoch 00273: val_loss did not improve from 16.52083
Epoch 274/10000
4/4 - 0s - loss: 22.2574 - val_loss: 16.6277

Epoch 00274: val_loss did not improve from 16.52083
Epoch 275/10000
4/4 - 0s - loss: 22.2614 - val_loss: 16.6346

Epoch 00275: val_loss did not improve from 16.52083
Epoch 276/10000
4/4 - 0s - loss: 22.2727 - val_loss: 16.7084

Epoch 00276: val_loss did not improve from 16.52083
Epoch 277/10000
4/4 - 0s - loss: 22.2585 - val_loss: 16.6277

Epoch 00277: val_loss did not improve from 16.52083
Epoch 278/10000
4/4 - 0s - loss: 22.2662 - val_loss: 16.5584

Epoch 00278: val_loss did not improve from 16.52083
Epoch 279/10000
4/4 - 0s - loss: 22.2692 - val_loss: 16.6690

Epoch 00279: val_loss did not improve from 16.52083
Epoch 280/10000
4/4 - 0s - loss: 22.2697 - val_loss: 16.6815

Epoch 00280: val_loss did not improve from 16.52083
Epoch 281/10000
4/4 - 0s - loss: 22.2632 - val_loss: 16.6490

Epoch 00281: val_loss did not improve from 16.52083
Epoch 282/10000
4/4 - 0s - loss: 22.2651 - val_loss: 16.6564

Epoch 00282: val_loss did not improve from 16.52083
Epoch 283/10000
4/4 - 0s - loss: 22.2610 - val_loss: 16.5723

Epoch 00283: val_loss did not improve from 16.52083
Epoch 284/10000
4/4 - 0s - loss: 22.2618 - val_loss: 16.6151

Epoch 00284: val_loss did not improve from 16.52083
Epoch 285/10000
4/4 - 0s - loss: 22.2552 - val_loss: 16.6881

Epoch 00285: val_loss did not improve from 16.52083
Epoch 286/10000
4/4 - 0s - loss: 22.2638 - val_loss: 16.6831

Epoch 00286: val_loss did not improve from 16.52083
Epoch 287/10000
4/4 - 0s - loss: 22.2809 - val_loss: 16.5838

Epoch 00287: val_loss did not improve from 16.52083
Epoch 288/10000
4/4 - 0s - loss: 22.2630 - val_loss: 16.6455

Epoch 00288: val_loss did not improve from 16.52083
Epoch 289/10000
4/4 - 0s - loss: 22.2649 - val_loss: 16.7117

Epoch 00289: val_loss did not improve from 16.52083
Epoch 290/10000
4/4 - 0s - loss: 22.2594 - val_loss: 16.6325

Epoch 00290: val_loss did not improve from 16.52083
Epoch 291/10000
4/4 - 0s - loss: 22.2548 - val_loss: 16.5895

Epoch 00291: val_loss did not improve from 16.52083
Epoch 292/10000
4/4 - 0s - loss: 22.2678 - val_loss: 16.5883

Epoch 00292: val_loss did not improve from 16.52083
Epoch 293/10000
4/4 - 0s - loss: 22.2673 - val_loss: 16.6910

Epoch 00293: val_loss did not improve from 16.52083
Epoch 294/10000
4/4 - 0s - loss: 22.2658 - val_loss: 16.6307

Epoch 00294: val_loss did not improve from 16.52083
Epoch 295/10000
4/4 - 0s - loss: 22.2624 - val_loss: 16.6050

Epoch 00295: val_loss did not improve from 16.52083
Epoch 296/10000
4/4 - 0s - loss: 22.2621 - val_loss: 16.5915

Epoch 00296: val_loss did not improve from 16.52083
Epoch 297/10000
4/4 - 0s - loss: 22.2606 - val_loss: 16.6821

Epoch 00297: val_loss did not improve from 16.52083
Epoch 298/10000
4/4 - 0s - loss: 22.2636 - val_loss: 16.6625

Epoch 00298: val_loss did not improve from 16.52083
Epoch 299/10000
4/4 - 0s - loss: 22.2678 - val_loss: 16.6317

Epoch 00299: val_loss did not improve from 16.52083
Epoch 300/10000
4/4 - 0s - loss: 22.2630 - val_loss: 16.6547

Epoch 00300: val_loss did not improve from 16.52083
Epoch 301/10000
4/4 - 0s - loss: 22.2634 - val_loss: 16.6478

Epoch 00301: val_loss did not improve from 16.52083
Epoch 302/10000
4/4 - 0s - loss: 22.2557 - val_loss: 16.7002

Epoch 00302: val_loss did not improve from 16.52083
Epoch 303/10000
4/4 - 0s - loss: 22.2618 - val_loss: 16.6925

Epoch 00303: val_loss did not improve from 16.52083
Epoch 304/10000
4/4 - 0s - loss: 22.2622 - val_loss: 16.6404

Epoch 00304: val_loss did not improve from 16.52083
Epoch 305/10000
4/4 - 0s - loss: 22.2596 - val_loss: 16.6433

Epoch 00305: val_loss did not improve from 16.52083
Epoch 306/10000
4/4 - 0s - loss: 22.2640 - val_loss: 16.6819

Epoch 00306: val_loss did not improve from 16.52083
Epoch 307/10000
4/4 - 0s - loss: 22.2591 - val_loss: 16.6133

Epoch 00307: val_loss did not improve from 16.52083
Epoch 308/10000
4/4 - 0s - loss: 22.2639 - val_loss: 16.5923

Epoch 00308: val_loss did not improve from 16.52083
Epoch 309/10000
4/4 - 0s - loss: 22.2556 - val_loss: 16.6792

Epoch 00309: val_loss did not improve from 16.52083
Epoch 310/10000
4/4 - 0s - loss: 22.2744 - val_loss: 16.7113

Epoch 00310: val_loss did not improve from 16.52083
Epoch 311/10000
4/4 - 0s - loss: 22.2671 - val_loss: 16.5732

Epoch 00311: val_loss did not improve from 16.52083
Epoch 312/10000
4/4 - 0s - loss: 22.2627 - val_loss: 16.5810

Epoch 00312: val_loss did not improve from 16.52083
Epoch 313/10000
4/4 - 0s - loss: 22.2614 - val_loss: 16.6379

Epoch 00313: val_loss did not improve from 16.52083
Epoch 314/10000
4/4 - 0s - loss: 22.2582 - val_loss: 16.6261

Epoch 00314: val_loss did not improve from 16.52083
Epoch 315/10000
4/4 - 0s - loss: 22.2714 - val_loss: 16.5857

Epoch 00315: val_loss did not improve from 16.52083
Epoch 316/10000
4/4 - 0s - loss: 22.2644 - val_loss: 16.6605

Epoch 00316: val_loss did not improve from 16.52083
Epoch 317/10000
4/4 - 0s - loss: 22.2620 - val_loss: 16.6374

Epoch 00317: val_loss did not improve from 16.52083
Epoch 318/10000
4/4 - 0s - loss: 22.2573 - val_loss: 16.6727

Epoch 00318: val_loss did not improve from 16.52083
Epoch 319/10000
4/4 - 0s - loss: 22.2598 - val_loss: 16.6503

Epoch 00319: val_loss did not improve from 16.52083
Epoch 320/10000
4/4 - 0s - loss: 22.2586 - val_loss: 16.6262

Epoch 00320: val_loss did not improve from 16.52083
Epoch 321/10000
4/4 - 0s - loss: 22.2701 - val_loss: 16.6132

Epoch 00321: val_loss did not improve from 16.52083
Epoch 322/10000
4/4 - 0s - loss: 22.2589 - val_loss: 16.5778

Epoch 00322: val_loss did not improve from 16.52083
Epoch 323/10000
4/4 - 0s - loss: 22.2610 - val_loss: 16.6253

Epoch 00323: val_loss did not improve from 16.52083
Epoch 324/10000
4/4 - 0s - loss: 22.2680 - val_loss: 16.6544

Epoch 00324: val_loss did not improve from 16.52083
Epoch 325/10000
4/4 - 0s - loss: 22.2570 - val_loss: 16.5890

Epoch 00325: val_loss did not improve from 16.52083
Epoch 326/10000
4/4 - 0s - loss: 22.2630 - val_loss: 16.5815

Epoch 00326: val_loss did not improve from 16.52083
Epoch 327/10000
4/4 - 0s - loss: 22.2713 - val_loss: 16.6239

Epoch 00327: val_loss did not improve from 16.52083
Epoch 328/10000
4/4 - 0s - loss: 22.2556 - val_loss: 16.5770

Epoch 00328: val_loss did not improve from 16.52083
Epoch 329/10000
4/4 - 0s - loss: 22.2621 - val_loss: 16.6085

Epoch 00329: val_loss did not improve from 16.52083
Epoch 330/10000
4/4 - 0s - loss: 22.2578 - val_loss: 16.6593

Epoch 00330: val_loss did not improve from 16.52083
Epoch 331/10000
4/4 - 0s - loss: 22.2569 - val_loss: 16.7032

Epoch 00331: val_loss did not improve from 16.52083
Epoch 332/10000
4/4 - 0s - loss: 22.2640 - val_loss: 16.6936

Epoch 00332: val_loss did not improve from 16.52083
Epoch 333/10000
4/4 - 0s - loss: 22.2600 - val_loss: 16.6681

Epoch 00333: val_loss did not improve from 16.52083
Epoch 334/10000
4/4 - 0s - loss: 22.2658 - val_loss: 16.6086

Epoch 00334: val_loss did not improve from 16.52083
Epoch 335/10000
4/4 - 0s - loss: 22.2680 - val_loss: 16.6501

Epoch 00335: val_loss did not improve from 16.52083
Epoch 336/10000
4/4 - 0s - loss: 22.2800 - val_loss: 16.8279

Epoch 00336: val_loss did not improve from 16.52083
Epoch 337/10000
4/4 - 0s - loss: 22.2992 - val_loss: 16.7378

Epoch 00337: val_loss did not improve from 16.52083
Epoch 338/10000
4/4 - 0s - loss: 22.2651 - val_loss: 16.6342

Epoch 00338: val_loss did not improve from 16.52083
Epoch 339/10000
4/4 - 0s - loss: 22.2602 - val_loss: 16.6307

Epoch 00339: val_loss did not improve from 16.52083
Epoch 340/10000
4/4 - 0s - loss: 22.2597 - val_loss: 16.6803

Epoch 00340: val_loss did not improve from 16.52083
Epoch 341/10000
4/4 - 0s - loss: 22.2608 - val_loss: 16.6932

Epoch 00341: val_loss did not improve from 16.52083
Epoch 342/10000
4/4 - 0s - loss: 22.2672 - val_loss: 16.6118

Epoch 00342: val_loss did not improve from 16.52083
Epoch 343/10000
4/4 - 0s - loss: 22.2566 - val_loss: 16.6705

Epoch 00343: val_loss did not improve from 16.52083
Epoch 344/10000
4/4 - 0s - loss: 22.2587 - val_loss: 16.6960

Epoch 00344: val_loss did not improve from 16.52083
Epoch 345/10000
4/4 - 0s - loss: 22.2631 - val_loss: 16.6427

Epoch 00345: val_loss did not improve from 16.52083
Epoch 346/10000
4/4 - 0s - loss: 22.2666 - val_loss: 16.6392

Epoch 00346: val_loss did not improve from 16.52083
Epoch 347/10000
4/4 - 0s - loss: 22.2789 - val_loss: 16.5686

Epoch 00347: val_loss did not improve from 16.52083
Epoch 348/10000
4/4 - 0s - loss: 22.2699 - val_loss: 16.7006

Epoch 00348: val_loss did not improve from 16.52083
Epoch 00348: early stopping
*************************** Fold #: 3 ***************************
Model: "sequential_22"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_242 (Dense)            (None, 30)                150       
_________________________________________________________________
dense_243 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_244 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_245 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_246 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_247 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_248 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_249 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_250 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_251 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_252 (Dense)            (None, 1)                 31        
=================================================================
Total params: 8,551
Trainable params: 8,551
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
4/4 - 0s - loss: 31.7937 - val_loss: 27.0133

Epoch 00001: val_loss improved from inf to 27.01335, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 2/10000
4/4 - 0s - loss: 31.7547 - val_loss: 26.9691

Epoch 00002: val_loss improved from 27.01335 to 26.96914, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 3/10000
4/4 - 0s - loss: 31.7097 - val_loss: 26.9184

Epoch 00003: val_loss improved from 26.96914 to 26.91839, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 4/10000
4/4 - 0s - loss: 31.6586 - val_loss: 26.8583

Epoch 00004: val_loss improved from 26.91839 to 26.85832, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 5/10000
4/4 - 0s - loss: 31.5973 - val_loss: 26.7847

Epoch 00005: val_loss improved from 26.85832 to 26.78466, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 6/10000
4/4 - 0s - loss: 31.5190 - val_loss: 26.6928

Epoch 00006: val_loss improved from 26.78466 to 26.69276, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 7/10000
4/4 - 0s - loss: 31.4238 - val_loss: 26.5741

Epoch 00007: val_loss improved from 26.69276 to 26.57407, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 8/10000
4/4 - 0s - loss: 31.2949 - val_loss: 26.4169

Epoch 00008: val_loss improved from 26.57407 to 26.41688, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 9/10000
4/4 - 0s - loss: 31.1321 - val_loss: 26.2021

Epoch 00009: val_loss improved from 26.41688 to 26.20205, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 10/10000
4/4 - 0s - loss: 30.8989 - val_loss: 25.9012

Epoch 00010: val_loss improved from 26.20205 to 25.90116, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 11/10000
4/4 - 0s - loss: 30.5704 - val_loss: 25.4659

Epoch 00011: val_loss improved from 25.90116 to 25.46585, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 12/10000
4/4 - 0s - loss: 30.0912 - val_loss: 24.8173

Epoch 00012: val_loss improved from 25.46585 to 24.81730, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 13/10000
4/4 - 0s - loss: 29.3830 - val_loss: 23.8268

Epoch 00013: val_loss improved from 24.81730 to 23.82677, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 14/10000
4/4 - 0s - loss: 28.2770 - val_loss: 22.3088

Epoch 00014: val_loss improved from 23.82677 to 22.30882, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 15/10000
4/4 - 0s - loss: 26.6969 - val_loss: 20.1450

Epoch 00015: val_loss improved from 22.30882 to 20.14501, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 16/10000
4/4 - 0s - loss: 24.5699 - val_loss: 18.0962

Epoch 00016: val_loss improved from 20.14501 to 18.09623, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 17/10000
4/4 - 0s - loss: 23.6856 - val_loss: 18.5029

Epoch 00017: val_loss did not improve from 18.09623
Epoch 18/10000
4/4 - 0s - loss: 24.0865 - val_loss: 17.8772

Epoch 00018: val_loss improved from 18.09623 to 17.87724, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 19/10000
4/4 - 0s - loss: 23.3667 - val_loss: 17.8576

Epoch 00019: val_loss improved from 17.87724 to 17.85764, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 20/10000
4/4 - 0s - loss: 23.3350 - val_loss: 17.9681

Epoch 00020: val_loss did not improve from 17.85764
Epoch 21/10000
4/4 - 0s - loss: 23.3555 - val_loss: 17.7993

Epoch 00021: val_loss improved from 17.85764 to 17.79926, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 22/10000
4/4 - 0s - loss: 23.1985 - val_loss: 17.4990

Epoch 00022: val_loss improved from 17.79926 to 17.49902, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 23/10000
4/4 - 0s - loss: 23.0171 - val_loss: 17.3328

Epoch 00023: val_loss improved from 17.49902 to 17.33279, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 24/10000
4/4 - 0s - loss: 23.0149 - val_loss: 17.2316

Epoch 00024: val_loss improved from 17.33279 to 17.23157, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 25/10000
4/4 - 0s - loss: 22.9593 - val_loss: 17.1519

Epoch 00025: val_loss improved from 17.23157 to 17.15195, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 26/10000
4/4 - 0s - loss: 22.8547 - val_loss: 17.1247

Epoch 00026: val_loss improved from 17.15195 to 17.12475, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 27/10000
4/4 - 0s - loss: 22.8027 - val_loss: 17.0865

Epoch 00027: val_loss improved from 17.12475 to 17.08645, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 28/10000
4/4 - 0s - loss: 22.7589 - val_loss: 16.9908

Epoch 00028: val_loss improved from 17.08645 to 16.99078, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 29/10000
4/4 - 0s - loss: 22.7042 - val_loss: 16.8470

Epoch 00029: val_loss improved from 16.99078 to 16.84704, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 30/10000
4/4 - 0s - loss: 22.6754 - val_loss: 16.7846

Epoch 00030: val_loss improved from 16.84704 to 16.78464, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 31/10000
4/4 - 0s - loss: 22.6318 - val_loss: 16.7922

Epoch 00031: val_loss did not improve from 16.78464
Epoch 32/10000
4/4 - 0s - loss: 22.5982 - val_loss: 16.8179

Epoch 00032: val_loss did not improve from 16.78464
Epoch 33/10000
4/4 - 0s - loss: 22.5804 - val_loss: 16.7435

Epoch 00033: val_loss improved from 16.78464 to 16.74354, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 34/10000
4/4 - 0s - loss: 22.5454 - val_loss: 16.6619

Epoch 00034: val_loss improved from 16.74354 to 16.66188, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 35/10000
4/4 - 0s - loss: 22.5250 - val_loss: 16.6249

Epoch 00035: val_loss improved from 16.66188 to 16.62492, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 36/10000
4/4 - 0s - loss: 22.5016 - val_loss: 16.6181

Epoch 00036: val_loss improved from 16.62492 to 16.61810, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 37/10000
4/4 - 0s - loss: 22.4826 - val_loss: 16.6496

Epoch 00037: val_loss did not improve from 16.61810
Epoch 38/10000
4/4 - 0s - loss: 22.4654 - val_loss: 16.6034

Epoch 00038: val_loss improved from 16.61810 to 16.60344, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 39/10000
4/4 - 0s - loss: 22.4383 - val_loss: 16.5920

Epoch 00039: val_loss improved from 16.60344 to 16.59197, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 40/10000
4/4 - 0s - loss: 22.4180 - val_loss: 16.5506

Epoch 00040: val_loss improved from 16.59197 to 16.55056, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 41/10000
4/4 - 0s - loss: 22.4243 - val_loss: 16.5132

Epoch 00041: val_loss improved from 16.55056 to 16.51321, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 42/10000
4/4 - 0s - loss: 22.3902 - val_loss: 16.5598

Epoch 00042: val_loss did not improve from 16.51321
Epoch 43/10000
4/4 - 0s - loss: 22.3812 - val_loss: 16.5870

Epoch 00043: val_loss did not improve from 16.51321
Epoch 44/10000
4/4 - 0s - loss: 22.3752 - val_loss: 16.5177

Epoch 00044: val_loss did not improve from 16.51321
Epoch 45/10000
4/4 - 0s - loss: 22.3504 - val_loss: 16.4884

Epoch 00045: val_loss improved from 16.51321 to 16.48837, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 46/10000
4/4 - 0s - loss: 22.3387 - val_loss: 16.5101

Epoch 00046: val_loss did not improve from 16.48837
Epoch 47/10000
4/4 - 0s - loss: 22.3359 - val_loss: 16.5177

Epoch 00047: val_loss did not improve from 16.48837
Epoch 48/10000
4/4 - 0s - loss: 22.3201 - val_loss: 16.4718

Epoch 00048: val_loss improved from 16.48837 to 16.47183, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 49/10000
4/4 - 0s - loss: 22.3128 - val_loss: 16.4598

Epoch 00049: val_loss improved from 16.47183 to 16.45981, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 50/10000
4/4 - 0s - loss: 22.3046 - val_loss: 16.4907

Epoch 00050: val_loss did not improve from 16.45981
Epoch 51/10000
4/4 - 0s - loss: 22.3047 - val_loss: 16.5135

Epoch 00051: val_loss did not improve from 16.45981
Epoch 52/10000
4/4 - 0s - loss: 22.2985 - val_loss: 16.4832

Epoch 00052: val_loss did not improve from 16.45981
Epoch 53/10000
4/4 - 0s - loss: 22.3005 - val_loss: 16.4455

Epoch 00053: val_loss improved from 16.45981 to 16.44545, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 54/10000
4/4 - 0s - loss: 22.2975 - val_loss: 16.4591

Epoch 00054: val_loss did not improve from 16.44545
Epoch 55/10000
4/4 - 0s - loss: 22.2929 - val_loss: 16.4979

Epoch 00055: val_loss did not improve from 16.44545
Epoch 56/10000
4/4 - 0s - loss: 22.2902 - val_loss: 16.4953

Epoch 00056: val_loss did not improve from 16.44545
Epoch 57/10000
4/4 - 0s - loss: 22.2882 - val_loss: 16.4480

Epoch 00057: val_loss did not improve from 16.44545
Epoch 58/10000
4/4 - 0s - loss: 22.2931 - val_loss: 16.4718

Epoch 00058: val_loss did not improve from 16.44545
Epoch 59/10000
4/4 - 0s - loss: 22.2824 - val_loss: 16.4642

Epoch 00059: val_loss did not improve from 16.44545
Epoch 60/10000
4/4 - 0s - loss: 22.2768 - val_loss: 16.4995

Epoch 00060: val_loss did not improve from 16.44545
Epoch 61/10000
4/4 - 0s - loss: 22.2852 - val_loss: 16.5328

Epoch 00061: val_loss did not improve from 16.44545
Epoch 62/10000
4/4 - 0s - loss: 22.2882 - val_loss: 16.4817

Epoch 00062: val_loss did not improve from 16.44545
Epoch 63/10000
4/4 - 0s - loss: 22.2893 - val_loss: 16.4489

Epoch 00063: val_loss did not improve from 16.44545
Epoch 64/10000
4/4 - 0s - loss: 22.2852 - val_loss: 16.4605

Epoch 00064: val_loss did not improve from 16.44545
Epoch 65/10000
4/4 - 0s - loss: 22.2898 - val_loss: 16.5412

Epoch 00065: val_loss did not improve from 16.44545
Epoch 66/10000
4/4 - 0s - loss: 22.2884 - val_loss: 16.4740

Epoch 00066: val_loss did not improve from 16.44545
Epoch 67/10000
4/4 - 0s - loss: 22.2712 - val_loss: 16.4611

Epoch 00067: val_loss did not improve from 16.44545
Epoch 68/10000
4/4 - 0s - loss: 22.2738 - val_loss: 16.4617

Epoch 00068: val_loss did not improve from 16.44545
Epoch 69/10000
4/4 - 0s - loss: 22.2753 - val_loss: 16.4779

Epoch 00069: val_loss did not improve from 16.44545
Epoch 70/10000
4/4 - 0s - loss: 22.2715 - val_loss: 16.4908

Epoch 00070: val_loss did not improve from 16.44545
Epoch 71/10000
4/4 - 0s - loss: 22.2779 - val_loss: 16.4967

Epoch 00071: val_loss did not improve from 16.44545
Epoch 72/10000
4/4 - 0s - loss: 22.2738 - val_loss: 16.4568

Epoch 00072: val_loss did not improve from 16.44545
Epoch 73/10000
4/4 - 0s - loss: 22.2792 - val_loss: 16.4705

Epoch 00073: val_loss did not improve from 16.44545
Epoch 74/10000
4/4 - 0s - loss: 22.2706 - val_loss: 16.4815

Epoch 00074: val_loss did not improve from 16.44545
Epoch 75/10000
4/4 - 0s - loss: 22.2756 - val_loss: 16.4890

Epoch 00075: val_loss did not improve from 16.44545
Epoch 76/10000
4/4 - 0s - loss: 22.2716 - val_loss: 16.4711

Epoch 00076: val_loss did not improve from 16.44545
Epoch 77/10000
4/4 - 0s - loss: 22.2830 - val_loss: 16.4815

Epoch 00077: val_loss did not improve from 16.44545
Epoch 78/10000
4/4 - 0s - loss: 22.2752 - val_loss: 16.4510

Epoch 00078: val_loss did not improve from 16.44545
Epoch 79/10000
4/4 - 0s - loss: 22.2796 - val_loss: 16.4676

Epoch 00079: val_loss did not improve from 16.44545
Epoch 80/10000
4/4 - 0s - loss: 22.2761 - val_loss: 16.5107

Epoch 00080: val_loss did not improve from 16.44545
Epoch 81/10000
4/4 - 0s - loss: 22.2762 - val_loss: 16.4759

Epoch 00081: val_loss did not improve from 16.44545
Epoch 82/10000
4/4 - 0s - loss: 22.2814 - val_loss: 16.4598

Epoch 00082: val_loss did not improve from 16.44545
Epoch 83/10000
4/4 - 0s - loss: 22.2747 - val_loss: 16.4800

Epoch 00083: val_loss did not improve from 16.44545
Epoch 84/10000
4/4 - 0s - loss: 22.2731 - val_loss: 16.4823

Epoch 00084: val_loss did not improve from 16.44545
Epoch 85/10000
4/4 - 0s - loss: 22.2753 - val_loss: 16.4789

Epoch 00085: val_loss did not improve from 16.44545
Epoch 86/10000
4/4 - 0s - loss: 22.2736 - val_loss: 16.4849

Epoch 00086: val_loss did not improve from 16.44545
Epoch 87/10000
4/4 - 0s - loss: 22.2812 - val_loss: 16.4657

Epoch 00087: val_loss did not improve from 16.44545
Epoch 88/10000
4/4 - 0s - loss: 22.2783 - val_loss: 16.5132

Epoch 00088: val_loss did not improve from 16.44545
Epoch 89/10000
4/4 - 0s - loss: 22.2779 - val_loss: 16.4839

Epoch 00089: val_loss did not improve from 16.44545
Epoch 90/10000
4/4 - 0s - loss: 22.2708 - val_loss: 16.4584

Epoch 00090: val_loss did not improve from 16.44545
Epoch 91/10000
4/4 - 0s - loss: 22.2794 - val_loss: 16.4673

Epoch 00091: val_loss did not improve from 16.44545
Epoch 92/10000
4/4 - 0s - loss: 22.2727 - val_loss: 16.5150

Epoch 00092: val_loss did not improve from 16.44545
Epoch 93/10000
4/4 - 0s - loss: 22.2808 - val_loss: 16.5061

Epoch 00093: val_loss did not improve from 16.44545
Epoch 94/10000
4/4 - 0s - loss: 22.2690 - val_loss: 16.4539

Epoch 00094: val_loss did not improve from 16.44545
Epoch 95/10000
4/4 - 0s - loss: 22.2780 - val_loss: 16.4502

Epoch 00095: val_loss did not improve from 16.44545
Epoch 96/10000
4/4 - 0s - loss: 22.2802 - val_loss: 16.4719

Epoch 00096: val_loss did not improve from 16.44545
Epoch 97/10000
4/4 - 0s - loss: 22.2722 - val_loss: 16.4788

Epoch 00097: val_loss did not improve from 16.44545
Epoch 98/10000
4/4 - 0s - loss: 22.2742 - val_loss: 16.4815

Epoch 00098: val_loss did not improve from 16.44545
Epoch 99/10000
4/4 - 0s - loss: 22.3037 - val_loss: 16.4797

Epoch 00099: val_loss did not improve from 16.44545
Epoch 100/10000
4/4 - 0s - loss: 22.2881 - val_loss: 16.4355

Epoch 00100: val_loss improved from 16.44545 to 16.43549, saving model to ./results/dataset/trial_3/ckpt_3
Epoch 101/10000
4/4 - 0s - loss: 22.3093 - val_loss: 16.4591

Epoch 00101: val_loss did not improve from 16.43549
Epoch 102/10000
4/4 - 0s - loss: 22.2775 - val_loss: 16.5830

Epoch 00102: val_loss did not improve from 16.43549
Epoch 103/10000
4/4 - 0s - loss: 22.3187 - val_loss: 16.5218

Epoch 00103: val_loss did not improve from 16.43549
Epoch 104/10000
4/4 - 0s - loss: 22.3100 - val_loss: 16.4389

Epoch 00104: val_loss did not improve from 16.43549
Epoch 105/10000
4/4 - 0s - loss: 22.2858 - val_loss: 16.4852

Epoch 00105: val_loss did not improve from 16.43549
Epoch 106/10000
4/4 - 0s - loss: 22.2751 - val_loss: 16.5242

Epoch 00106: val_loss did not improve from 16.43549
Epoch 107/10000
4/4 - 0s - loss: 22.2805 - val_loss: 16.4824

Epoch 00107: val_loss did not improve from 16.43549
Epoch 108/10000
4/4 - 0s - loss: 22.2713 - val_loss: 16.4554

Epoch 00108: val_loss did not improve from 16.43549
Epoch 109/10000
4/4 - 0s - loss: 22.3056 - val_loss: 16.4406

Epoch 00109: val_loss did not improve from 16.43549
Epoch 110/10000
4/4 - 0s - loss: 22.2683 - val_loss: 16.5069

Epoch 00110: val_loss did not improve from 16.43549
Epoch 111/10000
4/4 - 0s - loss: 22.3129 - val_loss: 16.5916

Epoch 00111: val_loss did not improve from 16.43549
Epoch 112/10000
4/4 - 0s - loss: 22.3085 - val_loss: 16.4541

Epoch 00112: val_loss did not improve from 16.43549
Epoch 113/10000
4/4 - 0s - loss: 22.2796 - val_loss: 16.4434

Epoch 00113: val_loss did not improve from 16.43549
Epoch 114/10000
4/4 - 0s - loss: 22.2745 - val_loss: 16.4858

Epoch 00114: val_loss did not improve from 16.43549
Epoch 115/10000
4/4 - 0s - loss: 22.2896 - val_loss: 16.5296

Epoch 00115: val_loss did not improve from 16.43549
Epoch 116/10000
4/4 - 0s - loss: 22.2786 - val_loss: 16.4820

Epoch 00116: val_loss did not improve from 16.43549
Epoch 117/10000
4/4 - 0s - loss: 22.3093 - val_loss: 16.4604

Epoch 00117: val_loss did not improve from 16.43549
Epoch 118/10000
4/4 - 0s - loss: 22.2798 - val_loss: 16.5284

Epoch 00118: val_loss did not improve from 16.43549
Epoch 119/10000
4/4 - 0s - loss: 22.2875 - val_loss: 16.5255

Epoch 00119: val_loss did not improve from 16.43549
Epoch 120/10000
4/4 - 0s - loss: 22.2808 - val_loss: 16.4647

Epoch 00120: val_loss did not improve from 16.43549
Epoch 121/10000
4/4 - 0s - loss: 22.2746 - val_loss: 16.4671

Epoch 00121: val_loss did not improve from 16.43549
Epoch 122/10000
4/4 - 0s - loss: 22.2769 - val_loss: 16.5118

Epoch 00122: val_loss did not improve from 16.43549
Epoch 123/10000
4/4 - 0s - loss: 22.2927 - val_loss: 16.5482

Epoch 00123: val_loss did not improve from 16.43549
Epoch 124/10000
4/4 - 0s - loss: 22.2838 - val_loss: 16.4602

Epoch 00124: val_loss did not improve from 16.43549
Epoch 125/10000
4/4 - 0s - loss: 22.2888 - val_loss: 16.4483

Epoch 00125: val_loss did not improve from 16.43549
Epoch 126/10000
4/4 - 0s - loss: 22.2746 - val_loss: 16.4759

Epoch 00126: val_loss did not improve from 16.43549
Epoch 127/10000
4/4 - 0s - loss: 22.2830 - val_loss: 16.5271

Epoch 00127: val_loss did not improve from 16.43549
Epoch 128/10000
4/4 - 0s - loss: 22.2767 - val_loss: 16.4761

Epoch 00128: val_loss did not improve from 16.43549
Epoch 129/10000
4/4 - 0s - loss: 22.3002 - val_loss: 16.4440

Epoch 00129: val_loss did not improve from 16.43549
Epoch 130/10000
4/4 - 0s - loss: 22.2936 - val_loss: 16.5089

Epoch 00130: val_loss did not improve from 16.43549
Epoch 131/10000
4/4 - 0s - loss: 22.2780 - val_loss: 16.5052

Epoch 00131: val_loss did not improve from 16.43549
Epoch 132/10000
4/4 - 0s - loss: 22.2738 - val_loss: 16.4644

Epoch 00132: val_loss did not improve from 16.43549
Epoch 133/10000
4/4 - 0s - loss: 22.2718 - val_loss: 16.4541

Epoch 00133: val_loss did not improve from 16.43549
Epoch 134/10000
4/4 - 0s - loss: 22.2839 - val_loss: 16.4812

Epoch 00134: val_loss did not improve from 16.43549
Epoch 135/10000
4/4 - 0s - loss: 22.2726 - val_loss: 16.4638

Epoch 00135: val_loss did not improve from 16.43549
Epoch 136/10000
4/4 - 0s - loss: 22.2768 - val_loss: 16.4639

Epoch 00136: val_loss did not improve from 16.43549
Epoch 137/10000
4/4 - 0s - loss: 22.2710 - val_loss: 16.4897

Epoch 00137: val_loss did not improve from 16.43549
Epoch 138/10000
4/4 - 0s - loss: 22.2876 - val_loss: 16.5401

Epoch 00138: val_loss did not improve from 16.43549
Epoch 139/10000
4/4 - 0s - loss: 22.2802 - val_loss: 16.4683

Epoch 00139: val_loss did not improve from 16.43549
Epoch 140/10000
4/4 - 0s - loss: 22.2735 - val_loss: 16.4542

Epoch 00140: val_loss did not improve from 16.43549
Epoch 141/10000
4/4 - 0s - loss: 22.2760 - val_loss: 16.4711

Epoch 00141: val_loss did not improve from 16.43549
Epoch 142/10000
4/4 - 0s - loss: 22.2695 - val_loss: 16.5058

Epoch 00142: val_loss did not improve from 16.43549
Epoch 143/10000
4/4 - 0s - loss: 22.2845 - val_loss: 16.5050

Epoch 00143: val_loss did not improve from 16.43549
Epoch 144/10000
4/4 - 0s - loss: 22.2826 - val_loss: 16.4470

Epoch 00144: val_loss did not improve from 16.43549
Epoch 145/10000
4/4 - 0s - loss: 22.2815 - val_loss: 16.4693

Epoch 00145: val_loss did not improve from 16.43549
Epoch 146/10000
4/4 - 0s - loss: 22.2768 - val_loss: 16.4976

Epoch 00146: val_loss did not improve from 16.43549
Epoch 147/10000
4/4 - 0s - loss: 22.2727 - val_loss: 16.4734

Epoch 00147: val_loss did not improve from 16.43549
Epoch 148/10000
4/4 - 0s - loss: 22.2749 - val_loss: 16.4569

Epoch 00148: val_loss did not improve from 16.43549
Epoch 149/10000
4/4 - 0s - loss: 22.2731 - val_loss: 16.4850

Epoch 00149: val_loss did not improve from 16.43549
Epoch 150/10000
4/4 - 0s - loss: 22.2725 - val_loss: 16.4954

Epoch 00150: val_loss did not improve from 16.43549
Epoch 151/10000
4/4 - 0s - loss: 22.2757 - val_loss: 16.4831

Epoch 00151: val_loss did not improve from 16.43549
Epoch 152/10000
4/4 - 0s - loss: 22.2752 - val_loss: 16.4758

Epoch 00152: val_loss did not improve from 16.43549
Epoch 153/10000
4/4 - 0s - loss: 22.2764 - val_loss: 16.4942

Epoch 00153: val_loss did not improve from 16.43549
Epoch 154/10000
4/4 - 0s - loss: 22.2756 - val_loss: 16.4746

Epoch 00154: val_loss did not improve from 16.43549
Epoch 155/10000
4/4 - 0s - loss: 22.2786 - val_loss: 16.4794

Epoch 00155: val_loss did not improve from 16.43549
Epoch 156/10000
4/4 - 0s - loss: 22.2802 - val_loss: 16.4949

Epoch 00156: val_loss did not improve from 16.43549
Epoch 157/10000
4/4 - 0s - loss: 22.2757 - val_loss: 16.4581

Epoch 00157: val_loss did not improve from 16.43549
Epoch 158/10000
4/4 - 0s - loss: 22.2783 - val_loss: 16.4566

Epoch 00158: val_loss did not improve from 16.43549
Epoch 159/10000
4/4 - 0s - loss: 22.2789 - val_loss: 16.5108

Epoch 00159: val_loss did not improve from 16.43549
Epoch 160/10000
4/4 - 0s - loss: 22.2788 - val_loss: 16.4732

Epoch 00160: val_loss did not improve from 16.43549
Epoch 161/10000
4/4 - 0s - loss: 22.2700 - val_loss: 16.4531

Epoch 00161: val_loss did not improve from 16.43549
Epoch 162/10000
4/4 - 0s - loss: 22.2832 - val_loss: 16.4528

Epoch 00162: val_loss did not improve from 16.43549
Epoch 163/10000
4/4 - 0s - loss: 22.2748 - val_loss: 16.5186

Epoch 00163: val_loss did not improve from 16.43549
Epoch 164/10000
4/4 - 0s - loss: 22.2839 - val_loss: 16.4985

Epoch 00164: val_loss did not improve from 16.43549
Epoch 165/10000
4/4 - 0s - loss: 22.2757 - val_loss: 16.4865

Epoch 00165: val_loss did not improve from 16.43549
Epoch 166/10000
4/4 - 0s - loss: 22.2715 - val_loss: 16.4614

Epoch 00166: val_loss did not improve from 16.43549
Epoch 167/10000
4/4 - 0s - loss: 22.2739 - val_loss: 16.4459

Epoch 00167: val_loss did not improve from 16.43549
Epoch 168/10000
4/4 - 0s - loss: 22.2911 - val_loss: 16.4550

Epoch 00168: val_loss did not improve from 16.43549
Epoch 169/10000
4/4 - 0s - loss: 22.2852 - val_loss: 16.5399

Epoch 00169: val_loss did not improve from 16.43549
Epoch 170/10000
4/4 - 0s - loss: 22.3070 - val_loss: 16.4753

Epoch 00170: val_loss did not improve from 16.43549
Epoch 171/10000
4/4 - 0s - loss: 22.2730 - val_loss: 16.4902

Epoch 00171: val_loss did not improve from 16.43549
Epoch 172/10000
4/4 - 0s - loss: 22.2790 - val_loss: 16.4791

Epoch 00172: val_loss did not improve from 16.43549
Epoch 173/10000
4/4 - 0s - loss: 22.2752 - val_loss: 16.4993

Epoch 00173: val_loss did not improve from 16.43549
Epoch 174/10000
4/4 - 0s - loss: 22.2735 - val_loss: 16.4788

Epoch 00174: val_loss did not improve from 16.43549
Epoch 175/10000
4/4 - 0s - loss: 22.2731 - val_loss: 16.4765

Epoch 00175: val_loss did not improve from 16.43549
Epoch 176/10000
4/4 - 0s - loss: 22.2709 - val_loss: 16.4655

Epoch 00176: val_loss did not improve from 16.43549
Epoch 177/10000
4/4 - 0s - loss: 22.2790 - val_loss: 16.4677

Epoch 00177: val_loss did not improve from 16.43549
Epoch 178/10000
4/4 - 0s - loss: 22.2728 - val_loss: 16.4897

Epoch 00178: val_loss did not improve from 16.43549
Epoch 179/10000
4/4 - 0s - loss: 22.3041 - val_loss: 16.4995

Epoch 00179: val_loss did not improve from 16.43549
Epoch 180/10000
4/4 - 0s - loss: 22.2711 - val_loss: 16.4367

Epoch 00180: val_loss did not improve from 16.43549
Epoch 181/10000
4/4 - 0s - loss: 22.3028 - val_loss: 16.4422

Epoch 00181: val_loss did not improve from 16.43549
Epoch 182/10000
4/4 - 0s - loss: 22.2852 - val_loss: 16.4852

Epoch 00182: val_loss did not improve from 16.43549
Epoch 183/10000
4/4 - 0s - loss: 22.2893 - val_loss: 16.4644

Epoch 00183: val_loss did not improve from 16.43549
Epoch 184/10000
4/4 - 0s - loss: 22.2667 - val_loss: 16.5293

Epoch 00184: val_loss did not improve from 16.43549
Epoch 185/10000
4/4 - 0s - loss: 22.3026 - val_loss: 16.5259

Epoch 00185: val_loss did not improve from 16.43549
Epoch 186/10000
4/4 - 0s - loss: 22.3287 - val_loss: 16.4478

Epoch 00186: val_loss did not improve from 16.43549
Epoch 187/10000
4/4 - 0s - loss: 22.2791 - val_loss: 16.5015

Epoch 00187: val_loss did not improve from 16.43549
Epoch 188/10000
4/4 - 0s - loss: 22.2985 - val_loss: 16.5739

Epoch 00188: val_loss did not improve from 16.43549
Epoch 189/10000
4/4 - 0s - loss: 22.2775 - val_loss: 16.4685

Epoch 00189: val_loss did not improve from 16.43549
Epoch 190/10000
4/4 - 0s - loss: 22.3349 - val_loss: 16.4446

Epoch 00190: val_loss did not improve from 16.43549
Epoch 191/10000
4/4 - 0s - loss: 22.2835 - val_loss: 16.5031

Epoch 00191: val_loss did not improve from 16.43549
Epoch 192/10000
4/4 - 0s - loss: 22.3107 - val_loss: 16.6250

Epoch 00192: val_loss did not improve from 16.43549
Epoch 193/10000
4/4 - 0s - loss: 22.3236 - val_loss: 16.5023

Epoch 00193: val_loss did not improve from 16.43549
Epoch 194/10000
4/4 - 0s - loss: 22.2768 - val_loss: 16.4460

Epoch 00194: val_loss did not improve from 16.43549
Epoch 195/10000
4/4 - 0s - loss: 22.2885 - val_loss: 16.4599

Epoch 00195: val_loss did not improve from 16.43549
Epoch 196/10000
4/4 - 0s - loss: 22.2759 - val_loss: 16.4805

Epoch 00196: val_loss did not improve from 16.43549
Epoch 197/10000
4/4 - 0s - loss: 22.2721 - val_loss: 16.4851

Epoch 00197: val_loss did not improve from 16.43549
Epoch 198/10000
4/4 - 0s - loss: 22.2917 - val_loss: 16.4820

Epoch 00198: val_loss did not improve from 16.43549
Epoch 199/10000
4/4 - 0s - loss: 22.2688 - val_loss: 16.4510

Epoch 00199: val_loss did not improve from 16.43549
Epoch 200/10000
4/4 - 0s - loss: 22.2912 - val_loss: 16.4682

Epoch 00200: val_loss did not improve from 16.43549
Epoch 201/10000
4/4 - 0s - loss: 22.2756 - val_loss: 16.4707

Epoch 00201: val_loss did not improve from 16.43549
Epoch 202/10000
4/4 - 0s - loss: 22.2830 - val_loss: 16.4965

Epoch 00202: val_loss did not improve from 16.43549
Epoch 203/10000
4/4 - 0s - loss: 22.2848 - val_loss: 16.4864

Epoch 00203: val_loss did not improve from 16.43549
Epoch 204/10000
4/4 - 0s - loss: 22.2811 - val_loss: 16.5222

Epoch 00204: val_loss did not improve from 16.43549
Epoch 205/10000
4/4 - 0s - loss: 22.2926 - val_loss: 16.4665

Epoch 00205: val_loss did not improve from 16.43549
Epoch 206/10000
4/4 - 0s - loss: 22.2733 - val_loss: 16.4803

Epoch 00206: val_loss did not improve from 16.43549
Epoch 207/10000
4/4 - 0s - loss: 22.2725 - val_loss: 16.4740

Epoch 00207: val_loss did not improve from 16.43549
Epoch 208/10000
4/4 - 0s - loss: 22.2796 - val_loss: 16.4741

Epoch 00208: val_loss did not improve from 16.43549
Epoch 209/10000
4/4 - 0s - loss: 22.3126 - val_loss: 16.5515

Epoch 00209: val_loss did not improve from 16.43549
Epoch 210/10000
4/4 - 0s - loss: 22.2845 - val_loss: 16.4709

Epoch 00210: val_loss did not improve from 16.43549
Epoch 211/10000
4/4 - 0s - loss: 22.2731 - val_loss: 16.4580

Epoch 00211: val_loss did not improve from 16.43549
Epoch 212/10000
4/4 - 0s - loss: 22.2805 - val_loss: 16.4735

Epoch 00212: val_loss did not improve from 16.43549
Epoch 213/10000
4/4 - 0s - loss: 22.2783 - val_loss: 16.4787

Epoch 00213: val_loss did not improve from 16.43549
Epoch 214/10000
4/4 - 0s - loss: 22.2707 - val_loss: 16.5164

Epoch 00214: val_loss did not improve from 16.43549
Epoch 215/10000
4/4 - 0s - loss: 22.2797 - val_loss: 16.5000

Epoch 00215: val_loss did not improve from 16.43549
Epoch 216/10000
4/4 - 0s - loss: 22.2746 - val_loss: 16.4796

Epoch 00216: val_loss did not improve from 16.43549
Epoch 217/10000
4/4 - 0s - loss: 22.2731 - val_loss: 16.4773

Epoch 00217: val_loss did not improve from 16.43549
Epoch 218/10000
4/4 - 0s - loss: 22.2717 - val_loss: 16.4869

Epoch 00218: val_loss did not improve from 16.43549
Epoch 219/10000
4/4 - 0s - loss: 22.2736 - val_loss: 16.5114

Epoch 00219: val_loss did not improve from 16.43549
Epoch 220/10000
4/4 - 0s - loss: 22.2770 - val_loss: 16.4770

Epoch 00220: val_loss did not improve from 16.43549
Epoch 221/10000
4/4 - 0s - loss: 22.3103 - val_loss: 16.4396

Epoch 00221: val_loss did not improve from 16.43549
Epoch 222/10000
4/4 - 0s - loss: 22.2708 - val_loss: 16.5287

Epoch 00222: val_loss did not improve from 16.43549
Epoch 223/10000
4/4 - 0s - loss: 22.3141 - val_loss: 16.5883

Epoch 00223: val_loss did not improve from 16.43549
Epoch 224/10000
4/4 - 0s - loss: 22.3074 - val_loss: 16.5189

Epoch 00224: val_loss did not improve from 16.43549
Epoch 225/10000
4/4 - 0s - loss: 22.2928 - val_loss: 16.4482

Epoch 00225: val_loss did not improve from 16.43549
Epoch 226/10000
4/4 - 0s - loss: 22.3064 - val_loss: 16.4586

Epoch 00226: val_loss did not improve from 16.43549
Epoch 227/10000
4/4 - 0s - loss: 22.2745 - val_loss: 16.5137

Epoch 00227: val_loss did not improve from 16.43549
Epoch 228/10000
4/4 - 0s - loss: 22.2788 - val_loss: 16.5025

Epoch 00228: val_loss did not improve from 16.43549
Epoch 229/10000
4/4 - 0s - loss: 22.2959 - val_loss: 16.4615

Epoch 00229: val_loss did not improve from 16.43549
Epoch 230/10000
4/4 - 0s - loss: 22.2804 - val_loss: 16.5092

Epoch 00230: val_loss did not improve from 16.43549
Epoch 231/10000
4/4 - 0s - loss: 22.2901 - val_loss: 16.4745

Epoch 00231: val_loss did not improve from 16.43549
Epoch 232/10000
4/4 - 0s - loss: 22.2710 - val_loss: 16.4847

Epoch 00232: val_loss did not improve from 16.43549
Epoch 233/10000
4/4 - 0s - loss: 22.2724 - val_loss: 16.4790

Epoch 00233: val_loss did not improve from 16.43549
Epoch 234/10000
4/4 - 0s - loss: 22.2777 - val_loss: 16.4936

Epoch 00234: val_loss did not improve from 16.43549
Epoch 235/10000
4/4 - 0s - loss: 22.2797 - val_loss: 16.4889

Epoch 00235: val_loss did not improve from 16.43549
Epoch 236/10000
4/4 - 0s - loss: 22.2749 - val_loss: 16.4966

Epoch 00236: val_loss did not improve from 16.43549
Epoch 237/10000
4/4 - 0s - loss: 22.2741 - val_loss: 16.5118

Epoch 00237: val_loss did not improve from 16.43549
Epoch 238/10000
4/4 - 0s - loss: 22.2758 - val_loss: 16.4858

Epoch 00238: val_loss did not improve from 16.43549
Epoch 239/10000
4/4 - 0s - loss: 22.2780 - val_loss: 16.4516

Epoch 00239: val_loss did not improve from 16.43549
Epoch 240/10000
4/4 - 0s - loss: 22.2825 - val_loss: 16.4680

Epoch 00240: val_loss did not improve from 16.43549
Epoch 241/10000
4/4 - 0s - loss: 22.2731 - val_loss: 16.4927

Epoch 00241: val_loss did not improve from 16.43549
Epoch 242/10000
4/4 - 0s - loss: 22.2772 - val_loss: 16.4739

Epoch 00242: val_loss did not improve from 16.43549
Epoch 243/10000
4/4 - 0s - loss: 22.2726 - val_loss: 16.4758

Epoch 00243: val_loss did not improve from 16.43549
Epoch 244/10000
4/4 - 0s - loss: 22.2715 - val_loss: 16.4630

Epoch 00244: val_loss did not improve from 16.43549
Epoch 245/10000
4/4 - 0s - loss: 22.2750 - val_loss: 16.4634

Epoch 00245: val_loss did not improve from 16.43549
Epoch 246/10000
4/4 - 0s - loss: 22.2716 - val_loss: 16.4563

Epoch 00246: val_loss did not improve from 16.43549
Epoch 247/10000
4/4 - 0s - loss: 22.2765 - val_loss: 16.4689

Epoch 00247: val_loss did not improve from 16.43549
Epoch 248/10000
4/4 - 0s - loss: 22.2711 - val_loss: 16.4617

Epoch 00248: val_loss did not improve from 16.43549
Epoch 249/10000
4/4 - 0s - loss: 22.2774 - val_loss: 16.4702

Epoch 00249: val_loss did not improve from 16.43549
Epoch 250/10000
4/4 - 0s - loss: 22.2726 - val_loss: 16.4587

Epoch 00250: val_loss did not improve from 16.43549
Epoch 251/10000
4/4 - 0s - loss: 22.2740 - val_loss: 16.4771

Epoch 00251: val_loss did not improve from 16.43549
Epoch 252/10000
4/4 - 0s - loss: 22.2720 - val_loss: 16.5126

Epoch 00252: val_loss did not improve from 16.43549
Epoch 253/10000
4/4 - 0s - loss: 22.2851 - val_loss: 16.5054

Epoch 00253: val_loss did not improve from 16.43549
Epoch 254/10000
4/4 - 0s - loss: 22.2702 - val_loss: 16.4637

Epoch 00254: val_loss did not improve from 16.43549
Epoch 255/10000
4/4 - 0s - loss: 22.2760 - val_loss: 16.4513

Epoch 00255: val_loss did not improve from 16.43549
Epoch 256/10000
4/4 - 0s - loss: 22.2779 - val_loss: 16.4796

Epoch 00256: val_loss did not improve from 16.43549
Epoch 257/10000
4/4 - 0s - loss: 22.2772 - val_loss: 16.5211

Epoch 00257: val_loss did not improve from 16.43549
Epoch 258/10000
4/4 - 0s - loss: 22.2776 - val_loss: 16.4752

Epoch 00258: val_loss did not improve from 16.43549
Epoch 259/10000
4/4 - 0s - loss: 22.2743 - val_loss: 16.4528

Epoch 00259: val_loss did not improve from 16.43549
Epoch 260/10000
4/4 - 0s - loss: 22.2900 - val_loss: 16.4850

Epoch 00260: val_loss did not improve from 16.43549
Epoch 261/10000
4/4 - 0s - loss: 22.2738 - val_loss: 16.4655

Epoch 00261: val_loss did not improve from 16.43549
Epoch 262/10000
4/4 - 0s - loss: 22.2755 - val_loss: 16.4462

Epoch 00262: val_loss did not improve from 16.43549
Epoch 263/10000
4/4 - 0s - loss: 22.2831 - val_loss: 16.4417

Epoch 00263: val_loss did not improve from 16.43549
Epoch 264/10000
4/4 - 0s - loss: 22.2842 - val_loss: 16.4502

Epoch 00264: val_loss did not improve from 16.43549
Epoch 265/10000
4/4 - 0s - loss: 22.2926 - val_loss: 16.5266

Epoch 00265: val_loss did not improve from 16.43549
Epoch 266/10000
4/4 - 0s - loss: 22.2831 - val_loss: 16.4779

Epoch 00266: val_loss did not improve from 16.43549
Epoch 267/10000
4/4 - 0s - loss: 22.2731 - val_loss: 16.4578

Epoch 00267: val_loss did not improve from 16.43549
Epoch 268/10000
4/4 - 0s - loss: 22.2746 - val_loss: 16.4706

Epoch 00268: val_loss did not improve from 16.43549
Epoch 269/10000
4/4 - 0s - loss: 22.2735 - val_loss: 16.4755

Epoch 00269: val_loss did not improve from 16.43549
Epoch 270/10000
4/4 - 0s - loss: 22.2725 - val_loss: 16.4662

Epoch 00270: val_loss did not improve from 16.43549
Epoch 271/10000
4/4 - 0s - loss: 22.2752 - val_loss: 16.4494

Epoch 00271: val_loss did not improve from 16.43549
Epoch 272/10000
4/4 - 0s - loss: 22.2788 - val_loss: 16.4802

Epoch 00272: val_loss did not improve from 16.43549
Epoch 273/10000
4/4 - 0s - loss: 22.2738 - val_loss: 16.4811

Epoch 00273: val_loss did not improve from 16.43549
Epoch 274/10000
4/4 - 0s - loss: 22.2713 - val_loss: 16.4626

Epoch 00274: val_loss did not improve from 16.43549
Epoch 275/10000
4/4 - 0s - loss: 22.2780 - val_loss: 16.4624

Epoch 00275: val_loss did not improve from 16.43549
Epoch 276/10000
4/4 - 0s - loss: 22.2912 - val_loss: 16.5079

Epoch 00276: val_loss did not improve from 16.43549
Epoch 277/10000
4/4 - 0s - loss: 22.3016 - val_loss: 16.4515

Epoch 00277: val_loss did not improve from 16.43549
Epoch 278/10000
4/4 - 0s - loss: 22.2887 - val_loss: 16.5230

Epoch 00278: val_loss did not improve from 16.43549
Epoch 279/10000
4/4 - 0s - loss: 22.2856 - val_loss: 16.5024

Epoch 00279: val_loss did not improve from 16.43549
Epoch 280/10000
4/4 - 0s - loss: 22.2751 - val_loss: 16.4969

Epoch 00280: val_loss did not improve from 16.43549
Epoch 281/10000
4/4 - 0s - loss: 22.2764 - val_loss: 16.4765

Epoch 00281: val_loss did not improve from 16.43549
Epoch 282/10000
4/4 - 0s - loss: 22.2768 - val_loss: 16.4679

Epoch 00282: val_loss did not improve from 16.43549
Epoch 283/10000
4/4 - 0s - loss: 22.2718 - val_loss: 16.4767

Epoch 00283: val_loss did not improve from 16.43549
Epoch 284/10000
4/4 - 0s - loss: 22.2769 - val_loss: 16.4761

Epoch 00284: val_loss did not improve from 16.43549
Epoch 285/10000
4/4 - 0s - loss: 22.2707 - val_loss: 16.5066

Epoch 00285: val_loss did not improve from 16.43549
Epoch 286/10000
4/4 - 0s - loss: 22.2778 - val_loss: 16.4869

Epoch 00286: val_loss did not improve from 16.43549
Epoch 287/10000
4/4 - 0s - loss: 22.2732 - val_loss: 16.4469

Epoch 00287: val_loss did not improve from 16.43549
Epoch 288/10000
4/4 - 0s - loss: 22.2787 - val_loss: 16.4676

Epoch 00288: val_loss did not improve from 16.43549
Epoch 289/10000
4/4 - 0s - loss: 22.2878 - val_loss: 16.5289

Epoch 00289: val_loss did not improve from 16.43549
Epoch 290/10000
4/4 - 0s - loss: 22.2856 - val_loss: 16.4739

Epoch 00290: val_loss did not improve from 16.43549
Epoch 291/10000
4/4 - 0s - loss: 22.2968 - val_loss: 16.4511

Epoch 00291: val_loss did not improve from 16.43549
Epoch 292/10000
4/4 - 0s - loss: 22.2883 - val_loss: 16.5286

Epoch 00292: val_loss did not improve from 16.43549
Epoch 293/10000
4/4 - 0s - loss: 22.3082 - val_loss: 16.4763

Epoch 00293: val_loss did not improve from 16.43549
Epoch 294/10000
4/4 - 0s - loss: 22.2712 - val_loss: 16.5009

Epoch 00294: val_loss did not improve from 16.43549
Epoch 295/10000
4/4 - 0s - loss: 22.2757 - val_loss: 16.4923

Epoch 00295: val_loss did not improve from 16.43549
Epoch 296/10000
4/4 - 0s - loss: 22.2679 - val_loss: 16.4598

Epoch 00296: val_loss did not improve from 16.43549
Epoch 297/10000
4/4 - 0s - loss: 22.2897 - val_loss: 16.4432

Epoch 00297: val_loss did not improve from 16.43549
Epoch 298/10000
4/4 - 0s - loss: 22.2828 - val_loss: 16.4943

Epoch 00298: val_loss did not improve from 16.43549
Epoch 299/10000
4/4 - 0s - loss: 22.3007 - val_loss: 16.5433

Epoch 00299: val_loss did not improve from 16.43549
Epoch 300/10000
4/4 - 0s - loss: 22.2810 - val_loss: 16.4548

Epoch 00300: val_loss did not improve from 16.43549
Epoch 00300: early stopping
*************************** Fold #: 4 ***************************
Model: "sequential_23"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_253 (Dense)            (None, 30)                150       
_________________________________________________________________
dense_254 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_255 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_256 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_257 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_258 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_259 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_260 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_261 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_262 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_263 (Dense)            (None, 1)                 31        
=================================================================
Total params: 8,551
Trainable params: 8,551
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
4/4 - 0s - loss: 32.8728 - val_loss: 17.3287

Epoch 00001: val_loss improved from inf to 17.32872, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 2/10000
4/4 - 0s - loss: 32.8376 - val_loss: 17.2965

Epoch 00002: val_loss improved from 17.32872 to 17.29651, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 3/10000
4/4 - 0s - loss: 32.7991 - val_loss: 17.2617

Epoch 00003: val_loss improved from 17.29651 to 17.26165, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 4/10000
4/4 - 0s - loss: 32.7577 - val_loss: 17.2236

Epoch 00004: val_loss improved from 17.26165 to 17.22355, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 5/10000
4/4 - 0s - loss: 32.7120 - val_loss: 17.1815

Epoch 00005: val_loss improved from 17.22355 to 17.18154, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 6/10000
4/4 - 0s - loss: 32.6620 - val_loss: 17.1348

Epoch 00006: val_loss improved from 17.18154 to 17.13477, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 7/10000
4/4 - 0s - loss: 32.6058 - val_loss: 17.0822

Epoch 00007: val_loss improved from 17.13477 to 17.08218, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 8/10000
4/4 - 0s - loss: 32.5413 - val_loss: 17.0221

Epoch 00008: val_loss improved from 17.08218 to 17.02207, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 9/10000
4/4 - 0s - loss: 32.4685 - val_loss: 16.9518

Epoch 00009: val_loss improved from 17.02207 to 16.95181, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 10/10000
4/4 - 0s - loss: 32.3824 - val_loss: 16.8685

Epoch 00010: val_loss improved from 16.95181 to 16.86848, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 11/10000
4/4 - 0s - loss: 32.2782 - val_loss: 16.7675

Epoch 00011: val_loss improved from 16.86848 to 16.76746, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 12/10000
4/4 - 0s - loss: 32.1508 - val_loss: 16.6419

Epoch 00012: val_loss improved from 16.76746 to 16.64191, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 13/10000
4/4 - 0s - loss: 31.9941 - val_loss: 16.4812

Epoch 00013: val_loss improved from 16.64191 to 16.48120, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 14/10000
4/4 - 0s - loss: 31.7890 - val_loss: 16.2689

Epoch 00014: val_loss improved from 16.48120 to 16.26894, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 15/10000
4/4 - 0s - loss: 31.5139 - val_loss: 15.9763

Epoch 00015: val_loss improved from 16.26894 to 15.97628, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 16/10000
4/4 - 0s - loss: 31.1263 - val_loss: 15.5531

Epoch 00016: val_loss improved from 15.97628 to 15.55307, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 17/10000
4/4 - 0s - loss: 30.5357 - val_loss: 14.9116

Epoch 00017: val_loss improved from 15.55307 to 14.91155, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 18/10000
4/4 - 0s - loss: 29.6669 - val_loss: 13.9156

Epoch 00018: val_loss improved from 14.91155 to 13.91564, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 19/10000
4/4 - 0s - loss: 28.2508 - val_loss: 12.4745

Epoch 00019: val_loss improved from 13.91564 to 12.47453, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 20/10000
4/4 - 0s - loss: 26.2197 - val_loss: 11.2295

Epoch 00020: val_loss improved from 12.47453 to 11.22945, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 21/10000
4/4 - 0s - loss: 24.8097 - val_loss: 12.7320

Epoch 00021: val_loss did not improve from 11.22945
Epoch 22/10000
4/4 - 0s - loss: 25.5066 - val_loss: 12.0737

Epoch 00022: val_loss did not improve from 11.22945
Epoch 23/10000
4/4 - 0s - loss: 24.6938 - val_loss: 11.1105

Epoch 00023: val_loss improved from 11.22945 to 11.11054, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 24/10000
4/4 - 0s - loss: 24.5764 - val_loss: 11.0332

Epoch 00024: val_loss improved from 11.11054 to 11.03324, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 25/10000
4/4 - 0s - loss: 24.5845 - val_loss: 10.9848

Epoch 00025: val_loss improved from 11.03324 to 10.98476, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 26/10000
4/4 - 0s - loss: 24.3777 - val_loss: 11.0588

Epoch 00026: val_loss did not improve from 10.98476
Epoch 27/10000
4/4 - 0s - loss: 24.2282 - val_loss: 11.3084

Epoch 00027: val_loss did not improve from 10.98476
Epoch 28/10000
4/4 - 0s - loss: 24.1475 - val_loss: 11.2618

Epoch 00028: val_loss did not improve from 10.98476
Epoch 29/10000
4/4 - 0s - loss: 24.0515 - val_loss: 11.0637

Epoch 00029: val_loss did not improve from 10.98476
Epoch 30/10000
4/4 - 0s - loss: 23.9721 - val_loss: 10.9534

Epoch 00030: val_loss improved from 10.98476 to 10.95339, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 31/10000
4/4 - 0s - loss: 23.9097 - val_loss: 10.9444

Epoch 00031: val_loss improved from 10.95339 to 10.94439, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 32/10000
4/4 - 0s - loss: 23.8359 - val_loss: 10.9578

Epoch 00032: val_loss did not improve from 10.94439
Epoch 33/10000
4/4 - 0s - loss: 23.7637 - val_loss: 10.9980

Epoch 00033: val_loss did not improve from 10.94439
Epoch 34/10000
4/4 - 0s - loss: 23.6900 - val_loss: 10.9809

Epoch 00034: val_loss did not improve from 10.94439
Epoch 35/10000
4/4 - 0s - loss: 23.6225 - val_loss: 10.9700

Epoch 00035: val_loss did not improve from 10.94439
Epoch 36/10000
4/4 - 0s - loss: 23.5538 - val_loss: 10.9326

Epoch 00036: val_loss improved from 10.94439 to 10.93260, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 37/10000
4/4 - 0s - loss: 23.4890 - val_loss: 10.9259

Epoch 00037: val_loss improved from 10.93260 to 10.92586, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 38/10000
4/4 - 0s - loss: 23.4309 - val_loss: 10.9810

Epoch 00038: val_loss did not improve from 10.92586
Epoch 39/10000
4/4 - 0s - loss: 23.3685 - val_loss: 10.9443

Epoch 00039: val_loss did not improve from 10.92586
Epoch 40/10000
4/4 - 0s - loss: 23.3224 - val_loss: 10.9419

Epoch 00040: val_loss did not improve from 10.92586
Epoch 41/10000
4/4 - 0s - loss: 23.2889 - val_loss: 10.8631

Epoch 00041: val_loss improved from 10.92586 to 10.86311, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 42/10000
4/4 - 0s - loss: 23.2406 - val_loss: 10.9742

Epoch 00042: val_loss did not improve from 10.86311
Epoch 43/10000
4/4 - 0s - loss: 23.2098 - val_loss: 11.0535

Epoch 00043: val_loss did not improve from 10.86311
Epoch 44/10000
4/4 - 0s - loss: 23.1803 - val_loss: 10.9911

Epoch 00044: val_loss did not improve from 10.86311
Epoch 45/10000
4/4 - 0s - loss: 23.1532 - val_loss: 10.9450

Epoch 00045: val_loss did not improve from 10.86311
Epoch 46/10000
4/4 - 0s - loss: 23.1399 - val_loss: 10.8362

Epoch 00046: val_loss improved from 10.86311 to 10.83624, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 47/10000
4/4 - 0s - loss: 23.1147 - val_loss: 10.9279

Epoch 00047: val_loss did not improve from 10.83624
Epoch 48/10000
4/4 - 0s - loss: 23.1112 - val_loss: 11.0989

Epoch 00048: val_loss did not improve from 10.83624
Epoch 49/10000
4/4 - 0s - loss: 23.0761 - val_loss: 10.9876

Epoch 00049: val_loss did not improve from 10.83624
Epoch 50/10000
4/4 - 0s - loss: 23.0476 - val_loss: 10.8625

Epoch 00050: val_loss did not improve from 10.83624
Epoch 51/10000
4/4 - 0s - loss: 23.0362 - val_loss: 10.8753

Epoch 00051: val_loss did not improve from 10.83624
Epoch 52/10000
4/4 - 0s - loss: 23.0191 - val_loss: 10.9727

Epoch 00052: val_loss did not improve from 10.83624
Epoch 53/10000
4/4 - 0s - loss: 23.0053 - val_loss: 10.9464

Epoch 00053: val_loss did not improve from 10.83624
Epoch 54/10000
4/4 - 0s - loss: 22.9897 - val_loss: 10.8198

Epoch 00054: val_loss improved from 10.83624 to 10.81982, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 55/10000
4/4 - 0s - loss: 22.9889 - val_loss: 10.8610

Epoch 00055: val_loss did not improve from 10.81982
Epoch 56/10000
4/4 - 0s - loss: 22.9776 - val_loss: 10.8204

Epoch 00056: val_loss did not improve from 10.81982
Epoch 57/10000
4/4 - 0s - loss: 22.9498 - val_loss: 10.9771

Epoch 00057: val_loss did not improve from 10.81982
Epoch 58/10000
4/4 - 0s - loss: 22.9812 - val_loss: 11.1594

Epoch 00058: val_loss did not improve from 10.81982
Epoch 59/10000
4/4 - 0s - loss: 22.9637 - val_loss: 10.9082

Epoch 00059: val_loss did not improve from 10.81982
Epoch 60/10000
4/4 - 0s - loss: 22.9317 - val_loss: 10.7764

Epoch 00060: val_loss improved from 10.81982 to 10.77641, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 61/10000
4/4 - 0s - loss: 22.9392 - val_loss: 10.8360

Epoch 00061: val_loss did not improve from 10.77641
Epoch 62/10000
4/4 - 0s - loss: 22.9201 - val_loss: 10.9574

Epoch 00062: val_loss did not improve from 10.77641
Epoch 63/10000
4/4 - 0s - loss: 22.9260 - val_loss: 10.9835

Epoch 00063: val_loss did not improve from 10.77641
Epoch 64/10000
4/4 - 0s - loss: 22.9205 - val_loss: 10.8629

Epoch 00064: val_loss did not improve from 10.77641
Epoch 65/10000
4/4 - 0s - loss: 22.9101 - val_loss: 10.8802

Epoch 00065: val_loss did not improve from 10.77641
Epoch 66/10000
4/4 - 0s - loss: 22.9086 - val_loss: 10.9217

Epoch 00066: val_loss did not improve from 10.77641
Epoch 67/10000
4/4 - 0s - loss: 22.9058 - val_loss: 10.9411

Epoch 00067: val_loss did not improve from 10.77641
Epoch 68/10000
4/4 - 0s - loss: 22.9229 - val_loss: 10.8379

Epoch 00068: val_loss did not improve from 10.77641
Epoch 69/10000
4/4 - 0s - loss: 22.8963 - val_loss: 10.9754

Epoch 00069: val_loss did not improve from 10.77641
Epoch 70/10000
4/4 - 0s - loss: 22.9063 - val_loss: 10.9898

Epoch 00070: val_loss did not improve from 10.77641
Epoch 71/10000
4/4 - 0s - loss: 22.9061 - val_loss: 10.9212

Epoch 00071: val_loss did not improve from 10.77641
Epoch 72/10000
4/4 - 0s - loss: 22.9249 - val_loss: 10.7739

Epoch 00072: val_loss improved from 10.77641 to 10.77388, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 73/10000
4/4 - 0s - loss: 22.9168 - val_loss: 10.9006

Epoch 00073: val_loss did not improve from 10.77388
Epoch 74/10000
4/4 - 0s - loss: 22.8993 - val_loss: 10.9199

Epoch 00074: val_loss did not improve from 10.77388
Epoch 75/10000
4/4 - 0s - loss: 22.9014 - val_loss: 10.8450

Epoch 00075: val_loss did not improve from 10.77388
Epoch 76/10000
4/4 - 0s - loss: 22.8958 - val_loss: 10.9028

Epoch 00076: val_loss did not improve from 10.77388
Epoch 77/10000
4/4 - 0s - loss: 22.8984 - val_loss: 10.9877

Epoch 00077: val_loss did not improve from 10.77388
Epoch 78/10000
4/4 - 0s - loss: 22.9090 - val_loss: 10.9435

Epoch 00078: val_loss did not improve from 10.77388
Epoch 79/10000
4/4 - 0s - loss: 22.8991 - val_loss: 10.8371

Epoch 00079: val_loss did not improve from 10.77388
Epoch 80/10000
4/4 - 0s - loss: 22.8975 - val_loss: 10.8838

Epoch 00080: val_loss did not improve from 10.77388
Epoch 81/10000
4/4 - 0s - loss: 22.9200 - val_loss: 11.0321

Epoch 00081: val_loss did not improve from 10.77388
Epoch 82/10000
4/4 - 0s - loss: 22.8970 - val_loss: 10.8727

Epoch 00082: val_loss did not improve from 10.77388
Epoch 83/10000
4/4 - 0s - loss: 22.9095 - val_loss: 10.8001

Epoch 00083: val_loss did not improve from 10.77388
Epoch 84/10000
4/4 - 0s - loss: 22.9119 - val_loss: 10.9470

Epoch 00084: val_loss did not improve from 10.77388
Epoch 85/10000
4/4 - 0s - loss: 22.8981 - val_loss: 10.9144

Epoch 00085: val_loss did not improve from 10.77388
Epoch 86/10000
4/4 - 0s - loss: 22.9153 - val_loss: 10.7953

Epoch 00086: val_loss did not improve from 10.77388
Epoch 87/10000
4/4 - 0s - loss: 22.8956 - val_loss: 10.9471

Epoch 00087: val_loss did not improve from 10.77388
Epoch 88/10000
4/4 - 0s - loss: 22.9069 - val_loss: 11.0229

Epoch 00088: val_loss did not improve from 10.77388
Epoch 89/10000
4/4 - 0s - loss: 22.9035 - val_loss: 10.9714

Epoch 00089: val_loss did not improve from 10.77388
Epoch 90/10000
4/4 - 0s - loss: 22.9183 - val_loss: 10.7965

Epoch 00090: val_loss did not improve from 10.77388
Epoch 91/10000
4/4 - 0s - loss: 22.9035 - val_loss: 10.8964

Epoch 00091: val_loss did not improve from 10.77388
Epoch 92/10000
4/4 - 0s - loss: 22.9017 - val_loss: 11.1449

Epoch 00092: val_loss did not improve from 10.77388
Epoch 93/10000
4/4 - 0s - loss: 22.9333 - val_loss: 11.0229

Epoch 00093: val_loss did not improve from 10.77388
Epoch 94/10000
4/4 - 0s - loss: 22.8974 - val_loss: 10.7930

Epoch 00094: val_loss did not improve from 10.77388
Epoch 95/10000
4/4 - 0s - loss: 22.9083 - val_loss: 10.8149

Epoch 00095: val_loss did not improve from 10.77388
Epoch 96/10000
4/4 - 0s - loss: 22.9019 - val_loss: 10.8657

Epoch 00096: val_loss did not improve from 10.77388
Epoch 97/10000
4/4 - 0s - loss: 22.8987 - val_loss: 11.0426

Epoch 00097: val_loss did not improve from 10.77388
Epoch 98/10000
4/4 - 0s - loss: 22.9065 - val_loss: 10.9199

Epoch 00098: val_loss did not improve from 10.77388
Epoch 99/10000
4/4 - 0s - loss: 22.8951 - val_loss: 10.8591

Epoch 00099: val_loss did not improve from 10.77388
Epoch 100/10000
4/4 - 0s - loss: 22.8969 - val_loss: 10.8423

Epoch 00100: val_loss did not improve from 10.77388
Epoch 101/10000
4/4 - 0s - loss: 22.8968 - val_loss: 10.9267

Epoch 00101: val_loss did not improve from 10.77388
Epoch 102/10000
4/4 - 0s - loss: 22.8956 - val_loss: 10.9854

Epoch 00102: val_loss did not improve from 10.77388
Epoch 103/10000
4/4 - 0s - loss: 22.8974 - val_loss: 10.9220

Epoch 00103: val_loss did not improve from 10.77388
Epoch 104/10000
4/4 - 0s - loss: 22.8977 - val_loss: 10.8664

Epoch 00104: val_loss did not improve from 10.77388
Epoch 105/10000
4/4 - 0s - loss: 22.8952 - val_loss: 10.9210

Epoch 00105: val_loss did not improve from 10.77388
Epoch 106/10000
4/4 - 0s - loss: 22.8989 - val_loss: 10.9935

Epoch 00106: val_loss did not improve from 10.77388
Epoch 107/10000
4/4 - 0s - loss: 22.8951 - val_loss: 10.8988

Epoch 00107: val_loss did not improve from 10.77388
Epoch 108/10000
4/4 - 0s - loss: 22.9007 - val_loss: 10.8173

Epoch 00108: val_loss did not improve from 10.77388
Epoch 109/10000
4/4 - 0s - loss: 22.9045 - val_loss: 10.8850

Epoch 00109: val_loss did not improve from 10.77388
Epoch 110/10000
4/4 - 0s - loss: 22.8958 - val_loss: 10.8925

Epoch 00110: val_loss did not improve from 10.77388
Epoch 111/10000
4/4 - 0s - loss: 22.8927 - val_loss: 10.9557

Epoch 00111: val_loss did not improve from 10.77388
Epoch 112/10000
4/4 - 0s - loss: 22.9001 - val_loss: 10.9245

Epoch 00112: val_loss did not improve from 10.77388
Epoch 113/10000
4/4 - 0s - loss: 22.8947 - val_loss: 10.9041

Epoch 00113: val_loss did not improve from 10.77388
Epoch 114/10000
4/4 - 0s - loss: 22.8967 - val_loss: 10.9146

Epoch 00114: val_loss did not improve from 10.77388
Epoch 115/10000
4/4 - 0s - loss: 22.8963 - val_loss: 10.9498

Epoch 00115: val_loss did not improve from 10.77388
Epoch 116/10000
4/4 - 0s - loss: 22.9066 - val_loss: 10.9227

Epoch 00116: val_loss did not improve from 10.77388
Epoch 117/10000
4/4 - 0s - loss: 22.8975 - val_loss: 10.9708

Epoch 00117: val_loss did not improve from 10.77388
Epoch 118/10000
4/4 - 0s - loss: 22.8972 - val_loss: 10.9260

Epoch 00118: val_loss did not improve from 10.77388
Epoch 119/10000
4/4 - 0s - loss: 22.8953 - val_loss: 10.8358

Epoch 00119: val_loss did not improve from 10.77388
Epoch 120/10000
4/4 - 0s - loss: 22.9112 - val_loss: 10.8357

Epoch 00120: val_loss did not improve from 10.77388
Epoch 121/10000
4/4 - 0s - loss: 22.8970 - val_loss: 10.9637

Epoch 00121: val_loss did not improve from 10.77388
Epoch 122/10000
4/4 - 0s - loss: 22.9013 - val_loss: 10.9454

Epoch 00122: val_loss did not improve from 10.77388
Epoch 123/10000
4/4 - 0s - loss: 22.8940 - val_loss: 10.8217

Epoch 00123: val_loss did not improve from 10.77388
Epoch 124/10000
4/4 - 0s - loss: 22.9103 - val_loss: 10.8223

Epoch 00124: val_loss did not improve from 10.77388
Epoch 125/10000
4/4 - 0s - loss: 22.9065 - val_loss: 10.9935

Epoch 00125: val_loss did not improve from 10.77388
Epoch 126/10000
4/4 - 0s - loss: 22.8988 - val_loss: 10.9345

Epoch 00126: val_loss did not improve from 10.77388
Epoch 127/10000
4/4 - 0s - loss: 22.8900 - val_loss: 10.8367

Epoch 00127: val_loss did not improve from 10.77388
Epoch 128/10000
4/4 - 0s - loss: 22.9161 - val_loss: 10.7749

Epoch 00128: val_loss did not improve from 10.77388
Epoch 129/10000
4/4 - 0s - loss: 22.9026 - val_loss: 10.9712

Epoch 00129: val_loss did not improve from 10.77388
Epoch 130/10000
4/4 - 0s - loss: 22.9009 - val_loss: 10.9995

Epoch 00130: val_loss did not improve from 10.77388
Epoch 131/10000
4/4 - 0s - loss: 22.8958 - val_loss: 10.8444

Epoch 00131: val_loss did not improve from 10.77388
Epoch 132/10000
4/4 - 0s - loss: 22.8974 - val_loss: 10.7131

Epoch 00132: val_loss improved from 10.77388 to 10.71309, saving model to ./results/dataset/trial_3/ckpt_4
Epoch 133/10000
4/4 - 0s - loss: 22.9408 - val_loss: 10.7691

Epoch 00133: val_loss did not improve from 10.71309
Epoch 134/10000
4/4 - 0s - loss: 22.9132 - val_loss: 11.1087

Epoch 00134: val_loss did not improve from 10.71309
Epoch 135/10000
4/4 - 0s - loss: 22.9452 - val_loss: 11.0270

Epoch 00135: val_loss did not improve from 10.71309
Epoch 136/10000
4/4 - 0s - loss: 22.9078 - val_loss: 10.7373

Epoch 00136: val_loss did not improve from 10.71309
Epoch 137/10000
4/4 - 0s - loss: 22.9329 - val_loss: 10.7648

Epoch 00137: val_loss did not improve from 10.71309
Epoch 138/10000
4/4 - 0s - loss: 22.9141 - val_loss: 10.7951

Epoch 00138: val_loss did not improve from 10.71309
Epoch 139/10000
4/4 - 0s - loss: 22.8991 - val_loss: 10.9362

Epoch 00139: val_loss did not improve from 10.71309
Epoch 140/10000
4/4 - 0s - loss: 22.8980 - val_loss: 10.9946

Epoch 00140: val_loss did not improve from 10.71309
Epoch 141/10000
4/4 - 0s - loss: 22.9006 - val_loss: 10.8977

Epoch 00141: val_loss did not improve from 10.71309
Epoch 142/10000
4/4 - 0s - loss: 22.9192 - val_loss: 10.7606

Epoch 00142: val_loss did not improve from 10.71309
Epoch 143/10000
4/4 - 0s - loss: 22.9243 - val_loss: 10.9333

Epoch 00143: val_loss did not improve from 10.71309
Epoch 144/10000
4/4 - 0s - loss: 22.8973 - val_loss: 10.9367

Epoch 00144: val_loss did not improve from 10.71309
Epoch 145/10000
4/4 - 0s - loss: 22.8971 - val_loss: 10.8739

Epoch 00145: val_loss did not improve from 10.71309
Epoch 146/10000
4/4 - 0s - loss: 22.9023 - val_loss: 10.8345

Epoch 00146: val_loss did not improve from 10.71309
Epoch 147/10000
4/4 - 0s - loss: 22.8941 - val_loss: 10.9503

Epoch 00147: val_loss did not improve from 10.71309
Epoch 148/10000
4/4 - 0s - loss: 22.8970 - val_loss: 11.0045

Epoch 00148: val_loss did not improve from 10.71309
Epoch 149/10000
4/4 - 0s - loss: 22.9037 - val_loss: 10.9111

Epoch 00149: val_loss did not improve from 10.71309
Epoch 150/10000
4/4 - 0s - loss: 22.8963 - val_loss: 10.9094

Epoch 00150: val_loss did not improve from 10.71309
Epoch 151/10000
4/4 - 0s - loss: 22.8944 - val_loss: 10.9369

Epoch 00151: val_loss did not improve from 10.71309
Epoch 152/10000
4/4 - 0s - loss: 22.8955 - val_loss: 10.9083

Epoch 00152: val_loss did not improve from 10.71309
Epoch 153/10000
4/4 - 0s - loss: 22.8923 - val_loss: 10.8327

Epoch 00153: val_loss did not improve from 10.71309
Epoch 154/10000
4/4 - 0s - loss: 22.8993 - val_loss: 10.8328

Epoch 00154: val_loss did not improve from 10.71309
Epoch 155/10000
4/4 - 0s - loss: 22.9043 - val_loss: 10.9247

Epoch 00155: val_loss did not improve from 10.71309
Epoch 156/10000
4/4 - 0s - loss: 22.8949 - val_loss: 10.9370

Epoch 00156: val_loss did not improve from 10.71309
Epoch 157/10000
4/4 - 0s - loss: 22.9048 - val_loss: 10.9305

Epoch 00157: val_loss did not improve from 10.71309
Epoch 158/10000
4/4 - 0s - loss: 22.8948 - val_loss: 10.8120

Epoch 00158: val_loss did not improve from 10.71309
Epoch 159/10000
4/4 - 0s - loss: 22.9020 - val_loss: 10.8221

Epoch 00159: val_loss did not improve from 10.71309
Epoch 160/10000
4/4 - 0s - loss: 22.9000 - val_loss: 10.8504

Epoch 00160: val_loss did not improve from 10.71309
Epoch 161/10000
4/4 - 0s - loss: 22.8962 - val_loss: 10.8991

Epoch 00161: val_loss did not improve from 10.71309
Epoch 162/10000
4/4 - 0s - loss: 22.9086 - val_loss: 10.9263

Epoch 00162: val_loss did not improve from 10.71309
Epoch 163/10000
4/4 - 0s - loss: 22.9192 - val_loss: 10.7659

Epoch 00163: val_loss did not improve from 10.71309
Epoch 164/10000
4/4 - 0s - loss: 22.9048 - val_loss: 10.9066

Epoch 00164: val_loss did not improve from 10.71309
Epoch 165/10000
4/4 - 0s - loss: 22.8936 - val_loss: 10.9923

Epoch 00165: val_loss did not improve from 10.71309
Epoch 166/10000
4/4 - 0s - loss: 22.9072 - val_loss: 10.9542

Epoch 00166: val_loss did not improve from 10.71309
Epoch 167/10000
4/4 - 0s - loss: 22.9084 - val_loss: 10.8162

Epoch 00167: val_loss did not improve from 10.71309
Epoch 168/10000
4/4 - 0s - loss: 22.9010 - val_loss: 10.9043

Epoch 00168: val_loss did not improve from 10.71309
Epoch 169/10000
4/4 - 0s - loss: 22.8964 - val_loss: 10.9250

Epoch 00169: val_loss did not improve from 10.71309
Epoch 170/10000
4/4 - 0s - loss: 22.8921 - val_loss: 10.8573

Epoch 00170: val_loss did not improve from 10.71309
Epoch 171/10000
4/4 - 0s - loss: 22.8975 - val_loss: 10.8330

Epoch 00171: val_loss did not improve from 10.71309
Epoch 172/10000
4/4 - 0s - loss: 22.8965 - val_loss: 10.8933

Epoch 00172: val_loss did not improve from 10.71309
Epoch 173/10000
4/4 - 0s - loss: 22.9012 - val_loss: 10.8762

Epoch 00173: val_loss did not improve from 10.71309
Epoch 174/10000
4/4 - 0s - loss: 22.8973 - val_loss: 10.8914

Epoch 00174: val_loss did not improve from 10.71309
Epoch 175/10000
4/4 - 0s - loss: 22.9043 - val_loss: 10.9726

Epoch 00175: val_loss did not improve from 10.71309
Epoch 176/10000
4/4 - 0s - loss: 22.8972 - val_loss: 10.8391

Epoch 00176: val_loss did not improve from 10.71309
Epoch 177/10000
4/4 - 0s - loss: 22.9013 - val_loss: 10.8263

Epoch 00177: val_loss did not improve from 10.71309
Epoch 178/10000
4/4 - 0s - loss: 22.9202 - val_loss: 10.9980

Epoch 00178: val_loss did not improve from 10.71309
Epoch 179/10000
4/4 - 0s - loss: 22.9024 - val_loss: 10.8392

Epoch 00179: val_loss did not improve from 10.71309
Epoch 180/10000
4/4 - 0s - loss: 22.9001 - val_loss: 10.8571

Epoch 00180: val_loss did not improve from 10.71309
Epoch 181/10000
4/4 - 0s - loss: 22.8968 - val_loss: 10.8937

Epoch 00181: val_loss did not improve from 10.71309
Epoch 182/10000
4/4 - 0s - loss: 22.8997 - val_loss: 11.0178

Epoch 00182: val_loss did not improve from 10.71309
Epoch 183/10000
4/4 - 0s - loss: 22.9039 - val_loss: 10.9310

Epoch 00183: val_loss did not improve from 10.71309
Epoch 184/10000
4/4 - 0s - loss: 22.9117 - val_loss: 10.7585

Epoch 00184: val_loss did not improve from 10.71309
Epoch 185/10000
4/4 - 0s - loss: 22.9088 - val_loss: 10.8669

Epoch 00185: val_loss did not improve from 10.71309
Epoch 186/10000
4/4 - 0s - loss: 22.8953 - val_loss: 11.0743

Epoch 00186: val_loss did not improve from 10.71309
Epoch 187/10000
4/4 - 0s - loss: 22.9156 - val_loss: 10.9196

Epoch 00187: val_loss did not improve from 10.71309
Epoch 188/10000
4/4 - 0s - loss: 22.9035 - val_loss: 10.8132

Epoch 00188: val_loss did not improve from 10.71309
Epoch 189/10000
4/4 - 0s - loss: 22.8969 - val_loss: 10.8890

Epoch 00189: val_loss did not improve from 10.71309
Epoch 190/10000
4/4 - 0s - loss: 22.9035 - val_loss: 10.9711

Epoch 00190: val_loss did not improve from 10.71309
Epoch 191/10000
4/4 - 0s - loss: 22.8967 - val_loss: 10.8677

Epoch 00191: val_loss did not improve from 10.71309
Epoch 192/10000
4/4 - 0s - loss: 22.9015 - val_loss: 10.8172

Epoch 00192: val_loss did not improve from 10.71309
Epoch 193/10000
4/4 - 0s - loss: 22.8964 - val_loss: 10.9258

Epoch 00193: val_loss did not improve from 10.71309
Epoch 194/10000
4/4 - 0s - loss: 22.9005 - val_loss: 10.9665

Epoch 00194: val_loss did not improve from 10.71309
Epoch 195/10000
4/4 - 0s - loss: 22.9267 - val_loss: 10.7977

Epoch 00195: val_loss did not improve from 10.71309
Epoch 196/10000
4/4 - 0s - loss: 22.9132 - val_loss: 10.9474

Epoch 00196: val_loss did not improve from 10.71309
Epoch 197/10000
4/4 - 0s - loss: 22.9008 - val_loss: 10.8885

Epoch 00197: val_loss did not improve from 10.71309
Epoch 198/10000
4/4 - 0s - loss: 22.8939 - val_loss: 10.9280

Epoch 00198: val_loss did not improve from 10.71309
Epoch 199/10000
4/4 - 0s - loss: 22.9003 - val_loss: 11.0008

Epoch 00199: val_loss did not improve from 10.71309
Epoch 200/10000
4/4 - 0s - loss: 22.8951 - val_loss: 10.8758

Epoch 00200: val_loss did not improve from 10.71309
Epoch 201/10000
4/4 - 0s - loss: 22.8912 - val_loss: 10.7478

Epoch 00201: val_loss did not improve from 10.71309
Epoch 202/10000
4/4 - 0s - loss: 22.9242 - val_loss: 10.7828

Epoch 00202: val_loss did not improve from 10.71309
Epoch 203/10000
4/4 - 0s - loss: 22.9031 - val_loss: 11.0056

Epoch 00203: val_loss did not improve from 10.71309
Epoch 204/10000
4/4 - 0s - loss: 22.9054 - val_loss: 10.9908

Epoch 00204: val_loss did not improve from 10.71309
Epoch 205/10000
4/4 - 0s - loss: 22.8934 - val_loss: 10.8140

Epoch 00205: val_loss did not improve from 10.71309
Epoch 206/10000
4/4 - 0s - loss: 22.9032 - val_loss: 10.8218

Epoch 00206: val_loss did not improve from 10.71309
Epoch 207/10000
4/4 - 0s - loss: 22.9031 - val_loss: 10.8900

Epoch 00207: val_loss did not improve from 10.71309
Epoch 208/10000
4/4 - 0s - loss: 22.8981 - val_loss: 11.0579

Epoch 00208: val_loss did not improve from 10.71309
Epoch 209/10000
4/4 - 0s - loss: 22.9046 - val_loss: 10.9359

Epoch 00209: val_loss did not improve from 10.71309
Epoch 210/10000
4/4 - 0s - loss: 22.8997 - val_loss: 10.8120

Epoch 00210: val_loss did not improve from 10.71309
Epoch 211/10000
4/4 - 0s - loss: 22.9069 - val_loss: 10.8818

Epoch 00211: val_loss did not improve from 10.71309
Epoch 212/10000
4/4 - 0s - loss: 22.8958 - val_loss: 10.8733

Epoch 00212: val_loss did not improve from 10.71309
Epoch 213/10000
4/4 - 0s - loss: 22.8976 - val_loss: 10.8760

Epoch 00213: val_loss did not improve from 10.71309
Epoch 214/10000
4/4 - 0s - loss: 22.8992 - val_loss: 10.9662

Epoch 00214: val_loss did not improve from 10.71309
Epoch 215/10000
4/4 - 0s - loss: 22.8994 - val_loss: 10.8663

Epoch 00215: val_loss did not improve from 10.71309
Epoch 216/10000
4/4 - 0s - loss: 22.8972 - val_loss: 10.8357

Epoch 00216: val_loss did not improve from 10.71309
Epoch 217/10000
4/4 - 0s - loss: 22.8981 - val_loss: 10.8350

Epoch 00217: val_loss did not improve from 10.71309
Epoch 218/10000
4/4 - 0s - loss: 22.9038 - val_loss: 10.9113

Epoch 00218: val_loss did not improve from 10.71309
Epoch 219/10000
4/4 - 0s - loss: 22.9027 - val_loss: 10.9430

Epoch 00219: val_loss did not improve from 10.71309
Epoch 220/10000
4/4 - 0s - loss: 22.8957 - val_loss: 10.8308

Epoch 00220: val_loss did not improve from 10.71309
Epoch 221/10000
4/4 - 0s - loss: 22.9143 - val_loss: 10.8133

Epoch 00221: val_loss did not improve from 10.71309
Epoch 222/10000
4/4 - 0s - loss: 22.8930 - val_loss: 10.9642

Epoch 00222: val_loss did not improve from 10.71309
Epoch 223/10000
4/4 - 0s - loss: 22.9075 - val_loss: 11.0081

Epoch 00223: val_loss did not improve from 10.71309
Epoch 224/10000
4/4 - 0s - loss: 22.8927 - val_loss: 10.8329

Epoch 00224: val_loss did not improve from 10.71309
Epoch 225/10000
4/4 - 0s - loss: 22.9149 - val_loss: 10.7676

Epoch 00225: val_loss did not improve from 10.71309
Epoch 226/10000
4/4 - 0s - loss: 22.9108 - val_loss: 10.8319

Epoch 00226: val_loss did not improve from 10.71309
Epoch 227/10000
4/4 - 0s - loss: 22.8983 - val_loss: 11.0164

Epoch 00227: val_loss did not improve from 10.71309
Epoch 228/10000
4/4 - 0s - loss: 22.9058 - val_loss: 10.9428

Epoch 00228: val_loss did not improve from 10.71309
Epoch 229/10000
4/4 - 0s - loss: 22.8943 - val_loss: 10.8151

Epoch 00229: val_loss did not improve from 10.71309
Epoch 230/10000
4/4 - 0s - loss: 22.8996 - val_loss: 10.7843

Epoch 00230: val_loss did not improve from 10.71309
Epoch 231/10000
4/4 - 0s - loss: 22.9051 - val_loss: 10.8778

Epoch 00231: val_loss did not improve from 10.71309
Epoch 232/10000
4/4 - 0s - loss: 22.9093 - val_loss: 11.0162

Epoch 00232: val_loss did not improve from 10.71309
Epoch 233/10000
4/4 - 0s - loss: 22.9032 - val_loss: 10.9232

Epoch 00233: val_loss did not improve from 10.71309
Epoch 234/10000
4/4 - 0s - loss: 22.8932 - val_loss: 10.8575

Epoch 00234: val_loss did not improve from 10.71309
Epoch 235/10000
4/4 - 0s - loss: 22.9017 - val_loss: 10.8035

Epoch 00235: val_loss did not improve from 10.71309
Epoch 236/10000
4/4 - 0s - loss: 22.9027 - val_loss: 10.9418

Epoch 00236: val_loss did not improve from 10.71309
Epoch 237/10000
4/4 - 0s - loss: 22.9152 - val_loss: 10.9943

Epoch 00237: val_loss did not improve from 10.71309
Epoch 238/10000
4/4 - 0s - loss: 22.9032 - val_loss: 10.8139

Epoch 00238: val_loss did not improve from 10.71309
Epoch 239/10000
4/4 - 0s - loss: 22.9006 - val_loss: 10.8604

Epoch 00239: val_loss did not improve from 10.71309
Epoch 240/10000
4/4 - 0s - loss: 22.8933 - val_loss: 10.9680

Epoch 00240: val_loss did not improve from 10.71309
Epoch 241/10000
4/4 - 0s - loss: 22.9092 - val_loss: 10.9743

Epoch 00241: val_loss did not improve from 10.71309
Epoch 242/10000
4/4 - 0s - loss: 22.8958 - val_loss: 10.7845

Epoch 00242: val_loss did not improve from 10.71309
Epoch 243/10000
4/4 - 0s - loss: 22.9092 - val_loss: 10.8538

Epoch 00243: val_loss did not improve from 10.71309
Epoch 244/10000
4/4 - 0s - loss: 22.8977 - val_loss: 10.8779

Epoch 00244: val_loss did not improve from 10.71309
Epoch 245/10000
4/4 - 0s - loss: 22.8980 - val_loss: 10.8712

Epoch 00245: val_loss did not improve from 10.71309
Epoch 246/10000
4/4 - 0s - loss: 22.9065 - val_loss: 10.7836

Epoch 00246: val_loss did not improve from 10.71309
Epoch 247/10000
4/4 - 0s - loss: 22.9053 - val_loss: 10.8063

Epoch 00247: val_loss did not improve from 10.71309
Epoch 248/10000
4/4 - 0s - loss: 22.8959 - val_loss: 10.9270

Epoch 00248: val_loss did not improve from 10.71309
Epoch 249/10000
4/4 - 0s - loss: 22.9006 - val_loss: 10.9997

Epoch 00249: val_loss did not improve from 10.71309
Epoch 250/10000
4/4 - 0s - loss: 22.9018 - val_loss: 10.9300

Epoch 00250: val_loss did not improve from 10.71309
Epoch 251/10000
4/4 - 0s - loss: 22.8962 - val_loss: 10.8323

Epoch 00251: val_loss did not improve from 10.71309
Epoch 252/10000
4/4 - 0s - loss: 22.8976 - val_loss: 10.8942

Epoch 00252: val_loss did not improve from 10.71309
Epoch 253/10000
4/4 - 0s - loss: 22.9009 - val_loss: 11.0031

Epoch 00253: val_loss did not improve from 10.71309
Epoch 254/10000
4/4 - 0s - loss: 22.9046 - val_loss: 10.9451

Epoch 00254: val_loss did not improve from 10.71309
Epoch 255/10000
4/4 - 0s - loss: 22.8924 - val_loss: 10.7976

Epoch 00255: val_loss did not improve from 10.71309
Epoch 256/10000
4/4 - 0s - loss: 22.9065 - val_loss: 10.8229

Epoch 00256: val_loss did not improve from 10.71309
Epoch 257/10000
4/4 - 0s - loss: 22.8906 - val_loss: 10.9766

Epoch 00257: val_loss did not improve from 10.71309
Epoch 258/10000
4/4 - 0s - loss: 22.9061 - val_loss: 11.0547

Epoch 00258: val_loss did not improve from 10.71309
Epoch 259/10000
4/4 - 0s - loss: 22.9342 - val_loss: 10.8266

Epoch 00259: val_loss did not improve from 10.71309
Epoch 260/10000
4/4 - 0s - loss: 22.9019 - val_loss: 10.9327

Epoch 00260: val_loss did not improve from 10.71309
Epoch 261/10000
4/4 - 0s - loss: 22.8939 - val_loss: 10.9035

Epoch 00261: val_loss did not improve from 10.71309
Epoch 262/10000
4/4 - 0s - loss: 22.8948 - val_loss: 10.8649

Epoch 00262: val_loss did not improve from 10.71309
Epoch 263/10000
4/4 - 0s - loss: 22.8963 - val_loss: 10.8917

Epoch 00263: val_loss did not improve from 10.71309
Epoch 264/10000
4/4 - 0s - loss: 22.8989 - val_loss: 10.9460

Epoch 00264: val_loss did not improve from 10.71309
Epoch 265/10000
4/4 - 0s - loss: 22.9061 - val_loss: 10.8562

Epoch 00265: val_loss did not improve from 10.71309
Epoch 266/10000
4/4 - 0s - loss: 22.9014 - val_loss: 10.9022

Epoch 00266: val_loss did not improve from 10.71309
Epoch 267/10000
4/4 - 0s - loss: 22.8960 - val_loss: 10.8176

Epoch 00267: val_loss did not improve from 10.71309
Epoch 268/10000
4/4 - 0s - loss: 22.9084 - val_loss: 10.8087

Epoch 00268: val_loss did not improve from 10.71309
Epoch 269/10000
4/4 - 0s - loss: 22.8956 - val_loss: 10.9058

Epoch 00269: val_loss did not improve from 10.71309
Epoch 270/10000
4/4 - 0s - loss: 22.8950 - val_loss: 11.0132

Epoch 00270: val_loss did not improve from 10.71309
Epoch 271/10000
4/4 - 0s - loss: 22.9038 - val_loss: 10.9172

Epoch 00271: val_loss did not improve from 10.71309
Epoch 272/10000
4/4 - 0s - loss: 22.8968 - val_loss: 10.8769

Epoch 00272: val_loss did not improve from 10.71309
Epoch 273/10000
4/4 - 0s - loss: 22.9234 - val_loss: 10.7986

Epoch 00273: val_loss did not improve from 10.71309
Epoch 274/10000
4/4 - 0s - loss: 22.8895 - val_loss: 11.0467

Epoch 00274: val_loss did not improve from 10.71309
Epoch 275/10000
4/4 - 0s - loss: 22.9175 - val_loss: 11.0688

Epoch 00275: val_loss did not improve from 10.71309
Epoch 276/10000
4/4 - 0s - loss: 22.9025 - val_loss: 10.8321

Epoch 00276: val_loss did not improve from 10.71309
Epoch 277/10000
4/4 - 0s - loss: 22.9088 - val_loss: 10.8097

Epoch 00277: val_loss did not improve from 10.71309
Epoch 278/10000
4/4 - 0s - loss: 22.9063 - val_loss: 10.9824

Epoch 00278: val_loss did not improve from 10.71309
Epoch 279/10000
4/4 - 0s - loss: 22.8991 - val_loss: 10.9608

Epoch 00279: val_loss did not improve from 10.71309
Epoch 280/10000
4/4 - 0s - loss: 22.8945 - val_loss: 10.9108

Epoch 00280: val_loss did not improve from 10.71309
Epoch 281/10000
4/4 - 0s - loss: 22.8978 - val_loss: 10.8709

Epoch 00281: val_loss did not improve from 10.71309
Epoch 282/10000
4/4 - 0s - loss: 22.8944 - val_loss: 10.8999

Epoch 00282: val_loss did not improve from 10.71309
Epoch 283/10000
4/4 - 0s - loss: 22.8999 - val_loss: 10.9253

Epoch 00283: val_loss did not improve from 10.71309
Epoch 284/10000
4/4 - 0s - loss: 22.8987 - val_loss: 10.8220

Epoch 00284: val_loss did not improve from 10.71309
Epoch 285/10000
4/4 - 0s - loss: 22.9102 - val_loss: 10.8688

Epoch 00285: val_loss did not improve from 10.71309
Epoch 286/10000
4/4 - 0s - loss: 22.8953 - val_loss: 10.8258

Epoch 00286: val_loss did not improve from 10.71309
Epoch 287/10000
4/4 - 0s - loss: 22.9052 - val_loss: 10.8902

Epoch 00287: val_loss did not improve from 10.71309
Epoch 288/10000
4/4 - 0s - loss: 22.8936 - val_loss: 10.8532

Epoch 00288: val_loss did not improve from 10.71309
Epoch 289/10000
4/4 - 0s - loss: 22.8979 - val_loss: 10.8649

Epoch 00289: val_loss did not improve from 10.71309
Epoch 290/10000
4/4 - 0s - loss: 22.8924 - val_loss: 10.9583

Epoch 00290: val_loss did not improve from 10.71309
Epoch 291/10000
4/4 - 0s - loss: 22.8961 - val_loss: 11.0219

Epoch 00291: val_loss did not improve from 10.71309
Epoch 292/10000
4/4 - 0s - loss: 22.9313 - val_loss: 10.9079

Epoch 00292: val_loss did not improve from 10.71309
Epoch 293/10000
4/4 - 0s - loss: 22.8917 - val_loss: 11.0268

Epoch 00293: val_loss did not improve from 10.71309
Epoch 294/10000
4/4 - 0s - loss: 22.9112 - val_loss: 11.0400

Epoch 00294: val_loss did not improve from 10.71309
Epoch 295/10000
4/4 - 0s - loss: 22.9064 - val_loss: 10.9501

Epoch 00295: val_loss did not improve from 10.71309
Epoch 296/10000
4/4 - 0s - loss: 22.8848 - val_loss: 10.7758

Epoch 00296: val_loss did not improve from 10.71309
Epoch 297/10000
4/4 - 0s - loss: 22.9227 - val_loss: 10.7748

Epoch 00297: val_loss did not improve from 10.71309
Epoch 298/10000
4/4 - 0s - loss: 22.8959 - val_loss: 11.0114

Epoch 00298: val_loss did not improve from 10.71309
Epoch 299/10000
4/4 - 0s - loss: 22.9304 - val_loss: 11.0823

Epoch 00299: val_loss did not improve from 10.71309
Epoch 300/10000
4/4 - 0s - loss: 22.9016 - val_loss: 10.8204

Epoch 00300: val_loss did not improve from 10.71309
Epoch 301/10000
4/4 - 0s - loss: 22.9226 - val_loss: 10.7572

Epoch 00301: val_loss did not improve from 10.71309
Epoch 302/10000
4/4 - 0s - loss: 22.9023 - val_loss: 10.9827

Epoch 00302: val_loss did not improve from 10.71309
Epoch 303/10000
4/4 - 0s - loss: 22.9034 - val_loss: 10.9842

Epoch 00303: val_loss did not improve from 10.71309
Epoch 304/10000
4/4 - 0s - loss: 22.9053 - val_loss: 10.8567

Epoch 00304: val_loss did not improve from 10.71309
Epoch 305/10000
4/4 - 0s - loss: 22.9008 - val_loss: 10.8063

Epoch 00305: val_loss did not improve from 10.71309
Epoch 306/10000
4/4 - 0s - loss: 22.9070 - val_loss: 10.8819

Epoch 00306: val_loss did not improve from 10.71309
Epoch 307/10000
4/4 - 0s - loss: 22.8954 - val_loss: 10.8712

Epoch 00307: val_loss did not improve from 10.71309
Epoch 308/10000
4/4 - 0s - loss: 22.9023 - val_loss: 10.8844

Epoch 00308: val_loss did not improve from 10.71309
Epoch 309/10000
4/4 - 0s - loss: 22.9048 - val_loss: 10.9824

Epoch 00309: val_loss did not improve from 10.71309
Epoch 310/10000
4/4 - 0s - loss: 22.9063 - val_loss: 10.9634

Epoch 00310: val_loss did not improve from 10.71309
Epoch 311/10000
4/4 - 0s - loss: 22.8975 - val_loss: 10.8232

Epoch 00311: val_loss did not improve from 10.71309
Epoch 312/10000
4/4 - 0s - loss: 22.9074 - val_loss: 10.8185

Epoch 00312: val_loss did not improve from 10.71309
Epoch 313/10000
4/4 - 0s - loss: 22.8975 - val_loss: 10.9799

Epoch 00313: val_loss did not improve from 10.71309
Epoch 314/10000
4/4 - 0s - loss: 22.9047 - val_loss: 11.0173

Epoch 00314: val_loss did not improve from 10.71309
Epoch 315/10000
4/4 - 0s - loss: 22.8996 - val_loss: 10.8487

Epoch 00315: val_loss did not improve from 10.71309
Epoch 316/10000
4/4 - 0s - loss: 22.9086 - val_loss: 10.8371

Epoch 00316: val_loss did not improve from 10.71309
Epoch 317/10000
4/4 - 0s - loss: 22.8890 - val_loss: 11.0153

Epoch 00317: val_loss did not improve from 10.71309
Epoch 318/10000
4/4 - 0s - loss: 22.9316 - val_loss: 11.0893

Epoch 00318: val_loss did not improve from 10.71309
Epoch 319/10000
4/4 - 0s - loss: 22.9048 - val_loss: 10.8180

Epoch 00319: val_loss did not improve from 10.71309
Epoch 320/10000
4/4 - 0s - loss: 22.9203 - val_loss: 10.7887

Epoch 00320: val_loss did not improve from 10.71309
Epoch 321/10000
4/4 - 0s - loss: 22.8982 - val_loss: 10.9969

Epoch 00321: val_loss did not improve from 10.71309
Epoch 322/10000
4/4 - 0s - loss: 22.9128 - val_loss: 11.0521

Epoch 00322: val_loss did not improve from 10.71309
Epoch 323/10000
4/4 - 0s - loss: 22.9092 - val_loss: 10.9987

Epoch 00323: val_loss did not improve from 10.71309
Epoch 324/10000
4/4 - 0s - loss: 22.8966 - val_loss: 10.8445

Epoch 00324: val_loss did not improve from 10.71309
Epoch 325/10000
4/4 - 0s - loss: 22.8998 - val_loss: 10.8375

Epoch 00325: val_loss did not improve from 10.71309
Epoch 326/10000
4/4 - 0s - loss: 22.9055 - val_loss: 10.9528

Epoch 00326: val_loss did not improve from 10.71309
Epoch 327/10000
4/4 - 0s - loss: 22.8962 - val_loss: 10.9141

Epoch 00327: val_loss did not improve from 10.71309
Epoch 328/10000
4/4 - 0s - loss: 22.8924 - val_loss: 10.8318

Epoch 00328: val_loss did not improve from 10.71309
Epoch 329/10000
4/4 - 0s - loss: 22.9035 - val_loss: 10.8342

Epoch 00329: val_loss did not improve from 10.71309
Epoch 330/10000
4/4 - 0s - loss: 22.8954 - val_loss: 10.9281

Epoch 00330: val_loss did not improve from 10.71309
Epoch 331/10000
4/4 - 0s - loss: 22.9007 - val_loss: 10.9620

Epoch 00331: val_loss did not improve from 10.71309
Epoch 332/10000
4/4 - 0s - loss: 22.9009 - val_loss: 10.8387

Epoch 00332: val_loss did not improve from 10.71309
Epoch 00332: early stopping
*************************** Fold #: 5 ***************************
Model: "sequential_24"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_264 (Dense)            (None, 30)                150       
_________________________________________________________________
dense_265 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_266 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_267 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_268 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_269 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_270 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_271 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_272 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_273 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_274 (Dense)            (None, 1)                 31        
=================================================================
Total params: 8,551
Trainable params: 8,551
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
4/4 - 0s - loss: 31.9114 - val_loss: 25.9803

Epoch 00001: val_loss improved from inf to 25.98035, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 2/10000
4/4 - 0s - loss: 31.8771 - val_loss: 25.9467

Epoch 00002: val_loss improved from 25.98035 to 25.94670, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 3/10000
4/4 - 0s - loss: 31.8387 - val_loss: 25.9098

Epoch 00003: val_loss improved from 25.94670 to 25.90980, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 4/10000
4/4 - 0s - loss: 31.7970 - val_loss: 25.8688

Epoch 00004: val_loss improved from 25.90980 to 25.86883, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 5/10000
4/4 - 0s - loss: 31.7510 - val_loss: 25.8230

Epoch 00005: val_loss improved from 25.86883 to 25.82299, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 6/10000
4/4 - 0s - loss: 31.6990 - val_loss: 25.7711

Epoch 00006: val_loss improved from 25.82299 to 25.77112, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 7/10000
4/4 - 0s - loss: 31.6388 - val_loss: 25.7118

Epoch 00007: val_loss improved from 25.77112 to 25.71178, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 8/10000
4/4 - 0s - loss: 31.5708 - val_loss: 25.6426

Epoch 00008: val_loss improved from 25.71178 to 25.64257, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 9/10000
4/4 - 0s - loss: 31.4910 - val_loss: 25.5609

Epoch 00009: val_loss improved from 25.64257 to 25.56090, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 10/10000
4/4 - 0s - loss: 31.3956 - val_loss: 25.4625

Epoch 00010: val_loss improved from 25.56090 to 25.46250, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 11/10000
4/4 - 0s - loss: 31.2782 - val_loss: 25.3412

Epoch 00011: val_loss improved from 25.46250 to 25.34119, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 12/10000
4/4 - 0s - loss: 31.1364 - val_loss: 25.1871

Epoch 00012: val_loss improved from 25.34119 to 25.18711, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 13/10000
4/4 - 0s - loss: 30.9479 - val_loss: 24.9868

Epoch 00013: val_loss improved from 25.18711 to 24.98675, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 14/10000
4/4 - 0s - loss: 30.7054 - val_loss: 24.7160

Epoch 00014: val_loss improved from 24.98675 to 24.71603, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 15/10000
4/4 - 0s - loss: 30.3692 - val_loss: 24.3330

Epoch 00015: val_loss improved from 24.71603 to 24.33302, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 16/10000
4/4 - 0s - loss: 29.8832 - val_loss: 23.7683

Epoch 00016: val_loss improved from 24.33302 to 23.76830, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 17/10000
4/4 - 0s - loss: 29.1635 - val_loss: 22.9126

Epoch 00017: val_loss improved from 23.76830 to 22.91264, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 18/10000
4/4 - 0s - loss: 28.0639 - val_loss: 21.6192

Epoch 00018: val_loss improved from 22.91264 to 21.61918, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 19/10000
4/4 - 0s - loss: 26.3448 - val_loss: 19.9028

Epoch 00019: val_loss improved from 21.61918 to 19.90285, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 20/10000
4/4 - 0s - loss: 24.3546 - val_loss: 19.1425

Epoch 00020: val_loss improved from 19.90285 to 19.14253, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 21/10000
4/4 - 0s - loss: 23.7624 - val_loss: 20.1510

Epoch 00021: val_loss did not improve from 19.14253
Epoch 22/10000
4/4 - 0s - loss: 23.8959 - val_loss: 19.0749

Epoch 00022: val_loss improved from 19.14253 to 19.07491, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 23/10000
4/4 - 0s - loss: 23.3623 - val_loss: 18.8169

Epoch 00023: val_loss improved from 19.07491 to 18.81693, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 24/10000
4/4 - 0s - loss: 23.4055 - val_loss: 18.7640

Epoch 00024: val_loss improved from 18.81693 to 18.76401, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 25/10000
4/4 - 0s - loss: 23.3137 - val_loss: 18.6633

Epoch 00025: val_loss improved from 18.76401 to 18.66329, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 26/10000
4/4 - 0s - loss: 23.0972 - val_loss: 18.6893

Epoch 00026: val_loss did not improve from 18.66329
Epoch 27/10000
4/4 - 0s - loss: 23.0220 - val_loss: 18.7169

Epoch 00027: val_loss did not improve from 18.66329
Epoch 28/10000
4/4 - 0s - loss: 22.9935 - val_loss: 18.5895

Epoch 00028: val_loss improved from 18.66329 to 18.58949, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 29/10000
4/4 - 0s - loss: 22.8631 - val_loss: 18.3692

Epoch 00029: val_loss improved from 18.58949 to 18.36922, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 30/10000
4/4 - 0s - loss: 22.7663 - val_loss: 18.2689

Epoch 00030: val_loss improved from 18.36922 to 18.26890, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 31/10000
4/4 - 0s - loss: 22.6827 - val_loss: 18.1929

Epoch 00031: val_loss improved from 18.26890 to 18.19289, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 32/10000
4/4 - 0s - loss: 22.6013 - val_loss: 18.1540

Epoch 00032: val_loss improved from 18.19289 to 18.15397, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 33/10000
4/4 - 0s - loss: 22.5250 - val_loss: 18.1156

Epoch 00033: val_loss improved from 18.15397 to 18.11564, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 34/10000
4/4 - 0s - loss: 22.5224 - val_loss: 18.0915

Epoch 00034: val_loss improved from 18.11564 to 18.09151, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 35/10000
4/4 - 0s - loss: 22.4473 - val_loss: 17.9344

Epoch 00035: val_loss improved from 18.09151 to 17.93440, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 36/10000
4/4 - 0s - loss: 22.3978 - val_loss: 17.8843

Epoch 00036: val_loss improved from 17.93440 to 17.88429, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 37/10000
4/4 - 0s - loss: 22.3653 - val_loss: 17.8666

Epoch 00037: val_loss improved from 17.88429 to 17.86660, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 38/10000
4/4 - 0s - loss: 22.3357 - val_loss: 17.8764

Epoch 00038: val_loss did not improve from 17.86660
Epoch 39/10000
4/4 - 0s - loss: 22.3214 - val_loss: 17.8463

Epoch 00039: val_loss improved from 17.86660 to 17.84630, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 40/10000
4/4 - 0s - loss: 22.2958 - val_loss: 17.8037

Epoch 00040: val_loss improved from 17.84630 to 17.80373, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 41/10000
4/4 - 0s - loss: 22.2800 - val_loss: 17.7686

Epoch 00041: val_loss improved from 17.80373 to 17.76860, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 42/10000
4/4 - 0s - loss: 22.2715 - val_loss: 17.7591

Epoch 00042: val_loss improved from 17.76860 to 17.75909, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 43/10000
4/4 - 0s - loss: 22.2499 - val_loss: 17.7667

Epoch 00043: val_loss did not improve from 17.75909
Epoch 44/10000
4/4 - 0s - loss: 22.2368 - val_loss: 17.7823

Epoch 00044: val_loss did not improve from 17.75909
Epoch 45/10000
4/4 - 0s - loss: 22.2246 - val_loss: 17.7719

Epoch 00045: val_loss did not improve from 17.75909
Epoch 46/10000
4/4 - 0s - loss: 22.2220 - val_loss: 17.7225

Epoch 00046: val_loss improved from 17.75909 to 17.72250, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 47/10000
4/4 - 0s - loss: 22.2074 - val_loss: 17.7144

Epoch 00047: val_loss improved from 17.72250 to 17.71436, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 48/10000
4/4 - 0s - loss: 22.1990 - val_loss: 17.7388

Epoch 00048: val_loss did not improve from 17.71436
Epoch 49/10000
4/4 - 0s - loss: 22.1850 - val_loss: 17.7178

Epoch 00049: val_loss did not improve from 17.71436
Epoch 50/10000
4/4 - 0s - loss: 22.1750 - val_loss: 17.7175

Epoch 00050: val_loss did not improve from 17.71436
Epoch 51/10000
4/4 - 0s - loss: 22.1709 - val_loss: 17.7235

Epoch 00051: val_loss did not improve from 17.71436
Epoch 52/10000
4/4 - 0s - loss: 22.1631 - val_loss: 17.6997

Epoch 00052: val_loss improved from 17.71436 to 17.69971, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 53/10000
4/4 - 0s - loss: 22.1584 - val_loss: 17.6913

Epoch 00053: val_loss improved from 17.69971 to 17.69126, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 54/10000
4/4 - 0s - loss: 22.1542 - val_loss: 17.7012

Epoch 00054: val_loss did not improve from 17.69126
Epoch 55/10000
4/4 - 0s - loss: 22.1570 - val_loss: 17.7430

Epoch 00055: val_loss did not improve from 17.69126
Epoch 56/10000
4/4 - 0s - loss: 22.1738 - val_loss: 17.6898

Epoch 00056: val_loss improved from 17.69126 to 17.68977, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 57/10000
4/4 - 0s - loss: 22.1467 - val_loss: 17.6833

Epoch 00057: val_loss improved from 17.68977 to 17.68328, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 58/10000
4/4 - 0s - loss: 22.1479 - val_loss: 17.6871

Epoch 00058: val_loss did not improve from 17.68328
Epoch 59/10000
4/4 - 0s - loss: 22.1448 - val_loss: 17.6944

Epoch 00059: val_loss did not improve from 17.68328
Epoch 60/10000
4/4 - 0s - loss: 22.1422 - val_loss: 17.7027

Epoch 00060: val_loss did not improve from 17.68328
Epoch 61/10000
4/4 - 0s - loss: 22.1402 - val_loss: 17.7016

Epoch 00061: val_loss did not improve from 17.68328
Epoch 62/10000
4/4 - 0s - loss: 22.1399 - val_loss: 17.7049

Epoch 00062: val_loss did not improve from 17.68328
Epoch 63/10000
4/4 - 0s - loss: 22.1400 - val_loss: 17.6990

Epoch 00063: val_loss did not improve from 17.68328
Epoch 64/10000
4/4 - 0s - loss: 22.1477 - val_loss: 17.6948

Epoch 00064: val_loss did not improve from 17.68328
Epoch 65/10000
4/4 - 0s - loss: 22.1414 - val_loss: 17.6863

Epoch 00065: val_loss did not improve from 17.68328
Epoch 66/10000
4/4 - 0s - loss: 22.1394 - val_loss: 17.6975

Epoch 00066: val_loss did not improve from 17.68328
Epoch 67/10000
4/4 - 0s - loss: 22.1404 - val_loss: 17.7296

Epoch 00067: val_loss did not improve from 17.68328
Epoch 68/10000
4/4 - 0s - loss: 22.1383 - val_loss: 17.7102

Epoch 00068: val_loss did not improve from 17.68328
Epoch 69/10000
4/4 - 0s - loss: 22.1367 - val_loss: 17.7030

Epoch 00069: val_loss did not improve from 17.68328
Epoch 70/10000
4/4 - 0s - loss: 22.1405 - val_loss: 17.7096

Epoch 00070: val_loss did not improve from 17.68328
Epoch 71/10000
4/4 - 0s - loss: 22.1367 - val_loss: 17.6942

Epoch 00071: val_loss did not improve from 17.68328
Epoch 72/10000
4/4 - 0s - loss: 22.1471 - val_loss: 17.6912

Epoch 00072: val_loss did not improve from 17.68328
Epoch 73/10000
4/4 - 0s - loss: 22.1404 - val_loss: 17.7126

Epoch 00073: val_loss did not improve from 17.68328
Epoch 74/10000
4/4 - 0s - loss: 22.1525 - val_loss: 17.7236

Epoch 00074: val_loss did not improve from 17.68328
Epoch 75/10000
4/4 - 0s - loss: 22.1345 - val_loss: 17.6879

Epoch 00075: val_loss did not improve from 17.68328
Epoch 76/10000
4/4 - 0s - loss: 22.1411 - val_loss: 17.6847

Epoch 00076: val_loss did not improve from 17.68328
Epoch 77/10000
4/4 - 0s - loss: 22.1384 - val_loss: 17.6966

Epoch 00077: val_loss did not improve from 17.68328
Epoch 78/10000
4/4 - 0s - loss: 22.1376 - val_loss: 17.7183

Epoch 00078: val_loss did not improve from 17.68328
Epoch 79/10000
4/4 - 0s - loss: 22.1378 - val_loss: 17.7013

Epoch 00079: val_loss did not improve from 17.68328
Epoch 80/10000
4/4 - 0s - loss: 22.1364 - val_loss: 17.6966

Epoch 00080: val_loss did not improve from 17.68328
Epoch 81/10000
4/4 - 0s - loss: 22.1489 - val_loss: 17.6892

Epoch 00081: val_loss did not improve from 17.68328
Epoch 82/10000
4/4 - 0s - loss: 22.1467 - val_loss: 17.7194

Epoch 00082: val_loss did not improve from 17.68328
Epoch 83/10000
4/4 - 0s - loss: 22.1385 - val_loss: 17.7141

Epoch 00083: val_loss did not improve from 17.68328
Epoch 84/10000
4/4 - 0s - loss: 22.1361 - val_loss: 17.7042

Epoch 00084: val_loss did not improve from 17.68328
Epoch 85/10000
4/4 - 0s - loss: 22.1384 - val_loss: 17.6951

Epoch 00085: val_loss did not improve from 17.68328
Epoch 86/10000
4/4 - 0s - loss: 22.1372 - val_loss: 17.7147

Epoch 00086: val_loss did not improve from 17.68328
Epoch 87/10000
4/4 - 0s - loss: 22.1501 - val_loss: 17.7377

Epoch 00087: val_loss did not improve from 17.68328
Epoch 88/10000
4/4 - 0s - loss: 22.1411 - val_loss: 17.6970

Epoch 00088: val_loss did not improve from 17.68328
Epoch 89/10000
4/4 - 0s - loss: 22.1493 - val_loss: 17.6842

Epoch 00089: val_loss did not improve from 17.68328
Epoch 90/10000
4/4 - 0s - loss: 22.1430 - val_loss: 17.7292

Epoch 00090: val_loss did not improve from 17.68328
Epoch 91/10000
4/4 - 0s - loss: 22.1692 - val_loss: 17.7208

Epoch 00091: val_loss did not improve from 17.68328
Epoch 92/10000
4/4 - 0s - loss: 22.1320 - val_loss: 17.6856

Epoch 00092: val_loss did not improve from 17.68328
Epoch 93/10000
4/4 - 0s - loss: 22.1411 - val_loss: 17.6867

Epoch 00093: val_loss did not improve from 17.68328
Epoch 94/10000
4/4 - 0s - loss: 22.1405 - val_loss: 17.6965

Epoch 00094: val_loss did not improve from 17.68328
Epoch 95/10000
4/4 - 0s - loss: 22.1361 - val_loss: 17.7319

Epoch 00095: val_loss did not improve from 17.68328
Epoch 96/10000
4/4 - 0s - loss: 22.1423 - val_loss: 17.7196

Epoch 00096: val_loss did not improve from 17.68328
Epoch 97/10000
4/4 - 0s - loss: 22.1667 - val_loss: 17.6874

Epoch 00097: val_loss did not improve from 17.68328
Epoch 98/10000
4/4 - 0s - loss: 22.1427 - val_loss: 17.7153

Epoch 00098: val_loss did not improve from 17.68328
Epoch 99/10000
4/4 - 0s - loss: 22.1355 - val_loss: 17.7103

Epoch 00099: val_loss did not improve from 17.68328
Epoch 100/10000
4/4 - 0s - loss: 22.1385 - val_loss: 17.7033

Epoch 00100: val_loss did not improve from 17.68328
Epoch 101/10000
4/4 - 0s - loss: 22.1345 - val_loss: 17.6906

Epoch 00101: val_loss did not improve from 17.68328
Epoch 102/10000
4/4 - 0s - loss: 22.1514 - val_loss: 17.6873

Epoch 00102: val_loss did not improve from 17.68328
Epoch 103/10000
4/4 - 0s - loss: 22.1436 - val_loss: 17.7122

Epoch 00103: val_loss did not improve from 17.68328
Epoch 104/10000
4/4 - 0s - loss: 22.1398 - val_loss: 17.7129

Epoch 00104: val_loss did not improve from 17.68328
Epoch 105/10000
4/4 - 0s - loss: 22.1355 - val_loss: 17.6997

Epoch 00105: val_loss did not improve from 17.68328
Epoch 106/10000
4/4 - 0s - loss: 22.1363 - val_loss: 17.6878

Epoch 00106: val_loss did not improve from 17.68328
Epoch 107/10000
4/4 - 0s - loss: 22.1393 - val_loss: 17.7032

Epoch 00107: val_loss did not improve from 17.68328
Epoch 108/10000
4/4 - 0s - loss: 22.1326 - val_loss: 17.7440

Epoch 00108: val_loss did not improve from 17.68328
Epoch 109/10000
4/4 - 0s - loss: 22.1489 - val_loss: 17.7329

Epoch 00109: val_loss did not improve from 17.68328
Epoch 110/10000
4/4 - 0s - loss: 22.1374 - val_loss: 17.7000

Epoch 00110: val_loss did not improve from 17.68328
Epoch 111/10000
4/4 - 0s - loss: 22.1357 - val_loss: 17.6791

Epoch 00111: val_loss improved from 17.68328 to 17.67915, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 112/10000
4/4 - 0s - loss: 22.1526 - val_loss: 17.6822

Epoch 00112: val_loss did not improve from 17.67915
Epoch 113/10000
4/4 - 0s - loss: 22.1551 - val_loss: 17.7410

Epoch 00113: val_loss did not improve from 17.67915
Epoch 114/10000
4/4 - 0s - loss: 22.1418 - val_loss: 17.7017

Epoch 00114: val_loss did not improve from 17.67915
Epoch 115/10000
4/4 - 0s - loss: 22.1459 - val_loss: 17.6918

Epoch 00115: val_loss did not improve from 17.67915
Epoch 116/10000
4/4 - 0s - loss: 22.1363 - val_loss: 17.7139

Epoch 00116: val_loss did not improve from 17.67915
Epoch 117/10000
4/4 - 0s - loss: 22.1548 - val_loss: 17.7594

Epoch 00117: val_loss did not improve from 17.67915
Epoch 118/10000
4/4 - 0s - loss: 22.1404 - val_loss: 17.6961

Epoch 00118: val_loss did not improve from 17.67915
Epoch 119/10000
4/4 - 0s - loss: 22.1484 - val_loss: 17.6855

Epoch 00119: val_loss did not improve from 17.67915
Epoch 120/10000
4/4 - 0s - loss: 22.1582 - val_loss: 17.7283

Epoch 00120: val_loss did not improve from 17.67915
Epoch 121/10000
4/4 - 0s - loss: 22.1392 - val_loss: 17.7114

Epoch 00121: val_loss did not improve from 17.67915
Epoch 122/10000
4/4 - 0s - loss: 22.1439 - val_loss: 17.6949

Epoch 00122: val_loss did not improve from 17.67915
Epoch 123/10000
4/4 - 0s - loss: 22.1406 - val_loss: 17.7345

Epoch 00123: val_loss did not improve from 17.67915
Epoch 124/10000
4/4 - 0s - loss: 22.1409 - val_loss: 17.7249

Epoch 00124: val_loss did not improve from 17.67915
Epoch 125/10000
4/4 - 0s - loss: 22.1431 - val_loss: 17.6984

Epoch 00125: val_loss did not improve from 17.67915
Epoch 126/10000
4/4 - 0s - loss: 22.1377 - val_loss: 17.6969

Epoch 00126: val_loss did not improve from 17.67915
Epoch 127/10000
4/4 - 0s - loss: 22.1359 - val_loss: 17.7147

Epoch 00127: val_loss did not improve from 17.67915
Epoch 128/10000
4/4 - 0s - loss: 22.1349 - val_loss: 17.7378

Epoch 00128: val_loss did not improve from 17.67915
Epoch 129/10000
4/4 - 0s - loss: 22.1502 - val_loss: 17.7137

Epoch 00129: val_loss did not improve from 17.67915
Epoch 130/10000
4/4 - 0s - loss: 22.1339 - val_loss: 17.6833

Epoch 00130: val_loss did not improve from 17.67915
Epoch 131/10000
4/4 - 0s - loss: 22.1749 - val_loss: 17.6831

Epoch 00131: val_loss did not improve from 17.67915
Epoch 132/10000
4/4 - 0s - loss: 22.1511 - val_loss: 17.7441

Epoch 00132: val_loss did not improve from 17.67915
Epoch 133/10000
4/4 - 0s - loss: 22.1481 - val_loss: 17.7449

Epoch 00133: val_loss did not improve from 17.67915
Epoch 134/10000
4/4 - 0s - loss: 22.1462 - val_loss: 17.7031

Epoch 00134: val_loss did not improve from 17.67915
Epoch 135/10000
4/4 - 0s - loss: 22.1348 - val_loss: 17.6950

Epoch 00135: val_loss did not improve from 17.67915
Epoch 136/10000
4/4 - 0s - loss: 22.1441 - val_loss: 17.6991

Epoch 00136: val_loss did not improve from 17.67915
Epoch 137/10000
4/4 - 0s - loss: 22.1362 - val_loss: 17.7547

Epoch 00137: val_loss did not improve from 17.67915
Epoch 138/10000
4/4 - 0s - loss: 22.1503 - val_loss: 17.7533

Epoch 00138: val_loss did not improve from 17.67915
Epoch 139/10000
4/4 - 0s - loss: 22.1506 - val_loss: 17.7042

Epoch 00139: val_loss did not improve from 17.67915
Epoch 140/10000
4/4 - 0s - loss: 22.1359 - val_loss: 17.6819

Epoch 00140: val_loss did not improve from 17.67915
Epoch 141/10000
4/4 - 0s - loss: 22.1507 - val_loss: 17.6824

Epoch 00141: val_loss did not improve from 17.67915
Epoch 142/10000
4/4 - 0s - loss: 22.1412 - val_loss: 17.7557

Epoch 00142: val_loss did not improve from 17.67915
Epoch 143/10000
4/4 - 0s - loss: 22.1534 - val_loss: 17.7305

Epoch 00143: val_loss did not improve from 17.67915
Epoch 144/10000
4/4 - 0s - loss: 22.1509 - val_loss: 17.6798

Epoch 00144: val_loss did not improve from 17.67915
Epoch 145/10000
4/4 - 0s - loss: 22.1454 - val_loss: 17.6924

Epoch 00145: val_loss did not improve from 17.67915
Epoch 146/10000
4/4 - 0s - loss: 22.1526 - val_loss: 17.7420

Epoch 00146: val_loss did not improve from 17.67915
Epoch 147/10000
4/4 - 0s - loss: 22.1538 - val_loss: 17.6958

Epoch 00147: val_loss did not improve from 17.67915
Epoch 148/10000
4/4 - 0s - loss: 22.1375 - val_loss: 17.6936

Epoch 00148: val_loss did not improve from 17.67915
Epoch 149/10000
4/4 - 0s - loss: 22.1451 - val_loss: 17.7177

Epoch 00149: val_loss did not improve from 17.67915
Epoch 150/10000
4/4 - 0s - loss: 22.1338 - val_loss: 17.6961

Epoch 00150: val_loss did not improve from 17.67915
Epoch 151/10000
4/4 - 0s - loss: 22.1439 - val_loss: 17.7012

Epoch 00151: val_loss did not improve from 17.67915
Epoch 152/10000
4/4 - 0s - loss: 22.1365 - val_loss: 17.7072

Epoch 00152: val_loss did not improve from 17.67915
Epoch 153/10000
4/4 - 0s - loss: 22.1385 - val_loss: 17.7021

Epoch 00153: val_loss did not improve from 17.67915
Epoch 154/10000
4/4 - 0s - loss: 22.1410 - val_loss: 17.7322

Epoch 00154: val_loss did not improve from 17.67915
Epoch 155/10000
4/4 - 0s - loss: 22.1440 - val_loss: 17.7038

Epoch 00155: val_loss did not improve from 17.67915
Epoch 156/10000
4/4 - 0s - loss: 22.1358 - val_loss: 17.6982

Epoch 00156: val_loss did not improve from 17.67915
Epoch 157/10000
4/4 - 0s - loss: 22.1366 - val_loss: 17.6931

Epoch 00157: val_loss did not improve from 17.67915
Epoch 158/10000
4/4 - 0s - loss: 22.1515 - val_loss: 17.6884

Epoch 00158: val_loss did not improve from 17.67915
Epoch 159/10000
4/4 - 0s - loss: 22.1371 - val_loss: 17.7158

Epoch 00159: val_loss did not improve from 17.67915
Epoch 160/10000
4/4 - 0s - loss: 22.1491 - val_loss: 17.7307

Epoch 00160: val_loss did not improve from 17.67915
Epoch 161/10000
4/4 - 0s - loss: 22.1490 - val_loss: 17.6878

Epoch 00161: val_loss did not improve from 17.67915
Epoch 162/10000
4/4 - 0s - loss: 22.1370 - val_loss: 17.7040

Epoch 00162: val_loss did not improve from 17.67915
Epoch 163/10000
4/4 - 0s - loss: 22.1517 - val_loss: 17.7400

Epoch 00163: val_loss did not improve from 17.67915
Epoch 164/10000
4/4 - 0s - loss: 22.1461 - val_loss: 17.7116

Epoch 00164: val_loss did not improve from 17.67915
Epoch 165/10000
4/4 - 0s - loss: 22.1347 - val_loss: 17.6882

Epoch 00165: val_loss did not improve from 17.67915
Epoch 166/10000
4/4 - 0s - loss: 22.1395 - val_loss: 17.6899

Epoch 00166: val_loss did not improve from 17.67915
Epoch 167/10000
4/4 - 0s - loss: 22.1414 - val_loss: 17.6847

Epoch 00167: val_loss did not improve from 17.67915
Epoch 168/10000
4/4 - 0s - loss: 22.1473 - val_loss: 17.7252

Epoch 00168: val_loss did not improve from 17.67915
Epoch 169/10000
4/4 - 0s - loss: 22.1493 - val_loss: 17.7318

Epoch 00169: val_loss did not improve from 17.67915
Epoch 170/10000
4/4 - 0s - loss: 22.1376 - val_loss: 17.6971

Epoch 00170: val_loss did not improve from 17.67915
Epoch 171/10000
4/4 - 0s - loss: 22.1708 - val_loss: 17.6800

Epoch 00171: val_loss did not improve from 17.67915
Epoch 172/10000
4/4 - 0s - loss: 22.1598 - val_loss: 17.7510

Epoch 00172: val_loss did not improve from 17.67915
Epoch 173/10000
4/4 - 0s - loss: 22.1510 - val_loss: 17.7207

Epoch 00173: val_loss did not improve from 17.67915
Epoch 174/10000
4/4 - 0s - loss: 22.1494 - val_loss: 17.7156

Epoch 00174: val_loss did not improve from 17.67915
Epoch 175/10000
4/4 - 0s - loss: 22.1448 - val_loss: 17.6819

Epoch 00175: val_loss did not improve from 17.67915
Epoch 176/10000
4/4 - 0s - loss: 22.1484 - val_loss: 17.6953

Epoch 00176: val_loss did not improve from 17.67915
Epoch 177/10000
4/4 - 0s - loss: 22.1356 - val_loss: 17.7612

Epoch 00177: val_loss did not improve from 17.67915
Epoch 178/10000
4/4 - 0s - loss: 22.1551 - val_loss: 17.7127

Epoch 00178: val_loss did not improve from 17.67915
Epoch 179/10000
4/4 - 0s - loss: 22.1473 - val_loss: 17.6907

Epoch 00179: val_loss did not improve from 17.67915
Epoch 180/10000
4/4 - 0s - loss: 22.1415 - val_loss: 17.7107

Epoch 00180: val_loss did not improve from 17.67915
Epoch 181/10000
4/4 - 0s - loss: 22.1335 - val_loss: 17.6896

Epoch 00181: val_loss did not improve from 17.67915
Epoch 182/10000
4/4 - 0s - loss: 22.1404 - val_loss: 17.6833

Epoch 00182: val_loss did not improve from 17.67915
Epoch 183/10000
4/4 - 0s - loss: 22.1441 - val_loss: 17.6938

Epoch 00183: val_loss did not improve from 17.67915
Epoch 184/10000
4/4 - 0s - loss: 22.1480 - val_loss: 17.6940

Epoch 00184: val_loss did not improve from 17.67915
Epoch 185/10000
4/4 - 0s - loss: 22.1478 - val_loss: 17.7459

Epoch 00185: val_loss did not improve from 17.67915
Epoch 186/10000
4/4 - 0s - loss: 22.1394 - val_loss: 17.7002

Epoch 00186: val_loss did not improve from 17.67915
Epoch 187/10000
4/4 - 0s - loss: 22.1394 - val_loss: 17.6857

Epoch 00187: val_loss did not improve from 17.67915
Epoch 188/10000
4/4 - 0s - loss: 22.1452 - val_loss: 17.6998

Epoch 00188: val_loss did not improve from 17.67915
Epoch 189/10000
4/4 - 0s - loss: 22.1403 - val_loss: 17.7276

Epoch 00189: val_loss did not improve from 17.67915
Epoch 190/10000
4/4 - 0s - loss: 22.1362 - val_loss: 17.7080

Epoch 00190: val_loss did not improve from 17.67915
Epoch 191/10000
4/4 - 0s - loss: 22.1373 - val_loss: 17.6985

Epoch 00191: val_loss did not improve from 17.67915
Epoch 192/10000
4/4 - 0s - loss: 22.1364 - val_loss: 17.7138

Epoch 00192: val_loss did not improve from 17.67915
Epoch 193/10000
4/4 - 0s - loss: 22.1368 - val_loss: 17.7233

Epoch 00193: val_loss did not improve from 17.67915
Epoch 194/10000
4/4 - 0s - loss: 22.1364 - val_loss: 17.7022

Epoch 00194: val_loss did not improve from 17.67915
Epoch 195/10000
4/4 - 0s - loss: 22.1373 - val_loss: 17.6865

Epoch 00195: val_loss did not improve from 17.67915
Epoch 196/10000
4/4 - 0s - loss: 22.1378 - val_loss: 17.7030

Epoch 00196: val_loss did not improve from 17.67915
Epoch 197/10000
4/4 - 0s - loss: 22.1373 - val_loss: 17.7374

Epoch 00197: val_loss did not improve from 17.67915
Epoch 198/10000
4/4 - 0s - loss: 22.1396 - val_loss: 17.7035

Epoch 00198: val_loss did not improve from 17.67915
Epoch 199/10000
4/4 - 0s - loss: 22.1289 - val_loss: 17.6806

Epoch 00199: val_loss did not improve from 17.67915
Epoch 200/10000
4/4 - 0s - loss: 22.1723 - val_loss: 17.6815

Epoch 00200: val_loss did not improve from 17.67915
Epoch 201/10000
4/4 - 0s - loss: 22.1353 - val_loss: 17.7272

Epoch 00201: val_loss did not improve from 17.67915
Epoch 202/10000
4/4 - 0s - loss: 22.1544 - val_loss: 17.7782

Epoch 00202: val_loss did not improve from 17.67915
Epoch 203/10000
4/4 - 0s - loss: 22.1487 - val_loss: 17.6999

Epoch 00203: val_loss did not improve from 17.67915
Epoch 204/10000
4/4 - 0s - loss: 22.1427 - val_loss: 17.6826

Epoch 00204: val_loss did not improve from 17.67915
Epoch 205/10000
4/4 - 0s - loss: 22.1545 - val_loss: 17.7143

Epoch 00205: val_loss did not improve from 17.67915
Epoch 206/10000
4/4 - 0s - loss: 22.1467 - val_loss: 17.7412

Epoch 00206: val_loss did not improve from 17.67915
Epoch 207/10000
4/4 - 0s - loss: 22.1403 - val_loss: 17.7090

Epoch 00207: val_loss did not improve from 17.67915
Epoch 208/10000
4/4 - 0s - loss: 22.1330 - val_loss: 17.6876

Epoch 00208: val_loss did not improve from 17.67915
Epoch 209/10000
4/4 - 0s - loss: 22.1479 - val_loss: 17.6981

Epoch 00209: val_loss did not improve from 17.67915
Epoch 210/10000
4/4 - 0s - loss: 22.1389 - val_loss: 17.6942

Epoch 00210: val_loss did not improve from 17.67915
Epoch 211/10000
4/4 - 0s - loss: 22.1354 - val_loss: 17.7119

Epoch 00211: val_loss did not improve from 17.67915
Epoch 212/10000
4/4 - 0s - loss: 22.1429 - val_loss: 17.7356

Epoch 00212: val_loss did not improve from 17.67915
Epoch 213/10000
4/4 - 0s - loss: 22.1406 - val_loss: 17.7013

Epoch 00213: val_loss did not improve from 17.67915
Epoch 214/10000
4/4 - 0s - loss: 22.1374 - val_loss: 17.6932

Epoch 00214: val_loss did not improve from 17.67915
Epoch 215/10000
4/4 - 0s - loss: 22.1471 - val_loss: 17.7193

Epoch 00215: val_loss did not improve from 17.67915
Epoch 216/10000
4/4 - 0s - loss: 22.1535 - val_loss: 17.6904

Epoch 00216: val_loss did not improve from 17.67915
Epoch 217/10000
4/4 - 0s - loss: 22.1367 - val_loss: 17.7318

Epoch 00217: val_loss did not improve from 17.67915
Epoch 218/10000
4/4 - 0s - loss: 22.1551 - val_loss: 17.7087

Epoch 00218: val_loss did not improve from 17.67915
Epoch 219/10000
4/4 - 0s - loss: 22.1379 - val_loss: 17.6736

Epoch 00219: val_loss improved from 17.67915 to 17.67357, saving model to ./results/dataset/trial_3/ckpt_5
Epoch 220/10000
4/4 - 0s - loss: 22.1608 - val_loss: 17.6803

Epoch 00220: val_loss did not improve from 17.67357
Epoch 221/10000
4/4 - 0s - loss: 22.1350 - val_loss: 17.7268

Epoch 00221: val_loss did not improve from 17.67357
Epoch 222/10000
4/4 - 0s - loss: 22.1489 - val_loss: 17.7408

Epoch 00222: val_loss did not improve from 17.67357
Epoch 223/10000
4/4 - 0s - loss: 22.1401 - val_loss: 17.6932

Epoch 00223: val_loss did not improve from 17.67357
Epoch 224/10000
4/4 - 0s - loss: 22.1565 - val_loss: 17.6824

Epoch 00224: val_loss did not improve from 17.67357
Epoch 225/10000
4/4 - 0s - loss: 22.1334 - val_loss: 17.7350

Epoch 00225: val_loss did not improve from 17.67357
Epoch 226/10000
4/4 - 0s - loss: 22.1440 - val_loss: 17.7357

Epoch 00226: val_loss did not improve from 17.67357
Epoch 227/10000
4/4 - 0s - loss: 22.1342 - val_loss: 17.6925

Epoch 00227: val_loss did not improve from 17.67357
Epoch 228/10000
4/4 - 0s - loss: 22.1741 - val_loss: 17.6793

Epoch 00228: val_loss did not improve from 17.67357
Epoch 229/10000
4/4 - 0s - loss: 22.1649 - val_loss: 17.7208

Epoch 00229: val_loss did not improve from 17.67357
Epoch 230/10000
4/4 - 0s - loss: 22.1479 - val_loss: 17.7344

Epoch 00230: val_loss did not improve from 17.67357
Epoch 231/10000
4/4 - 0s - loss: 22.1540 - val_loss: 17.6871

Epoch 00231: val_loss did not improve from 17.67357
Epoch 232/10000
4/4 - 0s - loss: 22.1477 - val_loss: 17.7152

Epoch 00232: val_loss did not improve from 17.67357
Epoch 233/10000
4/4 - 0s - loss: 22.1338 - val_loss: 17.7000

Epoch 00233: val_loss did not improve from 17.67357
Epoch 234/10000
4/4 - 0s - loss: 22.1408 - val_loss: 17.7059

Epoch 00234: val_loss did not improve from 17.67357
Epoch 235/10000
4/4 - 0s - loss: 22.1392 - val_loss: 17.6963

Epoch 00235: val_loss did not improve from 17.67357
Epoch 236/10000
4/4 - 0s - loss: 22.1435 - val_loss: 17.6987

Epoch 00236: val_loss did not improve from 17.67357
Epoch 237/10000
4/4 - 0s - loss: 22.1415 - val_loss: 17.7171

Epoch 00237: val_loss did not improve from 17.67357
Epoch 238/10000
4/4 - 0s - loss: 22.1351 - val_loss: 17.7063

Epoch 00238: val_loss did not improve from 17.67357
Epoch 239/10000
4/4 - 0s - loss: 22.1444 - val_loss: 17.6972

Epoch 00239: val_loss did not improve from 17.67357
Epoch 240/10000
4/4 - 0s - loss: 22.1392 - val_loss: 17.7058

Epoch 00240: val_loss did not improve from 17.67357
Epoch 241/10000
4/4 - 0s - loss: 22.1369 - val_loss: 17.7464

Epoch 00241: val_loss did not improve from 17.67357
Epoch 242/10000
4/4 - 0s - loss: 22.1463 - val_loss: 17.7260

Epoch 00242: val_loss did not improve from 17.67357
Epoch 243/10000
4/4 - 0s - loss: 22.1426 - val_loss: 17.6870

Epoch 00243: val_loss did not improve from 17.67357
Epoch 244/10000
4/4 - 0s - loss: 22.1414 - val_loss: 17.6932

Epoch 00244: val_loss did not improve from 17.67357
Epoch 245/10000
4/4 - 0s - loss: 22.1364 - val_loss: 17.7173

Epoch 00245: val_loss did not improve from 17.67357
Epoch 246/10000
4/4 - 0s - loss: 22.1431 - val_loss: 17.7169

Epoch 00246: val_loss did not improve from 17.67357
Epoch 247/10000
4/4 - 0s - loss: 22.1325 - val_loss: 17.6887

Epoch 00247: val_loss did not improve from 17.67357
Epoch 248/10000
4/4 - 0s - loss: 22.1430 - val_loss: 17.6942

Epoch 00248: val_loss did not improve from 17.67357
Epoch 249/10000
4/4 - 0s - loss: 22.1415 - val_loss: 17.7402

Epoch 00249: val_loss did not improve from 17.67357
Epoch 250/10000
4/4 - 0s - loss: 22.1623 - val_loss: 17.7202

Epoch 00250: val_loss did not improve from 17.67357
Epoch 251/10000
4/4 - 0s - loss: 22.1299 - val_loss: 17.6783

Epoch 00251: val_loss did not improve from 17.67357
Epoch 252/10000
4/4 - 0s - loss: 22.1603 - val_loss: 17.6834

Epoch 00252: val_loss did not improve from 17.67357
Epoch 253/10000
4/4 - 0s - loss: 22.1439 - val_loss: 17.7019

Epoch 00253: val_loss did not improve from 17.67357
Epoch 254/10000
4/4 - 0s - loss: 22.1354 - val_loss: 17.7041

Epoch 00254: val_loss did not improve from 17.67357
Epoch 255/10000
4/4 - 0s - loss: 22.1429 - val_loss: 17.7037

Epoch 00255: val_loss did not improve from 17.67357
Epoch 256/10000
4/4 - 0s - loss: 22.1353 - val_loss: 17.6900

Epoch 00256: val_loss did not improve from 17.67357
Epoch 257/10000
4/4 - 0s - loss: 22.1407 - val_loss: 17.6977

Epoch 00257: val_loss did not improve from 17.67357
Epoch 258/10000
4/4 - 0s - loss: 22.1433 - val_loss: 17.7203

Epoch 00258: val_loss did not improve from 17.67357
Epoch 259/10000
4/4 - 0s - loss: 22.1347 - val_loss: 17.7017

Epoch 00259: val_loss did not improve from 17.67357
Epoch 260/10000
4/4 - 0s - loss: 22.1622 - val_loss: 17.6845

Epoch 00260: val_loss did not improve from 17.67357
Epoch 261/10000
4/4 - 0s - loss: 22.1536 - val_loss: 17.7384

Epoch 00261: val_loss did not improve from 17.67357
Epoch 262/10000
4/4 - 0s - loss: 22.1530 - val_loss: 17.6938

Epoch 00262: val_loss did not improve from 17.67357
Epoch 263/10000
4/4 - 0s - loss: 22.1445 - val_loss: 17.7090

Epoch 00263: val_loss did not improve from 17.67357
Epoch 264/10000
4/4 - 0s - loss: 22.1393 - val_loss: 17.6916

Epoch 00264: val_loss did not improve from 17.67357
Epoch 265/10000
4/4 - 0s - loss: 22.1386 - val_loss: 17.7115

Epoch 00265: val_loss did not improve from 17.67357
Epoch 266/10000
4/4 - 0s - loss: 22.1352 - val_loss: 17.7071

Epoch 00266: val_loss did not improve from 17.67357
Epoch 267/10000
4/4 - 0s - loss: 22.1398 - val_loss: 17.7126

Epoch 00267: val_loss did not improve from 17.67357
Epoch 268/10000
4/4 - 0s - loss: 22.1364 - val_loss: 17.6936

Epoch 00268: val_loss did not improve from 17.67357
Epoch 269/10000
4/4 - 0s - loss: 22.1506 - val_loss: 17.7073

Epoch 00269: val_loss did not improve from 17.67357
Epoch 270/10000
4/4 - 0s - loss: 22.1422 - val_loss: 17.6865

Epoch 00270: val_loss did not improve from 17.67357
Epoch 271/10000
4/4 - 0s - loss: 22.1463 - val_loss: 17.6986

Epoch 00271: val_loss did not improve from 17.67357
Epoch 272/10000
4/4 - 0s - loss: 22.1813 - val_loss: 17.7426

Epoch 00272: val_loss did not improve from 17.67357
Epoch 273/10000
4/4 - 0s - loss: 22.1315 - val_loss: 17.6903

Epoch 00273: val_loss did not improve from 17.67357
Epoch 274/10000
4/4 - 0s - loss: 22.1700 - val_loss: 17.6860

Epoch 00274: val_loss did not improve from 17.67357
Epoch 275/10000
4/4 - 0s - loss: 22.1413 - val_loss: 17.7653

Epoch 00275: val_loss did not improve from 17.67357
Epoch 276/10000
4/4 - 0s - loss: 22.1516 - val_loss: 17.7263

Epoch 00276: val_loss did not improve from 17.67357
Epoch 277/10000
4/4 - 0s - loss: 22.1465 - val_loss: 17.6891

Epoch 00277: val_loss did not improve from 17.67357
Epoch 278/10000
4/4 - 0s - loss: 22.1371 - val_loss: 17.7042

Epoch 00278: val_loss did not improve from 17.67357
Epoch 279/10000
4/4 - 0s - loss: 22.1373 - val_loss: 17.6979

Epoch 00279: val_loss did not improve from 17.67357
Epoch 280/10000
4/4 - 0s - loss: 22.1395 - val_loss: 17.7030

Epoch 00280: val_loss did not improve from 17.67357
Epoch 281/10000
4/4 - 0s - loss: 22.1370 - val_loss: 17.6851

Epoch 00281: val_loss did not improve from 17.67357
Epoch 282/10000
4/4 - 0s - loss: 22.1398 - val_loss: 17.6913

Epoch 00282: val_loss did not improve from 17.67357
Epoch 283/10000
4/4 - 0s - loss: 22.1445 - val_loss: 17.7278

Epoch 00283: val_loss did not improve from 17.67357
Epoch 284/10000
4/4 - 0s - loss: 22.1458 - val_loss: 17.7014

Epoch 00284: val_loss did not improve from 17.67357
Epoch 285/10000
4/4 - 0s - loss: 22.1409 - val_loss: 17.7006

Epoch 00285: val_loss did not improve from 17.67357
Epoch 286/10000
4/4 - 0s - loss: 22.1402 - val_loss: 17.7064

Epoch 00286: val_loss did not improve from 17.67357
Epoch 287/10000
4/4 - 0s - loss: 22.1353 - val_loss: 17.6996

Epoch 00287: val_loss did not improve from 17.67357
Epoch 288/10000
4/4 - 0s - loss: 22.1355 - val_loss: 17.7119

Epoch 00288: val_loss did not improve from 17.67357
Epoch 289/10000
4/4 - 0s - loss: 22.1449 - val_loss: 17.7040

Epoch 00289: val_loss did not improve from 17.67357
Epoch 290/10000
4/4 - 0s - loss: 22.1417 - val_loss: 17.7045

Epoch 00290: val_loss did not improve from 17.67357
Epoch 291/10000
4/4 - 0s - loss: 22.1376 - val_loss: 17.7356

Epoch 00291: val_loss did not improve from 17.67357
Epoch 292/10000
4/4 - 0s - loss: 22.1496 - val_loss: 17.7348

Epoch 00292: val_loss did not improve from 17.67357
Epoch 293/10000
4/4 - 0s - loss: 22.1350 - val_loss: 17.6856

Epoch 00293: val_loss did not improve from 17.67357
Epoch 294/10000
4/4 - 0s - loss: 22.1435 - val_loss: 17.6856

Epoch 00294: val_loss did not improve from 17.67357
Epoch 295/10000
4/4 - 0s - loss: 22.1365 - val_loss: 17.7108

Epoch 00295: val_loss did not improve from 17.67357
Epoch 296/10000
4/4 - 0s - loss: 22.1376 - val_loss: 17.7196

Epoch 00296: val_loss did not improve from 17.67357
Epoch 297/10000
4/4 - 0s - loss: 22.1458 - val_loss: 17.7040

Epoch 00297: val_loss did not improve from 17.67357
Epoch 298/10000
4/4 - 0s - loss: 22.1363 - val_loss: 17.6998

Epoch 00298: val_loss did not improve from 17.67357
Epoch 299/10000
4/4 - 0s - loss: 22.1419 - val_loss: 17.6872

Epoch 00299: val_loss did not improve from 17.67357
Epoch 300/10000
4/4 - 0s - loss: 22.1398 - val_loss: 17.6850

Epoch 00300: val_loss did not improve from 17.67357
Epoch 301/10000
4/4 - 0s - loss: 22.1342 - val_loss: 17.7141

Epoch 00301: val_loss did not improve from 17.67357
Epoch 302/10000
4/4 - 0s - loss: 22.1547 - val_loss: 17.7270

Epoch 00302: val_loss did not improve from 17.67357
Epoch 303/10000
4/4 - 0s - loss: 22.1491 - val_loss: 17.6760

Epoch 00303: val_loss did not improve from 17.67357
Epoch 304/10000
4/4 - 0s - loss: 22.1574 - val_loss: 17.6929

Epoch 00304: val_loss did not improve from 17.67357
Epoch 305/10000
4/4 - 0s - loss: 22.1369 - val_loss: 17.6968

Epoch 00305: val_loss did not improve from 17.67357
Epoch 306/10000
4/4 - 0s - loss: 22.1434 - val_loss: 17.6994

Epoch 00306: val_loss did not improve from 17.67357
Epoch 307/10000
4/4 - 0s - loss: 22.1311 - val_loss: 17.7575

Epoch 00307: val_loss did not improve from 17.67357
Epoch 308/10000
4/4 - 0s - loss: 22.1668 - val_loss: 17.7431

Epoch 00308: val_loss did not improve from 17.67357
Epoch 309/10000
4/4 - 0s - loss: 22.1533 - val_loss: 17.6755

Epoch 00309: val_loss did not improve from 17.67357
Epoch 310/10000
4/4 - 0s - loss: 22.1494 - val_loss: 17.6900

Epoch 00310: val_loss did not improve from 17.67357
Epoch 311/10000
4/4 - 0s - loss: 22.1327 - val_loss: 17.7382

Epoch 00311: val_loss did not improve from 17.67357
Epoch 312/10000
4/4 - 0s - loss: 22.1459 - val_loss: 17.7141

Epoch 00312: val_loss did not improve from 17.67357
Epoch 313/10000
4/4 - 0s - loss: 22.1359 - val_loss: 17.6961

Epoch 00313: val_loss did not improve from 17.67357
Epoch 314/10000
4/4 - 0s - loss: 22.1367 - val_loss: 17.7014

Epoch 00314: val_loss did not improve from 17.67357
Epoch 315/10000
4/4 - 0s - loss: 22.1353 - val_loss: 17.7079

Epoch 00315: val_loss did not improve from 17.67357
Epoch 316/10000
4/4 - 0s - loss: 22.1351 - val_loss: 17.6987

Epoch 00316: val_loss did not improve from 17.67357
Epoch 317/10000
4/4 - 0s - loss: 22.1381 - val_loss: 17.7095

Epoch 00317: val_loss did not improve from 17.67357
Epoch 318/10000
4/4 - 0s - loss: 22.1351 - val_loss: 17.7035

Epoch 00318: val_loss did not improve from 17.67357
Epoch 319/10000
4/4 - 0s - loss: 22.1407 - val_loss: 17.6926

Epoch 00319: val_loss did not improve from 17.67357
Epoch 320/10000
4/4 - 0s - loss: 22.1433 - val_loss: 17.7059

Epoch 00320: val_loss did not improve from 17.67357
Epoch 321/10000
4/4 - 0s - loss: 22.1380 - val_loss: 17.7170

Epoch 00321: val_loss did not improve from 17.67357
Epoch 322/10000
4/4 - 0s - loss: 22.1385 - val_loss: 17.7358

Epoch 00322: val_loss did not improve from 17.67357
Epoch 323/10000
4/4 - 0s - loss: 22.1570 - val_loss: 17.6944

Epoch 00323: val_loss did not improve from 17.67357
Epoch 324/10000
4/4 - 0s - loss: 22.1426 - val_loss: 17.7195

Epoch 00324: val_loss did not improve from 17.67357
Epoch 325/10000
4/4 - 0s - loss: 22.1404 - val_loss: 17.6982

Epoch 00325: val_loss did not improve from 17.67357
Epoch 326/10000
4/4 - 0s - loss: 22.1391 - val_loss: 17.6799

Epoch 00326: val_loss did not improve from 17.67357
Epoch 327/10000
4/4 - 0s - loss: 22.1423 - val_loss: 17.6995

Epoch 00327: val_loss did not improve from 17.67357
Epoch 328/10000
4/4 - 0s - loss: 22.1470 - val_loss: 17.7266

Epoch 00328: val_loss did not improve from 17.67357
Epoch 329/10000
4/4 - 0s - loss: 22.1377 - val_loss: 17.6927

Epoch 00329: val_loss did not improve from 17.67357
Epoch 330/10000
4/4 - 0s - loss: 22.1469 - val_loss: 17.6946

Epoch 00330: val_loss did not improve from 17.67357
Epoch 331/10000
4/4 - 0s - loss: 22.1463 - val_loss: 17.7720

Epoch 00331: val_loss did not improve from 17.67357
Epoch 332/10000
4/4 - 0s - loss: 22.1497 - val_loss: 17.7139

Epoch 00332: val_loss did not improve from 17.67357
Epoch 333/10000
4/4 - 0s - loss: 22.1304 - val_loss: 17.6774

Epoch 00333: val_loss did not improve from 17.67357
Epoch 334/10000
4/4 - 0s - loss: 22.1766 - val_loss: 17.6778

Epoch 00334: val_loss did not improve from 17.67357
Epoch 335/10000
4/4 - 0s - loss: 22.1419 - val_loss: 17.7282

Epoch 00335: val_loss did not improve from 17.67357
Epoch 336/10000
4/4 - 0s - loss: 22.1519 - val_loss: 17.7697

Epoch 00336: val_loss did not improve from 17.67357
Epoch 337/10000
4/4 - 0s - loss: 22.1479 - val_loss: 17.6913

Epoch 00337: val_loss did not improve from 17.67357
Epoch 338/10000
4/4 - 0s - loss: 22.1453 - val_loss: 17.6755

Epoch 00338: val_loss did not improve from 17.67357
Epoch 339/10000
4/4 - 0s - loss: 22.1447 - val_loss: 17.7005

Epoch 00339: val_loss did not improve from 17.67357
Epoch 340/10000
4/4 - 0s - loss: 22.1413 - val_loss: 17.7558

Epoch 00340: val_loss did not improve from 17.67357
Epoch 341/10000
4/4 - 0s - loss: 22.1423 - val_loss: 17.7079

Epoch 00341: val_loss did not improve from 17.67357
Epoch 342/10000
4/4 - 0s - loss: 22.1381 - val_loss: 17.6854

Epoch 00342: val_loss did not improve from 17.67357
Epoch 343/10000
4/4 - 0s - loss: 22.1480 - val_loss: 17.6981

Epoch 00343: val_loss did not improve from 17.67357
Epoch 344/10000
4/4 - 0s - loss: 22.1400 - val_loss: 17.7171

Epoch 00344: val_loss did not improve from 17.67357
Epoch 345/10000
4/4 - 0s - loss: 22.1356 - val_loss: 17.7372

Epoch 00345: val_loss did not improve from 17.67357
Epoch 346/10000
4/4 - 0s - loss: 22.1537 - val_loss: 17.7099

Epoch 00346: val_loss did not improve from 17.67357
Epoch 347/10000
4/4 - 0s - loss: 22.1352 - val_loss: 17.7317

Epoch 00347: val_loss did not improve from 17.67357
Epoch 348/10000
4/4 - 0s - loss: 22.1400 - val_loss: 17.7148

Epoch 00348: val_loss did not improve from 17.67357
Epoch 349/10000
4/4 - 0s - loss: 22.1359 - val_loss: 17.7188

Epoch 00349: val_loss did not improve from 17.67357
Epoch 350/10000
4/4 - 0s - loss: 22.1350 - val_loss: 17.7258

Epoch 00350: val_loss did not improve from 17.67357
Epoch 351/10000
4/4 - 0s - loss: 22.1379 - val_loss: 17.7105

Epoch 00351: val_loss did not improve from 17.67357
Epoch 352/10000
4/4 - 0s - loss: 22.1350 - val_loss: 17.6807

Epoch 00352: val_loss did not improve from 17.67357
Epoch 353/10000
4/4 - 0s - loss: 22.1654 - val_loss: 17.6825

Epoch 00353: val_loss did not improve from 17.67357
Epoch 354/10000
4/4 - 0s - loss: 22.1273 - val_loss: 17.7627

Epoch 00354: val_loss did not improve from 17.67357
Epoch 355/10000
4/4 - 0s - loss: 22.1553 - val_loss: 17.7468

Epoch 00355: val_loss did not improve from 17.67357
Epoch 356/10000
4/4 - 0s - loss: 22.1635 - val_loss: 17.6947

Epoch 00356: val_loss did not improve from 17.67357
Epoch 357/10000
4/4 - 0s - loss: 22.1357 - val_loss: 17.7104

Epoch 00357: val_loss did not improve from 17.67357
Epoch 358/10000
4/4 - 0s - loss: 22.1477 - val_loss: 17.7236

Epoch 00358: val_loss did not improve from 17.67357
Epoch 359/10000
4/4 - 0s - loss: 22.1372 - val_loss: 17.6966

Epoch 00359: val_loss did not improve from 17.67357
Epoch 360/10000
4/4 - 0s - loss: 22.1425 - val_loss: 17.6890

Epoch 00360: val_loss did not improve from 17.67357
Epoch 361/10000
4/4 - 0s - loss: 22.1360 - val_loss: 17.6982

Epoch 00361: val_loss did not improve from 17.67357
Epoch 362/10000
4/4 - 0s - loss: 22.1391 - val_loss: 17.7009

Epoch 00362: val_loss did not improve from 17.67357
Epoch 363/10000
4/4 - 0s - loss: 22.1434 - val_loss: 17.7383

Epoch 00363: val_loss did not improve from 17.67357
Epoch 364/10000
4/4 - 0s - loss: 22.1391 - val_loss: 17.6994

Epoch 00364: val_loss did not improve from 17.67357
Epoch 365/10000
4/4 - 0s - loss: 22.1484 - val_loss: 17.6756

Epoch 00365: val_loss did not improve from 17.67357
Epoch 366/10000
4/4 - 0s - loss: 22.1540 - val_loss: 17.6948

Epoch 00366: val_loss did not improve from 17.67357
Epoch 367/10000
4/4 - 0s - loss: 22.1400 - val_loss: 17.7056

Epoch 00367: val_loss did not improve from 17.67357
Epoch 368/10000
4/4 - 0s - loss: 22.1373 - val_loss: 17.6942

Epoch 00368: val_loss did not improve from 17.67357
Epoch 369/10000
4/4 - 0s - loss: 22.1418 - val_loss: 17.6864

Epoch 00369: val_loss did not improve from 17.67357
Epoch 370/10000
4/4 - 0s - loss: 22.1425 - val_loss: 17.7151

Epoch 00370: val_loss did not improve from 17.67357
Epoch 371/10000
4/4 - 0s - loss: 22.1345 - val_loss: 17.7621

Epoch 00371: val_loss did not improve from 17.67357
Epoch 372/10000
4/4 - 0s - loss: 22.1514 - val_loss: 17.7286

Epoch 00372: val_loss did not improve from 17.67357
Epoch 373/10000
4/4 - 0s - loss: 22.1382 - val_loss: 17.7151

Epoch 00373: val_loss did not improve from 17.67357
Epoch 374/10000
4/4 - 0s - loss: 22.1417 - val_loss: 17.6851

Epoch 00374: val_loss did not improve from 17.67357
Epoch 375/10000
4/4 - 0s - loss: 22.1416 - val_loss: 17.6977

Epoch 00375: val_loss did not improve from 17.67357
Epoch 376/10000
4/4 - 0s - loss: 22.1760 - val_loss: 17.7228

Epoch 00376: val_loss did not improve from 17.67357
Epoch 377/10000
4/4 - 0s - loss: 22.1331 - val_loss: 17.6811

Epoch 00377: val_loss did not improve from 17.67357
Epoch 378/10000
4/4 - 0s - loss: 22.1535 - val_loss: 17.6845

Epoch 00378: val_loss did not improve from 17.67357
Epoch 379/10000
4/4 - 0s - loss: 22.1390 - val_loss: 17.7259

Epoch 00379: val_loss did not improve from 17.67357
Epoch 380/10000
4/4 - 0s - loss: 22.1523 - val_loss: 17.7968

Epoch 00380: val_loss did not improve from 17.67357
Epoch 381/10000
4/4 - 0s - loss: 22.1552 - val_loss: 17.6983

Epoch 00381: val_loss did not improve from 17.67357
Epoch 382/10000
4/4 - 0s - loss: 22.1555 - val_loss: 17.6750

Epoch 00382: val_loss did not improve from 17.67357
Epoch 383/10000
4/4 - 0s - loss: 22.1427 - val_loss: 17.7057

Epoch 00383: val_loss did not improve from 17.67357
Epoch 384/10000
4/4 - 0s - loss: 22.1498 - val_loss: 17.7569

Epoch 00384: val_loss did not improve from 17.67357
Epoch 385/10000
4/4 - 0s - loss: 22.1569 - val_loss: 17.6825

Epoch 00385: val_loss did not improve from 17.67357
Epoch 386/10000
4/4 - 0s - loss: 22.1463 - val_loss: 17.6796

Epoch 00386: val_loss did not improve from 17.67357
Epoch 387/10000
4/4 - 0s - loss: 22.1328 - val_loss: 17.7156

Epoch 00387: val_loss did not improve from 17.67357
Epoch 388/10000
4/4 - 0s - loss: 22.1452 - val_loss: 17.7437

Epoch 00388: val_loss did not improve from 17.67357
Epoch 389/10000
4/4 - 0s - loss: 22.1402 - val_loss: 17.6901

Epoch 00389: val_loss did not improve from 17.67357
Epoch 390/10000
4/4 - 0s - loss: 22.1371 - val_loss: 17.6820

Epoch 00390: val_loss did not improve from 17.67357
Epoch 391/10000
4/4 - 0s - loss: 22.1485 - val_loss: 17.6968

Epoch 00391: val_loss did not improve from 17.67357
Epoch 392/10000
4/4 - 0s - loss: 22.1437 - val_loss: 17.7123

Epoch 00392: val_loss did not improve from 17.67357
Epoch 393/10000
4/4 - 0s - loss: 22.1509 - val_loss: 17.6894

Epoch 00393: val_loss did not improve from 17.67357
Epoch 394/10000
4/4 - 0s - loss: 22.1435 - val_loss: 17.7140

Epoch 00394: val_loss did not improve from 17.67357
Epoch 395/10000
4/4 - 0s - loss: 22.1480 - val_loss: 17.7219

Epoch 00395: val_loss did not improve from 17.67357
Epoch 396/10000
4/4 - 0s - loss: 22.1512 - val_loss: 17.6898

Epoch 00396: val_loss did not improve from 17.67357
Epoch 397/10000
4/4 - 0s - loss: 22.1451 - val_loss: 17.7138

Epoch 00397: val_loss did not improve from 17.67357
Epoch 398/10000
4/4 - 0s - loss: 22.1449 - val_loss: 17.7183

Epoch 00398: val_loss did not improve from 17.67357
Epoch 399/10000
4/4 - 0s - loss: 22.1326 - val_loss: 17.6878

Epoch 00399: val_loss did not improve from 17.67357
Epoch 400/10000
4/4 - 0s - loss: 22.1515 - val_loss: 17.6797

Epoch 00400: val_loss did not improve from 17.67357
Epoch 401/10000
4/4 - 0s - loss: 22.1413 - val_loss: 17.7043

Epoch 00401: val_loss did not improve from 17.67357
Epoch 402/10000
4/4 - 0s - loss: 22.1339 - val_loss: 17.7397

Epoch 00402: val_loss did not improve from 17.67357
Epoch 403/10000
4/4 - 0s - loss: 22.1419 - val_loss: 17.7084

Epoch 00403: val_loss did not improve from 17.67357
Epoch 404/10000
4/4 - 0s - loss: 22.1353 - val_loss: 17.6828

Epoch 00404: val_loss did not improve from 17.67357
Epoch 405/10000
4/4 - 0s - loss: 22.1402 - val_loss: 17.6959

Epoch 00405: val_loss did not improve from 17.67357
Epoch 406/10000
4/4 - 0s - loss: 22.1461 - val_loss: 17.7289

Epoch 00406: val_loss did not improve from 17.67357
Epoch 407/10000
4/4 - 0s - loss: 22.1422 - val_loss: 17.6946

Epoch 00407: val_loss did not improve from 17.67357
Epoch 408/10000
4/4 - 0s - loss: 22.1382 - val_loss: 17.7038

Epoch 00408: val_loss did not improve from 17.67357
Epoch 409/10000
4/4 - 0s - loss: 22.1340 - val_loss: 17.7174

Epoch 00409: val_loss did not improve from 17.67357
Epoch 410/10000
4/4 - 0s - loss: 22.1612 - val_loss: 17.7246

Epoch 00410: val_loss did not improve from 17.67357
Epoch 411/10000
4/4 - 0s - loss: 22.1393 - val_loss: 17.6806

Epoch 00411: val_loss did not improve from 17.67357
Epoch 412/10000
4/4 - 0s - loss: 22.1508 - val_loss: 17.6851

Epoch 00412: val_loss did not improve from 17.67357
Epoch 413/10000
4/4 - 0s - loss: 22.1296 - val_loss: 17.7331

Epoch 00413: val_loss did not improve from 17.67357
Epoch 414/10000
4/4 - 0s - loss: 22.1768 - val_loss: 17.7606

Epoch 00414: val_loss did not improve from 17.67357
Epoch 415/10000
4/4 - 0s - loss: 22.1539 - val_loss: 17.6775

Epoch 00415: val_loss did not improve from 17.67357
Epoch 416/10000
4/4 - 0s - loss: 22.1634 - val_loss: 17.6892

Epoch 00416: val_loss did not improve from 17.67357
Epoch 417/10000
4/4 - 0s - loss: 22.1435 - val_loss: 17.7268

Epoch 00417: val_loss did not improve from 17.67357
Epoch 418/10000
4/4 - 0s - loss: 22.1403 - val_loss: 17.7025

Epoch 00418: val_loss did not improve from 17.67357
Epoch 419/10000
4/4 - 0s - loss: 22.1353 - val_loss: 17.7032

Epoch 00419: val_loss did not improve from 17.67357
Epoch 00419: early stopping
*************************** Fold #: 6 ***************************
Model: "sequential_25"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_275 (Dense)            (None, 30)                150       
_________________________________________________________________
dense_276 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_277 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_278 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_279 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_280 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_281 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_282 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_283 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_284 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_285 (Dense)            (None, 1)                 31        
=================================================================
Total params: 8,551
Trainable params: 8,551
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
4/4 - 0s - loss: 29.0836 - val_loss: 51.4304

Epoch 00001: val_loss improved from inf to 51.43041, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 2/10000
4/4 - 0s - loss: 29.0525 - val_loss: 51.3927

Epoch 00002: val_loss improved from 51.43041 to 51.39272, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 3/10000
4/4 - 0s - loss: 29.0181 - val_loss: 51.3518

Epoch 00003: val_loss improved from 51.39272 to 51.35183, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 4/10000
4/4 - 0s - loss: 28.9821 - val_loss: 51.3067

Epoch 00004: val_loss improved from 51.35183 to 51.30671, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 5/10000
4/4 - 0s - loss: 28.9416 - val_loss: 51.2564

Epoch 00005: val_loss improved from 51.30671 to 51.25636, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 6/10000
4/4 - 0s - loss: 28.8957 - val_loss: 51.1995

Epoch 00006: val_loss improved from 51.25636 to 51.19955, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 7/10000
4/4 - 0s - loss: 28.8440 - val_loss: 51.1336

Epoch 00007: val_loss improved from 51.19955 to 51.13362, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 8/10000
4/4 - 0s - loss: 28.7833 - val_loss: 51.0550

Epoch 00008: val_loss improved from 51.13362 to 51.05498, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 9/10000
4/4 - 0s - loss: 28.7109 - val_loss: 50.9596

Epoch 00009: val_loss improved from 51.05498 to 50.95956, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 10/10000
4/4 - 0s - loss: 28.6218 - val_loss: 50.8414

Epoch 00010: val_loss improved from 50.95956 to 50.84138, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 11/10000
4/4 - 0s - loss: 28.5120 - val_loss: 50.6916

Epoch 00011: val_loss improved from 50.84138 to 50.69157, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 12/10000
4/4 - 0s - loss: 28.3699 - val_loss: 50.4971

Epoch 00012: val_loss improved from 50.69157 to 50.49705, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 13/10000
4/4 - 0s - loss: 28.1879 - val_loss: 50.2355

Epoch 00013: val_loss improved from 50.49705 to 50.23547, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 14/10000
4/4 - 0s - loss: 27.9344 - val_loss: 49.8720

Epoch 00014: val_loss improved from 50.23547 to 49.87204, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 15/10000
4/4 - 0s - loss: 27.5776 - val_loss: 49.3445

Epoch 00015: val_loss improved from 49.87204 to 49.34454, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 16/10000
4/4 - 0s - loss: 27.0677 - val_loss: 48.5451

Epoch 00016: val_loss improved from 49.34454 to 48.54506, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 17/10000
4/4 - 0s - loss: 26.2833 - val_loss: 47.2966

Epoch 00017: val_loss improved from 48.54506 to 47.29663, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 18/10000
4/4 - 0s - loss: 25.0651 - val_loss: 45.3561

Epoch 00018: val_loss improved from 47.29663 to 45.35610, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 19/10000
4/4 - 0s - loss: 23.2787 - val_loss: 42.6652

Epoch 00019: val_loss improved from 45.35610 to 42.66516, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 20/10000
4/4 - 0s - loss: 21.3629 - val_loss: 40.8375

Epoch 00020: val_loss improved from 42.66516 to 40.83752, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 21/10000
4/4 - 0s - loss: 21.6066 - val_loss: 40.9139

Epoch 00021: val_loss did not improve from 40.83752
Epoch 22/10000
4/4 - 0s - loss: 21.2456 - val_loss: 40.7983

Epoch 00022: val_loss improved from 40.83752 to 40.79829, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 23/10000
4/4 - 0s - loss: 20.8804 - val_loss: 41.2682

Epoch 00023: val_loss did not improve from 40.79829
Epoch 24/10000
4/4 - 0s - loss: 20.9583 - val_loss: 41.2832

Epoch 00024: val_loss did not improve from 40.79829
Epoch 25/10000
4/4 - 0s - loss: 20.8529 - val_loss: 40.8992

Epoch 00025: val_loss did not improve from 40.79829
Epoch 26/10000
4/4 - 0s - loss: 20.6466 - val_loss: 40.5093

Epoch 00026: val_loss improved from 40.79829 to 40.50932, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 27/10000
4/4 - 0s - loss: 20.5765 - val_loss: 40.3641

Epoch 00027: val_loss improved from 40.50932 to 40.36410, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 28/10000
4/4 - 0s - loss: 20.5467 - val_loss: 40.3322

Epoch 00028: val_loss improved from 40.36410 to 40.33216, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 29/10000
4/4 - 0s - loss: 20.4463 - val_loss: 40.4000

Epoch 00029: val_loss did not improve from 40.33216
Epoch 30/10000
4/4 - 0s - loss: 20.3718 - val_loss: 40.4299

Epoch 00030: val_loss did not improve from 40.33216
Epoch 31/10000
4/4 - 0s - loss: 20.3088 - val_loss: 40.3154

Epoch 00031: val_loss improved from 40.33216 to 40.31540, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 32/10000
4/4 - 0s - loss: 20.2420 - val_loss: 40.1831

Epoch 00032: val_loss improved from 40.31540 to 40.18307, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 33/10000
4/4 - 0s - loss: 20.1792 - val_loss: 40.1129

Epoch 00033: val_loss improved from 40.18307 to 40.11289, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 34/10000
4/4 - 0s - loss: 20.1287 - val_loss: 40.0830

Epoch 00034: val_loss improved from 40.11289 to 40.08300, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 35/10000
4/4 - 0s - loss: 20.0868 - val_loss: 40.1056

Epoch 00035: val_loss did not improve from 40.08300
Epoch 36/10000
4/4 - 0s - loss: 20.0400 - val_loss: 40.1008

Epoch 00036: val_loss did not improve from 40.08300
Epoch 37/10000
4/4 - 0s - loss: 20.0070 - val_loss: 40.0477

Epoch 00037: val_loss improved from 40.08300 to 40.04770, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 38/10000
4/4 - 0s - loss: 19.9737 - val_loss: 40.0229

Epoch 00038: val_loss improved from 40.04770 to 40.02291, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 39/10000
4/4 - 0s - loss: 19.9490 - val_loss: 39.9896

Epoch 00039: val_loss improved from 40.02291 to 39.98965, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 40/10000
4/4 - 0s - loss: 19.9292 - val_loss: 40.0141

Epoch 00040: val_loss did not improve from 39.98965
Epoch 41/10000
4/4 - 0s - loss: 19.9076 - val_loss: 39.9899

Epoch 00041: val_loss did not improve from 39.98965
Epoch 42/10000
4/4 - 0s - loss: 19.8890 - val_loss: 39.9717

Epoch 00042: val_loss improved from 39.98965 to 39.97173, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 43/10000
4/4 - 0s - loss: 19.8640 - val_loss: 39.9192

Epoch 00043: val_loss improved from 39.97173 to 39.91921, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 44/10000
4/4 - 0s - loss: 19.8556 - val_loss: 39.8961

Epoch 00044: val_loss improved from 39.91921 to 39.89610, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 45/10000
4/4 - 0s - loss: 19.8623 - val_loss: 39.9533

Epoch 00045: val_loss did not improve from 39.89610
Epoch 46/10000
4/4 - 0s - loss: 19.8289 - val_loss: 39.8859

Epoch 00046: val_loss improved from 39.89610 to 39.88594, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 47/10000
4/4 - 0s - loss: 19.8058 - val_loss: 39.8849

Epoch 00047: val_loss improved from 39.88594 to 39.88487, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 48/10000
4/4 - 0s - loss: 19.7970 - val_loss: 39.9111

Epoch 00048: val_loss did not improve from 39.88487
Epoch 49/10000
4/4 - 0s - loss: 19.7866 - val_loss: 39.8780

Epoch 00049: val_loss improved from 39.88487 to 39.87802, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 50/10000
4/4 - 0s - loss: 19.7693 - val_loss: 39.7913

Epoch 00050: val_loss improved from 39.87802 to 39.79132, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 51/10000
4/4 - 0s - loss: 19.7605 - val_loss: 39.7697

Epoch 00051: val_loss improved from 39.79132 to 39.76974, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 52/10000
4/4 - 0s - loss: 19.7599 - val_loss: 39.7483

Epoch 00052: val_loss improved from 39.76974 to 39.74828, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 53/10000
4/4 - 0s - loss: 19.7439 - val_loss: 39.8324

Epoch 00053: val_loss did not improve from 39.74828
Epoch 54/10000
4/4 - 0s - loss: 19.7406 - val_loss: 39.8282

Epoch 00054: val_loss did not improve from 39.74828
Epoch 55/10000
4/4 - 0s - loss: 19.7366 - val_loss: 39.7762

Epoch 00055: val_loss did not improve from 39.74828
Epoch 56/10000
4/4 - 0s - loss: 19.7230 - val_loss: 39.7640

Epoch 00056: val_loss did not improve from 39.74828
Epoch 57/10000
4/4 - 0s - loss: 19.7147 - val_loss: 39.7096

Epoch 00057: val_loss improved from 39.74828 to 39.70964, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 58/10000
4/4 - 0s - loss: 19.7470 - val_loss: 39.6977

Epoch 00058: val_loss improved from 39.70964 to 39.69765, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 59/10000
4/4 - 0s - loss: 19.7089 - val_loss: 39.7756

Epoch 00059: val_loss did not improve from 39.69765
Epoch 60/10000
4/4 - 0s - loss: 19.7131 - val_loss: 39.7778

Epoch 00060: val_loss did not improve from 39.69765
Epoch 61/10000
4/4 - 0s - loss: 19.7002 - val_loss: 39.6941

Epoch 00061: val_loss improved from 39.69765 to 39.69413, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 62/10000
4/4 - 0s - loss: 19.7185 - val_loss: 39.6539

Epoch 00062: val_loss improved from 39.69413 to 39.65395, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 63/10000
4/4 - 0s - loss: 19.6996 - val_loss: 39.7393

Epoch 00063: val_loss did not improve from 39.65395
Epoch 64/10000
4/4 - 0s - loss: 19.7132 - val_loss: 39.8203

Epoch 00064: val_loss did not improve from 39.65395
Epoch 65/10000
4/4 - 0s - loss: 19.7127 - val_loss: 39.6955

Epoch 00065: val_loss did not improve from 39.65395
Epoch 66/10000
4/4 - 0s - loss: 19.7088 - val_loss: 39.6617

Epoch 00066: val_loss did not improve from 39.65395
Epoch 67/10000
4/4 - 0s - loss: 19.6928 - val_loss: 39.7507

Epoch 00067: val_loss did not improve from 39.65395
Epoch 68/10000
4/4 - 0s - loss: 19.6986 - val_loss: 39.7927

Epoch 00068: val_loss did not improve from 39.65395
Epoch 69/10000
4/4 - 0s - loss: 19.7215 - val_loss: 39.7066

Epoch 00069: val_loss did not improve from 39.65395
Epoch 70/10000
4/4 - 0s - loss: 19.7025 - val_loss: 39.7070

Epoch 00070: val_loss did not improve from 39.65395
Epoch 71/10000
4/4 - 0s - loss: 19.6949 - val_loss: 39.7032

Epoch 00071: val_loss did not improve from 39.65395
Epoch 72/10000
4/4 - 0s - loss: 19.6996 - val_loss: 39.7178

Epoch 00072: val_loss did not improve from 39.65395
Epoch 73/10000
4/4 - 0s - loss: 19.6919 - val_loss: 39.6639

Epoch 00073: val_loss did not improve from 39.65395
Epoch 74/10000
4/4 - 0s - loss: 19.7165 - val_loss: 39.6326

Epoch 00074: val_loss improved from 39.65395 to 39.63263, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 75/10000
4/4 - 0s - loss: 19.6973 - val_loss: 39.7176

Epoch 00075: val_loss did not improve from 39.63263
Epoch 76/10000
4/4 - 0s - loss: 19.6921 - val_loss: 39.7755

Epoch 00076: val_loss did not improve from 39.63263
Epoch 77/10000
4/4 - 0s - loss: 19.7267 - val_loss: 39.8342

Epoch 00077: val_loss did not improve from 39.63263
Epoch 78/10000
4/4 - 0s - loss: 19.7022 - val_loss: 39.6775

Epoch 00078: val_loss did not improve from 39.63263
Epoch 79/10000
4/4 - 0s - loss: 19.7044 - val_loss: 39.5889

Epoch 00079: val_loss improved from 39.63263 to 39.58892, saving model to ./results/dataset/trial_3/ckpt_6
Epoch 80/10000
4/4 - 0s - loss: 19.7404 - val_loss: 39.6174

Epoch 00080: val_loss did not improve from 39.58892
Epoch 81/10000
4/4 - 0s - loss: 19.6872 - val_loss: 39.7812

Epoch 00081: val_loss did not improve from 39.58892
Epoch 82/10000
4/4 - 0s - loss: 19.7150 - val_loss: 39.8293

Epoch 00082: val_loss did not improve from 39.58892
Epoch 83/10000
4/4 - 0s - loss: 19.7139 - val_loss: 39.7236

Epoch 00083: val_loss did not improve from 39.58892
Epoch 84/10000
4/4 - 0s - loss: 19.7544 - val_loss: 39.6035

Epoch 00084: val_loss did not improve from 39.58892
Epoch 85/10000
4/4 - 0s - loss: 19.7124 - val_loss: 39.7120

Epoch 00085: val_loss did not improve from 39.58892
Epoch 86/10000
4/4 - 0s - loss: 19.6966 - val_loss: 39.7369

Epoch 00086: val_loss did not improve from 39.58892
Epoch 87/10000
4/4 - 0s - loss: 19.7004 - val_loss: 39.7028

Epoch 00087: val_loss did not improve from 39.58892
Epoch 88/10000
4/4 - 0s - loss: 19.6908 - val_loss: 39.6515

Epoch 00088: val_loss did not improve from 39.58892
Epoch 89/10000
4/4 - 0s - loss: 19.7024 - val_loss: 39.6262

Epoch 00089: val_loss did not improve from 39.58892
Epoch 90/10000
4/4 - 0s - loss: 19.7071 - val_loss: 39.7186

Epoch 00090: val_loss did not improve from 39.58892
Epoch 91/10000
4/4 - 0s - loss: 19.6972 - val_loss: 39.7605

Epoch 00091: val_loss did not improve from 39.58892
Epoch 92/10000
4/4 - 0s - loss: 19.7050 - val_loss: 39.7099

Epoch 00092: val_loss did not improve from 39.58892
Epoch 93/10000
4/4 - 0s - loss: 19.6931 - val_loss: 39.6833

Epoch 00093: val_loss did not improve from 39.58892
Epoch 94/10000
4/4 - 0s - loss: 19.7052 - val_loss: 39.6663

Epoch 00094: val_loss did not improve from 39.58892
Epoch 95/10000
4/4 - 0s - loss: 19.6929 - val_loss: 39.7132

Epoch 00095: val_loss did not improve from 39.58892
Epoch 96/10000
4/4 - 0s - loss: 19.6933 - val_loss: 39.7479

Epoch 00096: val_loss did not improve from 39.58892
Epoch 97/10000
4/4 - 0s - loss: 19.7070 - val_loss: 39.7482

Epoch 00097: val_loss did not improve from 39.58892
Epoch 98/10000
4/4 - 0s - loss: 19.6951 - val_loss: 39.6512

Epoch 00098: val_loss did not improve from 39.58892
Epoch 99/10000
4/4 - 0s - loss: 19.6995 - val_loss: 39.6504

Epoch 00099: val_loss did not improve from 39.58892
Epoch 100/10000
4/4 - 0s - loss: 19.6943 - val_loss: 39.6975

Epoch 00100: val_loss did not improve from 39.58892
Epoch 101/10000
4/4 - 0s - loss: 19.6997 - val_loss: 39.7678

Epoch 00101: val_loss did not improve from 39.58892
Epoch 102/10000
4/4 - 0s - loss: 19.7047 - val_loss: 39.6886

Epoch 00102: val_loss did not improve from 39.58892
Epoch 103/10000
4/4 - 0s - loss: 19.6936 - val_loss: 39.6744

Epoch 00103: val_loss did not improve from 39.58892
Epoch 104/10000
4/4 - 0s - loss: 19.6936 - val_loss: 39.6762

Epoch 00104: val_loss did not improve from 39.58892
Epoch 105/10000
4/4 - 0s - loss: 19.6990 - val_loss: 39.6786

Epoch 00105: val_loss did not improve from 39.58892
Epoch 106/10000
4/4 - 0s - loss: 19.6918 - val_loss: 39.7131

Epoch 00106: val_loss did not improve from 39.58892
Epoch 107/10000
4/4 - 0s - loss: 19.6947 - val_loss: 39.7316

Epoch 00107: val_loss did not improve from 39.58892
Epoch 108/10000
4/4 - 0s - loss: 19.7017 - val_loss: 39.7419

Epoch 00108: val_loss did not improve from 39.58892
Epoch 109/10000
4/4 - 0s - loss: 19.7000 - val_loss: 39.7166

Epoch 00109: val_loss did not improve from 39.58892
Epoch 110/10000
4/4 - 0s - loss: 19.6976 - val_loss: 39.6638

Epoch 00110: val_loss did not improve from 39.58892
Epoch 111/10000
4/4 - 0s - loss: 19.7172 - val_loss: 39.6557

Epoch 00111: val_loss did not improve from 39.58892
Epoch 112/10000
4/4 - 0s - loss: 19.6946 - val_loss: 39.7640

Epoch 00112: val_loss did not improve from 39.58892
Epoch 113/10000
4/4 - 0s - loss: 19.7114 - val_loss: 39.7816

Epoch 00113: val_loss did not improve from 39.58892
Epoch 114/10000
4/4 - 0s - loss: 19.7125 - val_loss: 39.7117

Epoch 00114: val_loss did not improve from 39.58892
Epoch 115/10000
4/4 - 0s - loss: 19.7224 - val_loss: 39.6288

Epoch 00115: val_loss did not improve from 39.58892
Epoch 116/10000
4/4 - 0s - loss: 19.6972 - val_loss: 39.7017

Epoch 00116: val_loss did not improve from 39.58892
Epoch 117/10000
4/4 - 0s - loss: 19.6967 - val_loss: 39.7480

Epoch 00117: val_loss did not improve from 39.58892
Epoch 118/10000
4/4 - 0s - loss: 19.6982 - val_loss: 39.6892

Epoch 00118: val_loss did not improve from 39.58892
Epoch 119/10000
4/4 - 0s - loss: 19.6926 - val_loss: 39.6476

Epoch 00119: val_loss did not improve from 39.58892
Epoch 120/10000
4/4 - 0s - loss: 19.7003 - val_loss: 39.6538

Epoch 00120: val_loss did not improve from 39.58892
Epoch 121/10000
4/4 - 0s - loss: 19.7029 - val_loss: 39.6966

Epoch 00121: val_loss did not improve from 39.58892
Epoch 122/10000
4/4 - 0s - loss: 19.7081 - val_loss: 39.6879

Epoch 00122: val_loss did not improve from 39.58892
Epoch 123/10000
4/4 - 0s - loss: 19.7045 - val_loss: 39.6085

Epoch 00123: val_loss did not improve from 39.58892
Epoch 124/10000
4/4 - 0s - loss: 19.7121 - val_loss: 39.6726

Epoch 00124: val_loss did not improve from 39.58892
Epoch 125/10000
4/4 - 0s - loss: 19.7145 - val_loss: 39.8507

Epoch 00125: val_loss did not improve from 39.58892
Epoch 126/10000
4/4 - 0s - loss: 19.7250 - val_loss: 39.7542

Epoch 00126: val_loss did not improve from 39.58892
Epoch 127/10000
4/4 - 0s - loss: 19.6818 - val_loss: 39.6322

Epoch 00127: val_loss did not improve from 39.58892
Epoch 128/10000
4/4 - 0s - loss: 19.7100 - val_loss: 39.6127

Epoch 00128: val_loss did not improve from 39.58892
Epoch 129/10000
4/4 - 0s - loss: 19.7032 - val_loss: 39.6977

Epoch 00129: val_loss did not improve from 39.58892
Epoch 130/10000
4/4 - 0s - loss: 19.6973 - val_loss: 39.7916

Epoch 00130: val_loss did not improve from 39.58892
Epoch 131/10000
4/4 - 0s - loss: 19.7086 - val_loss: 39.7259

Epoch 00131: val_loss did not improve from 39.58892
Epoch 132/10000
4/4 - 0s - loss: 19.7056 - val_loss: 39.6490

Epoch 00132: val_loss did not improve from 39.58892
Epoch 133/10000
4/4 - 0s - loss: 19.7050 - val_loss: 39.6902

Epoch 00133: val_loss did not improve from 39.58892
Epoch 134/10000
4/4 - 0s - loss: 19.6969 - val_loss: 39.6541

Epoch 00134: val_loss did not improve from 39.58892
Epoch 135/10000
4/4 - 0s - loss: 19.7145 - val_loss: 39.6897

Epoch 00135: val_loss did not improve from 39.58892
Epoch 136/10000
4/4 - 0s - loss: 19.6971 - val_loss: 39.6308

Epoch 00136: val_loss did not improve from 39.58892
Epoch 137/10000
4/4 - 0s - loss: 19.7029 - val_loss: 39.6841

Epoch 00137: val_loss did not improve from 39.58892
Epoch 138/10000
4/4 - 0s - loss: 19.6954 - val_loss: 39.7102

Epoch 00138: val_loss did not improve from 39.58892
Epoch 139/10000
4/4 - 0s - loss: 19.7031 - val_loss: 39.7243

Epoch 00139: val_loss did not improve from 39.58892
Epoch 140/10000
4/4 - 0s - loss: 19.7006 - val_loss: 39.6390

Epoch 00140: val_loss did not improve from 39.58892
Epoch 141/10000
4/4 - 0s - loss: 19.7069 - val_loss: 39.6474

Epoch 00141: val_loss did not improve from 39.58892
Epoch 142/10000
4/4 - 0s - loss: 19.7123 - val_loss: 39.7736

Epoch 00142: val_loss did not improve from 39.58892
Epoch 143/10000
4/4 - 0s - loss: 19.7024 - val_loss: 39.7167

Epoch 00143: val_loss did not improve from 39.58892
Epoch 144/10000
4/4 - 0s - loss: 19.6936 - val_loss: 39.6643

Epoch 00144: val_loss did not improve from 39.58892
Epoch 145/10000
4/4 - 0s - loss: 19.6997 - val_loss: 39.6816

Epoch 00145: val_loss did not improve from 39.58892
Epoch 146/10000
4/4 - 0s - loss: 19.7004 - val_loss: 39.7094

Epoch 00146: val_loss did not improve from 39.58892
Epoch 147/10000
4/4 - 0s - loss: 19.6991 - val_loss: 39.6837

Epoch 00147: val_loss did not improve from 39.58892
Epoch 148/10000
4/4 - 0s - loss: 19.6935 - val_loss: 39.6866

Epoch 00148: val_loss did not improve from 39.58892
Epoch 149/10000
4/4 - 0s - loss: 19.7024 - val_loss: 39.7159

Epoch 00149: val_loss did not improve from 39.58892
Epoch 150/10000
4/4 - 0s - loss: 19.6943 - val_loss: 39.6911

Epoch 00150: val_loss did not improve from 39.58892
Epoch 151/10000
4/4 - 0s - loss: 19.7178 - val_loss: 39.6479

Epoch 00151: val_loss did not improve from 39.58892
Epoch 152/10000
4/4 - 0s - loss: 19.7014 - val_loss: 39.7519

Epoch 00152: val_loss did not improve from 39.58892
Epoch 153/10000
4/4 - 0s - loss: 19.7081 - val_loss: 39.7466

Epoch 00153: val_loss did not improve from 39.58892
Epoch 154/10000
4/4 - 0s - loss: 19.7032 - val_loss: 39.7308

Epoch 00154: val_loss did not improve from 39.58892
Epoch 155/10000
4/4 - 0s - loss: 19.6975 - val_loss: 39.6730

Epoch 00155: val_loss did not improve from 39.58892
Epoch 156/10000
4/4 - 0s - loss: 19.6932 - val_loss: 39.6403

Epoch 00156: val_loss did not improve from 39.58892
Epoch 157/10000
4/4 - 0s - loss: 19.7121 - val_loss: 39.6929

Epoch 00157: val_loss did not improve from 39.58892
Epoch 158/10000
4/4 - 0s - loss: 19.6949 - val_loss: 39.6879

Epoch 00158: val_loss did not improve from 39.58892
Epoch 159/10000
4/4 - 0s - loss: 19.6934 - val_loss: 39.6642

Epoch 00159: val_loss did not improve from 39.58892
Epoch 160/10000
4/4 - 0s - loss: 19.7007 - val_loss: 39.6510

Epoch 00160: val_loss did not improve from 39.58892
Epoch 161/10000
4/4 - 0s - loss: 19.6981 - val_loss: 39.7088

Epoch 00161: val_loss did not improve from 39.58892
Epoch 162/10000
4/4 - 0s - loss: 19.7007 - val_loss: 39.7383

Epoch 00162: val_loss did not improve from 39.58892
Epoch 163/10000
4/4 - 0s - loss: 19.6972 - val_loss: 39.6697

Epoch 00163: val_loss did not improve from 39.58892
Epoch 164/10000
4/4 - 0s - loss: 19.6982 - val_loss: 39.6854

Epoch 00164: val_loss did not improve from 39.58892
Epoch 165/10000
4/4 - 0s - loss: 19.6958 - val_loss: 39.7171

Epoch 00165: val_loss did not improve from 39.58892
Epoch 166/10000
4/4 - 0s - loss: 19.6965 - val_loss: 39.6983

Epoch 00166: val_loss did not improve from 39.58892
Epoch 167/10000
4/4 - 0s - loss: 19.6956 - val_loss: 39.7026

Epoch 00167: val_loss did not improve from 39.58892
Epoch 168/10000
4/4 - 0s - loss: 19.7004 - val_loss: 39.7415

Epoch 00168: val_loss did not improve from 39.58892
Epoch 169/10000
4/4 - 0s - loss: 19.6968 - val_loss: 39.7068

Epoch 00169: val_loss did not improve from 39.58892
Epoch 170/10000
4/4 - 0s - loss: 19.7019 - val_loss: 39.6889

Epoch 00170: val_loss did not improve from 39.58892
Epoch 171/10000
4/4 - 0s - loss: 19.7006 - val_loss: 39.6238

Epoch 00171: val_loss did not improve from 39.58892
Epoch 172/10000
4/4 - 0s - loss: 19.7010 - val_loss: 39.6799

Epoch 00172: val_loss did not improve from 39.58892
Epoch 173/10000
4/4 - 0s - loss: 19.6985 - val_loss: 39.7680

Epoch 00173: val_loss did not improve from 39.58892
Epoch 174/10000
4/4 - 0s - loss: 19.7086 - val_loss: 39.7166

Epoch 00174: val_loss did not improve from 39.58892
Epoch 175/10000
4/4 - 0s - loss: 19.6968 - val_loss: 39.6799

Epoch 00175: val_loss did not improve from 39.58892
Epoch 176/10000
4/4 - 0s - loss: 19.6928 - val_loss: 39.6307

Epoch 00176: val_loss did not improve from 39.58892
Epoch 177/10000
4/4 - 0s - loss: 19.7088 - val_loss: 39.6515

Epoch 00177: val_loss did not improve from 39.58892
Epoch 178/10000
4/4 - 0s - loss: 19.6962 - val_loss: 39.6626

Epoch 00178: val_loss did not improve from 39.58892
Epoch 179/10000
4/4 - 0s - loss: 19.6998 - val_loss: 39.6982

Epoch 00179: val_loss did not improve from 39.58892
Epoch 180/10000
4/4 - 0s - loss: 19.6952 - val_loss: 39.6821

Epoch 00180: val_loss did not improve from 39.58892
Epoch 181/10000
4/4 - 0s - loss: 19.7151 - val_loss: 39.7238

Epoch 00181: val_loss did not improve from 39.58892
Epoch 182/10000
4/4 - 0s - loss: 19.6930 - val_loss: 39.6496

Epoch 00182: val_loss did not improve from 39.58892
Epoch 183/10000
4/4 - 0s - loss: 19.7004 - val_loss: 39.6678

Epoch 00183: val_loss did not improve from 39.58892
Epoch 184/10000
4/4 - 0s - loss: 19.6982 - val_loss: 39.6732

Epoch 00184: val_loss did not improve from 39.58892
Epoch 185/10000
4/4 - 0s - loss: 19.6955 - val_loss: 39.7005

Epoch 00185: val_loss did not improve from 39.58892
Epoch 186/10000
4/4 - 0s - loss: 19.6979 - val_loss: 39.7455

Epoch 00186: val_loss did not improve from 39.58892
Epoch 187/10000
4/4 - 0s - loss: 19.6987 - val_loss: 39.7183

Epoch 00187: val_loss did not improve from 39.58892
Epoch 188/10000
4/4 - 0s - loss: 19.6930 - val_loss: 39.6606

Epoch 00188: val_loss did not improve from 39.58892
Epoch 189/10000
4/4 - 0s - loss: 19.7013 - val_loss: 39.6453

Epoch 00189: val_loss did not improve from 39.58892
Epoch 190/10000
4/4 - 0s - loss: 19.6993 - val_loss: 39.6760

Epoch 00190: val_loss did not improve from 39.58892
Epoch 191/10000
4/4 - 0s - loss: 19.7005 - val_loss: 39.7715

Epoch 00191: val_loss did not improve from 39.58892
Epoch 192/10000
4/4 - 0s - loss: 19.7039 - val_loss: 39.7026

Epoch 00192: val_loss did not improve from 39.58892
Epoch 193/10000
4/4 - 0s - loss: 19.6970 - val_loss: 39.6457

Epoch 00193: val_loss did not improve from 39.58892
Epoch 194/10000
4/4 - 0s - loss: 19.7008 - val_loss: 39.6782

Epoch 00194: val_loss did not improve from 39.58892
Epoch 195/10000
4/4 - 0s - loss: 19.6952 - val_loss: 39.6969

Epoch 00195: val_loss did not improve from 39.58892
Epoch 196/10000
4/4 - 0s - loss: 19.6944 - val_loss: 39.6676

Epoch 00196: val_loss did not improve from 39.58892
Epoch 197/10000
4/4 - 0s - loss: 19.7052 - val_loss: 39.6527

Epoch 00197: val_loss did not improve from 39.58892
Epoch 198/10000
4/4 - 0s - loss: 19.7055 - val_loss: 39.7281

Epoch 00198: val_loss did not improve from 39.58892
Epoch 199/10000
4/4 - 0s - loss: 19.7103 - val_loss: 39.7572

Epoch 00199: val_loss did not improve from 39.58892
Epoch 200/10000
4/4 - 0s - loss: 19.7022 - val_loss: 39.6789

Epoch 00200: val_loss did not improve from 39.58892
Epoch 201/10000
4/4 - 0s - loss: 19.7027 - val_loss: 39.6494

Epoch 00201: val_loss did not improve from 39.58892
Epoch 202/10000
4/4 - 0s - loss: 19.7059 - val_loss: 39.7144

Epoch 00202: val_loss did not improve from 39.58892
Epoch 203/10000
4/4 - 0s - loss: 19.6957 - val_loss: 39.6770

Epoch 00203: val_loss did not improve from 39.58892
Epoch 204/10000
4/4 - 0s - loss: 19.6918 - val_loss: 39.6379

Epoch 00204: val_loss did not improve from 39.58892
Epoch 205/10000
4/4 - 0s - loss: 19.7030 - val_loss: 39.6639

Epoch 00205: val_loss did not improve from 39.58892
Epoch 206/10000
4/4 - 0s - loss: 19.6935 - val_loss: 39.7311

Epoch 00206: val_loss did not improve from 39.58892
Epoch 207/10000
4/4 - 0s - loss: 19.6975 - val_loss: 39.7247

Epoch 00207: val_loss did not improve from 39.58892
Epoch 208/10000
4/4 - 0s - loss: 19.6969 - val_loss: 39.6889

Epoch 00208: val_loss did not improve from 39.58892
Epoch 209/10000
4/4 - 0s - loss: 19.6937 - val_loss: 39.6516

Epoch 00209: val_loss did not improve from 39.58892
Epoch 210/10000
4/4 - 0s - loss: 19.6996 - val_loss: 39.6502

Epoch 00210: val_loss did not improve from 39.58892
Epoch 211/10000
4/4 - 0s - loss: 19.7018 - val_loss: 39.7060

Epoch 00211: val_loss did not improve from 39.58892
Epoch 212/10000
4/4 - 0s - loss: 19.7028 - val_loss: 39.7104

Epoch 00212: val_loss did not improve from 39.58892
Epoch 213/10000
4/4 - 0s - loss: 19.6929 - val_loss: 39.6380

Epoch 00213: val_loss did not improve from 39.58892
Epoch 214/10000
4/4 - 0s - loss: 19.7275 - val_loss: 39.6427

Epoch 00214: val_loss did not improve from 39.58892
Epoch 215/10000
4/4 - 0s - loss: 19.6875 - val_loss: 39.7864

Epoch 00215: val_loss did not improve from 39.58892
Epoch 216/10000
4/4 - 0s - loss: 19.7231 - val_loss: 39.7956

Epoch 00216: val_loss did not improve from 39.58892
Epoch 217/10000
4/4 - 0s - loss: 19.7128 - val_loss: 39.6231

Epoch 00217: val_loss did not improve from 39.58892
Epoch 218/10000
4/4 - 0s - loss: 19.7119 - val_loss: 39.6359

Epoch 00218: val_loss did not improve from 39.58892
Epoch 219/10000
4/4 - 0s - loss: 19.6928 - val_loss: 39.7225

Epoch 00219: val_loss did not improve from 39.58892
Epoch 220/10000
4/4 - 0s - loss: 19.6982 - val_loss: 39.7847

Epoch 00220: val_loss did not improve from 39.58892
Epoch 221/10000
4/4 - 0s - loss: 19.7071 - val_loss: 39.7307

Epoch 00221: val_loss did not improve from 39.58892
Epoch 222/10000
4/4 - 0s - loss: 19.6957 - val_loss: 39.6397

Epoch 00222: val_loss did not improve from 39.58892
Epoch 223/10000
4/4 - 0s - loss: 19.7045 - val_loss: 39.6539

Epoch 00223: val_loss did not improve from 39.58892
Epoch 224/10000
4/4 - 0s - loss: 19.6947 - val_loss: 39.6978

Epoch 00224: val_loss did not improve from 39.58892
Epoch 225/10000
4/4 - 0s - loss: 19.6988 - val_loss: 39.7667

Epoch 00225: val_loss did not improve from 39.58892
Epoch 226/10000
4/4 - 0s - loss: 19.7068 - val_loss: 39.6958

Epoch 00226: val_loss did not improve from 39.58892
Epoch 227/10000
4/4 - 0s - loss: 19.6996 - val_loss: 39.6548

Epoch 00227: val_loss did not improve from 39.58892
Epoch 228/10000
4/4 - 0s - loss: 19.7029 - val_loss: 39.6971

Epoch 00228: val_loss did not improve from 39.58892
Epoch 229/10000
4/4 - 0s - loss: 19.7003 - val_loss: 39.6581

Epoch 00229: val_loss did not improve from 39.58892
Epoch 230/10000
4/4 - 0s - loss: 19.7024 - val_loss: 39.6809

Epoch 00230: val_loss did not improve from 39.58892
Epoch 231/10000
4/4 - 0s - loss: 19.6983 - val_loss: 39.7397

Epoch 00231: val_loss did not improve from 39.58892
Epoch 232/10000
4/4 - 0s - loss: 19.6995 - val_loss: 39.6823

Epoch 00232: val_loss did not improve from 39.58892
Epoch 233/10000
4/4 - 0s - loss: 19.7036 - val_loss: 39.6994

Epoch 00233: val_loss did not improve from 39.58892
Epoch 234/10000
4/4 - 0s - loss: 19.6911 - val_loss: 39.6396

Epoch 00234: val_loss did not improve from 39.58892
Epoch 235/10000
4/4 - 0s - loss: 19.7043 - val_loss: 39.6555

Epoch 00235: val_loss did not improve from 39.58892
Epoch 236/10000
4/4 - 0s - loss: 19.6961 - val_loss: 39.6873

Epoch 00236: val_loss did not improve from 39.58892
Epoch 237/10000
4/4 - 0s - loss: 19.6972 - val_loss: 39.7541

Epoch 00237: val_loss did not improve from 39.58892
Epoch 238/10000
4/4 - 0s - loss: 19.6989 - val_loss: 39.6984

Epoch 00238: val_loss did not improve from 39.58892
Epoch 239/10000
4/4 - 0s - loss: 19.6932 - val_loss: 39.6745

Epoch 00239: val_loss did not improve from 39.58892
Epoch 240/10000
4/4 - 0s - loss: 19.6979 - val_loss: 39.6842

Epoch 00240: val_loss did not improve from 39.58892
Epoch 241/10000
4/4 - 0s - loss: 19.6947 - val_loss: 39.6867

Epoch 00241: val_loss did not improve from 39.58892
Epoch 242/10000
4/4 - 0s - loss: 19.6944 - val_loss: 39.6913

Epoch 00242: val_loss did not improve from 39.58892
Epoch 243/10000
4/4 - 0s - loss: 19.6962 - val_loss: 39.7077

Epoch 00243: val_loss did not improve from 39.58892
Epoch 244/10000
4/4 - 0s - loss: 19.6935 - val_loss: 39.6769

Epoch 00244: val_loss did not improve from 39.58892
Epoch 245/10000
4/4 - 0s - loss: 19.6949 - val_loss: 39.6892

Epoch 00245: val_loss did not improve from 39.58892
Epoch 246/10000
4/4 - 0s - loss: 19.6964 - val_loss: 39.6867

Epoch 00246: val_loss did not improve from 39.58892
Epoch 247/10000
4/4 - 0s - loss: 19.6933 - val_loss: 39.7371

Epoch 00247: val_loss did not improve from 39.58892
Epoch 248/10000
4/4 - 0s - loss: 19.6989 - val_loss: 39.7159

Epoch 00248: val_loss did not improve from 39.58892
Epoch 249/10000
4/4 - 0s - loss: 19.6976 - val_loss: 39.6686

Epoch 00249: val_loss did not improve from 39.58892
Epoch 250/10000
4/4 - 0s - loss: 19.6977 - val_loss: 39.6916

Epoch 00250: val_loss did not improve from 39.58892
Epoch 251/10000
4/4 - 0s - loss: 19.6934 - val_loss: 39.6947

Epoch 00251: val_loss did not improve from 39.58892
Epoch 252/10000
4/4 - 0s - loss: 19.6936 - val_loss: 39.6745

Epoch 00252: val_loss did not improve from 39.58892
Epoch 253/10000
4/4 - 0s - loss: 19.6986 - val_loss: 39.6953

Epoch 00253: val_loss did not improve from 39.58892
Epoch 254/10000
4/4 - 0s - loss: 19.6991 - val_loss: 39.7230

Epoch 00254: val_loss did not improve from 39.58892
Epoch 255/10000
4/4 - 0s - loss: 19.6996 - val_loss: 39.7189

Epoch 00255: val_loss did not improve from 39.58892
Epoch 256/10000
4/4 - 0s - loss: 19.7032 - val_loss: 39.6349

Epoch 00256: val_loss did not improve from 39.58892
Epoch 257/10000
4/4 - 0s - loss: 19.7007 - val_loss: 39.6573

Epoch 00257: val_loss did not improve from 39.58892
Epoch 258/10000
4/4 - 0s - loss: 19.6894 - val_loss: 39.7312

Epoch 00258: val_loss did not improve from 39.58892
Epoch 259/10000
4/4 - 0s - loss: 19.7122 - val_loss: 39.7698

Epoch 00259: val_loss did not improve from 39.58892
Epoch 260/10000
4/4 - 0s - loss: 19.7073 - val_loss: 39.7472

Epoch 00260: val_loss did not improve from 39.58892
Epoch 261/10000
4/4 - 0s - loss: 19.6966 - val_loss: 39.6549

Epoch 00261: val_loss did not improve from 39.58892
Epoch 262/10000
4/4 - 0s - loss: 19.7021 - val_loss: 39.6593

Epoch 00262: val_loss did not improve from 39.58892
Epoch 263/10000
4/4 - 0s - loss: 19.6971 - val_loss: 39.7271

Epoch 00263: val_loss did not improve from 39.58892
Epoch 264/10000
4/4 - 0s - loss: 19.6999 - val_loss: 39.6959

Epoch 00264: val_loss did not improve from 39.58892
Epoch 265/10000
4/4 - 0s - loss: 19.7118 - val_loss: 39.6251

Epoch 00265: val_loss did not improve from 39.58892
Epoch 266/10000
4/4 - 0s - loss: 19.7085 - val_loss: 39.6739

Epoch 00266: val_loss did not improve from 39.58892
Epoch 267/10000
4/4 - 0s - loss: 19.6935 - val_loss: 39.7085

Epoch 00267: val_loss did not improve from 39.58892
Epoch 268/10000
4/4 - 0s - loss: 19.7146 - val_loss: 39.7823

Epoch 00268: val_loss did not improve from 39.58892
Epoch 269/10000
4/4 - 0s - loss: 19.6978 - val_loss: 39.6665

Epoch 00269: val_loss did not improve from 39.58892
Epoch 270/10000
4/4 - 0s - loss: 19.7083 - val_loss: 39.6191

Epoch 00270: val_loss did not improve from 39.58892
Epoch 271/10000
4/4 - 0s - loss: 19.6977 - val_loss: 39.7051

Epoch 00271: val_loss did not improve from 39.58892
Epoch 272/10000
4/4 - 0s - loss: 19.7137 - val_loss: 39.7952

Epoch 00272: val_loss did not improve from 39.58892
Epoch 273/10000
4/4 - 0s - loss: 19.7129 - val_loss: 39.6616

Epoch 00273: val_loss did not improve from 39.58892
Epoch 274/10000
4/4 - 0s - loss: 19.6956 - val_loss: 39.6487

Epoch 00274: val_loss did not improve from 39.58892
Epoch 275/10000
4/4 - 0s - loss: 19.7053 - val_loss: 39.6837

Epoch 00275: val_loss did not improve from 39.58892
Epoch 276/10000
4/4 - 0s - loss: 19.7013 - val_loss: 39.6466

Epoch 00276: val_loss did not improve from 39.58892
Epoch 277/10000
4/4 - 0s - loss: 19.7024 - val_loss: 39.7230

Epoch 00277: val_loss did not improve from 39.58892
Epoch 278/10000
4/4 - 0s - loss: 19.6997 - val_loss: 39.7672

Epoch 00278: val_loss did not improve from 39.58892
Epoch 279/10000
4/4 - 0s - loss: 19.7049 - val_loss: 39.6889

Epoch 00279: val_loss did not improve from 39.58892
Epoch 00279: early stopping
*************************** Fold #: 7 ***************************
Model: "sequential_26"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_286 (Dense)            (None, 30)                150       
_________________________________________________________________
dense_287 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_288 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_289 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_290 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_291 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_292 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_293 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_294 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_295 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_296 (Dense)            (None, 1)                 31        
=================================================================
Total params: 8,551
Trainable params: 8,551
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
4/4 - 0s - loss: 32.4404 - val_loss: 21.2045

Epoch 00001: val_loss improved from inf to 21.20452, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 2/10000
4/4 - 0s - loss: 32.4029 - val_loss: 21.1663

Epoch 00002: val_loss improved from 21.20452 to 21.16626, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 3/10000
4/4 - 0s - loss: 32.3604 - val_loss: 21.1228

Epoch 00003: val_loss improved from 21.16626 to 21.12283, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 4/10000
4/4 - 0s - loss: 32.3114 - val_loss: 21.0727

Epoch 00004: val_loss improved from 21.12283 to 21.07273, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 5/10000
4/4 - 0s - loss: 32.2550 - val_loss: 21.0138

Epoch 00005: val_loss improved from 21.07273 to 21.01381, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 6/10000
4/4 - 0s - loss: 32.1873 - val_loss: 20.9432

Epoch 00006: val_loss improved from 21.01381 to 20.94321, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 7/10000
4/4 - 0s - loss: 32.1065 - val_loss: 20.8564

Epoch 00007: val_loss improved from 20.94321 to 20.85639, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 8/10000
4/4 - 0s - loss: 32.0056 - val_loss: 20.7468

Epoch 00008: val_loss improved from 20.85639 to 20.74681, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 9/10000
4/4 - 0s - loss: 31.8760 - val_loss: 20.6041

Epoch 00009: val_loss improved from 20.74681 to 20.60406, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 10/10000
4/4 - 0s - loss: 31.7085 - val_loss: 20.4108

Epoch 00010: val_loss improved from 20.60406 to 20.41081, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 11/10000
4/4 - 0s - loss: 31.4781 - val_loss: 20.1386

Epoch 00011: val_loss improved from 20.41081 to 20.13862, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 12/10000
4/4 - 0s - loss: 31.1346 - val_loss: 19.7380

Epoch 00012: val_loss improved from 20.13862 to 19.73798, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 13/10000
4/4 - 0s - loss: 30.6415 - val_loss: 19.1209

Epoch 00013: val_loss improved from 19.73798 to 19.12090, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 14/10000
4/4 - 0s - loss: 29.8410 - val_loss: 18.1458

Epoch 00014: val_loss improved from 19.12090 to 18.14581, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 15/10000
4/4 - 0s - loss: 28.6368 - val_loss: 16.6376

Epoch 00015: val_loss improved from 18.14581 to 16.63760, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 16/10000
4/4 - 0s - loss: 26.7034 - val_loss: 14.6972

Epoch 00016: val_loss improved from 16.63760 to 14.69722, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 17/10000
4/4 - 0s - loss: 24.6550 - val_loss: 14.3645

Epoch 00017: val_loss improved from 14.69722 to 14.36451, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 18/10000
4/4 - 0s - loss: 24.6807 - val_loss: 14.9946

Epoch 00018: val_loss did not improve from 14.36451
Epoch 19/10000
4/4 - 0s - loss: 24.2987 - val_loss: 13.9934

Epoch 00019: val_loss improved from 14.36451 to 13.99342, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 20/10000
4/4 - 0s - loss: 23.9346 - val_loss: 13.9497

Epoch 00020: val_loss improved from 13.99342 to 13.94973, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 21/10000
4/4 - 0s - loss: 24.0657 - val_loss: 13.9466

Epoch 00021: val_loss improved from 13.94973 to 13.94664, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 22/10000
4/4 - 0s - loss: 23.9394 - val_loss: 13.8409

Epoch 00022: val_loss improved from 13.94664 to 13.84093, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 23/10000
4/4 - 0s - loss: 23.6530 - val_loss: 13.9247

Epoch 00023: val_loss did not improve from 13.84093
Epoch 24/10000
4/4 - 0s - loss: 23.6012 - val_loss: 14.0949

Epoch 00024: val_loss did not improve from 13.84093
Epoch 25/10000
4/4 - 0s - loss: 23.5255 - val_loss: 13.9396

Epoch 00025: val_loss did not improve from 13.84093
Epoch 26/10000
4/4 - 0s - loss: 23.3798 - val_loss: 13.8262

Epoch 00026: val_loss improved from 13.84093 to 13.82617, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 27/10000
4/4 - 0s - loss: 23.3059 - val_loss: 13.7915

Epoch 00027: val_loss improved from 13.82617 to 13.79146, saving model to ./results/dataset/trial_3/ckpt_7
Epoch 28/10000
4/4 - 0s - loss: 23.2374 - val_loss: 13.8464

Epoch 00028: val_loss did not improve from 13.79146
Epoch 29/10000
4/4 - 0s - loss: 23.1389 - val_loss: 13.8780

Epoch 00029: val_loss did not improve from 13.79146
Epoch 30/10000
4/4 - 0s - loss: 23.0714 - val_loss: 13.9125

Epoch 00030: val_loss did not improve from 13.79146
Epoch 31/10000
4/4 - 0s - loss: 23.0098 - val_loss: 13.9335

Epoch 00031: val_loss did not improve from 13.79146
Epoch 32/10000
4/4 - 0s - loss: 22.9592 - val_loss: 13.9409

Epoch 00032: val_loss did not improve from 13.79146
Epoch 33/10000
4/4 - 0s - loss: 22.9074 - val_loss: 13.8881

Epoch 00033: val_loss did not improve from 13.79146
Epoch 34/10000
4/4 - 0s - loss: 22.8702 - val_loss: 13.9491

Epoch 00034: val_loss did not improve from 13.79146
Epoch 35/10000
4/4 - 0s - loss: 22.8376 - val_loss: 14.1049

Epoch 00035: val_loss did not improve from 13.79146
Epoch 36/10000
4/4 - 0s - loss: 22.7988 - val_loss: 14.0812

Epoch 00036: val_loss did not improve from 13.79146
Epoch 37/10000
4/4 - 0s - loss: 22.7613 - val_loss: 14.0067

Epoch 00037: val_loss did not improve from 13.79146
Epoch 38/10000
4/4 - 0s - loss: 22.7441 - val_loss: 14.0350

Epoch 00038: val_loss did not improve from 13.79146
Epoch 39/10000
4/4 - 0s - loss: 22.7159 - val_loss: 14.0171

Epoch 00039: val_loss did not improve from 13.79146
Epoch 40/10000
4/4 - 0s - loss: 22.6943 - val_loss: 14.1010

Epoch 00040: val_loss did not improve from 13.79146
Epoch 41/10000
4/4 - 0s - loss: 22.6765 - val_loss: 14.1727

Epoch 00041: val_loss did not improve from 13.79146
Epoch 42/10000
4/4 - 0s - loss: 22.6506 - val_loss: 14.1036

Epoch 00042: val_loss did not improve from 13.79146
Epoch 43/10000
4/4 - 0s - loss: 22.6356 - val_loss: 14.1029

Epoch 00043: val_loss did not improve from 13.79146
Epoch 44/10000
4/4 - 0s - loss: 22.6374 - val_loss: 14.2522

Epoch 00044: val_loss did not improve from 13.79146
Epoch 45/10000
4/4 - 0s - loss: 22.6061 - val_loss: 14.1657

Epoch 00045: val_loss did not improve from 13.79146
Epoch 46/10000
4/4 - 0s - loss: 22.5985 - val_loss: 14.0742

Epoch 00046: val_loss did not improve from 13.79146
Epoch 47/10000
4/4 - 0s - loss: 22.5791 - val_loss: 14.1864

Epoch 00047: val_loss did not improve from 13.79146
Epoch 48/10000
4/4 - 0s - loss: 22.5692 - val_loss: 14.2837

Epoch 00048: val_loss did not improve from 13.79146
Epoch 49/10000
4/4 - 0s - loss: 22.5633 - val_loss: 14.2373

Epoch 00049: val_loss did not improve from 13.79146
Epoch 50/10000
4/4 - 0s - loss: 22.5537 - val_loss: 14.1704

Epoch 00050: val_loss did not improve from 13.79146
Epoch 51/10000
4/4 - 0s - loss: 22.5501 - val_loss: 14.2200

Epoch 00051: val_loss did not improve from 13.79146
Epoch 52/10000
4/4 - 0s - loss: 22.5414 - val_loss: 14.1909

Epoch 00052: val_loss did not improve from 13.79146
Epoch 53/10000
4/4 - 0s - loss: 22.5388 - val_loss: 14.2066

Epoch 00053: val_loss did not improve from 13.79146
Epoch 54/10000
4/4 - 0s - loss: 22.5343 - val_loss: 14.2806

Epoch 00054: val_loss did not improve from 13.79146
Epoch 55/10000
4/4 - 0s - loss: 22.5395 - val_loss: 14.2758

Epoch 00055: val_loss did not improve from 13.79146
Epoch 56/10000
4/4 - 0s - loss: 22.5401 - val_loss: 14.1674

Epoch 00056: val_loss did not improve from 13.79146
Epoch 57/10000
4/4 - 0s - loss: 22.5310 - val_loss: 14.2534

Epoch 00057: val_loss did not improve from 13.79146
Epoch 58/10000
4/4 - 0s - loss: 22.5370 - val_loss: 14.3819

Epoch 00058: val_loss did not improve from 13.79146
Epoch 59/10000
4/4 - 0s - loss: 22.5441 - val_loss: 14.3165

Epoch 00059: val_loss did not improve from 13.79146
Epoch 60/10000
4/4 - 0s - loss: 22.5244 - val_loss: 14.1252

Epoch 00060: val_loss did not improve from 13.79146
Epoch 61/10000
4/4 - 0s - loss: 22.5631 - val_loss: 14.1522

Epoch 00061: val_loss did not improve from 13.79146
Epoch 62/10000
4/4 - 0s - loss: 22.5476 - val_loss: 14.1902

Epoch 00062: val_loss did not improve from 13.79146
Epoch 63/10000
4/4 - 0s - loss: 22.5256 - val_loss: 14.3637

Epoch 00063: val_loss did not improve from 13.79146
Epoch 64/10000
4/4 - 0s - loss: 22.5467 - val_loss: 14.3451

Epoch 00064: val_loss did not improve from 13.79146
Epoch 65/10000
4/4 - 0s - loss: 22.5172 - val_loss: 14.1625

Epoch 00065: val_loss did not improve from 13.79146
Epoch 66/10000
4/4 - 0s - loss: 22.5498 - val_loss: 14.1277

Epoch 00066: val_loss did not improve from 13.79146
Epoch 67/10000
4/4 - 0s - loss: 22.5498 - val_loss: 14.2568

Epoch 00067: val_loss did not improve from 13.79146
Epoch 68/10000
4/4 - 0s - loss: 22.5286 - val_loss: 14.2638

Epoch 00068: val_loss did not improve from 13.79146
Epoch 69/10000
4/4 - 0s - loss: 22.5254 - val_loss: 14.2099

Epoch 00069: val_loss did not improve from 13.79146
Epoch 70/10000
4/4 - 0s - loss: 22.5250 - val_loss: 14.2196

Epoch 00070: val_loss did not improve from 13.79146
Epoch 71/10000
4/4 - 0s - loss: 22.5254 - val_loss: 14.2818

Epoch 00071: val_loss did not improve from 13.79146
Epoch 72/10000
4/4 - 0s - loss: 22.5251 - val_loss: 14.2615

Epoch 00072: val_loss did not improve from 13.79146
Epoch 73/10000
4/4 - 0s - loss: 22.5420 - val_loss: 14.1795

Epoch 00073: val_loss did not improve from 13.79146
Epoch 74/10000
4/4 - 0s - loss: 22.5238 - val_loss: 14.3425

Epoch 00074: val_loss did not improve from 13.79146
Epoch 75/10000
4/4 - 0s - loss: 22.5447 - val_loss: 14.4048

Epoch 00075: val_loss did not improve from 13.79146
Epoch 76/10000
4/4 - 0s - loss: 22.5412 - val_loss: 14.1824

Epoch 00076: val_loss did not improve from 13.79146
Epoch 77/10000
4/4 - 0s - loss: 22.5344 - val_loss: 14.2275

Epoch 00077: val_loss did not improve from 13.79146
Epoch 78/10000
4/4 - 0s - loss: 22.5253 - val_loss: 14.2920

Epoch 00078: val_loss did not improve from 13.79146
Epoch 79/10000
4/4 - 0s - loss: 22.5245 - val_loss: 14.3522

Epoch 00079: val_loss did not improve from 13.79146
Epoch 80/10000
4/4 - 0s - loss: 22.5298 - val_loss: 14.3269

Epoch 00080: val_loss did not improve from 13.79146
Epoch 81/10000
4/4 - 0s - loss: 22.5282 - val_loss: 14.2603

Epoch 00081: val_loss did not improve from 13.79146
Epoch 82/10000
4/4 - 0s - loss: 22.5242 - val_loss: 14.3060

Epoch 00082: val_loss did not improve from 13.79146
Epoch 83/10000
4/4 - 0s - loss: 22.5292 - val_loss: 14.3036

Epoch 00083: val_loss did not improve from 13.79146
Epoch 84/10000
4/4 - 0s - loss: 22.5432 - val_loss: 14.3700

Epoch 00084: val_loss did not improve from 13.79146
Epoch 85/10000
4/4 - 0s - loss: 22.5323 - val_loss: 14.1643

Epoch 00085: val_loss did not improve from 13.79146
Epoch 86/10000
4/4 - 0s - loss: 22.5375 - val_loss: 14.2071

Epoch 00086: val_loss did not improve from 13.79146
Epoch 87/10000
4/4 - 0s - loss: 22.5255 - val_loss: 14.2943

Epoch 00087: val_loss did not improve from 13.79146
Epoch 88/10000
4/4 - 0s - loss: 22.5298 - val_loss: 14.3362

Epoch 00088: val_loss did not improve from 13.79146
Epoch 89/10000
4/4 - 0s - loss: 22.5290 - val_loss: 14.2647

Epoch 00089: val_loss did not improve from 13.79146
Epoch 90/10000
4/4 - 0s - loss: 22.5305 - val_loss: 14.2059

Epoch 00090: val_loss did not improve from 13.79146
Epoch 91/10000
4/4 - 0s - loss: 22.5206 - val_loss: 14.2893

Epoch 00091: val_loss did not improve from 13.79146
Epoch 92/10000
4/4 - 0s - loss: 22.5563 - val_loss: 14.3297

Epoch 00092: val_loss did not improve from 13.79146
Epoch 93/10000
4/4 - 0s - loss: 22.5275 - val_loss: 14.1142

Epoch 00093: val_loss did not improve from 13.79146
Epoch 94/10000
4/4 - 0s - loss: 22.5431 - val_loss: 14.1292

Epoch 00094: val_loss did not improve from 13.79146
Epoch 95/10000
4/4 - 0s - loss: 22.5252 - val_loss: 14.2643

Epoch 00095: val_loss did not improve from 13.79146
Epoch 96/10000
4/4 - 0s - loss: 22.5348 - val_loss: 14.3787

Epoch 00096: val_loss did not improve from 13.79146
Epoch 97/10000
4/4 - 0s - loss: 22.5544 - val_loss: 14.3329

Epoch 00097: val_loss did not improve from 13.79146
Epoch 98/10000
4/4 - 0s - loss: 22.5476 - val_loss: 14.1228

Epoch 00098: val_loss did not improve from 13.79146
Epoch 99/10000
4/4 - 0s - loss: 22.5373 - val_loss: 14.2074

Epoch 00099: val_loss did not improve from 13.79146
Epoch 100/10000
4/4 - 0s - loss: 22.5227 - val_loss: 14.3938

Epoch 00100: val_loss did not improve from 13.79146
Epoch 101/10000
4/4 - 0s - loss: 22.5452 - val_loss: 14.3107

Epoch 00101: val_loss did not improve from 13.79146
Epoch 102/10000
4/4 - 0s - loss: 22.5111 - val_loss: 14.1260

Epoch 00102: val_loss did not improve from 13.79146
Epoch 103/10000
4/4 - 0s - loss: 22.5652 - val_loss: 14.1317

Epoch 00103: val_loss did not improve from 13.79146
Epoch 104/10000
4/4 - 0s - loss: 22.5231 - val_loss: 14.3991

Epoch 00104: val_loss did not improve from 13.79146
Epoch 105/10000
4/4 - 0s - loss: 22.5391 - val_loss: 14.4463

Epoch 00105: val_loss did not improve from 13.79146
Epoch 106/10000
4/4 - 0s - loss: 22.5360 - val_loss: 14.3067

Epoch 00106: val_loss did not improve from 13.79146
Epoch 107/10000
4/4 - 0s - loss: 22.5385 - val_loss: 14.1275

Epoch 00107: val_loss did not improve from 13.79146
Epoch 108/10000
4/4 - 0s - loss: 22.5495 - val_loss: 14.1930

Epoch 00108: val_loss did not improve from 13.79146
Epoch 109/10000
4/4 - 0s - loss: 22.5247 - val_loss: 14.3537

Epoch 00109: val_loss did not improve from 13.79146
Epoch 110/10000
4/4 - 0s - loss: 22.5330 - val_loss: 14.3011

Epoch 00110: val_loss did not improve from 13.79146
Epoch 111/10000
4/4 - 0s - loss: 22.5236 - val_loss: 14.3164

Epoch 00111: val_loss did not improve from 13.79146
Epoch 112/10000
4/4 - 0s - loss: 22.5346 - val_loss: 14.2477

Epoch 00112: val_loss did not improve from 13.79146
Epoch 113/10000
4/4 - 0s - loss: 22.5267 - val_loss: 14.3587

Epoch 00113: val_loss did not improve from 13.79146
Epoch 114/10000
4/4 - 0s - loss: 22.5312 - val_loss: 14.3132

Epoch 00114: val_loss did not improve from 13.79146
Epoch 115/10000
4/4 - 0s - loss: 22.5255 - val_loss: 14.1986

Epoch 00115: val_loss did not improve from 13.79146
Epoch 116/10000
4/4 - 0s - loss: 22.5517 - val_loss: 14.1791

Epoch 00116: val_loss did not improve from 13.79146
Epoch 117/10000
4/4 - 0s - loss: 22.5406 - val_loss: 14.4714

Epoch 00117: val_loss did not improve from 13.79146
Epoch 118/10000
4/4 - 0s - loss: 22.5492 - val_loss: 14.3934

Epoch 00118: val_loss did not improve from 13.79146
Epoch 119/10000
4/4 - 0s - loss: 22.5368 - val_loss: 14.1946

Epoch 00119: val_loss did not improve from 13.79146
Epoch 120/10000
4/4 - 0s - loss: 22.5354 - val_loss: 14.2056

Epoch 00120: val_loss did not improve from 13.79146
Epoch 121/10000
4/4 - 0s - loss: 22.5345 - val_loss: 14.3720

Epoch 00121: val_loss did not improve from 13.79146
Epoch 122/10000
4/4 - 0s - loss: 22.5333 - val_loss: 14.2987

Epoch 00122: val_loss did not improve from 13.79146
Epoch 123/10000
4/4 - 0s - loss: 22.5238 - val_loss: 14.2951

Epoch 00123: val_loss did not improve from 13.79146
Epoch 124/10000
4/4 - 0s - loss: 22.5256 - val_loss: 14.2560

Epoch 00124: val_loss did not improve from 13.79146
Epoch 125/10000
4/4 - 0s - loss: 22.5269 - val_loss: 14.2966

Epoch 00125: val_loss did not improve from 13.79146
Epoch 126/10000
4/4 - 0s - loss: 22.5269 - val_loss: 14.2820

Epoch 00126: val_loss did not improve from 13.79146
Epoch 127/10000
4/4 - 0s - loss: 22.5209 - val_loss: 14.1752

Epoch 00127: val_loss did not improve from 13.79146
Epoch 128/10000
4/4 - 0s - loss: 22.5313 - val_loss: 14.2034

Epoch 00128: val_loss did not improve from 13.79146
Epoch 129/10000
4/4 - 0s - loss: 22.5252 - val_loss: 14.2918

Epoch 00129: val_loss did not improve from 13.79146
Epoch 130/10000
4/4 - 0s - loss: 22.5247 - val_loss: 14.3095

Epoch 00130: val_loss did not improve from 13.79146
Epoch 131/10000
4/4 - 0s - loss: 22.5264 - val_loss: 14.2081

Epoch 00131: val_loss did not improve from 13.79146
Epoch 132/10000
4/4 - 0s - loss: 22.5247 - val_loss: 14.2148

Epoch 00132: val_loss did not improve from 13.79146
Epoch 133/10000
4/4 - 0s - loss: 22.5296 - val_loss: 14.2347

Epoch 00133: val_loss did not improve from 13.79146
Epoch 134/10000
4/4 - 0s - loss: 22.5253 - val_loss: 14.2960

Epoch 00134: val_loss did not improve from 13.79146
Epoch 135/10000
4/4 - 0s - loss: 22.5314 - val_loss: 14.2734

Epoch 00135: val_loss did not improve from 13.79146
Epoch 136/10000
4/4 - 0s - loss: 22.5528 - val_loss: 14.1686

Epoch 00136: val_loss did not improve from 13.79146
Epoch 137/10000
4/4 - 0s - loss: 22.5510 - val_loss: 14.3510

Epoch 00137: val_loss did not improve from 13.79146
Epoch 138/10000
4/4 - 0s - loss: 22.5318 - val_loss: 14.2245

Epoch 00138: val_loss did not improve from 13.79146
Epoch 139/10000
4/4 - 0s - loss: 22.5242 - val_loss: 14.2608

Epoch 00139: val_loss did not improve from 13.79146
Epoch 140/10000
4/4 - 0s - loss: 22.5220 - val_loss: 14.3300

Epoch 00140: val_loss did not improve from 13.79146
Epoch 141/10000
4/4 - 0s - loss: 22.5261 - val_loss: 14.3427

Epoch 00141: val_loss did not improve from 13.79146
Epoch 142/10000
4/4 - 0s - loss: 22.5231 - val_loss: 14.2378

Epoch 00142: val_loss did not improve from 13.79146
Epoch 143/10000
4/4 - 0s - loss: 22.5257 - val_loss: 14.2134

Epoch 00143: val_loss did not improve from 13.79146
Epoch 144/10000
4/4 - 0s - loss: 22.5353 - val_loss: 14.3012

Epoch 00144: val_loss did not improve from 13.79146
Epoch 145/10000
4/4 - 0s - loss: 22.5212 - val_loss: 14.2043

Epoch 00145: val_loss did not improve from 13.79146
Epoch 146/10000
4/4 - 0s - loss: 22.5341 - val_loss: 14.1840

Epoch 00146: val_loss did not improve from 13.79146
Epoch 147/10000
4/4 - 0s - loss: 22.5356 - val_loss: 14.3308

Epoch 00147: val_loss did not improve from 13.79146
Epoch 148/10000
4/4 - 0s - loss: 22.5307 - val_loss: 14.2333

Epoch 00148: val_loss did not improve from 13.79146
Epoch 149/10000
4/4 - 0s - loss: 22.5269 - val_loss: 14.2808

Epoch 00149: val_loss did not improve from 13.79146
Epoch 150/10000
4/4 - 0s - loss: 22.5226 - val_loss: 14.2139

Epoch 00150: val_loss did not improve from 13.79146
Epoch 151/10000
4/4 - 0s - loss: 22.5459 - val_loss: 14.1919

Epoch 00151: val_loss did not improve from 13.79146
Epoch 152/10000
4/4 - 0s - loss: 22.5405 - val_loss: 14.3339

Epoch 00152: val_loss did not improve from 13.79146
Epoch 153/10000
4/4 - 0s - loss: 22.5378 - val_loss: 14.3114

Epoch 00153: val_loss did not improve from 13.79146
Epoch 154/10000
4/4 - 0s - loss: 22.5326 - val_loss: 14.1811

Epoch 00154: val_loss did not improve from 13.79146
Epoch 155/10000
4/4 - 0s - loss: 22.5312 - val_loss: 14.2801

Epoch 00155: val_loss did not improve from 13.79146
Epoch 156/10000
4/4 - 0s - loss: 22.5260 - val_loss: 14.2912

Epoch 00156: val_loss did not improve from 13.79146
Epoch 157/10000
4/4 - 0s - loss: 22.5246 - val_loss: 14.2228

Epoch 00157: val_loss did not improve from 13.79146
Epoch 158/10000
4/4 - 0s - loss: 22.5237 - val_loss: 14.2385

Epoch 00158: val_loss did not improve from 13.79146
Epoch 159/10000
4/4 - 0s - loss: 22.5269 - val_loss: 14.2074

Epoch 00159: val_loss did not improve from 13.79146
Epoch 160/10000
4/4 - 0s - loss: 22.5239 - val_loss: 14.2315

Epoch 00160: val_loss did not improve from 13.79146
Epoch 161/10000
4/4 - 0s - loss: 22.5236 - val_loss: 14.2868

Epoch 00161: val_loss did not improve from 13.79146
Epoch 162/10000
4/4 - 0s - loss: 22.5442 - val_loss: 14.3869

Epoch 00162: val_loss did not improve from 13.79146
Epoch 163/10000
4/4 - 0s - loss: 22.5197 - val_loss: 14.1815

Epoch 00163: val_loss did not improve from 13.79146
Epoch 164/10000
4/4 - 0s - loss: 22.5421 - val_loss: 14.1328

Epoch 00164: val_loss did not improve from 13.79146
Epoch 165/10000
4/4 - 0s - loss: 22.5361 - val_loss: 14.3065

Epoch 00165: val_loss did not improve from 13.79146
Epoch 166/10000
4/4 - 0s - loss: 22.5255 - val_loss: 14.3373

Epoch 00166: val_loss did not improve from 13.79146
Epoch 167/10000
4/4 - 0s - loss: 22.5305 - val_loss: 14.2128

Epoch 00167: val_loss did not improve from 13.79146
Epoch 168/10000
4/4 - 0s - loss: 22.5314 - val_loss: 14.1655

Epoch 00168: val_loss did not improve from 13.79146
Epoch 169/10000
4/4 - 0s - loss: 22.5302 - val_loss: 14.2883

Epoch 00169: val_loss did not improve from 13.79146
Epoch 170/10000
4/4 - 0s - loss: 22.5316 - val_loss: 14.2996

Epoch 00170: val_loss did not improve from 13.79146
Epoch 171/10000
4/4 - 0s - loss: 22.5214 - val_loss: 14.3592

Epoch 00171: val_loss did not improve from 13.79146
Epoch 172/10000
4/4 - 0s - loss: 22.5417 - val_loss: 14.3708

Epoch 00172: val_loss did not improve from 13.79146
Epoch 173/10000
4/4 - 0s - loss: 22.5243 - val_loss: 14.2720

Epoch 00173: val_loss did not improve from 13.79146
Epoch 174/10000
4/4 - 0s - loss: 22.5240 - val_loss: 14.2225

Epoch 00174: val_loss did not improve from 13.79146
Epoch 175/10000
4/4 - 0s - loss: 22.5280 - val_loss: 14.2737

Epoch 00175: val_loss did not improve from 13.79146
Epoch 176/10000
4/4 - 0s - loss: 22.5342 - val_loss: 14.2790

Epoch 00176: val_loss did not improve from 13.79146
Epoch 177/10000
4/4 - 0s - loss: 22.5241 - val_loss: 14.1501

Epoch 00177: val_loss did not improve from 13.79146
Epoch 178/10000
4/4 - 0s - loss: 22.5453 - val_loss: 14.1705

Epoch 00178: val_loss did not improve from 13.79146
Epoch 179/10000
4/4 - 0s - loss: 22.5269 - val_loss: 14.2581

Epoch 00179: val_loss did not improve from 13.79146
Epoch 180/10000
4/4 - 0s - loss: 22.5164 - val_loss: 14.4238

Epoch 00180: val_loss did not improve from 13.79146
Epoch 181/10000
4/4 - 0s - loss: 22.5508 - val_loss: 14.3717

Epoch 00181: val_loss did not improve from 13.79146
Epoch 182/10000
4/4 - 0s - loss: 22.5330 - val_loss: 14.3057

Epoch 00182: val_loss did not improve from 13.79146
Epoch 183/10000
4/4 - 0s - loss: 22.5435 - val_loss: 14.1517

Epoch 00183: val_loss did not improve from 13.79146
Epoch 184/10000
4/4 - 0s - loss: 22.5339 - val_loss: 14.2640

Epoch 00184: val_loss did not improve from 13.79146
Epoch 185/10000
4/4 - 0s - loss: 22.5231 - val_loss: 14.4102

Epoch 00185: val_loss did not improve from 13.79146
Epoch 186/10000
4/4 - 0s - loss: 22.5451 - val_loss: 14.3324

Epoch 00186: val_loss did not improve from 13.79146
Epoch 187/10000
4/4 - 0s - loss: 22.5264 - val_loss: 14.1911

Epoch 00187: val_loss did not improve from 13.79146
Epoch 188/10000
4/4 - 0s - loss: 22.5372 - val_loss: 14.2426

Epoch 00188: val_loss did not improve from 13.79146
Epoch 189/10000
4/4 - 0s - loss: 22.5268 - val_loss: 14.3099

Epoch 00189: val_loss did not improve from 13.79146
Epoch 190/10000
4/4 - 0s - loss: 22.5237 - val_loss: 14.3383

Epoch 00190: val_loss did not improve from 13.79146
Epoch 191/10000
4/4 - 0s - loss: 22.5224 - val_loss: 14.2601

Epoch 00191: val_loss did not improve from 13.79146
Epoch 192/10000
4/4 - 0s - loss: 22.5251 - val_loss: 14.2419

Epoch 00192: val_loss did not improve from 13.79146
Epoch 193/10000
4/4 - 0s - loss: 22.5252 - val_loss: 14.2034

Epoch 00193: val_loss did not improve from 13.79146
Epoch 194/10000
4/4 - 0s - loss: 22.5317 - val_loss: 14.2391

Epoch 00194: val_loss did not improve from 13.79146
Epoch 195/10000
4/4 - 0s - loss: 22.5266 - val_loss: 14.2607

Epoch 00195: val_loss did not improve from 13.79146
Epoch 196/10000
4/4 - 0s - loss: 22.5257 - val_loss: 14.2602

Epoch 00196: val_loss did not improve from 13.79146
Epoch 197/10000
4/4 - 0s - loss: 22.5253 - val_loss: 14.2135

Epoch 00197: val_loss did not improve from 13.79146
Epoch 198/10000
4/4 - 0s - loss: 22.5316 - val_loss: 14.1637

Epoch 00198: val_loss did not improve from 13.79146
Epoch 199/10000
4/4 - 0s - loss: 22.5214 - val_loss: 14.3083

Epoch 00199: val_loss did not improve from 13.79146
Epoch 200/10000
4/4 - 0s - loss: 22.5419 - val_loss: 14.4309

Epoch 00200: val_loss did not improve from 13.79146
Epoch 201/10000
4/4 - 0s - loss: 22.5294 - val_loss: 14.1877

Epoch 00201: val_loss did not improve from 13.79146
Epoch 202/10000
4/4 - 0s - loss: 22.5463 - val_loss: 14.0425

Epoch 00202: val_loss did not improve from 13.79146
Epoch 203/10000
4/4 - 0s - loss: 22.5515 - val_loss: 14.2335

Epoch 00203: val_loss did not improve from 13.79146
Epoch 204/10000
4/4 - 0s - loss: 22.5662 - val_loss: 14.5297

Epoch 00204: val_loss did not improve from 13.79146
Epoch 205/10000
4/4 - 0s - loss: 22.5698 - val_loss: 14.2181

Epoch 00205: val_loss did not improve from 13.79146
Epoch 206/10000
4/4 - 0s - loss: 22.5277 - val_loss: 14.1862

Epoch 00206: val_loss did not improve from 13.79146
Epoch 207/10000
4/4 - 0s - loss: 22.5282 - val_loss: 14.2685

Epoch 00207: val_loss did not improve from 13.79146
Epoch 208/10000
4/4 - 0s - loss: 22.5254 - val_loss: 14.3081

Epoch 00208: val_loss did not improve from 13.79146
Epoch 209/10000
4/4 - 0s - loss: 22.5345 - val_loss: 14.2053

Epoch 00209: val_loss did not improve from 13.79146
Epoch 210/10000
4/4 - 0s - loss: 22.5243 - val_loss: 14.2671

Epoch 00210: val_loss did not improve from 13.79146
Epoch 211/10000
4/4 - 0s - loss: 22.5359 - val_loss: 14.3981

Epoch 00211: val_loss did not improve from 13.79146
Epoch 212/10000
4/4 - 0s - loss: 22.5421 - val_loss: 14.2644

Epoch 00212: val_loss did not improve from 13.79146
Epoch 213/10000
4/4 - 0s - loss: 22.5295 - val_loss: 14.0944

Epoch 00213: val_loss did not improve from 13.79146
Epoch 214/10000
4/4 - 0s - loss: 22.5616 - val_loss: 14.2135

Epoch 00214: val_loss did not improve from 13.79146
Epoch 215/10000
4/4 - 0s - loss: 22.5416 - val_loss: 14.3959

Epoch 00215: val_loss did not improve from 13.79146
Epoch 216/10000
4/4 - 0s - loss: 22.5294 - val_loss: 14.2517

Epoch 00216: val_loss did not improve from 13.79146
Epoch 217/10000
4/4 - 0s - loss: 22.5459 - val_loss: 14.1331

Epoch 00217: val_loss did not improve from 13.79146
Epoch 218/10000
4/4 - 0s - loss: 22.5403 - val_loss: 14.2381

Epoch 00218: val_loss did not improve from 13.79146
Epoch 219/10000
4/4 - 0s - loss: 22.5187 - val_loss: 14.3262

Epoch 00219: val_loss did not improve from 13.79146
Epoch 220/10000
4/4 - 0s - loss: 22.5275 - val_loss: 14.3630

Epoch 00220: val_loss did not improve from 13.79146
Epoch 221/10000
4/4 - 0s - loss: 22.5355 - val_loss: 14.3871

Epoch 00221: val_loss did not improve from 13.79146
Epoch 222/10000
4/4 - 0s - loss: 22.5254 - val_loss: 14.2282

Epoch 00222: val_loss did not improve from 13.79146
Epoch 223/10000
4/4 - 0s - loss: 22.5452 - val_loss: 14.1556

Epoch 00223: val_loss did not improve from 13.79146
Epoch 224/10000
4/4 - 0s - loss: 22.5457 - val_loss: 14.3322

Epoch 00224: val_loss did not improve from 13.79146
Epoch 225/10000
4/4 - 0s - loss: 22.5240 - val_loss: 14.3659

Epoch 00225: val_loss did not improve from 13.79146
Epoch 226/10000
4/4 - 0s - loss: 22.5484 - val_loss: 14.3556

Epoch 00226: val_loss did not improve from 13.79146
Epoch 227/10000
4/4 - 0s - loss: 22.5491 - val_loss: 14.1327

Epoch 00227: val_loss did not improve from 13.79146
Epoch 00227: early stopping
*************************** Fold #: 8 ***************************
Model: "sequential_27"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_297 (Dense)            (None, 30)                150       
_________________________________________________________________
dense_298 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_299 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_300 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_301 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_302 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_303 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_304 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_305 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_306 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_307 (Dense)            (None, 1)                 31        
=================================================================
Total params: 8,551
Trainable params: 8,551
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
4/4 - 0s - loss: 31.2618 - val_loss: 31.8083

Epoch 00001: val_loss improved from inf to 31.80827, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 2/10000
4/4 - 0s - loss: 31.2227 - val_loss: 31.7652

Epoch 00002: val_loss improved from 31.80827 to 31.76521, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 3/10000
4/4 - 0s - loss: 31.1767 - val_loss: 31.7156

Epoch 00003: val_loss improved from 31.76521 to 31.71563, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 4/10000
4/4 - 0s - loss: 31.1243 - val_loss: 31.6572

Epoch 00004: val_loss improved from 31.71563 to 31.65721, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 5/10000
4/4 - 0s - loss: 31.0615 - val_loss: 31.5870

Epoch 00005: val_loss improved from 31.65721 to 31.58698, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 6/10000
4/4 - 0s - loss: 30.9857 - val_loss: 31.5006

Epoch 00006: val_loss improved from 31.58698 to 31.50058, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 7/10000
4/4 - 0s - loss: 30.8909 - val_loss: 31.3923

Epoch 00007: val_loss improved from 31.50058 to 31.39233, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 8/10000
4/4 - 0s - loss: 30.7739 - val_loss: 31.2533

Epoch 00008: val_loss improved from 31.39233 to 31.25331, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 9/10000
4/4 - 0s - loss: 30.6174 - val_loss: 31.0708

Epoch 00009: val_loss improved from 31.25331 to 31.07079, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 10/10000
4/4 - 0s - loss: 30.4108 - val_loss: 30.8224

Epoch 00010: val_loss improved from 31.07079 to 30.82242, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 11/10000
4/4 - 0s - loss: 30.1339 - val_loss: 30.4697

Epoch 00011: val_loss improved from 30.82242 to 30.46973, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 12/10000
4/4 - 0s - loss: 29.7284 - val_loss: 29.9461

Epoch 00012: val_loss improved from 30.46973 to 29.94607, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 13/10000
4/4 - 0s - loss: 29.1177 - val_loss: 29.1305

Epoch 00013: val_loss improved from 29.94607 to 29.13054, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 14/10000
4/4 - 0s - loss: 28.1403 - val_loss: 27.8286

Epoch 00014: val_loss improved from 29.13054 to 27.82855, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 15/10000
4/4 - 0s - loss: 26.5969 - val_loss: 25.8604

Epoch 00015: val_loss improved from 27.82855 to 25.86044, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 16/10000
4/4 - 0s - loss: 24.4423 - val_loss: 23.8924

Epoch 00016: val_loss improved from 25.86044 to 23.89243, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 17/10000
4/4 - 0s - loss: 23.2136 - val_loss: 24.6689

Epoch 00017: val_loss did not improve from 23.89243
Epoch 18/10000
4/4 - 0s - loss: 23.6888 - val_loss: 23.8332

Epoch 00018: val_loss improved from 23.89243 to 23.83322, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 19/10000
4/4 - 0s - loss: 22.9284 - val_loss: 23.6638

Epoch 00019: val_loss improved from 23.83322 to 23.66377, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 20/10000
4/4 - 0s - loss: 23.0196 - val_loss: 23.7761

Epoch 00020: val_loss did not improve from 23.66377
Epoch 21/10000
4/4 - 0s - loss: 23.0326 - val_loss: 23.5640

Epoch 00021: val_loss improved from 23.66377 to 23.56403, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 22/10000
4/4 - 0s - loss: 22.7751 - val_loss: 23.3481

Epoch 00022: val_loss improved from 23.56403 to 23.34810, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 23/10000
4/4 - 0s - loss: 22.6796 - val_loss: 23.3654

Epoch 00023: val_loss did not improve from 23.34810
Epoch 24/10000
4/4 - 0s - loss: 22.6947 - val_loss: 23.2344

Epoch 00024: val_loss improved from 23.34810 to 23.23440, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 25/10000
4/4 - 0s - loss: 22.5691 - val_loss: 23.1227

Epoch 00025: val_loss improved from 23.23440 to 23.12269, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 26/10000
4/4 - 0s - loss: 22.4738 - val_loss: 23.0675

Epoch 00026: val_loss improved from 23.12269 to 23.06747, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 27/10000
4/4 - 0s - loss: 22.4309 - val_loss: 22.9684

Epoch 00027: val_loss improved from 23.06747 to 22.96836, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 28/10000
4/4 - 0s - loss: 22.3554 - val_loss: 22.8491

Epoch 00028: val_loss improved from 22.96836 to 22.84912, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 29/10000
4/4 - 0s - loss: 22.2755 - val_loss: 22.7553

Epoch 00029: val_loss improved from 22.84912 to 22.75532, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 30/10000
4/4 - 0s - loss: 22.2271 - val_loss: 22.6645

Epoch 00030: val_loss improved from 22.75532 to 22.66448, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 31/10000
4/4 - 0s - loss: 22.1679 - val_loss: 22.5826

Epoch 00031: val_loss improved from 22.66448 to 22.58264, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 32/10000
4/4 - 0s - loss: 22.1260 - val_loss: 22.5391

Epoch 00032: val_loss improved from 22.58264 to 22.53907, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 33/10000
4/4 - 0s - loss: 22.0792 - val_loss: 22.4582

Epoch 00033: val_loss improved from 22.53907 to 22.45815, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 34/10000
4/4 - 0s - loss: 22.0459 - val_loss: 22.3677

Epoch 00034: val_loss improved from 22.45815 to 22.36775, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 35/10000
4/4 - 0s - loss: 21.9957 - val_loss: 22.3198

Epoch 00035: val_loss improved from 22.36775 to 22.31977, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 36/10000
4/4 - 0s - loss: 21.9596 - val_loss: 22.2678

Epoch 00036: val_loss improved from 22.31977 to 22.26781, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 37/10000
4/4 - 0s - loss: 21.9327 - val_loss: 22.2372

Epoch 00037: val_loss improved from 22.26781 to 22.23723, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 38/10000
4/4 - 0s - loss: 21.9094 - val_loss: 22.1893

Epoch 00038: val_loss improved from 22.23723 to 22.18930, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 39/10000
4/4 - 0s - loss: 21.8843 - val_loss: 22.1283

Epoch 00039: val_loss improved from 22.18930 to 22.12831, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 40/10000
4/4 - 0s - loss: 21.8651 - val_loss: 22.0886

Epoch 00040: val_loss improved from 22.12831 to 22.08865, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 41/10000
4/4 - 0s - loss: 21.8522 - val_loss: 22.0506

Epoch 00041: val_loss improved from 22.08865 to 22.05059, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 42/10000
4/4 - 0s - loss: 21.8312 - val_loss: 22.0410

Epoch 00042: val_loss improved from 22.05059 to 22.04103, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 43/10000
4/4 - 0s - loss: 21.8098 - val_loss: 22.0927

Epoch 00043: val_loss did not improve from 22.04103
Epoch 44/10000
4/4 - 0s - loss: 21.8357 - val_loss: 22.0597

Epoch 00044: val_loss did not improve from 22.04103
Epoch 45/10000
4/4 - 0s - loss: 21.7815 - val_loss: 21.9561

Epoch 00045: val_loss improved from 22.04103 to 21.95611, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 46/10000
4/4 - 0s - loss: 21.7866 - val_loss: 21.9161

Epoch 00046: val_loss improved from 21.95611 to 21.91611, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 47/10000
4/4 - 0s - loss: 21.7892 - val_loss: 21.9420

Epoch 00047: val_loss did not improve from 21.91611
Epoch 48/10000
4/4 - 0s - loss: 21.7478 - val_loss: 21.9316

Epoch 00048: val_loss did not improve from 21.91611
Epoch 49/10000
4/4 - 0s - loss: 21.7439 - val_loss: 21.8961

Epoch 00049: val_loss improved from 21.91611 to 21.89606, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 50/10000
4/4 - 0s - loss: 21.7325 - val_loss: 21.8817

Epoch 00050: val_loss improved from 21.89606 to 21.88174, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 51/10000
4/4 - 0s - loss: 21.7263 - val_loss: 21.8747

Epoch 00051: val_loss improved from 21.88174 to 21.87465, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 52/10000
4/4 - 0s - loss: 21.7189 - val_loss: 21.9081

Epoch 00052: val_loss did not improve from 21.87465
Epoch 53/10000
4/4 - 0s - loss: 21.7209 - val_loss: 21.8789

Epoch 00053: val_loss did not improve from 21.87465
Epoch 54/10000
4/4 - 0s - loss: 21.7198 - val_loss: 21.8877

Epoch 00054: val_loss did not improve from 21.87465
Epoch 55/10000
4/4 - 0s - loss: 21.7029 - val_loss: 21.8344

Epoch 00055: val_loss improved from 21.87465 to 21.83440, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 56/10000
4/4 - 0s - loss: 21.7013 - val_loss: 21.8269

Epoch 00056: val_loss improved from 21.83440 to 21.82690, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 57/10000
4/4 - 0s - loss: 21.6987 - val_loss: 21.8299

Epoch 00057: val_loss did not improve from 21.82690
Epoch 58/10000
4/4 - 0s - loss: 21.6913 - val_loss: 21.8740

Epoch 00058: val_loss did not improve from 21.82690
Epoch 59/10000
4/4 - 0s - loss: 21.6934 - val_loss: 21.8380

Epoch 00059: val_loss did not improve from 21.82690
Epoch 60/10000
4/4 - 0s - loss: 21.6850 - val_loss: 21.8077

Epoch 00060: val_loss improved from 21.82690 to 21.80774, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 61/10000
4/4 - 0s - loss: 21.6938 - val_loss: 21.8072

Epoch 00061: val_loss improved from 21.80774 to 21.80719, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 62/10000
4/4 - 0s - loss: 21.6806 - val_loss: 21.8524

Epoch 00062: val_loss did not improve from 21.80719
Epoch 63/10000
4/4 - 0s - loss: 21.6867 - val_loss: 21.8508

Epoch 00063: val_loss did not improve from 21.80719
Epoch 64/10000
4/4 - 0s - loss: 21.6845 - val_loss: 21.8202

Epoch 00064: val_loss did not improve from 21.80719
Epoch 65/10000
4/4 - 0s - loss: 21.6828 - val_loss: 21.8160

Epoch 00065: val_loss did not improve from 21.80719
Epoch 66/10000
4/4 - 0s - loss: 21.6802 - val_loss: 21.8025

Epoch 00066: val_loss improved from 21.80719 to 21.80247, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 67/10000
4/4 - 0s - loss: 21.6863 - val_loss: 21.7930

Epoch 00067: val_loss improved from 21.80247 to 21.79299, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 68/10000
4/4 - 0s - loss: 21.6855 - val_loss: 21.8329

Epoch 00068: val_loss did not improve from 21.79299
Epoch 69/10000
4/4 - 0s - loss: 21.6824 - val_loss: 21.8340

Epoch 00069: val_loss did not improve from 21.79299
Epoch 70/10000
4/4 - 0s - loss: 21.6825 - val_loss: 21.8144

Epoch 00070: val_loss did not improve from 21.79299
Epoch 71/10000
4/4 - 0s - loss: 21.6925 - val_loss: 21.8194

Epoch 00071: val_loss did not improve from 21.79299
Epoch 72/10000
4/4 - 0s - loss: 21.6744 - val_loss: 21.7668

Epoch 00072: val_loss improved from 21.79299 to 21.76676, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 73/10000
4/4 - 0s - loss: 21.6958 - val_loss: 21.7749

Epoch 00073: val_loss did not improve from 21.76676
Epoch 74/10000
4/4 - 0s - loss: 21.6874 - val_loss: 21.7891

Epoch 00074: val_loss did not improve from 21.76676
Epoch 75/10000
4/4 - 0s - loss: 21.6980 - val_loss: 21.8461

Epoch 00075: val_loss did not improve from 21.76676
Epoch 76/10000
4/4 - 0s - loss: 21.6826 - val_loss: 21.7801

Epoch 00076: val_loss did not improve from 21.76676
Epoch 77/10000
4/4 - 0s - loss: 21.6939 - val_loss: 21.7699

Epoch 00077: val_loss did not improve from 21.76676
Epoch 78/10000
4/4 - 0s - loss: 21.6799 - val_loss: 21.8288

Epoch 00078: val_loss did not improve from 21.76676
Epoch 79/10000
4/4 - 0s - loss: 21.6839 - val_loss: 21.8429

Epoch 00079: val_loss did not improve from 21.76676
Epoch 80/10000
4/4 - 0s - loss: 21.6832 - val_loss: 21.8211

Epoch 00080: val_loss did not improve from 21.76676
Epoch 81/10000
4/4 - 0s - loss: 21.6842 - val_loss: 21.7954

Epoch 00081: val_loss did not improve from 21.76676
Epoch 82/10000
4/4 - 0s - loss: 21.6827 - val_loss: 21.8216

Epoch 00082: val_loss did not improve from 21.76676
Epoch 83/10000
4/4 - 0s - loss: 21.6804 - val_loss: 21.8366

Epoch 00083: val_loss did not improve from 21.76676
Epoch 84/10000
4/4 - 0s - loss: 21.6840 - val_loss: 21.8554

Epoch 00084: val_loss did not improve from 21.76676
Epoch 85/10000
4/4 - 0s - loss: 21.6898 - val_loss: 21.8637

Epoch 00085: val_loss did not improve from 21.76676
Epoch 86/10000
4/4 - 0s - loss: 21.6895 - val_loss: 21.8218

Epoch 00086: val_loss did not improve from 21.76676
Epoch 87/10000
4/4 - 0s - loss: 21.6826 - val_loss: 21.8061

Epoch 00087: val_loss did not improve from 21.76676
Epoch 88/10000
4/4 - 0s - loss: 21.7168 - val_loss: 21.7778

Epoch 00088: val_loss did not improve from 21.76676
Epoch 89/10000
4/4 - 0s - loss: 21.6836 - val_loss: 21.8434

Epoch 00089: val_loss did not improve from 21.76676
Epoch 90/10000
4/4 - 0s - loss: 21.7043 - val_loss: 21.8964

Epoch 00090: val_loss did not improve from 21.76676
Epoch 91/10000
4/4 - 0s - loss: 21.6903 - val_loss: 21.8016

Epoch 00091: val_loss did not improve from 21.76676
Epoch 92/10000
4/4 - 0s - loss: 21.6873 - val_loss: 21.7636

Epoch 00092: val_loss improved from 21.76676 to 21.76355, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 93/10000
4/4 - 0s - loss: 21.6992 - val_loss: 21.8291

Epoch 00093: val_loss did not improve from 21.76355
Epoch 94/10000
4/4 - 0s - loss: 21.6908 - val_loss: 21.8077

Epoch 00094: val_loss did not improve from 21.76355
Epoch 95/10000
4/4 - 0s - loss: 21.6827 - val_loss: 21.8232

Epoch 00095: val_loss did not improve from 21.76355
Epoch 96/10000
4/4 - 0s - loss: 21.7000 - val_loss: 21.7804

Epoch 00096: val_loss did not improve from 21.76355
Epoch 97/10000
4/4 - 0s - loss: 21.6833 - val_loss: 21.8053

Epoch 00097: val_loss did not improve from 21.76355
Epoch 98/10000
4/4 - 0s - loss: 21.6882 - val_loss: 21.8315

Epoch 00098: val_loss did not improve from 21.76355
Epoch 99/10000
4/4 - 0s - loss: 21.7001 - val_loss: 21.9085

Epoch 00099: val_loss did not improve from 21.76355
Epoch 100/10000
4/4 - 0s - loss: 21.7048 - val_loss: 21.8036

Epoch 00100: val_loss did not improve from 21.76355
Epoch 101/10000
4/4 - 0s - loss: 21.6796 - val_loss: 21.8052

Epoch 00101: val_loss did not improve from 21.76355
Epoch 102/10000
4/4 - 0s - loss: 21.6858 - val_loss: 21.8237

Epoch 00102: val_loss did not improve from 21.76355
Epoch 103/10000
4/4 - 0s - loss: 21.6789 - val_loss: 21.8039

Epoch 00103: val_loss did not improve from 21.76355
Epoch 104/10000
4/4 - 0s - loss: 21.6837 - val_loss: 21.7956

Epoch 00104: val_loss did not improve from 21.76355
Epoch 105/10000
4/4 - 0s - loss: 21.6814 - val_loss: 21.8152

Epoch 00105: val_loss did not improve from 21.76355
Epoch 106/10000
4/4 - 0s - loss: 21.6801 - val_loss: 21.8240

Epoch 00106: val_loss did not improve from 21.76355
Epoch 107/10000
4/4 - 0s - loss: 21.6796 - val_loss: 21.8472

Epoch 00107: val_loss did not improve from 21.76355
Epoch 108/10000
4/4 - 0s - loss: 21.6891 - val_loss: 21.8329

Epoch 00108: val_loss did not improve from 21.76355
Epoch 109/10000
4/4 - 0s - loss: 21.6812 - val_loss: 21.7922

Epoch 00109: val_loss did not improve from 21.76355
Epoch 110/10000
4/4 - 0s - loss: 21.6868 - val_loss: 21.7845

Epoch 00110: val_loss did not improve from 21.76355
Epoch 111/10000
4/4 - 0s - loss: 21.6829 - val_loss: 21.8257

Epoch 00111: val_loss did not improve from 21.76355
Epoch 112/10000
4/4 - 0s - loss: 21.6838 - val_loss: 21.8671

Epoch 00112: val_loss did not improve from 21.76355
Epoch 113/10000
4/4 - 0s - loss: 21.7146 - val_loss: 21.7967

Epoch 00113: val_loss did not improve from 21.76355
Epoch 114/10000
4/4 - 0s - loss: 21.6795 - val_loss: 21.8446

Epoch 00114: val_loss did not improve from 21.76355
Epoch 115/10000
4/4 - 0s - loss: 21.6845 - val_loss: 21.8465

Epoch 00115: val_loss did not improve from 21.76355
Epoch 116/10000
4/4 - 0s - loss: 21.6832 - val_loss: 21.8120

Epoch 00116: val_loss did not improve from 21.76355
Epoch 117/10000
4/4 - 0s - loss: 21.6789 - val_loss: 21.8058

Epoch 00117: val_loss did not improve from 21.76355
Epoch 118/10000
4/4 - 0s - loss: 21.6836 - val_loss: 21.8115

Epoch 00118: val_loss did not improve from 21.76355
Epoch 119/10000
4/4 - 0s - loss: 21.6913 - val_loss: 21.8298

Epoch 00119: val_loss did not improve from 21.76355
Epoch 120/10000
4/4 - 0s - loss: 21.7021 - val_loss: 21.7996

Epoch 00120: val_loss did not improve from 21.76355
Epoch 121/10000
4/4 - 0s - loss: 21.7014 - val_loss: 21.8757

Epoch 00121: val_loss did not improve from 21.76355
Epoch 122/10000
4/4 - 0s - loss: 21.6943 - val_loss: 21.8042

Epoch 00122: val_loss did not improve from 21.76355
Epoch 123/10000
4/4 - 0s - loss: 21.6811 - val_loss: 21.8153

Epoch 00123: val_loss did not improve from 21.76355
Epoch 124/10000
4/4 - 0s - loss: 21.6806 - val_loss: 21.8583

Epoch 00124: val_loss did not improve from 21.76355
Epoch 125/10000
4/4 - 0s - loss: 21.6905 - val_loss: 21.8466

Epoch 00125: val_loss did not improve from 21.76355
Epoch 126/10000
4/4 - 0s - loss: 21.6788 - val_loss: 21.7941

Epoch 00126: val_loss did not improve from 21.76355
Epoch 127/10000
4/4 - 0s - loss: 21.6967 - val_loss: 21.7893

Epoch 00127: val_loss did not improve from 21.76355
Epoch 128/10000
4/4 - 0s - loss: 21.6752 - val_loss: 21.8642

Epoch 00128: val_loss did not improve from 21.76355
Epoch 129/10000
4/4 - 0s - loss: 21.6952 - val_loss: 21.8504

Epoch 00129: val_loss did not improve from 21.76355
Epoch 130/10000
4/4 - 0s - loss: 21.6828 - val_loss: 21.8094

Epoch 00130: val_loss did not improve from 21.76355
Epoch 131/10000
4/4 - 0s - loss: 21.7043 - val_loss: 21.7793

Epoch 00131: val_loss did not improve from 21.76355
Epoch 132/10000
4/4 - 0s - loss: 21.7045 - val_loss: 21.8867

Epoch 00132: val_loss did not improve from 21.76355
Epoch 133/10000
4/4 - 0s - loss: 21.6950 - val_loss: 21.8190

Epoch 00133: val_loss did not improve from 21.76355
Epoch 134/10000
4/4 - 0s - loss: 21.7169 - val_loss: 21.7810

Epoch 00134: val_loss did not improve from 21.76355
Epoch 135/10000
4/4 - 0s - loss: 21.6830 - val_loss: 21.8587

Epoch 00135: val_loss did not improve from 21.76355
Epoch 136/10000
4/4 - 0s - loss: 21.7059 - val_loss: 21.8586

Epoch 00136: val_loss did not improve from 21.76355
Epoch 137/10000
4/4 - 0s - loss: 21.6726 - val_loss: 21.7754

Epoch 00137: val_loss did not improve from 21.76355
Epoch 138/10000
4/4 - 0s - loss: 21.6925 - val_loss: 21.7721

Epoch 00138: val_loss did not improve from 21.76355
Epoch 139/10000
4/4 - 0s - loss: 21.6879 - val_loss: 21.8127

Epoch 00139: val_loss did not improve from 21.76355
Epoch 140/10000
4/4 - 0s - loss: 21.6976 - val_loss: 21.9253

Epoch 00140: val_loss did not improve from 21.76355
Epoch 141/10000
4/4 - 0s - loss: 21.7215 - val_loss: 21.8059

Epoch 00141: val_loss did not improve from 21.76355
Epoch 142/10000
4/4 - 0s - loss: 21.6799 - val_loss: 21.7922

Epoch 00142: val_loss did not improve from 21.76355
Epoch 143/10000
4/4 - 0s - loss: 21.6787 - val_loss: 21.8122

Epoch 00143: val_loss did not improve from 21.76355
Epoch 144/10000
4/4 - 0s - loss: 21.6949 - val_loss: 21.8383

Epoch 00144: val_loss did not improve from 21.76355
Epoch 145/10000
4/4 - 0s - loss: 21.6861 - val_loss: 21.7893

Epoch 00145: val_loss did not improve from 21.76355
Epoch 146/10000
4/4 - 0s - loss: 21.6938 - val_loss: 21.7733

Epoch 00146: val_loss did not improve from 21.76355
Epoch 147/10000
4/4 - 0s - loss: 21.6852 - val_loss: 21.8332

Epoch 00147: val_loss did not improve from 21.76355
Epoch 148/10000
4/4 - 0s - loss: 21.6953 - val_loss: 21.8728

Epoch 00148: val_loss did not improve from 21.76355
Epoch 149/10000
4/4 - 0s - loss: 21.6832 - val_loss: 21.8008

Epoch 00149: val_loss did not improve from 21.76355
Epoch 150/10000
4/4 - 0s - loss: 21.6894 - val_loss: 21.7828

Epoch 00150: val_loss did not improve from 21.76355
Epoch 151/10000
4/4 - 0s - loss: 21.6972 - val_loss: 21.8529

Epoch 00151: val_loss did not improve from 21.76355
Epoch 152/10000
4/4 - 0s - loss: 21.6825 - val_loss: 21.8094

Epoch 00152: val_loss did not improve from 21.76355
Epoch 153/10000
4/4 - 0s - loss: 21.6822 - val_loss: 21.7709

Epoch 00153: val_loss did not improve from 21.76355
Epoch 154/10000
4/4 - 0s - loss: 21.6844 - val_loss: 21.7855

Epoch 00154: val_loss did not improve from 21.76355
Epoch 155/10000
4/4 - 0s - loss: 21.6900 - val_loss: 21.8371

Epoch 00155: val_loss did not improve from 21.76355
Epoch 156/10000
4/4 - 0s - loss: 21.6825 - val_loss: 21.7993

Epoch 00156: val_loss did not improve from 21.76355
Epoch 157/10000
4/4 - 0s - loss: 21.6926 - val_loss: 21.7787

Epoch 00157: val_loss did not improve from 21.76355
Epoch 158/10000
4/4 - 0s - loss: 21.6883 - val_loss: 21.8290

Epoch 00158: val_loss did not improve from 21.76355
Epoch 159/10000
4/4 - 0s - loss: 21.6807 - val_loss: 21.8124

Epoch 00159: val_loss did not improve from 21.76355
Epoch 160/10000
4/4 - 0s - loss: 21.6848 - val_loss: 21.7966

Epoch 00160: val_loss did not improve from 21.76355
Epoch 161/10000
4/4 - 0s - loss: 21.6766 - val_loss: 21.8433

Epoch 00161: val_loss did not improve from 21.76355
Epoch 162/10000
4/4 - 0s - loss: 21.6864 - val_loss: 21.8604

Epoch 00162: val_loss did not improve from 21.76355
Epoch 163/10000
4/4 - 0s - loss: 21.6862 - val_loss: 21.8124

Epoch 00163: val_loss did not improve from 21.76355
Epoch 164/10000
4/4 - 0s - loss: 21.6807 - val_loss: 21.8199

Epoch 00164: val_loss did not improve from 21.76355
Epoch 165/10000
4/4 - 0s - loss: 21.6829 - val_loss: 21.8163

Epoch 00165: val_loss did not improve from 21.76355
Epoch 166/10000
4/4 - 0s - loss: 21.6814 - val_loss: 21.8092

Epoch 00166: val_loss did not improve from 21.76355
Epoch 167/10000
4/4 - 0s - loss: 21.6832 - val_loss: 21.8145

Epoch 00167: val_loss did not improve from 21.76355
Epoch 168/10000
4/4 - 0s - loss: 21.6829 - val_loss: 21.7947

Epoch 00168: val_loss did not improve from 21.76355
Epoch 169/10000
4/4 - 0s - loss: 21.6845 - val_loss: 21.7858

Epoch 00169: val_loss did not improve from 21.76355
Epoch 170/10000
4/4 - 0s - loss: 21.6897 - val_loss: 21.7833

Epoch 00170: val_loss did not improve from 21.76355
Epoch 171/10000
4/4 - 0s - loss: 21.6845 - val_loss: 21.7888

Epoch 00171: val_loss did not improve from 21.76355
Epoch 172/10000
4/4 - 0s - loss: 21.6790 - val_loss: 21.8176

Epoch 00172: val_loss did not improve from 21.76355
Epoch 173/10000
4/4 - 0s - loss: 21.6812 - val_loss: 21.8283

Epoch 00173: val_loss did not improve from 21.76355
Epoch 174/10000
4/4 - 0s - loss: 21.6848 - val_loss: 21.8054

Epoch 00174: val_loss did not improve from 21.76355
Epoch 175/10000
4/4 - 0s - loss: 21.7013 - val_loss: 21.7685

Epoch 00175: val_loss did not improve from 21.76355
Epoch 176/10000
4/4 - 0s - loss: 21.6808 - val_loss: 21.8545

Epoch 00176: val_loss did not improve from 21.76355
Epoch 177/10000
4/4 - 0s - loss: 21.6929 - val_loss: 21.8639

Epoch 00177: val_loss did not improve from 21.76355
Epoch 178/10000
4/4 - 0s - loss: 21.6781 - val_loss: 21.7951

Epoch 00178: val_loss did not improve from 21.76355
Epoch 179/10000
4/4 - 0s - loss: 21.6916 - val_loss: 21.7864

Epoch 00179: val_loss did not improve from 21.76355
Epoch 180/10000
4/4 - 0s - loss: 21.6813 - val_loss: 21.8452

Epoch 00180: val_loss did not improve from 21.76355
Epoch 181/10000
4/4 - 0s - loss: 21.7102 - val_loss: 21.8750

Epoch 00181: val_loss did not improve from 21.76355
Epoch 182/10000
4/4 - 0s - loss: 21.6997 - val_loss: 21.7712

Epoch 00182: val_loss did not improve from 21.76355
Epoch 183/10000
4/4 - 0s - loss: 21.6962 - val_loss: 21.7960

Epoch 00183: val_loss did not improve from 21.76355
Epoch 184/10000
4/4 - 0s - loss: 21.6841 - val_loss: 21.8505

Epoch 00184: val_loss did not improve from 21.76355
Epoch 185/10000
4/4 - 0s - loss: 21.6855 - val_loss: 21.8115

Epoch 00185: val_loss did not improve from 21.76355
Epoch 186/10000
4/4 - 0s - loss: 21.6900 - val_loss: 21.7733

Epoch 00186: val_loss did not improve from 21.76355
Epoch 187/10000
4/4 - 0s - loss: 21.6906 - val_loss: 21.8107

Epoch 00187: val_loss did not improve from 21.76355
Epoch 188/10000
4/4 - 0s - loss: 21.6803 - val_loss: 21.7975

Epoch 00188: val_loss did not improve from 21.76355
Epoch 189/10000
4/4 - 0s - loss: 21.6813 - val_loss: 21.7873

Epoch 00189: val_loss did not improve from 21.76355
Epoch 190/10000
4/4 - 0s - loss: 21.6830 - val_loss: 21.8083

Epoch 00190: val_loss did not improve from 21.76355
Epoch 191/10000
4/4 - 0s - loss: 21.6786 - val_loss: 21.8145

Epoch 00191: val_loss did not improve from 21.76355
Epoch 192/10000
4/4 - 0s - loss: 21.6852 - val_loss: 21.8037

Epoch 00192: val_loss did not improve from 21.76355
Epoch 193/10000
4/4 - 0s - loss: 21.6832 - val_loss: 21.7804

Epoch 00193: val_loss did not improve from 21.76355
Epoch 194/10000
4/4 - 0s - loss: 21.6821 - val_loss: 21.8120

Epoch 00194: val_loss did not improve from 21.76355
Epoch 195/10000
4/4 - 0s - loss: 21.6966 - val_loss: 21.8746

Epoch 00195: val_loss did not improve from 21.76355
Epoch 196/10000
4/4 - 0s - loss: 21.6864 - val_loss: 21.7870

Epoch 00196: val_loss did not improve from 21.76355
Epoch 197/10000
4/4 - 0s - loss: 21.6990 - val_loss: 21.7717

Epoch 00197: val_loss did not improve from 21.76355
Epoch 198/10000
4/4 - 0s - loss: 21.7304 - val_loss: 21.8794

Epoch 00198: val_loss did not improve from 21.76355
Epoch 199/10000
4/4 - 0s - loss: 21.6853 - val_loss: 21.7869

Epoch 00199: val_loss did not improve from 21.76355
Epoch 200/10000
4/4 - 0s - loss: 21.6937 - val_loss: 21.7878

Epoch 00200: val_loss did not improve from 21.76355
Epoch 201/10000
4/4 - 0s - loss: 21.7046 - val_loss: 21.8545

Epoch 00201: val_loss did not improve from 21.76355
Epoch 202/10000
4/4 - 0s - loss: 21.6822 - val_loss: 21.8038

Epoch 00202: val_loss did not improve from 21.76355
Epoch 203/10000
4/4 - 0s - loss: 21.6921 - val_loss: 21.7731

Epoch 00203: val_loss did not improve from 21.76355
Epoch 204/10000
4/4 - 0s - loss: 21.7033 - val_loss: 21.8175

Epoch 00204: val_loss did not improve from 21.76355
Epoch 205/10000
4/4 - 0s - loss: 21.6782 - val_loss: 21.7970

Epoch 00205: val_loss did not improve from 21.76355
Epoch 206/10000
4/4 - 0s - loss: 21.6860 - val_loss: 21.7958

Epoch 00206: val_loss did not improve from 21.76355
Epoch 207/10000
4/4 - 0s - loss: 21.7036 - val_loss: 21.7683

Epoch 00207: val_loss did not improve from 21.76355
Epoch 208/10000
4/4 - 0s - loss: 21.7024 - val_loss: 21.8631

Epoch 00208: val_loss did not improve from 21.76355
Epoch 209/10000
4/4 - 0s - loss: 21.6904 - val_loss: 21.8320

Epoch 00209: val_loss did not improve from 21.76355
Epoch 210/10000
4/4 - 0s - loss: 21.6849 - val_loss: 21.7738

Epoch 00210: val_loss did not improve from 21.76355
Epoch 211/10000
4/4 - 0s - loss: 21.6935 - val_loss: 21.7960

Epoch 00211: val_loss did not improve from 21.76355
Epoch 212/10000
4/4 - 0s - loss: 21.6771 - val_loss: 21.8347

Epoch 00212: val_loss did not improve from 21.76355
Epoch 213/10000
4/4 - 0s - loss: 21.6899 - val_loss: 21.8437

Epoch 00213: val_loss did not improve from 21.76355
Epoch 214/10000
4/4 - 0s - loss: 21.6829 - val_loss: 21.7941

Epoch 00214: val_loss did not improve from 21.76355
Epoch 215/10000
4/4 - 0s - loss: 21.6858 - val_loss: 21.8156

Epoch 00215: val_loss did not improve from 21.76355
Epoch 216/10000
4/4 - 0s - loss: 21.6764 - val_loss: 21.8743

Epoch 00216: val_loss did not improve from 21.76355
Epoch 217/10000
4/4 - 0s - loss: 21.7073 - val_loss: 21.8631

Epoch 00217: val_loss did not improve from 21.76355
Epoch 218/10000
4/4 - 0s - loss: 21.6850 - val_loss: 21.8080

Epoch 00218: val_loss did not improve from 21.76355
Epoch 219/10000
4/4 - 0s - loss: 21.6872 - val_loss: 21.7837

Epoch 00219: val_loss did not improve from 21.76355
Epoch 220/10000
4/4 - 0s - loss: 21.6854 - val_loss: 21.8353

Epoch 00220: val_loss did not improve from 21.76355
Epoch 221/10000
4/4 - 0s - loss: 21.6914 - val_loss: 21.8292

Epoch 00221: val_loss did not improve from 21.76355
Epoch 222/10000
4/4 - 0s - loss: 21.6802 - val_loss: 21.8010

Epoch 00222: val_loss did not improve from 21.76355
Epoch 223/10000
4/4 - 0s - loss: 21.6851 - val_loss: 21.7705

Epoch 00223: val_loss did not improve from 21.76355
Epoch 224/10000
4/4 - 0s - loss: 21.6966 - val_loss: 21.8109

Epoch 00224: val_loss did not improve from 21.76355
Epoch 225/10000
4/4 - 0s - loss: 21.6816 - val_loss: 21.8142

Epoch 00225: val_loss did not improve from 21.76355
Epoch 226/10000
4/4 - 0s - loss: 21.6784 - val_loss: 21.8434

Epoch 00226: val_loss did not improve from 21.76355
Epoch 227/10000
4/4 - 0s - loss: 21.6863 - val_loss: 21.8666

Epoch 00227: val_loss did not improve from 21.76355
Epoch 228/10000
4/4 - 0s - loss: 21.6873 - val_loss: 21.8347

Epoch 00228: val_loss did not improve from 21.76355
Epoch 229/10000
4/4 - 0s - loss: 21.6832 - val_loss: 21.7978

Epoch 00229: val_loss did not improve from 21.76355
Epoch 230/10000
4/4 - 0s - loss: 21.6896 - val_loss: 21.8038

Epoch 00230: val_loss did not improve from 21.76355
Epoch 231/10000
4/4 - 0s - loss: 21.6800 - val_loss: 21.8444

Epoch 00231: val_loss did not improve from 21.76355
Epoch 232/10000
4/4 - 0s - loss: 21.6898 - val_loss: 21.8820

Epoch 00232: val_loss did not improve from 21.76355
Epoch 233/10000
4/4 - 0s - loss: 21.6847 - val_loss: 21.8123

Epoch 00233: val_loss did not improve from 21.76355
Epoch 234/10000
4/4 - 0s - loss: 21.6794 - val_loss: 21.7933

Epoch 00234: val_loss did not improve from 21.76355
Epoch 235/10000
4/4 - 0s - loss: 21.6893 - val_loss: 21.7965

Epoch 00235: val_loss did not improve from 21.76355
Epoch 236/10000
4/4 - 0s - loss: 21.6789 - val_loss: 21.8589

Epoch 00236: val_loss did not improve from 21.76355
Epoch 237/10000
4/4 - 0s - loss: 21.6905 - val_loss: 21.8312

Epoch 00237: val_loss did not improve from 21.76355
Epoch 238/10000
4/4 - 0s - loss: 21.6807 - val_loss: 21.8238

Epoch 00238: val_loss did not improve from 21.76355
Epoch 239/10000
4/4 - 0s - loss: 21.6913 - val_loss: 21.7992

Epoch 00239: val_loss did not improve from 21.76355
Epoch 240/10000
4/4 - 0s - loss: 21.6860 - val_loss: 21.8215

Epoch 00240: val_loss did not improve from 21.76355
Epoch 241/10000
4/4 - 0s - loss: 21.6804 - val_loss: 21.8060

Epoch 00241: val_loss did not improve from 21.76355
Epoch 242/10000
4/4 - 0s - loss: 21.7340 - val_loss: 21.8340

Epoch 00242: val_loss did not improve from 21.76355
Epoch 243/10000
4/4 - 0s - loss: 21.6871 - val_loss: 21.7614

Epoch 00243: val_loss improved from 21.76355 to 21.76144, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 244/10000
4/4 - 0s - loss: 21.7116 - val_loss: 21.7848

Epoch 00244: val_loss did not improve from 21.76144
Epoch 245/10000
4/4 - 0s - loss: 21.7146 - val_loss: 21.8928

Epoch 00245: val_loss did not improve from 21.76144
Epoch 246/10000
4/4 - 0s - loss: 21.7004 - val_loss: 21.7930

Epoch 00246: val_loss did not improve from 21.76144
Epoch 247/10000
4/4 - 0s - loss: 21.6774 - val_loss: 21.7724

Epoch 00247: val_loss did not improve from 21.76144
Epoch 248/10000
4/4 - 0s - loss: 21.6891 - val_loss: 21.7854

Epoch 00248: val_loss did not improve from 21.76144
Epoch 249/10000
4/4 - 0s - loss: 21.6791 - val_loss: 21.8148

Epoch 00249: val_loss did not improve from 21.76144
Epoch 250/10000
4/4 - 0s - loss: 21.6887 - val_loss: 21.8081

Epoch 00250: val_loss did not improve from 21.76144
Epoch 251/10000
4/4 - 0s - loss: 21.6890 - val_loss: 21.8068

Epoch 00251: val_loss did not improve from 21.76144
Epoch 252/10000
4/4 - 0s - loss: 21.6852 - val_loss: 21.7925

Epoch 00252: val_loss did not improve from 21.76144
Epoch 253/10000
4/4 - 0s - loss: 21.6802 - val_loss: 21.8253

Epoch 00253: val_loss did not improve from 21.76144
Epoch 254/10000
4/4 - 0s - loss: 21.6812 - val_loss: 21.8143

Epoch 00254: val_loss did not improve from 21.76144
Epoch 255/10000
4/4 - 0s - loss: 21.6823 - val_loss: 21.8211

Epoch 00255: val_loss did not improve from 21.76144
Epoch 256/10000
4/4 - 0s - loss: 21.6863 - val_loss: 21.7872

Epoch 00256: val_loss did not improve from 21.76144
Epoch 257/10000
4/4 - 0s - loss: 21.6904 - val_loss: 21.7961

Epoch 00257: val_loss did not improve from 21.76144
Epoch 258/10000
4/4 - 0s - loss: 21.6765 - val_loss: 21.8723

Epoch 00258: val_loss did not improve from 21.76144
Epoch 259/10000
4/4 - 0s - loss: 21.7004 - val_loss: 21.8596

Epoch 00259: val_loss did not improve from 21.76144
Epoch 260/10000
4/4 - 0s - loss: 21.6915 - val_loss: 21.8166

Epoch 00260: val_loss did not improve from 21.76144
Epoch 261/10000
4/4 - 0s - loss: 21.6812 - val_loss: 21.8246

Epoch 00261: val_loss did not improve from 21.76144
Epoch 262/10000
4/4 - 0s - loss: 21.6873 - val_loss: 21.8053

Epoch 00262: val_loss did not improve from 21.76144
Epoch 263/10000
4/4 - 0s - loss: 21.6786 - val_loss: 21.8319

Epoch 00263: val_loss did not improve from 21.76144
Epoch 264/10000
4/4 - 0s - loss: 21.6876 - val_loss: 21.8111

Epoch 00264: val_loss did not improve from 21.76144
Epoch 265/10000
4/4 - 0s - loss: 21.6797 - val_loss: 21.8208

Epoch 00265: val_loss did not improve from 21.76144
Epoch 266/10000
4/4 - 0s - loss: 21.6829 - val_loss: 21.8242

Epoch 00266: val_loss did not improve from 21.76144
Epoch 267/10000
4/4 - 0s - loss: 21.7015 - val_loss: 21.8545

Epoch 00267: val_loss did not improve from 21.76144
Epoch 268/10000
4/4 - 0s - loss: 21.6841 - val_loss: 21.7925

Epoch 00268: val_loss did not improve from 21.76144
Epoch 269/10000
4/4 - 0s - loss: 21.6871 - val_loss: 21.7932

Epoch 00269: val_loss did not improve from 21.76144
Epoch 270/10000
4/4 - 0s - loss: 21.6858 - val_loss: 21.7938

Epoch 00270: val_loss did not improve from 21.76144
Epoch 271/10000
4/4 - 0s - loss: 21.6797 - val_loss: 21.8155

Epoch 00271: val_loss did not improve from 21.76144
Epoch 272/10000
4/4 - 0s - loss: 21.6832 - val_loss: 21.8325

Epoch 00272: val_loss did not improve from 21.76144
Epoch 273/10000
4/4 - 0s - loss: 21.6783 - val_loss: 21.7986

Epoch 00273: val_loss did not improve from 21.76144
Epoch 274/10000
4/4 - 0s - loss: 21.6878 - val_loss: 21.7748

Epoch 00274: val_loss did not improve from 21.76144
Epoch 275/10000
4/4 - 0s - loss: 21.6872 - val_loss: 21.8101

Epoch 00275: val_loss did not improve from 21.76144
Epoch 276/10000
4/4 - 0s - loss: 21.6879 - val_loss: 21.8637

Epoch 00276: val_loss did not improve from 21.76144
Epoch 277/10000
4/4 - 0s - loss: 21.6953 - val_loss: 21.8295

Epoch 00277: val_loss did not improve from 21.76144
Epoch 278/10000
4/4 - 0s - loss: 21.6975 - val_loss: 21.7733

Epoch 00278: val_loss did not improve from 21.76144
Epoch 279/10000
4/4 - 0s - loss: 21.6888 - val_loss: 21.8287

Epoch 00279: val_loss did not improve from 21.76144
Epoch 280/10000
4/4 - 0s - loss: 21.7009 - val_loss: 21.8699

Epoch 00280: val_loss did not improve from 21.76144
Epoch 281/10000
4/4 - 0s - loss: 21.6816 - val_loss: 21.7758

Epoch 00281: val_loss did not improve from 21.76144
Epoch 282/10000
4/4 - 0s - loss: 21.7161 - val_loss: 21.7704

Epoch 00282: val_loss did not improve from 21.76144
Epoch 283/10000
4/4 - 0s - loss: 21.7012 - val_loss: 21.8829

Epoch 00283: val_loss did not improve from 21.76144
Epoch 284/10000
4/4 - 0s - loss: 21.6992 - val_loss: 21.8106

Epoch 00284: val_loss did not improve from 21.76144
Epoch 285/10000
4/4 - 0s - loss: 21.6773 - val_loss: 21.7719

Epoch 00285: val_loss did not improve from 21.76144
Epoch 286/10000
4/4 - 0s - loss: 21.6974 - val_loss: 21.7750

Epoch 00286: val_loss did not improve from 21.76144
Epoch 287/10000
4/4 - 0s - loss: 21.6980 - val_loss: 21.7617

Epoch 00287: val_loss did not improve from 21.76144
Epoch 288/10000
4/4 - 0s - loss: 21.6907 - val_loss: 21.8220

Epoch 00288: val_loss did not improve from 21.76144
Epoch 289/10000
4/4 - 0s - loss: 21.6965 - val_loss: 21.8608

Epoch 00289: val_loss did not improve from 21.76144
Epoch 290/10000
4/4 - 0s - loss: 21.6848 - val_loss: 21.8136

Epoch 00290: val_loss did not improve from 21.76144
Epoch 291/10000
4/4 - 0s - loss: 21.6822 - val_loss: 21.7801

Epoch 00291: val_loss did not improve from 21.76144
Epoch 292/10000
4/4 - 0s - loss: 21.6867 - val_loss: 21.8211

Epoch 00292: val_loss did not improve from 21.76144
Epoch 293/10000
4/4 - 0s - loss: 21.6832 - val_loss: 21.8427

Epoch 00293: val_loss did not improve from 21.76144
Epoch 294/10000
4/4 - 0s - loss: 21.6931 - val_loss: 21.8569

Epoch 00294: val_loss did not improve from 21.76144
Epoch 295/10000
4/4 - 0s - loss: 21.6803 - val_loss: 21.7907

Epoch 00295: val_loss did not improve from 21.76144
Epoch 296/10000
4/4 - 0s - loss: 21.6829 - val_loss: 21.7672

Epoch 00296: val_loss did not improve from 21.76144
Epoch 297/10000
4/4 - 0s - loss: 21.7116 - val_loss: 21.8026

Epoch 00297: val_loss did not improve from 21.76144
Epoch 298/10000
4/4 - 0s - loss: 21.6910 - val_loss: 21.8545

Epoch 00298: val_loss did not improve from 21.76144
Epoch 299/10000
4/4 - 0s - loss: 21.6875 - val_loss: 21.8418

Epoch 00299: val_loss did not improve from 21.76144
Epoch 300/10000
4/4 - 0s - loss: 21.6839 - val_loss: 21.8056

Epoch 00300: val_loss did not improve from 21.76144
Epoch 301/10000
4/4 - 0s - loss: 21.6849 - val_loss: 21.7802

Epoch 00301: val_loss did not improve from 21.76144
Epoch 302/10000
4/4 - 0s - loss: 21.6932 - val_loss: 21.8195

Epoch 00302: val_loss did not improve from 21.76144
Epoch 303/10000
4/4 - 0s - loss: 21.6805 - val_loss: 21.8327

Epoch 00303: val_loss did not improve from 21.76144
Epoch 304/10000
4/4 - 0s - loss: 21.6844 - val_loss: 21.8349

Epoch 00304: val_loss did not improve from 21.76144
Epoch 305/10000
4/4 - 0s - loss: 21.6818 - val_loss: 21.8260

Epoch 00305: val_loss did not improve from 21.76144
Epoch 306/10000
4/4 - 0s - loss: 21.6799 - val_loss: 21.8165

Epoch 00306: val_loss did not improve from 21.76144
Epoch 307/10000
4/4 - 0s - loss: 21.6814 - val_loss: 21.8119

Epoch 00307: val_loss did not improve from 21.76144
Epoch 308/10000
4/4 - 0s - loss: 21.7096 - val_loss: 21.8565

Epoch 00308: val_loss did not improve from 21.76144
Epoch 309/10000
4/4 - 0s - loss: 21.7059 - val_loss: 21.7945

Epoch 00309: val_loss did not improve from 21.76144
Epoch 310/10000
4/4 - 0s - loss: 21.6834 - val_loss: 21.8299

Epoch 00310: val_loss did not improve from 21.76144
Epoch 311/10000
4/4 - 0s - loss: 21.6796 - val_loss: 21.8668

Epoch 00311: val_loss did not improve from 21.76144
Epoch 312/10000
4/4 - 0s - loss: 21.6853 - val_loss: 21.8372

Epoch 00312: val_loss did not improve from 21.76144
Epoch 313/10000
4/4 - 0s - loss: 21.6742 - val_loss: 21.7970

Epoch 00313: val_loss did not improve from 21.76144
Epoch 314/10000
4/4 - 0s - loss: 21.7204 - val_loss: 21.7750

Epoch 00314: val_loss did not improve from 21.76144
Epoch 315/10000
4/4 - 0s - loss: 21.7016 - val_loss: 21.8643

Epoch 00315: val_loss did not improve from 21.76144
Epoch 316/10000
4/4 - 0s - loss: 21.6975 - val_loss: 21.8342

Epoch 00316: val_loss did not improve from 21.76144
Epoch 317/10000
4/4 - 0s - loss: 21.6809 - val_loss: 21.7560

Epoch 00317: val_loss improved from 21.76144 to 21.75599, saving model to ./results/dataset/trial_3/ckpt_8
Epoch 318/10000
4/4 - 0s - loss: 21.6977 - val_loss: 21.7852

Epoch 00318: val_loss did not improve from 21.75599
Epoch 319/10000
4/4 - 0s - loss: 21.6885 - val_loss: 21.8834

Epoch 00319: val_loss did not improve from 21.75599
Epoch 320/10000
4/4 - 0s - loss: 21.6944 - val_loss: 21.8072

Epoch 00320: val_loss did not improve from 21.75599
Epoch 321/10000
4/4 - 0s - loss: 21.6841 - val_loss: 21.7784

Epoch 00321: val_loss did not improve from 21.75599
Epoch 322/10000
4/4 - 0s - loss: 21.6882 - val_loss: 21.8300

Epoch 00322: val_loss did not improve from 21.75599
Epoch 323/10000
4/4 - 0s - loss: 21.6888 - val_loss: 21.8245

Epoch 00323: val_loss did not improve from 21.75599
Epoch 324/10000
4/4 - 0s - loss: 21.6916 - val_loss: 21.7730

Epoch 00324: val_loss did not improve from 21.75599
Epoch 325/10000
4/4 - 0s - loss: 21.6968 - val_loss: 21.7928

Epoch 00325: val_loss did not improve from 21.75599
Epoch 326/10000
4/4 - 0s - loss: 21.6745 - val_loss: 21.8806

Epoch 00326: val_loss did not improve from 21.75599
Epoch 327/10000
4/4 - 0s - loss: 21.7069 - val_loss: 21.8945

Epoch 00327: val_loss did not improve from 21.75599
Epoch 328/10000
4/4 - 0s - loss: 21.6985 - val_loss: 21.7910

Epoch 00328: val_loss did not improve from 21.75599
Epoch 329/10000
4/4 - 0s - loss: 21.6998 - val_loss: 21.7786

Epoch 00329: val_loss did not improve from 21.75599
Epoch 330/10000
4/4 - 0s - loss: 21.6904 - val_loss: 21.8545

Epoch 00330: val_loss did not improve from 21.75599
Epoch 331/10000
4/4 - 0s - loss: 21.6938 - val_loss: 21.8626

Epoch 00331: val_loss did not improve from 21.75599
Epoch 332/10000
4/4 - 0s - loss: 21.6896 - val_loss: 21.7841

Epoch 00332: val_loss did not improve from 21.75599
Epoch 333/10000
4/4 - 0s - loss: 21.6833 - val_loss: 21.7864

Epoch 00333: val_loss did not improve from 21.75599
Epoch 334/10000
4/4 - 0s - loss: 21.6869 - val_loss: 21.8158

Epoch 00334: val_loss did not improve from 21.75599
Epoch 335/10000
4/4 - 0s - loss: 21.6868 - val_loss: 21.8348

Epoch 00335: val_loss did not improve from 21.75599
Epoch 336/10000
4/4 - 0s - loss: 21.6830 - val_loss: 21.8029

Epoch 00336: val_loss did not improve from 21.75599
Epoch 337/10000
4/4 - 0s - loss: 21.6923 - val_loss: 21.8218

Epoch 00337: val_loss did not improve from 21.75599
Epoch 338/10000
4/4 - 0s - loss: 21.6910 - val_loss: 21.8938

Epoch 00338: val_loss did not improve from 21.75599
Epoch 339/10000
4/4 - 0s - loss: 21.6931 - val_loss: 21.8258

Epoch 00339: val_loss did not improve from 21.75599
Epoch 340/10000
4/4 - 0s - loss: 21.6819 - val_loss: 21.7907

Epoch 00340: val_loss did not improve from 21.75599
Epoch 341/10000
4/4 - 0s - loss: 21.7148 - val_loss: 21.8370

Epoch 00341: val_loss did not improve from 21.75599
Epoch 342/10000
4/4 - 0s - loss: 21.6855 - val_loss: 21.8061

Epoch 00342: val_loss did not improve from 21.75599
Epoch 343/10000
4/4 - 0s - loss: 21.6810 - val_loss: 21.8421

Epoch 00343: val_loss did not improve from 21.75599
Epoch 344/10000
4/4 - 0s - loss: 21.7050 - val_loss: 21.8607

Epoch 00344: val_loss did not improve from 21.75599
Epoch 345/10000
4/4 - 0s - loss: 21.6816 - val_loss: 21.7751

Epoch 00345: val_loss did not improve from 21.75599
Epoch 346/10000
4/4 - 0s - loss: 21.7184 - val_loss: 21.7756

Epoch 00346: val_loss did not improve from 21.75599
Epoch 347/10000
4/4 - 0s - loss: 21.6983 - val_loss: 21.8667

Epoch 00347: val_loss did not improve from 21.75599
Epoch 348/10000
4/4 - 0s - loss: 21.7049 - val_loss: 21.8246

Epoch 00348: val_loss did not improve from 21.75599
Epoch 349/10000
4/4 - 0s - loss: 21.6756 - val_loss: 21.7633

Epoch 00349: val_loss did not improve from 21.75599
Epoch 350/10000
4/4 - 0s - loss: 21.7087 - val_loss: 21.7919

Epoch 00350: val_loss did not improve from 21.75599
Epoch 351/10000
4/4 - 0s - loss: 21.6727 - val_loss: 21.8671

Epoch 00351: val_loss did not improve from 21.75599
Epoch 352/10000
4/4 - 0s - loss: 21.7037 - val_loss: 21.8430

Epoch 00352: val_loss did not improve from 21.75599
Epoch 353/10000
4/4 - 0s - loss: 21.6832 - val_loss: 21.8635

Epoch 00353: val_loss did not improve from 21.75599
Epoch 354/10000
4/4 - 0s - loss: 21.6908 - val_loss: 21.8314

Epoch 00354: val_loss did not improve from 21.75599
Epoch 355/10000
4/4 - 0s - loss: 21.6790 - val_loss: 21.7904

Epoch 00355: val_loss did not improve from 21.75599
Epoch 356/10000
4/4 - 0s - loss: 21.7004 - val_loss: 21.7963

Epoch 00356: val_loss did not improve from 21.75599
Epoch 357/10000
4/4 - 0s - loss: 21.7186 - val_loss: 21.8740

Epoch 00357: val_loss did not improve from 21.75599
Epoch 358/10000
4/4 - 0s - loss: 21.6831 - val_loss: 21.7889

Epoch 00358: val_loss did not improve from 21.75599
Epoch 359/10000
4/4 - 0s - loss: 21.6812 - val_loss: 21.7706

Epoch 00359: val_loss did not improve from 21.75599
Epoch 360/10000
4/4 - 0s - loss: 21.7025 - val_loss: 21.7845

Epoch 00360: val_loss did not improve from 21.75599
Epoch 361/10000
4/4 - 0s - loss: 21.6773 - val_loss: 21.8944

Epoch 00361: val_loss did not improve from 21.75599
Epoch 362/10000
4/4 - 0s - loss: 21.7189 - val_loss: 21.8497

Epoch 00362: val_loss did not improve from 21.75599
Epoch 363/10000
4/4 - 0s - loss: 21.6856 - val_loss: 21.7968

Epoch 00363: val_loss did not improve from 21.75599
Epoch 364/10000
4/4 - 0s - loss: 21.6790 - val_loss: 21.7880

Epoch 00364: val_loss did not improve from 21.75599
Epoch 365/10000
4/4 - 0s - loss: 21.6918 - val_loss: 21.8074

Epoch 00365: val_loss did not improve from 21.75599
Epoch 366/10000
4/4 - 0s - loss: 21.6800 - val_loss: 21.8000

Epoch 00366: val_loss did not improve from 21.75599
Epoch 367/10000
4/4 - 0s - loss: 21.6824 - val_loss: 21.8059

Epoch 00367: val_loss did not improve from 21.75599
Epoch 368/10000
4/4 - 0s - loss: 21.6857 - val_loss: 21.8237

Epoch 00368: val_loss did not improve from 21.75599
Epoch 369/10000
4/4 - 0s - loss: 21.6802 - val_loss: 21.7958

Epoch 00369: val_loss did not improve from 21.75599
Epoch 370/10000
4/4 - 0s - loss: 21.6812 - val_loss: 21.8080

Epoch 00370: val_loss did not improve from 21.75599
Epoch 371/10000
4/4 - 0s - loss: 21.6932 - val_loss: 21.8061

Epoch 00371: val_loss did not improve from 21.75599
Epoch 372/10000
4/4 - 0s - loss: 21.6973 - val_loss: 21.8844

Epoch 00372: val_loss did not improve from 21.75599
Epoch 373/10000
4/4 - 0s - loss: 21.6948 - val_loss: 21.7916

Epoch 00373: val_loss did not improve from 21.75599
Epoch 374/10000
4/4 - 0s - loss: 21.6917 - val_loss: 21.7845

Epoch 00374: val_loss did not improve from 21.75599
Epoch 375/10000
4/4 - 0s - loss: 21.6775 - val_loss: 21.8381

Epoch 00375: val_loss did not improve from 21.75599
Epoch 376/10000
4/4 - 0s - loss: 21.7172 - val_loss: 21.8937

Epoch 00376: val_loss did not improve from 21.75599
Epoch 377/10000
4/4 - 0s - loss: 21.6981 - val_loss: 21.8046

Epoch 00377: val_loss did not improve from 21.75599
Epoch 378/10000
4/4 - 0s - loss: 21.6841 - val_loss: 21.7737

Epoch 00378: val_loss did not improve from 21.75599
Epoch 379/10000
4/4 - 0s - loss: 21.6867 - val_loss: 21.8122

Epoch 00379: val_loss did not improve from 21.75599
Epoch 380/10000
4/4 - 0s - loss: 21.6843 - val_loss: 21.8417

Epoch 00380: val_loss did not improve from 21.75599
Epoch 381/10000
4/4 - 0s - loss: 21.6824 - val_loss: 21.8223

Epoch 00381: val_loss did not improve from 21.75599
Epoch 382/10000
4/4 - 0s - loss: 21.6823 - val_loss: 21.7928

Epoch 00382: val_loss did not improve from 21.75599
Epoch 383/10000
4/4 - 0s - loss: 21.6845 - val_loss: 21.8114

Epoch 00383: val_loss did not improve from 21.75599
Epoch 384/10000
4/4 - 0s - loss: 21.6841 - val_loss: 21.8417

Epoch 00384: val_loss did not improve from 21.75599
Epoch 385/10000
4/4 - 0s - loss: 21.6920 - val_loss: 21.8019

Epoch 00385: val_loss did not improve from 21.75599
Epoch 386/10000
4/4 - 0s - loss: 21.6816 - val_loss: 21.8270

Epoch 00386: val_loss did not improve from 21.75599
Epoch 387/10000
4/4 - 0s - loss: 21.6943 - val_loss: 21.8223

Epoch 00387: val_loss did not improve from 21.75599
Epoch 388/10000
4/4 - 0s - loss: 21.6799 - val_loss: 21.7913

Epoch 00388: val_loss did not improve from 21.75599
Epoch 389/10000
4/4 - 0s - loss: 21.6885 - val_loss: 21.7973

Epoch 00389: val_loss did not improve from 21.75599
Epoch 390/10000
4/4 - 0s - loss: 21.6911 - val_loss: 21.8735

Epoch 00390: val_loss did not improve from 21.75599
Epoch 391/10000
4/4 - 0s - loss: 21.6869 - val_loss: 21.8210

Epoch 00391: val_loss did not improve from 21.75599
Epoch 392/10000
4/4 - 0s - loss: 21.6783 - val_loss: 21.7807

Epoch 00392: val_loss did not improve from 21.75599
Epoch 393/10000
4/4 - 0s - loss: 21.6987 - val_loss: 21.7924

Epoch 00393: val_loss did not improve from 21.75599
Epoch 394/10000
4/4 - 0s - loss: 21.6820 - val_loss: 21.8139

Epoch 00394: val_loss did not improve from 21.75599
Epoch 395/10000
4/4 - 0s - loss: 21.6792 - val_loss: 21.8170

Epoch 00395: val_loss did not improve from 21.75599
Epoch 396/10000
4/4 - 0s - loss: 21.6822 - val_loss: 21.8154

Epoch 00396: val_loss did not improve from 21.75599
Epoch 397/10000
4/4 - 0s - loss: 21.6823 - val_loss: 21.8110

Epoch 00397: val_loss did not improve from 21.75599
Epoch 398/10000
4/4 - 0s - loss: 21.6824 - val_loss: 21.8481

Epoch 00398: val_loss did not improve from 21.75599
Epoch 399/10000
4/4 - 0s - loss: 21.6851 - val_loss: 21.8210

Epoch 00399: val_loss did not improve from 21.75599
Epoch 400/10000
4/4 - 0s - loss: 21.6821 - val_loss: 21.8334

Epoch 00400: val_loss did not improve from 21.75599
Epoch 401/10000
4/4 - 0s - loss: 21.6808 - val_loss: 21.8148

Epoch 00401: val_loss did not improve from 21.75599
Epoch 402/10000
4/4 - 0s - loss: 21.6822 - val_loss: 21.8296

Epoch 00402: val_loss did not improve from 21.75599
Epoch 403/10000
4/4 - 0s - loss: 21.6826 - val_loss: 21.8045

Epoch 00403: val_loss did not improve from 21.75599
Epoch 404/10000
4/4 - 0s - loss: 21.6793 - val_loss: 21.8256

Epoch 00404: val_loss did not improve from 21.75599
Epoch 405/10000
4/4 - 0s - loss: 21.6822 - val_loss: 21.8261

Epoch 00405: val_loss did not improve from 21.75599
Epoch 406/10000
4/4 - 0s - loss: 21.6961 - val_loss: 21.7913

Epoch 00406: val_loss did not improve from 21.75599
Epoch 407/10000
4/4 - 0s - loss: 21.6899 - val_loss: 21.8349

Epoch 00407: val_loss did not improve from 21.75599
Epoch 408/10000
4/4 - 0s - loss: 21.6842 - val_loss: 21.8204

Epoch 00408: val_loss did not improve from 21.75599
Epoch 409/10000
4/4 - 0s - loss: 21.6797 - val_loss: 21.7965

Epoch 00409: val_loss did not improve from 21.75599
Epoch 410/10000
4/4 - 0s - loss: 21.6829 - val_loss: 21.7897

Epoch 00410: val_loss did not improve from 21.75599
Epoch 411/10000
4/4 - 0s - loss: 21.6797 - val_loss: 21.8277

Epoch 00411: val_loss did not improve from 21.75599
Epoch 412/10000
4/4 - 0s - loss: 21.6814 - val_loss: 21.8445

Epoch 00412: val_loss did not improve from 21.75599
Epoch 413/10000
4/4 - 0s - loss: 21.6899 - val_loss: 21.8243

Epoch 00413: val_loss did not improve from 21.75599
Epoch 414/10000
4/4 - 0s - loss: 21.6911 - val_loss: 21.8584

Epoch 00414: val_loss did not improve from 21.75599
Epoch 415/10000
4/4 - 0s - loss: 21.6853 - val_loss: 21.8137

Epoch 00415: val_loss did not improve from 21.75599
Epoch 416/10000
4/4 - 0s - loss: 21.6806 - val_loss: 21.7707

Epoch 00416: val_loss did not improve from 21.75599
Epoch 417/10000
4/4 - 0s - loss: 21.7015 - val_loss: 21.8104

Epoch 00417: val_loss did not improve from 21.75599
Epoch 418/10000
4/4 - 0s - loss: 21.6760 - val_loss: 21.8771

Epoch 00418: val_loss did not improve from 21.75599
Epoch 419/10000
4/4 - 0s - loss: 21.7077 - val_loss: 21.8656

Epoch 00419: val_loss did not improve from 21.75599
Epoch 420/10000
4/4 - 0s - loss: 21.7098 - val_loss: 21.7581

Epoch 00420: val_loss did not improve from 21.75599
Epoch 421/10000
4/4 - 0s - loss: 21.7097 - val_loss: 21.7944

Epoch 00421: val_loss did not improve from 21.75599
Epoch 422/10000
4/4 - 0s - loss: 21.6808 - val_loss: 21.8351

Epoch 00422: val_loss did not improve from 21.75599
Epoch 423/10000
4/4 - 0s - loss: 21.6854 - val_loss: 21.8074

Epoch 00423: val_loss did not improve from 21.75599
Epoch 424/10000
4/4 - 0s - loss: 21.7210 - val_loss: 21.7677

Epoch 00424: val_loss did not improve from 21.75599
Epoch 425/10000
4/4 - 0s - loss: 21.6809 - val_loss: 21.8777

Epoch 00425: val_loss did not improve from 21.75599
Epoch 426/10000
4/4 - 0s - loss: 21.7008 - val_loss: 21.8622

Epoch 00426: val_loss did not improve from 21.75599
Epoch 427/10000
4/4 - 0s - loss: 21.6873 - val_loss: 21.7772

Epoch 00427: val_loss did not improve from 21.75599
Epoch 428/10000
4/4 - 0s - loss: 21.6897 - val_loss: 21.8015

Epoch 00428: val_loss did not improve from 21.75599
Epoch 429/10000
4/4 - 0s - loss: 21.6794 - val_loss: 21.8224

Epoch 00429: val_loss did not improve from 21.75599
Epoch 430/10000
4/4 - 0s - loss: 21.6884 - val_loss: 21.8388

Epoch 00430: val_loss did not improve from 21.75599
Epoch 431/10000
4/4 - 0s - loss: 21.6933 - val_loss: 21.8192

Epoch 00431: val_loss did not improve from 21.75599
Epoch 432/10000
4/4 - 0s - loss: 21.6811 - val_loss: 21.8376

Epoch 00432: val_loss did not improve from 21.75599
Epoch 433/10000
4/4 - 0s - loss: 21.6817 - val_loss: 21.8314

Epoch 00433: val_loss did not improve from 21.75599
Epoch 434/10000
4/4 - 0s - loss: 21.6874 - val_loss: 21.8292

Epoch 00434: val_loss did not improve from 21.75599
Epoch 435/10000
4/4 - 0s - loss: 21.6920 - val_loss: 21.7943

Epoch 00435: val_loss did not improve from 21.75599
Epoch 436/10000
4/4 - 0s - loss: 21.6863 - val_loss: 21.8541

Epoch 00436: val_loss did not improve from 21.75599
Epoch 437/10000
4/4 - 0s - loss: 21.6859 - val_loss: 21.8161

Epoch 00437: val_loss did not improve from 21.75599
Epoch 438/10000
4/4 - 0s - loss: 21.6806 - val_loss: 21.7987

Epoch 00438: val_loss did not improve from 21.75599
Epoch 439/10000
4/4 - 0s - loss: 21.6813 - val_loss: 21.7967

Epoch 00439: val_loss did not improve from 21.75599
Epoch 440/10000
4/4 - 0s - loss: 21.6888 - val_loss: 21.8319

Epoch 00440: val_loss did not improve from 21.75599
Epoch 441/10000
4/4 - 0s - loss: 21.6787 - val_loss: 21.7961

Epoch 00441: val_loss did not improve from 21.75599
Epoch 442/10000
4/4 - 0s - loss: 21.6811 - val_loss: 21.7904

Epoch 00442: val_loss did not improve from 21.75599
Epoch 443/10000
4/4 - 0s - loss: 21.6907 - val_loss: 21.8252

Epoch 00443: val_loss did not improve from 21.75599
Epoch 444/10000
4/4 - 0s - loss: 21.6776 - val_loss: 21.7898

Epoch 00444: val_loss did not improve from 21.75599
Epoch 445/10000
4/4 - 0s - loss: 21.6891 - val_loss: 21.7893

Epoch 00445: val_loss did not improve from 21.75599
Epoch 446/10000
4/4 - 0s - loss: 21.6848 - val_loss: 21.8624

Epoch 00446: val_loss did not improve from 21.75599
Epoch 447/10000
4/4 - 0s - loss: 21.6877 - val_loss: 21.8624

Epoch 00447: val_loss did not improve from 21.75599
Epoch 448/10000
4/4 - 0s - loss: 21.6911 - val_loss: 21.8044

Epoch 00448: val_loss did not improve from 21.75599
Epoch 449/10000
4/4 - 0s - loss: 21.6847 - val_loss: 21.8261

Epoch 00449: val_loss did not improve from 21.75599
Epoch 450/10000
4/4 - 0s - loss: 21.6846 - val_loss: 21.8102

Epoch 00450: val_loss did not improve from 21.75599
Epoch 451/10000
4/4 - 0s - loss: 21.6824 - val_loss: 21.8068

Epoch 00451: val_loss did not improve from 21.75599
Epoch 452/10000
4/4 - 0s - loss: 21.6786 - val_loss: 21.8201

Epoch 00452: val_loss did not improve from 21.75599
Epoch 453/10000
4/4 - 0s - loss: 21.6814 - val_loss: 21.8181

Epoch 00453: val_loss did not improve from 21.75599
Epoch 454/10000
4/4 - 0s - loss: 21.6806 - val_loss: 21.7922

Epoch 00454: val_loss did not improve from 21.75599
Epoch 455/10000
4/4 - 0s - loss: 21.6826 - val_loss: 21.8153

Epoch 00455: val_loss did not improve from 21.75599
Epoch 456/10000
4/4 - 0s - loss: 21.6815 - val_loss: 21.8056

Epoch 00456: val_loss did not improve from 21.75599
Epoch 457/10000
4/4 - 0s - loss: 21.6812 - val_loss: 21.8314

Epoch 00457: val_loss did not improve from 21.75599
Epoch 458/10000
4/4 - 0s - loss: 21.6808 - val_loss: 21.8344

Epoch 00458: val_loss did not improve from 21.75599
Epoch 459/10000
4/4 - 0s - loss: 21.6846 - val_loss: 21.8125

Epoch 00459: val_loss did not improve from 21.75599
Epoch 460/10000
4/4 - 0s - loss: 21.7067 - val_loss: 21.8409

Epoch 00460: val_loss did not improve from 21.75599
Epoch 461/10000
4/4 - 0s - loss: 21.6892 - val_loss: 21.7643

Epoch 00461: val_loss did not improve from 21.75599
Epoch 462/10000
4/4 - 0s - loss: 21.6941 - val_loss: 21.7874

Epoch 00462: val_loss did not improve from 21.75599
Epoch 463/10000
4/4 - 0s - loss: 21.7079 - val_loss: 21.8866

Epoch 00463: val_loss did not improve from 21.75599
Epoch 464/10000
4/4 - 0s - loss: 21.6922 - val_loss: 21.7845

Epoch 00464: val_loss did not improve from 21.75599
Epoch 465/10000
4/4 - 0s - loss: 21.6819 - val_loss: 21.7570

Epoch 00465: val_loss did not improve from 21.75599
Epoch 466/10000
4/4 - 0s - loss: 21.6971 - val_loss: 21.7895

Epoch 00466: val_loss did not improve from 21.75599
Epoch 467/10000
4/4 - 0s - loss: 21.6651 - val_loss: 21.8956

Epoch 00467: val_loss did not improve from 21.75599
Epoch 468/10000
4/4 - 0s - loss: 21.7085 - val_loss: 21.8669

Epoch 00468: val_loss did not improve from 21.75599
Epoch 469/10000
4/4 - 0s - loss: 21.6890 - val_loss: 21.8312

Epoch 00469: val_loss did not improve from 21.75599
Epoch 470/10000
4/4 - 0s - loss: 21.7032 - val_loss: 21.7766

Epoch 00470: val_loss did not improve from 21.75599
Epoch 471/10000
4/4 - 0s - loss: 21.6914 - val_loss: 21.8240

Epoch 00471: val_loss did not improve from 21.75599
Epoch 472/10000
4/4 - 0s - loss: 21.6858 - val_loss: 21.8322

Epoch 00472: val_loss did not improve from 21.75599
Epoch 473/10000
4/4 - 0s - loss: 21.7075 - val_loss: 21.7789

Epoch 00473: val_loss did not improve from 21.75599
Epoch 474/10000
4/4 - 0s - loss: 21.6786 - val_loss: 21.8393

Epoch 00474: val_loss did not improve from 21.75599
Epoch 475/10000
4/4 - 0s - loss: 21.7325 - val_loss: 21.9027

Epoch 00475: val_loss did not improve from 21.75599
Epoch 476/10000
4/4 - 0s - loss: 21.7191 - val_loss: 21.7834

Epoch 00476: val_loss did not improve from 21.75599
Epoch 477/10000
4/4 - 0s - loss: 21.6980 - val_loss: 21.8313

Epoch 00477: val_loss did not improve from 21.75599
Epoch 478/10000
4/4 - 0s - loss: 21.6791 - val_loss: 21.8431

Epoch 00478: val_loss did not improve from 21.75599
Epoch 479/10000
4/4 - 0s - loss: 21.6939 - val_loss: 21.8548

Epoch 00479: val_loss did not improve from 21.75599
Epoch 480/10000
4/4 - 0s - loss: 21.7216 - val_loss: 21.7845

Epoch 00480: val_loss did not improve from 21.75599
Epoch 481/10000
4/4 - 0s - loss: 21.6982 - val_loss: 21.8843

Epoch 00481: val_loss did not improve from 21.75599
Epoch 482/10000
4/4 - 0s - loss: 21.6977 - val_loss: 21.8547

Epoch 00482: val_loss did not improve from 21.75599
Epoch 483/10000
4/4 - 0s - loss: 21.6788 - val_loss: 21.8069

Epoch 00483: val_loss did not improve from 21.75599
Epoch 484/10000
4/4 - 0s - loss: 21.6880 - val_loss: 21.7853

Epoch 00484: val_loss did not improve from 21.75599
Epoch 485/10000
4/4 - 0s - loss: 21.6979 - val_loss: 21.8216

Epoch 00485: val_loss did not improve from 21.75599
Epoch 486/10000
4/4 - 0s - loss: 21.6872 - val_loss: 21.8827

Epoch 00486: val_loss did not improve from 21.75599
Epoch 487/10000
4/4 - 0s - loss: 21.6966 - val_loss: 21.8286

Epoch 00487: val_loss did not improve from 21.75599
Epoch 488/10000
4/4 - 0s - loss: 21.6924 - val_loss: 21.7790

Epoch 00488: val_loss did not improve from 21.75599
Epoch 489/10000
4/4 - 0s - loss: 21.6837 - val_loss: 21.8113

Epoch 00489: val_loss did not improve from 21.75599
Epoch 490/10000
4/4 - 0s - loss: 21.6924 - val_loss: 21.8689

Epoch 00490: val_loss did not improve from 21.75599
Epoch 491/10000
4/4 - 0s - loss: 21.6914 - val_loss: 21.8255

Epoch 00491: val_loss did not improve from 21.75599
Epoch 492/10000
4/4 - 0s - loss: 21.6780 - val_loss: 21.7971

Epoch 00492: val_loss did not improve from 21.75599
Epoch 493/10000
4/4 - 0s - loss: 21.6820 - val_loss: 21.8047

Epoch 00493: val_loss did not improve from 21.75599
Epoch 494/10000
4/4 - 0s - loss: 21.6817 - val_loss: 21.8330

Epoch 00494: val_loss did not improve from 21.75599
Epoch 495/10000
4/4 - 0s - loss: 21.6836 - val_loss: 21.8228

Epoch 00495: val_loss did not improve from 21.75599
Epoch 496/10000
4/4 - 0s - loss: 21.6864 - val_loss: 21.8397

Epoch 00496: val_loss did not improve from 21.75599
Epoch 497/10000
4/4 - 0s - loss: 21.6815 - val_loss: 21.8165

Epoch 00497: val_loss did not improve from 21.75599
Epoch 498/10000
4/4 - 0s - loss: 21.6921 - val_loss: 21.7884

Epoch 00498: val_loss did not improve from 21.75599
Epoch 499/10000
4/4 - 0s - loss: 21.6916 - val_loss: 21.8368

Epoch 00499: val_loss did not improve from 21.75599
Epoch 500/10000
4/4 - 0s - loss: 21.6841 - val_loss: 21.8022

Epoch 00500: val_loss did not improve from 21.75599
Epoch 501/10000
4/4 - 0s - loss: 21.6846 - val_loss: 21.8132

Epoch 00501: val_loss did not improve from 21.75599
Epoch 502/10000
4/4 - 0s - loss: 21.6786 - val_loss: 21.7950

Epoch 00502: val_loss did not improve from 21.75599
Epoch 503/10000
4/4 - 0s - loss: 21.6817 - val_loss: 21.7945

Epoch 00503: val_loss did not improve from 21.75599
Epoch 504/10000
4/4 - 0s - loss: 21.6843 - val_loss: 21.8114

Epoch 00504: val_loss did not improve from 21.75599
Epoch 505/10000
4/4 - 0s - loss: 21.6822 - val_loss: 21.8314

Epoch 00505: val_loss did not improve from 21.75599
Epoch 506/10000
4/4 - 0s - loss: 21.6885 - val_loss: 21.8137

Epoch 00506: val_loss did not improve from 21.75599
Epoch 507/10000
4/4 - 0s - loss: 21.6785 - val_loss: 21.8292

Epoch 00507: val_loss did not improve from 21.75599
Epoch 508/10000
4/4 - 0s - loss: 21.6906 - val_loss: 21.8433

Epoch 00508: val_loss did not improve from 21.75599
Epoch 509/10000
4/4 - 0s - loss: 21.6722 - val_loss: 21.7912

Epoch 00509: val_loss did not improve from 21.75599
Epoch 510/10000
4/4 - 0s - loss: 21.7025 - val_loss: 21.7926

Epoch 00510: val_loss did not improve from 21.75599
Epoch 511/10000
4/4 - 0s - loss: 21.6789 - val_loss: 21.8603

Epoch 00511: val_loss did not improve from 21.75599
Epoch 512/10000
4/4 - 0s - loss: 21.7060 - val_loss: 21.8921

Epoch 00512: val_loss did not improve from 21.75599
Epoch 513/10000
4/4 - 0s - loss: 21.6922 - val_loss: 21.8032

Epoch 00513: val_loss did not improve from 21.75599
Epoch 514/10000
4/4 - 0s - loss: 21.6848 - val_loss: 21.8117

Epoch 00514: val_loss did not improve from 21.75599
Epoch 515/10000
4/4 - 0s - loss: 21.6822 - val_loss: 21.8573

Epoch 00515: val_loss did not improve from 21.75599
Epoch 516/10000
4/4 - 0s - loss: 21.6853 - val_loss: 21.8558

Epoch 00516: val_loss did not improve from 21.75599
Epoch 517/10000
4/4 - 0s - loss: 21.6881 - val_loss: 21.8255

Epoch 00517: val_loss did not improve from 21.75599
Epoch 00517: early stopping
*************************** Fold #: 9 ***************************
Model: "sequential_28"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_308 (Dense)            (None, 30)                150       
_________________________________________________________________
dense_309 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_310 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_311 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_312 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_313 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_314 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_315 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_316 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_317 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_318 (Dense)            (None, 1)                 31        
=================================================================
Total params: 8,551
Trainable params: 8,551
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
4/4 - 0s - loss: 31.8583 - val_loss: 26.4375

Epoch 00001: val_loss improved from inf to 26.43754, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 2/10000
4/4 - 0s - loss: 31.8200 - val_loss: 26.3974

Epoch 00002: val_loss improved from 26.43754 to 26.39743, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 3/10000
4/4 - 0s - loss: 31.7761 - val_loss: 26.3527

Epoch 00003: val_loss improved from 26.39743 to 26.35270, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 4/10000
4/4 - 0s - loss: 31.7279 - val_loss: 26.3027

Epoch 00004: val_loss improved from 26.35270 to 26.30270, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 5/10000
4/4 - 0s - loss: 31.6720 - val_loss: 26.2460

Epoch 00005: val_loss improved from 26.30270 to 26.24600, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 6/10000
4/4 - 0s - loss: 31.6104 - val_loss: 26.1803

Epoch 00006: val_loss improved from 26.24600 to 26.18035, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 7/10000
4/4 - 0s - loss: 31.5382 - val_loss: 26.1034

Epoch 00007: val_loss improved from 26.18035 to 26.10339, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 8/10000
4/4 - 0s - loss: 31.4518 - val_loss: 26.0118

Epoch 00008: val_loss improved from 26.10339 to 26.01176, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 9/10000
4/4 - 0s - loss: 31.3488 - val_loss: 25.8998

Epoch 00009: val_loss improved from 26.01176 to 25.89979, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 10/10000
4/4 - 0s - loss: 31.2235 - val_loss: 25.7584

Epoch 00010: val_loss improved from 25.89979 to 25.75844, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 11/10000
4/4 - 0s - loss: 31.0598 - val_loss: 25.5713

Epoch 00011: val_loss improved from 25.75844 to 25.57126, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 12/10000
4/4 - 0s - loss: 30.8396 - val_loss: 25.3136

Epoch 00012: val_loss improved from 25.57126 to 25.31361, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 13/10000
4/4 - 0s - loss: 30.5286 - val_loss: 24.9397

Epoch 00013: val_loss improved from 25.31361 to 24.93966, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 14/10000
4/4 - 0s - loss: 30.0663 - val_loss: 24.3742

Epoch 00014: val_loss improved from 24.93966 to 24.37419, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 15/10000
4/4 - 0s - loss: 29.3869 - val_loss: 23.4852

Epoch 00015: val_loss improved from 24.37419 to 23.48519, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 16/10000
4/4 - 0s - loss: 28.2983 - val_loss: 22.0897

Epoch 00016: val_loss improved from 23.48519 to 22.08965, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 17/10000
4/4 - 0s - loss: 26.5994 - val_loss: 20.1483

Epoch 00017: val_loss improved from 22.08965 to 20.14833, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 18/10000
4/4 - 0s - loss: 24.4481 - val_loss: 18.9657

Epoch 00018: val_loss improved from 20.14833 to 18.96570, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 19/10000
4/4 - 0s - loss: 23.8848 - val_loss: 19.9618

Epoch 00019: val_loss did not improve from 18.96570
Epoch 20/10000
4/4 - 0s - loss: 23.9230 - val_loss: 18.9323

Epoch 00020: val_loss improved from 18.96570 to 18.93228, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 21/10000
4/4 - 0s - loss: 23.3328 - val_loss: 18.7634

Epoch 00021: val_loss improved from 18.93228 to 18.76338, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 22/10000
4/4 - 0s - loss: 23.5170 - val_loss: 18.7895

Epoch 00022: val_loss did not improve from 18.76338
Epoch 23/10000
4/4 - 0s - loss: 23.4507 - val_loss: 18.6026

Epoch 00023: val_loss improved from 18.76338 to 18.60257, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 24/10000
4/4 - 0s - loss: 23.1767 - val_loss: 18.5649

Epoch 00024: val_loss improved from 18.60257 to 18.56490, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 25/10000
4/4 - 0s - loss: 23.0702 - val_loss: 18.6374

Epoch 00025: val_loss did not improve from 18.56490
Epoch 26/10000
4/4 - 0s - loss: 23.0457 - val_loss: 18.5158

Epoch 00026: val_loss improved from 18.56490 to 18.51582, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 27/10000
4/4 - 0s - loss: 22.9287 - val_loss: 18.3286

Epoch 00027: val_loss improved from 18.51582 to 18.32864, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 28/10000
4/4 - 0s - loss: 22.8596 - val_loss: 18.2533

Epoch 00028: val_loss improved from 18.32864 to 18.25327, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 29/10000
4/4 - 0s - loss: 22.8011 - val_loss: 18.2137

Epoch 00029: val_loss improved from 18.25327 to 18.21367, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 30/10000
4/4 - 0s - loss: 22.7126 - val_loss: 18.1903

Epoch 00030: val_loss improved from 18.21367 to 18.19030, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 31/10000
4/4 - 0s - loss: 22.6473 - val_loss: 18.1692

Epoch 00031: val_loss improved from 18.19030 to 18.16920, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 32/10000
4/4 - 0s - loss: 22.6114 - val_loss: 18.1476

Epoch 00032: val_loss improved from 18.16920 to 18.14758, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 33/10000
4/4 - 0s - loss: 22.5656 - val_loss: 18.0656

Epoch 00033: val_loss improved from 18.14758 to 18.06564, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 34/10000
4/4 - 0s - loss: 22.5199 - val_loss: 18.0067

Epoch 00034: val_loss improved from 18.06564 to 18.00673, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 35/10000
4/4 - 0s - loss: 22.4802 - val_loss: 17.9701

Epoch 00035: val_loss improved from 18.00673 to 17.97011, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 36/10000
4/4 - 0s - loss: 22.4641 - val_loss: 17.9325

Epoch 00036: val_loss improved from 17.97011 to 17.93253, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 37/10000
4/4 - 0s - loss: 22.4284 - val_loss: 17.9660

Epoch 00037: val_loss did not improve from 17.93253
Epoch 38/10000
4/4 - 0s - loss: 22.4097 - val_loss: 17.9523

Epoch 00038: val_loss did not improve from 17.93253
Epoch 39/10000
4/4 - 0s - loss: 22.3799 - val_loss: 17.8831

Epoch 00039: val_loss improved from 17.93253 to 17.88309, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 40/10000
4/4 - 0s - loss: 22.3651 - val_loss: 17.8368

Epoch 00040: val_loss improved from 17.88309 to 17.83676, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 41/10000
4/4 - 0s - loss: 22.3480 - val_loss: 17.8390

Epoch 00041: val_loss did not improve from 17.83676
Epoch 42/10000
4/4 - 0s - loss: 22.3187 - val_loss: 17.8447

Epoch 00042: val_loss did not improve from 17.83676
Epoch 43/10000
4/4 - 0s - loss: 22.3223 - val_loss: 17.8944

Epoch 00043: val_loss did not improve from 17.83676
Epoch 44/10000
4/4 - 0s - loss: 22.2864 - val_loss: 17.7996

Epoch 00044: val_loss improved from 17.83676 to 17.79957, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 45/10000
4/4 - 0s - loss: 22.2697 - val_loss: 17.7726

Epoch 00045: val_loss improved from 17.79957 to 17.77263, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 46/10000
4/4 - 0s - loss: 22.2534 - val_loss: 17.7890

Epoch 00046: val_loss did not improve from 17.77263
Epoch 47/10000
4/4 - 0s - loss: 22.2543 - val_loss: 17.8153

Epoch 00047: val_loss did not improve from 17.77263
Epoch 48/10000
4/4 - 0s - loss: 22.2227 - val_loss: 17.7530

Epoch 00048: val_loss improved from 17.77263 to 17.75302, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 49/10000
4/4 - 0s - loss: 22.2247 - val_loss: 17.7270

Epoch 00049: val_loss improved from 17.75302 to 17.72695, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 50/10000
4/4 - 0s - loss: 22.2062 - val_loss: 17.7862

Epoch 00050: val_loss did not improve from 17.72695
Epoch 51/10000
4/4 - 0s - loss: 22.2017 - val_loss: 17.7914

Epoch 00051: val_loss did not improve from 17.72695
Epoch 52/10000
4/4 - 0s - loss: 22.1845 - val_loss: 17.7220

Epoch 00052: val_loss improved from 17.72695 to 17.72205, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 53/10000
4/4 - 0s - loss: 22.1790 - val_loss: 17.6997

Epoch 00053: val_loss improved from 17.72205 to 17.69966, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 54/10000
4/4 - 0s - loss: 22.1749 - val_loss: 17.7342

Epoch 00054: val_loss did not improve from 17.69966
Epoch 55/10000
4/4 - 0s - loss: 22.1644 - val_loss: 17.7693

Epoch 00055: val_loss did not improve from 17.69966
Epoch 56/10000
4/4 - 0s - loss: 22.1594 - val_loss: 17.7121

Epoch 00056: val_loss did not improve from 17.69966
Epoch 57/10000
4/4 - 0s - loss: 22.1557 - val_loss: 17.6893

Epoch 00057: val_loss improved from 17.69966 to 17.68933, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 58/10000
4/4 - 0s - loss: 22.1659 - val_loss: 17.6868

Epoch 00058: val_loss improved from 17.68933 to 17.68679, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 59/10000
4/4 - 0s - loss: 22.1465 - val_loss: 17.7766

Epoch 00059: val_loss did not improve from 17.68679
Epoch 60/10000
4/4 - 0s - loss: 22.1559 - val_loss: 17.7632

Epoch 00060: val_loss did not improve from 17.68679
Epoch 61/10000
4/4 - 0s - loss: 22.1477 - val_loss: 17.6940

Epoch 00061: val_loss did not improve from 17.68679
Epoch 62/10000
4/4 - 0s - loss: 22.1527 - val_loss: 17.6546

Epoch 00062: val_loss improved from 17.68679 to 17.65464, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 63/10000
4/4 - 0s - loss: 22.1541 - val_loss: 17.6949

Epoch 00063: val_loss did not improve from 17.65464
Epoch 64/10000
4/4 - 0s - loss: 22.1365 - val_loss: 17.7981

Epoch 00064: val_loss did not improve from 17.65464
Epoch 65/10000
4/4 - 0s - loss: 22.1514 - val_loss: 17.7414

Epoch 00065: val_loss did not improve from 17.65464
Epoch 66/10000
4/4 - 0s - loss: 22.1333 - val_loss: 17.6551

Epoch 00066: val_loss did not improve from 17.65464
Epoch 67/10000
4/4 - 0s - loss: 22.1556 - val_loss: 17.6700

Epoch 00067: val_loss did not improve from 17.65464
Epoch 68/10000
4/4 - 0s - loss: 22.1516 - val_loss: 17.7105

Epoch 00068: val_loss did not improve from 17.65464
Epoch 69/10000
4/4 - 0s - loss: 22.1386 - val_loss: 17.6975

Epoch 00069: val_loss did not improve from 17.65464
Epoch 70/10000
4/4 - 0s - loss: 22.1364 - val_loss: 17.7249

Epoch 00070: val_loss did not improve from 17.65464
Epoch 71/10000
4/4 - 0s - loss: 22.1423 - val_loss: 17.7308

Epoch 00071: val_loss did not improve from 17.65464
Epoch 72/10000
4/4 - 0s - loss: 22.1369 - val_loss: 17.7088

Epoch 00072: val_loss did not improve from 17.65464
Epoch 73/10000
4/4 - 0s - loss: 22.1360 - val_loss: 17.7170

Epoch 00073: val_loss did not improve from 17.65464
Epoch 74/10000
4/4 - 0s - loss: 22.1436 - val_loss: 17.7158

Epoch 00074: val_loss did not improve from 17.65464
Epoch 75/10000
4/4 - 0s - loss: 22.1410 - val_loss: 17.7337

Epoch 00075: val_loss did not improve from 17.65464
Epoch 76/10000
4/4 - 0s - loss: 22.1539 - val_loss: 17.8315

Epoch 00076: val_loss did not improve from 17.65464
Epoch 77/10000
4/4 - 0s - loss: 22.1470 - val_loss: 17.6881

Epoch 00077: val_loss did not improve from 17.65464
Epoch 78/10000
4/4 - 0s - loss: 22.1413 - val_loss: 17.6500

Epoch 00078: val_loss improved from 17.65464 to 17.65001, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 79/10000
4/4 - 0s - loss: 22.1549 - val_loss: 17.6887

Epoch 00079: val_loss did not improve from 17.65001
Epoch 80/10000
4/4 - 0s - loss: 22.1338 - val_loss: 17.7343

Epoch 00080: val_loss did not improve from 17.65001
Epoch 81/10000
4/4 - 0s - loss: 22.1404 - val_loss: 17.7556

Epoch 00081: val_loss did not improve from 17.65001
Epoch 82/10000
4/4 - 0s - loss: 22.1429 - val_loss: 17.6974

Epoch 00082: val_loss did not improve from 17.65001
Epoch 83/10000
4/4 - 0s - loss: 22.1433 - val_loss: 17.6851

Epoch 00083: val_loss did not improve from 17.65001
Epoch 84/10000
4/4 - 0s - loss: 22.1369 - val_loss: 17.7354

Epoch 00084: val_loss did not improve from 17.65001
Epoch 85/10000
4/4 - 0s - loss: 22.1388 - val_loss: 17.7265

Epoch 00085: val_loss did not improve from 17.65001
Epoch 86/10000
4/4 - 0s - loss: 22.1358 - val_loss: 17.7274

Epoch 00086: val_loss did not improve from 17.65001
Epoch 87/10000
4/4 - 0s - loss: 22.1377 - val_loss: 17.7178

Epoch 00087: val_loss did not improve from 17.65001
Epoch 88/10000
4/4 - 0s - loss: 22.1439 - val_loss: 17.7445

Epoch 00088: val_loss did not improve from 17.65001
Epoch 89/10000
4/4 - 0s - loss: 22.1401 - val_loss: 17.6953

Epoch 00089: val_loss did not improve from 17.65001
Epoch 90/10000
4/4 - 0s - loss: 22.1347 - val_loss: 17.7141

Epoch 00090: val_loss did not improve from 17.65001
Epoch 91/10000
4/4 - 0s - loss: 22.1380 - val_loss: 17.7493

Epoch 00091: val_loss did not improve from 17.65001
Epoch 92/10000
4/4 - 0s - loss: 22.1370 - val_loss: 17.7096

Epoch 00092: val_loss did not improve from 17.65001
Epoch 93/10000
4/4 - 0s - loss: 22.1367 - val_loss: 17.7168

Epoch 00093: val_loss did not improve from 17.65001
Epoch 94/10000
4/4 - 0s - loss: 22.1808 - val_loss: 17.7762

Epoch 00094: val_loss did not improve from 17.65001
Epoch 95/10000
4/4 - 0s - loss: 22.1530 - val_loss: 17.6497

Epoch 00095: val_loss improved from 17.65001 to 17.64969, saving model to ./results/dataset/trial_3/ckpt_9
Epoch 96/10000
4/4 - 0s - loss: 22.1667 - val_loss: 17.6704

Epoch 00096: val_loss did not improve from 17.64969
Epoch 97/10000
4/4 - 0s - loss: 22.1415 - val_loss: 17.7118

Epoch 00097: val_loss did not improve from 17.64969
Epoch 98/10000
4/4 - 0s - loss: 22.1328 - val_loss: 17.7394

Epoch 00098: val_loss did not improve from 17.64969
Epoch 99/10000
4/4 - 0s - loss: 22.1375 - val_loss: 17.7543

Epoch 00099: val_loss did not improve from 17.64969
Epoch 100/10000
4/4 - 0s - loss: 22.1349 - val_loss: 17.7028

Epoch 00100: val_loss did not improve from 17.64969
Epoch 101/10000
4/4 - 0s - loss: 22.1356 - val_loss: 17.6923

Epoch 00101: val_loss did not improve from 17.64969
Epoch 102/10000
4/4 - 0s - loss: 22.1342 - val_loss: 17.7335

Epoch 00102: val_loss did not improve from 17.64969
Epoch 103/10000
4/4 - 0s - loss: 22.1432 - val_loss: 17.8081

Epoch 00103: val_loss did not improve from 17.64969
Epoch 104/10000
4/4 - 0s - loss: 22.1423 - val_loss: 17.6976

Epoch 00104: val_loss did not improve from 17.64969
Epoch 105/10000
4/4 - 0s - loss: 22.1351 - val_loss: 17.6824

Epoch 00105: val_loss did not improve from 17.64969
Epoch 106/10000
4/4 - 0s - loss: 22.1446 - val_loss: 17.7241

Epoch 00106: val_loss did not improve from 17.64969
Epoch 107/10000
4/4 - 0s - loss: 22.1498 - val_loss: 17.6944

Epoch 00107: val_loss did not improve from 17.64969
Epoch 108/10000
4/4 - 0s - loss: 22.1372 - val_loss: 17.8000

Epoch 00108: val_loss did not improve from 17.64969
Epoch 109/10000
4/4 - 0s - loss: 22.1427 - val_loss: 17.7311

Epoch 00109: val_loss did not improve from 17.64969
Epoch 110/10000
4/4 - 0s - loss: 22.1383 - val_loss: 17.6690

Epoch 00110: val_loss did not improve from 17.64969
Epoch 111/10000
4/4 - 0s - loss: 22.1426 - val_loss: 17.7179

Epoch 00111: val_loss did not improve from 17.64969
Epoch 112/10000
4/4 - 0s - loss: 22.1406 - val_loss: 17.7505

Epoch 00112: val_loss did not improve from 17.64969
Epoch 113/10000
4/4 - 0s - loss: 22.1349 - val_loss: 17.7316

Epoch 00113: val_loss did not improve from 17.64969
Epoch 114/10000
4/4 - 0s - loss: 22.1394 - val_loss: 17.6902

Epoch 00114: val_loss did not improve from 17.64969
Epoch 115/10000
4/4 - 0s - loss: 22.1386 - val_loss: 17.7235

Epoch 00115: val_loss did not improve from 17.64969
Epoch 116/10000
4/4 - 0s - loss: 22.1400 - val_loss: 17.7323

Epoch 00116: val_loss did not improve from 17.64969
Epoch 117/10000
4/4 - 0s - loss: 22.1331 - val_loss: 17.6940

Epoch 00117: val_loss did not improve from 17.64969
Epoch 118/10000
4/4 - 0s - loss: 22.1409 - val_loss: 17.6953

Epoch 00118: val_loss did not improve from 17.64969
Epoch 119/10000
4/4 - 0s - loss: 22.1369 - val_loss: 17.7704

Epoch 00119: val_loss did not improve from 17.64969
Epoch 120/10000
4/4 - 0s - loss: 22.1412 - val_loss: 17.7267

Epoch 00120: val_loss did not improve from 17.64969
Epoch 121/10000
4/4 - 0s - loss: 22.1316 - val_loss: 17.7081

Epoch 00121: val_loss did not improve from 17.64969
Epoch 122/10000
4/4 - 0s - loss: 22.1551 - val_loss: 17.7014

Epoch 00122: val_loss did not improve from 17.64969
Epoch 123/10000
4/4 - 0s - loss: 22.1414 - val_loss: 17.6740

Epoch 00123: val_loss did not improve from 17.64969
Epoch 124/10000
4/4 - 0s - loss: 22.1585 - val_loss: 17.7497

Epoch 00124: val_loss did not improve from 17.64969
Epoch 125/10000
4/4 - 0s - loss: 22.1359 - val_loss: 17.7091

Epoch 00125: val_loss did not improve from 17.64969
Epoch 126/10000
4/4 - 0s - loss: 22.1373 - val_loss: 17.7136

Epoch 00126: val_loss did not improve from 17.64969
Epoch 127/10000
4/4 - 0s - loss: 22.1400 - val_loss: 17.6928

Epoch 00127: val_loss did not improve from 17.64969
Epoch 128/10000
4/4 - 0s - loss: 22.1418 - val_loss: 17.7220

Epoch 00128: val_loss did not improve from 17.64969
Epoch 129/10000
4/4 - 0s - loss: 22.1374 - val_loss: 17.7305

Epoch 00129: val_loss did not improve from 17.64969
Epoch 130/10000
4/4 - 0s - loss: 22.1349 - val_loss: 17.7049

Epoch 00130: val_loss did not improve from 17.64969
Epoch 131/10000
4/4 - 0s - loss: 22.1359 - val_loss: 17.6957

Epoch 00131: val_loss did not improve from 17.64969
Epoch 132/10000
4/4 - 0s - loss: 22.1388 - val_loss: 17.7252

Epoch 00132: val_loss did not improve from 17.64969
Epoch 133/10000
4/4 - 0s - loss: 22.1350 - val_loss: 17.7134

Epoch 00133: val_loss did not improve from 17.64969
Epoch 134/10000
4/4 - 0s - loss: 22.1369 - val_loss: 17.7217

Epoch 00134: val_loss did not improve from 17.64969
Epoch 135/10000
4/4 - 0s - loss: 22.1330 - val_loss: 17.7440

Epoch 00135: val_loss did not improve from 17.64969
Epoch 136/10000
4/4 - 0s - loss: 22.1336 - val_loss: 17.7264

Epoch 00136: val_loss did not improve from 17.64969
Epoch 137/10000
4/4 - 0s - loss: 22.1330 - val_loss: 17.7148

Epoch 00137: val_loss did not improve from 17.64969
Epoch 138/10000
4/4 - 0s - loss: 22.1353 - val_loss: 17.7251

Epoch 00138: val_loss did not improve from 17.64969
Epoch 139/10000
4/4 - 0s - loss: 22.1317 - val_loss: 17.7213

Epoch 00139: val_loss did not improve from 17.64969
Epoch 140/10000
4/4 - 0s - loss: 22.1354 - val_loss: 17.7297

Epoch 00140: val_loss did not improve from 17.64969
Epoch 141/10000
4/4 - 0s - loss: 22.1337 - val_loss: 17.7356

Epoch 00141: val_loss did not improve from 17.64969
Epoch 142/10000
4/4 - 0s - loss: 22.1338 - val_loss: 17.7501

Epoch 00142: val_loss did not improve from 17.64969
Epoch 143/10000
4/4 - 0s - loss: 22.1347 - val_loss: 17.7129

Epoch 00143: val_loss did not improve from 17.64969
Epoch 144/10000
4/4 - 0s - loss: 22.1379 - val_loss: 17.7092

Epoch 00144: val_loss did not improve from 17.64969
Epoch 145/10000
4/4 - 0s - loss: 22.1301 - val_loss: 17.7761

Epoch 00145: val_loss did not improve from 17.64969
Epoch 146/10000
4/4 - 0s - loss: 22.1387 - val_loss: 17.7466

Epoch 00146: val_loss did not improve from 17.64969
Epoch 147/10000
4/4 - 0s - loss: 22.1332 - val_loss: 17.7092

Epoch 00147: val_loss did not improve from 17.64969
Epoch 148/10000
4/4 - 0s - loss: 22.1414 - val_loss: 17.6832

Epoch 00148: val_loss did not improve from 17.64969
Epoch 149/10000
4/4 - 0s - loss: 22.1633 - val_loss: 17.7798

Epoch 00149: val_loss did not improve from 17.64969
Epoch 150/10000
4/4 - 0s - loss: 22.1365 - val_loss: 17.7034

Epoch 00150: val_loss did not improve from 17.64969
Epoch 151/10000
4/4 - 0s - loss: 22.1397 - val_loss: 17.6993

Epoch 00151: val_loss did not improve from 17.64969
Epoch 152/10000
4/4 - 0s - loss: 22.1375 - val_loss: 17.7225

Epoch 00152: val_loss did not improve from 17.64969
Epoch 153/10000
4/4 - 0s - loss: 22.1308 - val_loss: 17.7617

Epoch 00153: val_loss did not improve from 17.64969
Epoch 154/10000
4/4 - 0s - loss: 22.1376 - val_loss: 17.7945

Epoch 00154: val_loss did not improve from 17.64969
Epoch 155/10000
4/4 - 0s - loss: 22.1367 - val_loss: 17.7102

Epoch 00155: val_loss did not improve from 17.64969
Epoch 156/10000
4/4 - 0s - loss: 22.1560 - val_loss: 17.6663

Epoch 00156: val_loss did not improve from 17.64969
Epoch 157/10000
4/4 - 0s - loss: 22.1538 - val_loss: 17.7860

Epoch 00157: val_loss did not improve from 17.64969
Epoch 158/10000
4/4 - 0s - loss: 22.1600 - val_loss: 17.7681

Epoch 00158: val_loss did not improve from 17.64969
Epoch 159/10000
4/4 - 0s - loss: 22.1598 - val_loss: 17.6708

Epoch 00159: val_loss did not improve from 17.64969
Epoch 160/10000
4/4 - 0s - loss: 22.1475 - val_loss: 17.7175

Epoch 00160: val_loss did not improve from 17.64969
Epoch 161/10000
4/4 - 0s - loss: 22.1393 - val_loss: 17.7727

Epoch 00161: val_loss did not improve from 17.64969
Epoch 162/10000
4/4 - 0s - loss: 22.1357 - val_loss: 17.7410

Epoch 00162: val_loss did not improve from 17.64969
Epoch 163/10000
4/4 - 0s - loss: 22.1361 - val_loss: 17.6953

Epoch 00163: val_loss did not improve from 17.64969
Epoch 164/10000
4/4 - 0s - loss: 22.1386 - val_loss: 17.7308

Epoch 00164: val_loss did not improve from 17.64969
Epoch 165/10000
4/4 - 0s - loss: 22.1379 - val_loss: 17.8002

Epoch 00165: val_loss did not improve from 17.64969
Epoch 166/10000
4/4 - 0s - loss: 22.1416 - val_loss: 17.7396

Epoch 00166: val_loss did not improve from 17.64969
Epoch 167/10000
4/4 - 0s - loss: 22.1334 - val_loss: 17.7089

Epoch 00167: val_loss did not improve from 17.64969
Epoch 168/10000
4/4 - 0s - loss: 22.1398 - val_loss: 17.7112

Epoch 00168: val_loss did not improve from 17.64969
Epoch 169/10000
4/4 - 0s - loss: 22.1350 - val_loss: 17.7667

Epoch 00169: val_loss did not improve from 17.64969
Epoch 170/10000
4/4 - 0s - loss: 22.1346 - val_loss: 17.7417

Epoch 00170: val_loss did not improve from 17.64969
Epoch 171/10000
4/4 - 0s - loss: 22.1300 - val_loss: 17.7018

Epoch 00171: val_loss did not improve from 17.64969
Epoch 172/10000
4/4 - 0s - loss: 22.1355 - val_loss: 17.7113

Epoch 00172: val_loss did not improve from 17.64969
Epoch 173/10000
4/4 - 0s - loss: 22.1560 - val_loss: 17.7150

Epoch 00173: val_loss did not improve from 17.64969
Epoch 174/10000
4/4 - 0s - loss: 22.1367 - val_loss: 17.7854

Epoch 00174: val_loss did not improve from 17.64969
Epoch 175/10000
4/4 - 0s - loss: 22.1382 - val_loss: 17.7163

Epoch 00175: val_loss did not improve from 17.64969
Epoch 176/10000
4/4 - 0s - loss: 22.1359 - val_loss: 17.7095

Epoch 00176: val_loss did not improve from 17.64969
Epoch 177/10000
4/4 - 0s - loss: 22.1317 - val_loss: 17.7625

Epoch 00177: val_loss did not improve from 17.64969
Epoch 178/10000
4/4 - 0s - loss: 22.1368 - val_loss: 17.7488

Epoch 00178: val_loss did not improve from 17.64969
Epoch 179/10000
4/4 - 0s - loss: 22.1411 - val_loss: 17.7063

Epoch 00179: val_loss did not improve from 17.64969
Epoch 180/10000
4/4 - 0s - loss: 22.1332 - val_loss: 17.7683

Epoch 00180: val_loss did not improve from 17.64969
Epoch 181/10000
4/4 - 0s - loss: 22.1392 - val_loss: 17.7309

Epoch 00181: val_loss did not improve from 17.64969
Epoch 182/10000
4/4 - 0s - loss: 22.1316 - val_loss: 17.7331

Epoch 00182: val_loss did not improve from 17.64969
Epoch 183/10000
4/4 - 0s - loss: 22.1336 - val_loss: 17.7277

Epoch 00183: val_loss did not improve from 17.64969
Epoch 184/10000
4/4 - 0s - loss: 22.1350 - val_loss: 17.7630

Epoch 00184: val_loss did not improve from 17.64969
Epoch 185/10000
4/4 - 0s - loss: 22.1376 - val_loss: 17.7341

Epoch 00185: val_loss did not improve from 17.64969
Epoch 186/10000
4/4 - 0s - loss: 22.1310 - val_loss: 17.7514

Epoch 00186: val_loss did not improve from 17.64969
Epoch 187/10000
4/4 - 0s - loss: 22.1440 - val_loss: 17.7424

Epoch 00187: val_loss did not improve from 17.64969
Epoch 188/10000
4/4 - 0s - loss: 22.1418 - val_loss: 17.6834

Epoch 00188: val_loss did not improve from 17.64969
Epoch 189/10000
4/4 - 0s - loss: 22.1404 - val_loss: 17.7549

Epoch 00189: val_loss did not improve from 17.64969
Epoch 190/10000
4/4 - 0s - loss: 22.1324 - val_loss: 17.7653

Epoch 00190: val_loss did not improve from 17.64969
Epoch 191/10000
4/4 - 0s - loss: 22.1367 - val_loss: 17.7543

Epoch 00191: val_loss did not improve from 17.64969
Epoch 192/10000
4/4 - 0s - loss: 22.1384 - val_loss: 17.7620

Epoch 00192: val_loss did not improve from 17.64969
Epoch 193/10000
4/4 - 0s - loss: 22.1255 - val_loss: 17.6968

Epoch 00193: val_loss did not improve from 17.64969
Epoch 194/10000
4/4 - 0s - loss: 22.1623 - val_loss: 17.6755

Epoch 00194: val_loss did not improve from 17.64969
Epoch 195/10000
4/4 - 0s - loss: 22.1385 - val_loss: 17.7750

Epoch 00195: val_loss did not improve from 17.64969
Epoch 196/10000
4/4 - 0s - loss: 22.1378 - val_loss: 17.7997

Epoch 00196: val_loss did not improve from 17.64969
Epoch 197/10000
4/4 - 0s - loss: 22.1453 - val_loss: 17.7221

Epoch 00197: val_loss did not improve from 17.64969
Epoch 198/10000
4/4 - 0s - loss: 22.1355 - val_loss: 17.7494

Epoch 00198: val_loss did not improve from 17.64969
Epoch 199/10000
4/4 - 0s - loss: 22.1319 - val_loss: 17.7245

Epoch 00199: val_loss did not improve from 17.64969
Epoch 200/10000
4/4 - 0s - loss: 22.1362 - val_loss: 17.6960

Epoch 00200: val_loss did not improve from 17.64969
Epoch 201/10000
4/4 - 0s - loss: 22.1379 - val_loss: 17.7293

Epoch 00201: val_loss did not improve from 17.64969
Epoch 202/10000
4/4 - 0s - loss: 22.1318 - val_loss: 17.7588

Epoch 00202: val_loss did not improve from 17.64969
Epoch 203/10000
4/4 - 0s - loss: 22.1375 - val_loss: 17.7427

Epoch 00203: val_loss did not improve from 17.64969
Epoch 204/10000
4/4 - 0s - loss: 22.1323 - val_loss: 17.6893

Epoch 00204: val_loss did not improve from 17.64969
Epoch 205/10000
4/4 - 0s - loss: 22.1498 - val_loss: 17.6868

Epoch 00205: val_loss did not improve from 17.64969
Epoch 206/10000
4/4 - 0s - loss: 22.1426 - val_loss: 17.7098

Epoch 00206: val_loss did not improve from 17.64969
Epoch 207/10000
4/4 - 0s - loss: 22.1328 - val_loss: 17.7735

Epoch 00207: val_loss did not improve from 17.64969
Epoch 208/10000
4/4 - 0s - loss: 22.1401 - val_loss: 17.7654

Epoch 00208: val_loss did not improve from 17.64969
Epoch 209/10000
4/4 - 0s - loss: 22.1420 - val_loss: 17.7843

Epoch 00209: val_loss did not improve from 17.64969
Epoch 210/10000
4/4 - 0s - loss: 22.1361 - val_loss: 17.7211

Epoch 00210: val_loss did not improve from 17.64969
Epoch 211/10000
4/4 - 0s - loss: 22.1415 - val_loss: 17.6919

Epoch 00211: val_loss did not improve from 17.64969
Epoch 212/10000
4/4 - 0s - loss: 22.1336 - val_loss: 17.7615

Epoch 00212: val_loss did not improve from 17.64969
Epoch 213/10000
4/4 - 0s - loss: 22.1355 - val_loss: 17.7965

Epoch 00213: val_loss did not improve from 17.64969
Epoch 214/10000
4/4 - 0s - loss: 22.1391 - val_loss: 17.7197

Epoch 00214: val_loss did not improve from 17.64969
Epoch 215/10000
4/4 - 0s - loss: 22.1515 - val_loss: 17.6956

Epoch 00215: val_loss did not improve from 17.64969
Epoch 216/10000
4/4 - 0s - loss: 22.1297 - val_loss: 17.8087

Epoch 00216: val_loss did not improve from 17.64969
Epoch 217/10000
4/4 - 0s - loss: 22.1509 - val_loss: 17.8242

Epoch 00217: val_loss did not improve from 17.64969
Epoch 218/10000
4/4 - 0s - loss: 22.1463 - val_loss: 17.7146

Epoch 00218: val_loss did not improve from 17.64969
Epoch 219/10000
4/4 - 0s - loss: 22.1373 - val_loss: 17.7235

Epoch 00219: val_loss did not improve from 17.64969
Epoch 220/10000
4/4 - 0s - loss: 22.1343 - val_loss: 17.7308

Epoch 00220: val_loss did not improve from 17.64969
Epoch 221/10000
4/4 - 0s - loss: 22.1589 - val_loss: 17.7811

Epoch 00221: val_loss did not improve from 17.64969
Epoch 222/10000
4/4 - 0s - loss: 22.1377 - val_loss: 17.6967

Epoch 00222: val_loss did not improve from 17.64969
Epoch 223/10000
4/4 - 0s - loss: 22.1384 - val_loss: 17.7345

Epoch 00223: val_loss did not improve from 17.64969
Epoch 224/10000
4/4 - 0s - loss: 22.1352 - val_loss: 17.7797

Epoch 00224: val_loss did not improve from 17.64969
Epoch 225/10000
4/4 - 0s - loss: 22.1367 - val_loss: 17.7303

Epoch 00225: val_loss did not improve from 17.64969
Epoch 226/10000
4/4 - 0s - loss: 22.1412 - val_loss: 17.7324

Epoch 00226: val_loss did not improve from 17.64969
Epoch 227/10000
4/4 - 0s - loss: 22.1532 - val_loss: 17.8128

Epoch 00227: val_loss did not improve from 17.64969
Epoch 228/10000
4/4 - 0s - loss: 22.1356 - val_loss: 17.7163

Epoch 00228: val_loss did not improve from 17.64969
Epoch 229/10000
4/4 - 0s - loss: 22.1614 - val_loss: 17.6851

Epoch 00229: val_loss did not improve from 17.64969
Epoch 230/10000
4/4 - 0s - loss: 22.1494 - val_loss: 17.7766

Epoch 00230: val_loss did not improve from 17.64969
Epoch 231/10000
4/4 - 0s - loss: 22.1386 - val_loss: 17.7497

Epoch 00231: val_loss did not improve from 17.64969
Epoch 232/10000
4/4 - 0s - loss: 22.1404 - val_loss: 17.7572

Epoch 00232: val_loss did not improve from 17.64969
Epoch 233/10000
4/4 - 0s - loss: 22.1385 - val_loss: 17.7056

Epoch 00233: val_loss did not improve from 17.64969
Epoch 234/10000
4/4 - 0s - loss: 22.1366 - val_loss: 17.7258

Epoch 00234: val_loss did not improve from 17.64969
Epoch 235/10000
4/4 - 0s - loss: 22.1328 - val_loss: 17.7397

Epoch 00235: val_loss did not improve from 17.64969
Epoch 236/10000
4/4 - 0s - loss: 22.1313 - val_loss: 17.7437

Epoch 00236: val_loss did not improve from 17.64969
Epoch 237/10000
4/4 - 0s - loss: 22.1344 - val_loss: 17.7497

Epoch 00237: val_loss did not improve from 17.64969
Epoch 238/10000
4/4 - 0s - loss: 22.1313 - val_loss: 17.7756

Epoch 00238: val_loss did not improve from 17.64969
Epoch 239/10000
4/4 - 0s - loss: 22.1404 - val_loss: 17.7512

Epoch 00239: val_loss did not improve from 17.64969
Epoch 240/10000
4/4 - 0s - loss: 22.1317 - val_loss: 17.7198

Epoch 00240: val_loss did not improve from 17.64969
Epoch 241/10000
4/4 - 0s - loss: 22.1331 - val_loss: 17.7436

Epoch 00241: val_loss did not improve from 17.64969
Epoch 242/10000
4/4 - 0s - loss: 22.1619 - val_loss: 17.7694

Epoch 00242: val_loss did not improve from 17.64969
Epoch 243/10000
4/4 - 0s - loss: 22.1315 - val_loss: 17.6939

Epoch 00243: val_loss did not improve from 17.64969
Epoch 244/10000
4/4 - 0s - loss: 22.1416 - val_loss: 17.7270

Epoch 00244: val_loss did not improve from 17.64969
Epoch 245/10000
4/4 - 0s - loss: 22.1339 - val_loss: 17.7386

Epoch 00245: val_loss did not improve from 17.64969
Epoch 246/10000
4/4 - 0s - loss: 22.1421 - val_loss: 17.7752

Epoch 00246: val_loss did not improve from 17.64969
Epoch 247/10000
4/4 - 0s - loss: 22.1272 - val_loss: 17.7041

Epoch 00247: val_loss did not improve from 17.64969
Epoch 248/10000
4/4 - 0s - loss: 22.1446 - val_loss: 17.6795

Epoch 00248: val_loss did not improve from 17.64969
Epoch 249/10000
4/4 - 0s - loss: 22.1446 - val_loss: 17.7590

Epoch 00249: val_loss did not improve from 17.64969
Epoch 250/10000
4/4 - 0s - loss: 22.1611 - val_loss: 17.8224

Epoch 00250: val_loss did not improve from 17.64969
Epoch 251/10000
4/4 - 0s - loss: 22.1431 - val_loss: 17.6774

Epoch 00251: val_loss did not improve from 17.64969
Epoch 252/10000
4/4 - 0s - loss: 22.1619 - val_loss: 17.6852

Epoch 00252: val_loss did not improve from 17.64969
Epoch 253/10000
4/4 - 0s - loss: 22.1427 - val_loss: 17.7790

Epoch 00253: val_loss did not improve from 17.64969
Epoch 254/10000
4/4 - 0s - loss: 22.1451 - val_loss: 17.8094

Epoch 00254: val_loss did not improve from 17.64969
Epoch 255/10000
4/4 - 0s - loss: 22.1391 - val_loss: 17.7065

Epoch 00255: val_loss did not improve from 17.64969
Epoch 256/10000
4/4 - 0s - loss: 22.1381 - val_loss: 17.7095

Epoch 00256: val_loss did not improve from 17.64969
Epoch 257/10000
4/4 - 0s - loss: 22.1331 - val_loss: 17.7479

Epoch 00257: val_loss did not improve from 17.64969
Epoch 258/10000
4/4 - 0s - loss: 22.1417 - val_loss: 17.7988

Epoch 00258: val_loss did not improve from 17.64969
Epoch 259/10000
4/4 - 0s - loss: 22.1320 - val_loss: 17.7193

Epoch 00259: val_loss did not improve from 17.64969
Epoch 260/10000
4/4 - 0s - loss: 22.1366 - val_loss: 17.6783

Epoch 00260: val_loss did not improve from 17.64969
Epoch 261/10000
4/4 - 0s - loss: 22.1550 - val_loss: 17.7135

Epoch 00261: val_loss did not improve from 17.64969
Epoch 262/10000
4/4 - 0s - loss: 22.1336 - val_loss: 17.7839

Epoch 00262: val_loss did not improve from 17.64969
Epoch 263/10000
4/4 - 0s - loss: 22.1384 - val_loss: 17.7456

Epoch 00263: val_loss did not improve from 17.64969
Epoch 264/10000
4/4 - 0s - loss: 22.1424 - val_loss: 17.7088

Epoch 00264: val_loss did not improve from 17.64969
Epoch 265/10000
4/4 - 0s - loss: 22.1421 - val_loss: 17.7884

Epoch 00265: val_loss did not improve from 17.64969
Epoch 266/10000
4/4 - 0s - loss: 22.1402 - val_loss: 17.7482

Epoch 00266: val_loss did not improve from 17.64969
Epoch 267/10000
4/4 - 0s - loss: 22.1332 - val_loss: 17.7482

Epoch 00267: val_loss did not improve from 17.64969
Epoch 268/10000
4/4 - 0s - loss: 22.1402 - val_loss: 17.7335

Epoch 00268: val_loss did not improve from 17.64969
Epoch 269/10000
4/4 - 0s - loss: 22.1368 - val_loss: 17.7254

Epoch 00269: val_loss did not improve from 17.64969
Epoch 270/10000
4/4 - 0s - loss: 22.1429 - val_loss: 17.7259

Epoch 00270: val_loss did not improve from 17.64969
Epoch 271/10000
4/4 - 0s - loss: 22.1321 - val_loss: 17.7491

Epoch 00271: val_loss did not improve from 17.64969
Epoch 272/10000
4/4 - 0s - loss: 22.1364 - val_loss: 17.7392

Epoch 00272: val_loss did not improve from 17.64969
Epoch 273/10000
4/4 - 0s - loss: 22.1383 - val_loss: 17.7967

Epoch 00273: val_loss did not improve from 17.64969
Epoch 274/10000
4/4 - 0s - loss: 22.1344 - val_loss: 17.7189

Epoch 00274: val_loss did not improve from 17.64969
Epoch 275/10000
4/4 - 0s - loss: 22.1332 - val_loss: 17.6830

Epoch 00275: val_loss did not improve from 17.64969
Epoch 276/10000
4/4 - 0s - loss: 22.1484 - val_loss: 17.7214

Epoch 00276: val_loss did not improve from 17.64969
Epoch 277/10000
4/4 - 0s - loss: 22.1296 - val_loss: 17.7755

Epoch 00277: val_loss did not improve from 17.64969
Epoch 278/10000
4/4 - 0s - loss: 22.1572 - val_loss: 17.7935

Epoch 00278: val_loss did not improve from 17.64969
Epoch 279/10000
4/4 - 0s - loss: 22.1492 - val_loss: 17.7334

Epoch 00279: val_loss did not improve from 17.64969
Epoch 280/10000
4/4 - 0s - loss: 22.1333 - val_loss: 17.7171

Epoch 00280: val_loss did not improve from 17.64969
Epoch 281/10000
4/4 - 0s - loss: 22.1324 - val_loss: 17.7527

Epoch 00281: val_loss did not improve from 17.64969
Epoch 282/10000
4/4 - 0s - loss: 22.1327 - val_loss: 17.7677

Epoch 00282: val_loss did not improve from 17.64969
Epoch 283/10000
4/4 - 0s - loss: 22.1343 - val_loss: 17.7563

Epoch 00283: val_loss did not improve from 17.64969
Epoch 284/10000
4/4 - 0s - loss: 22.1437 - val_loss: 17.7215

Epoch 00284: val_loss did not improve from 17.64969
Epoch 285/10000
4/4 - 0s - loss: 22.1499 - val_loss: 17.8118

Epoch 00285: val_loss did not improve from 17.64969
Epoch 286/10000
4/4 - 0s - loss: 22.1487 - val_loss: 17.7635

Epoch 00286: val_loss did not improve from 17.64969
Epoch 287/10000
4/4 - 0s - loss: 22.1453 - val_loss: 17.6708

Epoch 00287: val_loss did not improve from 17.64969
Epoch 288/10000
4/4 - 0s - loss: 22.1620 - val_loss: 17.7190

Epoch 00288: val_loss did not improve from 17.64969
Epoch 289/10000
4/4 - 0s - loss: 22.1526 - val_loss: 17.8627

Epoch 00289: val_loss did not improve from 17.64969
Epoch 290/10000
4/4 - 0s - loss: 22.1460 - val_loss: 17.7147

Epoch 00290: val_loss did not improve from 17.64969
Epoch 291/10000
4/4 - 0s - loss: 22.1430 - val_loss: 17.6863

Epoch 00291: val_loss did not improve from 17.64969
Epoch 292/10000
4/4 - 0s - loss: 22.1382 - val_loss: 17.7623

Epoch 00292: val_loss did not improve from 17.64969
Epoch 293/10000
4/4 - 0s - loss: 22.1528 - val_loss: 17.8515

Epoch 00293: val_loss did not improve from 17.64969
Epoch 294/10000
4/4 - 0s - loss: 22.1542 - val_loss: 17.6990

Epoch 00294: val_loss did not improve from 17.64969
Epoch 295/10000
4/4 - 0s - loss: 22.1391 - val_loss: 17.7256

Epoch 00295: val_loss did not improve from 17.64969
Epoch 00295: early stopping
*************************** Fold #: 10 ***************************
Model: "sequential_29"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_319 (Dense)            (None, 30)                150       
_________________________________________________________________
dense_320 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_321 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_322 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_323 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_324 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_325 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_326 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_327 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_328 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_329 (Dense)            (None, 1)                 31        
=================================================================
Total params: 8,551
Trainable params: 8,551
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
4/4 - 0s - loss: 30.6396 - val_loss: 37.4095

Epoch 00001: val_loss improved from inf to 37.40951, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 2/10000
4/4 - 0s - loss: 30.6012 - val_loss: 37.3656

Epoch 00002: val_loss improved from 37.40951 to 37.36564, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 3/10000
4/4 - 0s - loss: 30.5576 - val_loss: 37.3151

Epoch 00003: val_loss improved from 37.36564 to 37.31511, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 4/10000
4/4 - 0s - loss: 30.5079 - val_loss: 37.2557

Epoch 00004: val_loss improved from 37.31511 to 37.25573, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 5/10000
4/4 - 0s - loss: 30.4475 - val_loss: 37.1841

Epoch 00005: val_loss improved from 37.25573 to 37.18413, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 6/10000
4/4 - 0s - loss: 30.3742 - val_loss: 37.0951

Epoch 00006: val_loss improved from 37.18413 to 37.09511, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 7/10000
4/4 - 0s - loss: 30.2844 - val_loss: 36.9810

Epoch 00007: val_loss improved from 37.09511 to 36.98096, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 8/10000
4/4 - 0s - loss: 30.1636 - val_loss: 36.8309

Epoch 00008: val_loss improved from 36.98096 to 36.83092, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 9/10000
4/4 - 0s - loss: 30.0068 - val_loss: 36.6265

Epoch 00009: val_loss improved from 36.83092 to 36.62647, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 10/10000
4/4 - 0s - loss: 29.7904 - val_loss: 36.3396

Epoch 00010: val_loss improved from 36.62647 to 36.33958, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 11/10000
4/4 - 0s - loss: 29.4860 - val_loss: 35.9238

Epoch 00011: val_loss improved from 36.33958 to 35.92377, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 12/10000
4/4 - 0s - loss: 29.0290 - val_loss: 35.3005

Epoch 00012: val_loss improved from 35.92377 to 35.30054, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 13/10000
4/4 - 0s - loss: 28.3439 - val_loss: 34.3406

Epoch 00013: val_loss improved from 35.30054 to 34.34056, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 14/10000
4/4 - 0s - loss: 27.3070 - val_loss: 32.8501

Epoch 00014: val_loss improved from 34.34056 to 32.85007, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 15/10000
4/4 - 0s - loss: 25.7367 - val_loss: 30.6836

Epoch 00015: val_loss improved from 32.85007 to 30.68364, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 16/10000
4/4 - 0s - loss: 23.6511 - val_loss: 28.5475

Epoch 00016: val_loss improved from 30.68364 to 28.54750, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 17/10000
4/4 - 0s - loss: 22.6708 - val_loss: 28.9258

Epoch 00017: val_loss did not improve from 28.54750
Epoch 18/10000
4/4 - 0s - loss: 23.0326 - val_loss: 28.3280

Epoch 00018: val_loss improved from 28.54750 to 28.32799, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 19/10000
4/4 - 0s - loss: 22.4206 - val_loss: 28.3867

Epoch 00019: val_loss did not improve from 28.32799
Epoch 20/10000
4/4 - 0s - loss: 22.3930 - val_loss: 28.4926

Epoch 00020: val_loss did not improve from 28.32799
Epoch 21/10000
4/4 - 0s - loss: 22.4077 - val_loss: 28.3068

Epoch 00021: val_loss improved from 28.32799 to 28.30684, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 22/10000
4/4 - 0s - loss: 22.2552 - val_loss: 28.0575

Epoch 00022: val_loss improved from 28.30684 to 28.05750, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 23/10000
4/4 - 0s - loss: 22.1660 - val_loss: 27.9563

Epoch 00023: val_loss improved from 28.05750 to 27.95631, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 24/10000
4/4 - 0s - loss: 22.1033 - val_loss: 27.8871

Epoch 00024: val_loss improved from 27.95631 to 27.88715, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 25/10000
4/4 - 0s - loss: 22.0237 - val_loss: 27.8391

Epoch 00025: val_loss improved from 27.88715 to 27.83907, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 26/10000
4/4 - 0s - loss: 21.9631 - val_loss: 27.7937

Epoch 00026: val_loss improved from 27.83907 to 27.79375, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 27/10000
4/4 - 0s - loss: 21.9051 - val_loss: 27.7036

Epoch 00027: val_loss improved from 27.79375 to 27.70365, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 28/10000
4/4 - 0s - loss: 21.8324 - val_loss: 27.6116

Epoch 00028: val_loss improved from 27.70365 to 27.61163, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 29/10000
4/4 - 0s - loss: 21.7722 - val_loss: 27.5199

Epoch 00029: val_loss improved from 27.61163 to 27.51986, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 30/10000
4/4 - 0s - loss: 21.7085 - val_loss: 27.4505

Epoch 00030: val_loss improved from 27.51986 to 27.45047, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 31/10000
4/4 - 0s - loss: 21.6525 - val_loss: 27.3809

Epoch 00031: val_loss improved from 27.45047 to 27.38093, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 32/10000
4/4 - 0s - loss: 21.6029 - val_loss: 27.3193

Epoch 00032: val_loss improved from 27.38093 to 27.31934, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 33/10000
4/4 - 0s - loss: 21.5570 - val_loss: 27.2951

Epoch 00033: val_loss improved from 27.31934 to 27.29507, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 34/10000
4/4 - 0s - loss: 21.5075 - val_loss: 27.2095

Epoch 00034: val_loss improved from 27.29507 to 27.20946, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 35/10000
4/4 - 0s - loss: 21.4661 - val_loss: 27.1441

Epoch 00035: val_loss improved from 27.20946 to 27.14412, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 36/10000
4/4 - 0s - loss: 21.4409 - val_loss: 27.1074

Epoch 00036: val_loss improved from 27.14412 to 27.10740, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 37/10000
4/4 - 0s - loss: 21.4104 - val_loss: 27.0676

Epoch 00037: val_loss improved from 27.10740 to 27.06755, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 38/10000
4/4 - 0s - loss: 21.3926 - val_loss: 27.0462

Epoch 00038: val_loss improved from 27.06755 to 27.04622, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 39/10000
4/4 - 0s - loss: 21.3702 - val_loss: 27.0202

Epoch 00039: val_loss improved from 27.04622 to 27.02019, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 40/10000
4/4 - 0s - loss: 21.3351 - val_loss: 26.9695

Epoch 00040: val_loss improved from 27.02019 to 26.96946, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 41/10000
4/4 - 0s - loss: 21.3255 - val_loss: 26.9371

Epoch 00041: val_loss improved from 26.96946 to 26.93712, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 42/10000
4/4 - 0s - loss: 21.3133 - val_loss: 26.9080

Epoch 00042: val_loss improved from 26.93712 to 26.90800, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 43/10000
4/4 - 0s - loss: 21.2940 - val_loss: 26.8877

Epoch 00043: val_loss improved from 26.90800 to 26.88774, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 44/10000
4/4 - 0s - loss: 21.2744 - val_loss: 26.8967

Epoch 00044: val_loss did not improve from 26.88774
Epoch 45/10000
4/4 - 0s - loss: 21.2599 - val_loss: 26.8684

Epoch 00045: val_loss improved from 26.88774 to 26.86841, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 46/10000
4/4 - 0s - loss: 21.2482 - val_loss: 26.8292

Epoch 00046: val_loss improved from 26.86841 to 26.82920, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 47/10000
4/4 - 0s - loss: 21.2284 - val_loss: 26.8141

Epoch 00047: val_loss improved from 26.82920 to 26.81406, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 48/10000
4/4 - 0s - loss: 21.2221 - val_loss: 26.7936

Epoch 00048: val_loss improved from 26.81406 to 26.79357, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 49/10000
4/4 - 0s - loss: 21.2079 - val_loss: 26.8060

Epoch 00049: val_loss did not improve from 26.79357
Epoch 50/10000
4/4 - 0s - loss: 21.2067 - val_loss: 26.7804

Epoch 00050: val_loss improved from 26.79357 to 26.78036, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 51/10000
4/4 - 0s - loss: 21.1802 - val_loss: 26.7254

Epoch 00051: val_loss improved from 26.78036 to 26.72541, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 52/10000
4/4 - 0s - loss: 21.1882 - val_loss: 26.7098

Epoch 00052: val_loss improved from 26.72541 to 26.70982, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 53/10000
4/4 - 0s - loss: 21.1867 - val_loss: 26.7109

Epoch 00053: val_loss did not improve from 26.70982
Epoch 54/10000
4/4 - 0s - loss: 21.1679 - val_loss: 26.7028

Epoch 00054: val_loss improved from 26.70982 to 26.70281, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 55/10000
4/4 - 0s - loss: 21.1850 - val_loss: 26.6800

Epoch 00055: val_loss improved from 26.70281 to 26.67999, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 56/10000
4/4 - 0s - loss: 21.1746 - val_loss: 26.7429

Epoch 00056: val_loss did not improve from 26.67999
Epoch 57/10000
4/4 - 0s - loss: 21.1722 - val_loss: 26.6868

Epoch 00057: val_loss did not improve from 26.67999
Epoch 58/10000
4/4 - 0s - loss: 21.1524 - val_loss: 26.6620

Epoch 00058: val_loss improved from 26.67999 to 26.66199, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 59/10000
4/4 - 0s - loss: 21.1584 - val_loss: 26.6500

Epoch 00059: val_loss improved from 26.66199 to 26.64997, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 60/10000
4/4 - 0s - loss: 21.1562 - val_loss: 26.6691

Epoch 00060: val_loss did not improve from 26.64997
Epoch 61/10000
4/4 - 0s - loss: 21.1650 - val_loss: 26.7176

Epoch 00061: val_loss did not improve from 26.64997
Epoch 62/10000
4/4 - 0s - loss: 21.1537 - val_loss: 26.6446

Epoch 00062: val_loss improved from 26.64997 to 26.64462, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 63/10000
4/4 - 0s - loss: 21.1666 - val_loss: 26.6325

Epoch 00063: val_loss improved from 26.64462 to 26.63246, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 64/10000
4/4 - 0s - loss: 21.1777 - val_loss: 26.6688

Epoch 00064: val_loss did not improve from 26.63246
Epoch 65/10000
4/4 - 0s - loss: 21.1477 - val_loss: 26.6373

Epoch 00065: val_loss did not improve from 26.63246
Epoch 66/10000
4/4 - 0s - loss: 21.1521 - val_loss: 26.6341

Epoch 00066: val_loss did not improve from 26.63246
Epoch 67/10000
4/4 - 0s - loss: 21.1472 - val_loss: 26.6634

Epoch 00067: val_loss did not improve from 26.63246
Epoch 68/10000
4/4 - 0s - loss: 21.1562 - val_loss: 26.6516

Epoch 00068: val_loss did not improve from 26.63246
Epoch 69/10000
4/4 - 0s - loss: 21.1531 - val_loss: 26.6588

Epoch 00069: val_loss did not improve from 26.63246
Epoch 70/10000
4/4 - 0s - loss: 21.1470 - val_loss: 26.6369

Epoch 00070: val_loss did not improve from 26.63246
Epoch 71/10000
4/4 - 0s - loss: 21.1462 - val_loss: 26.6234

Epoch 00071: val_loss improved from 26.63246 to 26.62342, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 72/10000
4/4 - 0s - loss: 21.1474 - val_loss: 26.6379

Epoch 00072: val_loss did not improve from 26.62342
Epoch 73/10000
4/4 - 0s - loss: 21.1441 - val_loss: 26.6486

Epoch 00073: val_loss did not improve from 26.62342
Epoch 74/10000
4/4 - 0s - loss: 21.1430 - val_loss: 26.6292

Epoch 00074: val_loss did not improve from 26.62342
Epoch 75/10000
4/4 - 0s - loss: 21.1552 - val_loss: 26.6187

Epoch 00075: val_loss improved from 26.62342 to 26.61868, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 76/10000
4/4 - 0s - loss: 21.1548 - val_loss: 26.6667

Epoch 00076: val_loss did not improve from 26.61868
Epoch 77/10000
4/4 - 0s - loss: 21.1485 - val_loss: 26.6421

Epoch 00077: val_loss did not improve from 26.61868
Epoch 78/10000
4/4 - 0s - loss: 21.1516 - val_loss: 26.6335

Epoch 00078: val_loss did not improve from 26.61868
Epoch 79/10000
4/4 - 0s - loss: 21.1498 - val_loss: 26.6708

Epoch 00079: val_loss did not improve from 26.61868
Epoch 80/10000
4/4 - 0s - loss: 21.1598 - val_loss: 26.6553

Epoch 00080: val_loss did not improve from 26.61868
Epoch 81/10000
4/4 - 0s - loss: 21.1491 - val_loss: 26.6150

Epoch 00081: val_loss improved from 26.61868 to 26.61501, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 82/10000
4/4 - 0s - loss: 21.1636 - val_loss: 26.6208

Epoch 00082: val_loss did not improve from 26.61501
Epoch 83/10000
4/4 - 0s - loss: 21.1495 - val_loss: 26.6846

Epoch 00083: val_loss did not improve from 26.61501
Epoch 84/10000
4/4 - 0s - loss: 21.1547 - val_loss: 26.6613

Epoch 00084: val_loss did not improve from 26.61501
Epoch 85/10000
4/4 - 0s - loss: 21.1428 - val_loss: 26.6198

Epoch 00085: val_loss did not improve from 26.61501
Epoch 86/10000
4/4 - 0s - loss: 21.1487 - val_loss: 26.6183

Epoch 00086: val_loss did not improve from 26.61501
Epoch 87/10000
4/4 - 0s - loss: 21.1498 - val_loss: 26.6383

Epoch 00087: val_loss did not improve from 26.61501
Epoch 88/10000
4/4 - 0s - loss: 21.1465 - val_loss: 26.6834

Epoch 00088: val_loss did not improve from 26.61501
Epoch 89/10000
4/4 - 0s - loss: 21.1622 - val_loss: 26.6664

Epoch 00089: val_loss did not improve from 26.61501
Epoch 90/10000
4/4 - 0s - loss: 21.1731 - val_loss: 26.6169

Epoch 00090: val_loss did not improve from 26.61501
Epoch 91/10000
4/4 - 0s - loss: 21.1481 - val_loss: 26.6380

Epoch 00091: val_loss did not improve from 26.61501
Epoch 92/10000
4/4 - 0s - loss: 21.1404 - val_loss: 26.6915

Epoch 00092: val_loss did not improve from 26.61501
Epoch 93/10000
4/4 - 0s - loss: 21.1576 - val_loss: 26.6532

Epoch 00093: val_loss did not improve from 26.61501
Epoch 94/10000
4/4 - 0s - loss: 21.1637 - val_loss: 26.6102

Epoch 00094: val_loss improved from 26.61501 to 26.61020, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 95/10000
4/4 - 0s - loss: 21.1816 - val_loss: 26.6428

Epoch 00095: val_loss did not improve from 26.61020
Epoch 96/10000
4/4 - 0s - loss: 21.1426 - val_loss: 26.6284

Epoch 00096: val_loss did not improve from 26.61020
Epoch 97/10000
4/4 - 0s - loss: 21.1460 - val_loss: 26.6233

Epoch 00097: val_loss did not improve from 26.61020
Epoch 98/10000
4/4 - 0s - loss: 21.1431 - val_loss: 26.6429

Epoch 00098: val_loss did not improve from 26.61020
Epoch 99/10000
4/4 - 0s - loss: 21.1443 - val_loss: 26.6412

Epoch 00099: val_loss did not improve from 26.61020
Epoch 100/10000
4/4 - 0s - loss: 21.1552 - val_loss: 26.6421

Epoch 00100: val_loss did not improve from 26.61020
Epoch 101/10000
4/4 - 0s - loss: 21.1496 - val_loss: 26.6210

Epoch 00101: val_loss did not improve from 26.61020
Epoch 102/10000
4/4 - 0s - loss: 21.1450 - val_loss: 26.6361

Epoch 00102: val_loss did not improve from 26.61020
Epoch 103/10000
4/4 - 0s - loss: 21.1504 - val_loss: 26.6586

Epoch 00103: val_loss did not improve from 26.61020
Epoch 104/10000
4/4 - 0s - loss: 21.1446 - val_loss: 26.6391

Epoch 00104: val_loss did not improve from 26.61020
Epoch 105/10000
4/4 - 0s - loss: 21.1571 - val_loss: 26.6230

Epoch 00105: val_loss did not improve from 26.61020
Epoch 106/10000
4/4 - 0s - loss: 21.1486 - val_loss: 26.6708

Epoch 00106: val_loss did not improve from 26.61020
Epoch 107/10000
4/4 - 0s - loss: 21.1490 - val_loss: 26.6466

Epoch 00107: val_loss did not improve from 26.61020
Epoch 108/10000
4/4 - 0s - loss: 21.1408 - val_loss: 26.6234

Epoch 00108: val_loss did not improve from 26.61020
Epoch 109/10000
4/4 - 0s - loss: 21.1702 - val_loss: 26.6175

Epoch 00109: val_loss did not improve from 26.61020
Epoch 110/10000
4/4 - 0s - loss: 21.1368 - val_loss: 26.6713

Epoch 00110: val_loss did not improve from 26.61020
Epoch 111/10000
4/4 - 0s - loss: 21.1543 - val_loss: 26.6766

Epoch 00111: val_loss did not improve from 26.61020
Epoch 112/10000
4/4 - 0s - loss: 21.1490 - val_loss: 26.6296

Epoch 00112: val_loss did not improve from 26.61020
Epoch 113/10000
4/4 - 0s - loss: 21.1511 - val_loss: 26.6189

Epoch 00113: val_loss did not improve from 26.61020
Epoch 114/10000
4/4 - 0s - loss: 21.1724 - val_loss: 26.6134

Epoch 00114: val_loss did not improve from 26.61020
Epoch 115/10000
4/4 - 0s - loss: 21.1510 - val_loss: 26.6582

Epoch 00115: val_loss did not improve from 26.61020
Epoch 116/10000
4/4 - 0s - loss: 21.1520 - val_loss: 26.6400

Epoch 00116: val_loss did not improve from 26.61020
Epoch 117/10000
4/4 - 0s - loss: 21.1513 - val_loss: 26.6416

Epoch 00117: val_loss did not improve from 26.61020
Epoch 118/10000
4/4 - 0s - loss: 21.1466 - val_loss: 26.6527

Epoch 00118: val_loss did not improve from 26.61020
Epoch 119/10000
4/4 - 0s - loss: 21.1437 - val_loss: 26.6292

Epoch 00119: val_loss did not improve from 26.61020
Epoch 120/10000
4/4 - 0s - loss: 21.1446 - val_loss: 26.6321

Epoch 00120: val_loss did not improve from 26.61020
Epoch 121/10000
4/4 - 0s - loss: 21.1466 - val_loss: 26.6275

Epoch 00121: val_loss did not improve from 26.61020
Epoch 122/10000
4/4 - 0s - loss: 21.1474 - val_loss: 26.6192

Epoch 00122: val_loss did not improve from 26.61020
Epoch 123/10000
4/4 - 0s - loss: 21.1492 - val_loss: 26.6214

Epoch 00123: val_loss did not improve from 26.61020
Epoch 124/10000
4/4 - 0s - loss: 21.1474 - val_loss: 26.6485

Epoch 00124: val_loss did not improve from 26.61020
Epoch 125/10000
4/4 - 0s - loss: 21.1499 - val_loss: 26.6314

Epoch 00125: val_loss did not improve from 26.61020
Epoch 126/10000
4/4 - 0s - loss: 21.1433 - val_loss: 26.6486

Epoch 00126: val_loss did not improve from 26.61020
Epoch 127/10000
4/4 - 0s - loss: 21.1526 - val_loss: 26.6813

Epoch 00127: val_loss did not improve from 26.61020
Epoch 128/10000
4/4 - 0s - loss: 21.1591 - val_loss: 26.6461

Epoch 00128: val_loss did not improve from 26.61020
Epoch 129/10000
4/4 - 0s - loss: 21.1497 - val_loss: 26.6097

Epoch 00129: val_loss improved from 26.61020 to 26.60970, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 130/10000
4/4 - 0s - loss: 21.1636 - val_loss: 26.6132

Epoch 00130: val_loss did not improve from 26.60970
Epoch 131/10000
4/4 - 0s - loss: 21.1441 - val_loss: 26.6439

Epoch 00131: val_loss did not improve from 26.60970
Epoch 132/10000
4/4 - 0s - loss: 21.1529 - val_loss: 26.6521

Epoch 00132: val_loss did not improve from 26.60970
Epoch 133/10000
4/4 - 0s - loss: 21.1420 - val_loss: 26.6145

Epoch 00133: val_loss did not improve from 26.60970
Epoch 134/10000
4/4 - 0s - loss: 21.2143 - val_loss: 26.6084

Epoch 00134: val_loss improved from 26.60970 to 26.60841, saving model to ./results/dataset/trial_3/ckpt_10
Epoch 135/10000
4/4 - 0s - loss: 21.1476 - val_loss: 26.7199

Epoch 00135: val_loss did not improve from 26.60841
Epoch 136/10000
4/4 - 0s - loss: 21.2115 - val_loss: 26.7032

Epoch 00136: val_loss did not improve from 26.60841
Epoch 137/10000
4/4 - 0s - loss: 21.1787 - val_loss: 26.6121

Epoch 00137: val_loss did not improve from 26.60841
Epoch 138/10000
4/4 - 0s - loss: 21.1733 - val_loss: 26.6269

Epoch 00138: val_loss did not improve from 26.60841
Epoch 139/10000
4/4 - 0s - loss: 21.1454 - val_loss: 26.6476

Epoch 00139: val_loss did not improve from 26.60841
Epoch 140/10000
4/4 - 0s - loss: 21.1434 - val_loss: 26.6321

Epoch 00140: val_loss did not improve from 26.60841
Epoch 141/10000
4/4 - 0s - loss: 21.1486 - val_loss: 26.6220

Epoch 00141: val_loss did not improve from 26.60841
Epoch 142/10000
4/4 - 0s - loss: 21.1487 - val_loss: 26.6311

Epoch 00142: val_loss did not improve from 26.60841
Epoch 143/10000
4/4 - 0s - loss: 21.1667 - val_loss: 26.6905

Epoch 00143: val_loss did not improve from 26.60841
Epoch 144/10000
4/4 - 0s - loss: 21.1662 - val_loss: 26.6196

Epoch 00144: val_loss did not improve from 26.60841
Epoch 145/10000
4/4 - 0s - loss: 21.1490 - val_loss: 26.6276

Epoch 00145: val_loss did not improve from 26.60841
Epoch 146/10000
4/4 - 0s - loss: 21.1454 - val_loss: 26.6414

Epoch 00146: val_loss did not improve from 26.60841
Epoch 147/10000
4/4 - 0s - loss: 21.1455 - val_loss: 26.6618

Epoch 00147: val_loss did not improve from 26.60841
Epoch 148/10000
4/4 - 0s - loss: 21.1461 - val_loss: 26.6330

Epoch 00148: val_loss did not improve from 26.60841
Epoch 149/10000
4/4 - 0s - loss: 21.1650 - val_loss: 26.6251

Epoch 00149: val_loss did not improve from 26.60841
Epoch 150/10000
4/4 - 0s - loss: 21.1601 - val_loss: 26.6835

Epoch 00150: val_loss did not improve from 26.60841
Epoch 151/10000
4/4 - 0s - loss: 21.1500 - val_loss: 26.6340

Epoch 00151: val_loss did not improve from 26.60841
Epoch 152/10000
4/4 - 0s - loss: 21.1423 - val_loss: 26.6157

Epoch 00152: val_loss did not improve from 26.60841
Epoch 153/10000
4/4 - 0s - loss: 21.1619 - val_loss: 26.6198

Epoch 00153: val_loss did not improve from 26.60841
Epoch 154/10000
4/4 - 0s - loss: 21.1468 - val_loss: 26.6177

Epoch 00154: val_loss did not improve from 26.60841
Epoch 155/10000
4/4 - 0s - loss: 21.1445 - val_loss: 26.6298

Epoch 00155: val_loss did not improve from 26.60841
Epoch 156/10000
4/4 - 0s - loss: 21.1422 - val_loss: 26.6490

Epoch 00156: val_loss did not improve from 26.60841
Epoch 157/10000
4/4 - 0s - loss: 21.1526 - val_loss: 26.6309

Epoch 00157: val_loss did not improve from 26.60841
Epoch 158/10000
4/4 - 0s - loss: 21.1451 - val_loss: 26.6439

Epoch 00158: val_loss did not improve from 26.60841
Epoch 159/10000
4/4 - 0s - loss: 21.1462 - val_loss: 26.6306

Epoch 00159: val_loss did not improve from 26.60841
Epoch 160/10000
4/4 - 0s - loss: 21.1548 - val_loss: 26.6218

Epoch 00160: val_loss did not improve from 26.60841
Epoch 161/10000
4/4 - 0s - loss: 21.1498 - val_loss: 26.6270

Epoch 00161: val_loss did not improve from 26.60841
Epoch 162/10000
4/4 - 0s - loss: 21.1425 - val_loss: 26.6175

Epoch 00162: val_loss did not improve from 26.60841
Epoch 163/10000
4/4 - 0s - loss: 21.1467 - val_loss: 26.6286

Epoch 00163: val_loss did not improve from 26.60841
Epoch 164/10000
4/4 - 0s - loss: 21.1466 - val_loss: 26.6536

Epoch 00164: val_loss did not improve from 26.60841
Epoch 165/10000
4/4 - 0s - loss: 21.1460 - val_loss: 26.6392

Epoch 00165: val_loss did not improve from 26.60841
Epoch 166/10000
4/4 - 0s - loss: 21.1482 - val_loss: 26.6155

Epoch 00166: val_loss did not improve from 26.60841
Epoch 167/10000
4/4 - 0s - loss: 21.1478 - val_loss: 26.6213

Epoch 00167: val_loss did not improve from 26.60841
Epoch 168/10000
4/4 - 0s - loss: 21.1438 - val_loss: 26.6496

Epoch 00168: val_loss did not improve from 26.60841
Epoch 169/10000
4/4 - 0s - loss: 21.1447 - val_loss: 26.6447

Epoch 00169: val_loss did not improve from 26.60841
Epoch 170/10000
4/4 - 0s - loss: 21.1486 - val_loss: 26.6334

Epoch 00170: val_loss did not improve from 26.60841
Epoch 171/10000
4/4 - 0s - loss: 21.1522 - val_loss: 26.6598

Epoch 00171: val_loss did not improve from 26.60841
Epoch 172/10000
4/4 - 0s - loss: 21.1438 - val_loss: 26.6277

Epoch 00172: val_loss did not improve from 26.60841
Epoch 173/10000
4/4 - 0s - loss: 21.1438 - val_loss: 26.6168

Epoch 00173: val_loss did not improve from 26.60841
Epoch 174/10000
4/4 - 0s - loss: 21.1487 - val_loss: 26.6283

Epoch 00174: val_loss did not improve from 26.60841
Epoch 175/10000
4/4 - 0s - loss: 21.1546 - val_loss: 26.6571

Epoch 00175: val_loss did not improve from 26.60841
Epoch 176/10000
4/4 - 0s - loss: 21.1481 - val_loss: 26.6358

Epoch 00176: val_loss did not improve from 26.60841
Epoch 177/10000
4/4 - 0s - loss: 21.1441 - val_loss: 26.6387

Epoch 00177: val_loss did not improve from 26.60841
Epoch 178/10000
4/4 - 0s - loss: 21.1704 - val_loss: 26.6746

Epoch 00178: val_loss did not improve from 26.60841
Epoch 179/10000
4/4 - 0s - loss: 21.1438 - val_loss: 26.6181

Epoch 00179: val_loss did not improve from 26.60841
Epoch 180/10000
4/4 - 0s - loss: 21.1597 - val_loss: 26.6171

Epoch 00180: val_loss did not improve from 26.60841
Epoch 181/10000
4/4 - 0s - loss: 21.1493 - val_loss: 26.6392

Epoch 00181: val_loss did not improve from 26.60841
Epoch 182/10000
4/4 - 0s - loss: 21.1477 - val_loss: 26.6857

Epoch 00182: val_loss did not improve from 26.60841
Epoch 183/10000
4/4 - 0s - loss: 21.1664 - val_loss: 26.6671

Epoch 00183: val_loss did not improve from 26.60841
Epoch 184/10000
4/4 - 0s - loss: 21.1454 - val_loss: 26.6196

Epoch 00184: val_loss did not improve from 26.60841
Epoch 185/10000
4/4 - 0s - loss: 21.1472 - val_loss: 26.6200

Epoch 00185: val_loss did not improve from 26.60841
Epoch 186/10000
4/4 - 0s - loss: 21.1558 - val_loss: 26.6507

Epoch 00186: val_loss did not improve from 26.60841
Epoch 187/10000
4/4 - 0s - loss: 21.1486 - val_loss: 26.6427

Epoch 00187: val_loss did not improve from 26.60841
Epoch 188/10000
4/4 - 0s - loss: 21.1378 - val_loss: 26.6163

Epoch 00188: val_loss did not improve from 26.60841
Epoch 189/10000
4/4 - 0s - loss: 21.1583 - val_loss: 26.6139

Epoch 00189: val_loss did not improve from 26.60841
Epoch 190/10000
4/4 - 0s - loss: 21.1503 - val_loss: 26.6220

Epoch 00190: val_loss did not improve from 26.60841
Epoch 191/10000
4/4 - 0s - loss: 21.1670 - val_loss: 26.6450

Epoch 00191: val_loss did not improve from 26.60841
Epoch 192/10000
4/4 - 0s - loss: 21.1535 - val_loss: 26.6088

Epoch 00192: val_loss did not improve from 26.60841
Epoch 193/10000
4/4 - 0s - loss: 21.1594 - val_loss: 26.6183

Epoch 00193: val_loss did not improve from 26.60841
Epoch 194/10000
4/4 - 0s - loss: 21.1446 - val_loss: 26.6540

Epoch 00194: val_loss did not improve from 26.60841
Epoch 195/10000
4/4 - 0s - loss: 21.1621 - val_loss: 26.6699

Epoch 00195: val_loss did not improve from 26.60841
Epoch 196/10000
4/4 - 0s - loss: 21.1496 - val_loss: 26.6252

Epoch 00196: val_loss did not improve from 26.60841
Epoch 197/10000
4/4 - 0s - loss: 21.1521 - val_loss: 26.6213

Epoch 00197: val_loss did not improve from 26.60841
Epoch 198/10000
4/4 - 0s - loss: 21.1550 - val_loss: 26.6239

Epoch 00198: val_loss did not improve from 26.60841
Epoch 199/10000
4/4 - 0s - loss: 21.1462 - val_loss: 26.6768

Epoch 00199: val_loss did not improve from 26.60841
Epoch 200/10000
4/4 - 0s - loss: 21.1534 - val_loss: 26.6707

Epoch 00200: val_loss did not improve from 26.60841
Epoch 201/10000
4/4 - 0s - loss: 21.1501 - val_loss: 26.6299

Epoch 00201: val_loss did not improve from 26.60841
Epoch 202/10000
4/4 - 0s - loss: 21.1451 - val_loss: 26.6292

Epoch 00202: val_loss did not improve from 26.60841
Epoch 203/10000
4/4 - 0s - loss: 21.1520 - val_loss: 26.6599

Epoch 00203: val_loss did not improve from 26.60841
Epoch 204/10000
4/4 - 0s - loss: 21.1479 - val_loss: 26.6267

Epoch 00204: val_loss did not improve from 26.60841
Epoch 205/10000
4/4 - 0s - loss: 21.1460 - val_loss: 26.6176

Epoch 00205: val_loss did not improve from 26.60841
Epoch 206/10000
4/4 - 0s - loss: 21.1455 - val_loss: 26.6303

Epoch 00206: val_loss did not improve from 26.60841
Epoch 207/10000
4/4 - 0s - loss: 21.1515 - val_loss: 26.6381

Epoch 00207: val_loss did not improve from 26.60841
Epoch 208/10000
4/4 - 0s - loss: 21.1531 - val_loss: 26.7039

Epoch 00208: val_loss did not improve from 26.60841
Epoch 209/10000
4/4 - 0s - loss: 21.1742 - val_loss: 26.6490

Epoch 00209: val_loss did not improve from 26.60841
Epoch 210/10000
4/4 - 0s - loss: 21.1427 - val_loss: 26.6322

Epoch 00210: val_loss did not improve from 26.60841
Epoch 211/10000
4/4 - 0s - loss: 21.1462 - val_loss: 26.6259

Epoch 00211: val_loss did not improve from 26.60841
Epoch 212/10000
4/4 - 0s - loss: 21.1502 - val_loss: 26.6297

Epoch 00212: val_loss did not improve from 26.60841
Epoch 213/10000
4/4 - 0s - loss: 21.1531 - val_loss: 26.6696

Epoch 00213: val_loss did not improve from 26.60841
Epoch 214/10000
4/4 - 0s - loss: 21.1593 - val_loss: 26.6250

Epoch 00214: val_loss did not improve from 26.60841
Epoch 215/10000
4/4 - 0s - loss: 21.1433 - val_loss: 26.6291

Epoch 00215: val_loss did not improve from 26.60841
Epoch 216/10000
4/4 - 0s - loss: 21.1532 - val_loss: 26.6541

Epoch 00216: val_loss did not improve from 26.60841
Epoch 217/10000
4/4 - 0s - loss: 21.1451 - val_loss: 26.6290

Epoch 00217: val_loss did not improve from 26.60841
Epoch 218/10000
4/4 - 0s - loss: 21.1488 - val_loss: 26.6331

Epoch 00218: val_loss did not improve from 26.60841
Epoch 219/10000
4/4 - 0s - loss: 21.1457 - val_loss: 26.6656

Epoch 00219: val_loss did not improve from 26.60841
Epoch 220/10000
4/4 - 0s - loss: 21.1520 - val_loss: 26.6606

Epoch 00220: val_loss did not improve from 26.60841
Epoch 221/10000
4/4 - 0s - loss: 21.1556 - val_loss: 26.6452

Epoch 00221: val_loss did not improve from 26.60841
Epoch 222/10000
4/4 - 0s - loss: 21.1433 - val_loss: 26.6380

Epoch 00222: val_loss did not improve from 26.60841
Epoch 223/10000
4/4 - 0s - loss: 21.1450 - val_loss: 26.6331

Epoch 00223: val_loss did not improve from 26.60841
Epoch 224/10000
4/4 - 0s - loss: 21.1446 - val_loss: 26.6483

Epoch 00224: val_loss did not improve from 26.60841
Epoch 225/10000
4/4 - 0s - loss: 21.1498 - val_loss: 26.6341

Epoch 00225: val_loss did not improve from 26.60841
Epoch 226/10000
4/4 - 0s - loss: 21.1542 - val_loss: 26.6269

Epoch 00226: val_loss did not improve from 26.60841
Epoch 227/10000
4/4 - 0s - loss: 21.1408 - val_loss: 26.6506

Epoch 00227: val_loss did not improve from 26.60841
Epoch 228/10000
4/4 - 0s - loss: 21.1501 - val_loss: 26.6482

Epoch 00228: val_loss did not improve from 26.60841
Epoch 229/10000
4/4 - 0s - loss: 21.1679 - val_loss: 26.6681

Epoch 00229: val_loss did not improve from 26.60841
Epoch 230/10000
4/4 - 0s - loss: 21.1419 - val_loss: 26.6109

Epoch 00230: val_loss did not improve from 26.60841
Epoch 231/10000
4/4 - 0s - loss: 21.1878 - val_loss: 26.6093

Epoch 00231: val_loss did not improve from 26.60841
Epoch 232/10000
4/4 - 0s - loss: 21.1651 - val_loss: 26.6747

Epoch 00232: val_loss did not improve from 26.60841
Epoch 233/10000
4/4 - 0s - loss: 21.1608 - val_loss: 26.6468

Epoch 00233: val_loss did not improve from 26.60841
Epoch 234/10000
4/4 - 0s - loss: 21.1466 - val_loss: 26.6501

Epoch 00234: val_loss did not improve from 26.60841
Epoch 235/10000
4/4 - 0s - loss: 21.1447 - val_loss: 26.6279

Epoch 00235: val_loss did not improve from 26.60841
Epoch 236/10000
4/4 - 0s - loss: 21.1438 - val_loss: 26.6265

Epoch 00236: val_loss did not improve from 26.60841
Epoch 237/10000
4/4 - 0s - loss: 21.1417 - val_loss: 26.6457

Epoch 00237: val_loss did not improve from 26.60841
Epoch 238/10000
4/4 - 0s - loss: 21.1533 - val_loss: 26.6620

Epoch 00238: val_loss did not improve from 26.60841
Epoch 239/10000
4/4 - 0s - loss: 21.1441 - val_loss: 26.6295

Epoch 00239: val_loss did not improve from 26.60841
Epoch 240/10000
4/4 - 0s - loss: 21.1417 - val_loss: 26.6123

Epoch 00240: val_loss did not improve from 26.60841
Epoch 241/10000
4/4 - 0s - loss: 21.1687 - val_loss: 26.6114

Epoch 00241: val_loss did not improve from 26.60841
Epoch 242/10000
4/4 - 0s - loss: 21.1445 - val_loss: 26.6591

Epoch 00242: val_loss did not improve from 26.60841
Epoch 243/10000
4/4 - 0s - loss: 21.1532 - val_loss: 26.6708

Epoch 00243: val_loss did not improve from 26.60841
Epoch 244/10000
4/4 - 0s - loss: 21.1566 - val_loss: 26.6760

Epoch 00244: val_loss did not improve from 26.60841
Epoch 245/10000
4/4 - 0s - loss: 21.1510 - val_loss: 26.6233

Epoch 00245: val_loss did not improve from 26.60841
Epoch 246/10000
4/4 - 0s - loss: 21.1776 - val_loss: 26.6112

Epoch 00246: val_loss did not improve from 26.60841
Epoch 247/10000
4/4 - 0s - loss: 21.1497 - val_loss: 26.6642

Epoch 00247: val_loss did not improve from 26.60841
Epoch 248/10000
4/4 - 0s - loss: 21.1495 - val_loss: 26.6642

Epoch 00248: val_loss did not improve from 26.60841
Epoch 249/10000
4/4 - 0s - loss: 21.1481 - val_loss: 26.6297

Epoch 00249: val_loss did not improve from 26.60841
Epoch 250/10000
4/4 - 0s - loss: 21.1447 - val_loss: 26.6309

Epoch 00250: val_loss did not improve from 26.60841
Epoch 251/10000
4/4 - 0s - loss: 21.1441 - val_loss: 26.6269

Epoch 00251: val_loss did not improve from 26.60841
Epoch 252/10000
4/4 - 0s - loss: 21.1442 - val_loss: 26.6295

Epoch 00252: val_loss did not improve from 26.60841
Epoch 253/10000
4/4 - 0s - loss: 21.1434 - val_loss: 26.6467

Epoch 00253: val_loss did not improve from 26.60841
Epoch 254/10000
4/4 - 0s - loss: 21.1480 - val_loss: 26.6343

Epoch 00254: val_loss did not improve from 26.60841
Epoch 255/10000
4/4 - 0s - loss: 21.1487 - val_loss: 26.6111

Epoch 00255: val_loss did not improve from 26.60841
Epoch 256/10000
4/4 - 0s - loss: 21.1525 - val_loss: 26.6217

Epoch 00256: val_loss did not improve from 26.60841
Epoch 257/10000
4/4 - 0s - loss: 21.1426 - val_loss: 26.6481

Epoch 00257: val_loss did not improve from 26.60841
Epoch 258/10000
4/4 - 0s - loss: 21.1479 - val_loss: 26.6391

Epoch 00258: val_loss did not improve from 26.60841
Epoch 259/10000
4/4 - 0s - loss: 21.1463 - val_loss: 26.6313

Epoch 00259: val_loss did not improve from 26.60841
Epoch 260/10000
4/4 - 0s - loss: 21.1392 - val_loss: 26.6096

Epoch 00260: val_loss did not improve from 26.60841
Epoch 261/10000
4/4 - 0s - loss: 21.1538 - val_loss: 26.6155

Epoch 00261: val_loss did not improve from 26.60841
Epoch 262/10000
4/4 - 0s - loss: 21.1440 - val_loss: 26.6652

Epoch 00262: val_loss did not improve from 26.60841
Epoch 263/10000
4/4 - 0s - loss: 21.1605 - val_loss: 26.6721

Epoch 00263: val_loss did not improve from 26.60841
Epoch 264/10000
4/4 - 0s - loss: 21.1472 - val_loss: 26.6310

Epoch 00264: val_loss did not improve from 26.60841
Epoch 265/10000
4/4 - 0s - loss: 21.1407 - val_loss: 26.6170

Epoch 00265: val_loss did not improve from 26.60841
Epoch 266/10000
4/4 - 0s - loss: 21.1461 - val_loss: 26.6142

Epoch 00266: val_loss did not improve from 26.60841
Epoch 267/10000
4/4 - 0s - loss: 21.1572 - val_loss: 26.6260

Epoch 00267: val_loss did not improve from 26.60841
Epoch 268/10000
4/4 - 0s - loss: 21.1552 - val_loss: 26.6132

Epoch 00268: val_loss did not improve from 26.60841
Epoch 269/10000
4/4 - 0s - loss: 21.1431 - val_loss: 26.6637

Epoch 00269: val_loss did not improve from 26.60841
Epoch 270/10000
4/4 - 0s - loss: 21.1550 - val_loss: 26.6534

Epoch 00270: val_loss did not improve from 26.60841
Epoch 271/10000
4/4 - 0s - loss: 21.1440 - val_loss: 26.6097

Epoch 00271: val_loss did not improve from 26.60841
Epoch 272/10000
4/4 - 0s - loss: 21.1675 - val_loss: 26.6130

Epoch 00272: val_loss did not improve from 26.60841
Epoch 273/10000
4/4 - 0s - loss: 21.1668 - val_loss: 26.6646

Epoch 00273: val_loss did not improve from 26.60841
Epoch 274/10000
4/4 - 0s - loss: 21.1491 - val_loss: 26.6169

Epoch 00274: val_loss did not improve from 26.60841
Epoch 275/10000
4/4 - 0s - loss: 21.1458 - val_loss: 26.6217

Epoch 00275: val_loss did not improve from 26.60841
Epoch 276/10000
4/4 - 0s - loss: 21.1520 - val_loss: 26.6378

Epoch 00276: val_loss did not improve from 26.60841
Epoch 277/10000
4/4 - 0s - loss: 21.1448 - val_loss: 26.6229

Epoch 00277: val_loss did not improve from 26.60841
Epoch 278/10000
4/4 - 0s - loss: 21.1449 - val_loss: 26.6311

Epoch 00278: val_loss did not improve from 26.60841
Epoch 279/10000
4/4 - 0s - loss: 21.1489 - val_loss: 26.6432

Epoch 00279: val_loss did not improve from 26.60841
Epoch 280/10000
4/4 - 0s - loss: 21.1462 - val_loss: 26.6173

Epoch 00280: val_loss did not improve from 26.60841
Epoch 281/10000
4/4 - 0s - loss: 21.1453 - val_loss: 26.6227

Epoch 00281: val_loss did not improve from 26.60841
Epoch 282/10000
4/4 - 0s - loss: 21.1503 - val_loss: 26.6453

Epoch 00282: val_loss did not improve from 26.60841
Epoch 283/10000
4/4 - 0s - loss: 21.1455 - val_loss: 26.6209

Epoch 00283: val_loss did not improve from 26.60841
Epoch 284/10000
4/4 - 0s - loss: 21.1583 - val_loss: 26.6204

Epoch 00284: val_loss did not improve from 26.60841
Epoch 285/10000
4/4 - 0s - loss: 21.1507 - val_loss: 26.6768

Epoch 00285: val_loss did not improve from 26.60841
Epoch 286/10000
4/4 - 0s - loss: 21.1581 - val_loss: 26.6513

Epoch 00286: val_loss did not improve from 26.60841
Epoch 287/10000
4/4 - 0s - loss: 21.1846 - val_loss: 26.6110

Epoch 00287: val_loss did not improve from 26.60841
Epoch 288/10000
4/4 - 0s - loss: 21.1565 - val_loss: 26.6355

Epoch 00288: val_loss did not improve from 26.60841
Epoch 289/10000
4/4 - 0s - loss: 21.1530 - val_loss: 26.6614

Epoch 00289: val_loss did not improve from 26.60841
Epoch 290/10000
4/4 - 0s - loss: 21.1522 - val_loss: 26.6526

Epoch 00290: val_loss did not improve from 26.60841
Epoch 291/10000
4/4 - 0s - loss: 21.1552 - val_loss: 26.6164

Epoch 00291: val_loss did not improve from 26.60841
Epoch 292/10000
4/4 - 0s - loss: 21.1635 - val_loss: 26.6448

Epoch 00292: val_loss did not improve from 26.60841
Epoch 293/10000
4/4 - 0s - loss: 21.1459 - val_loss: 26.6390

Epoch 00293: val_loss did not improve from 26.60841
Epoch 294/10000
4/4 - 0s - loss: 21.1603 - val_loss: 26.6146

Epoch 00294: val_loss did not improve from 26.60841
Epoch 295/10000
4/4 - 0s - loss: 21.1495 - val_loss: 26.6381

Epoch 00295: val_loss did not improve from 26.60841
Epoch 296/10000
4/4 - 0s - loss: 21.1466 - val_loss: 26.6408

Epoch 00296: val_loss did not improve from 26.60841
Epoch 297/10000
4/4 - 0s - loss: 21.1506 - val_loss: 26.6417

Epoch 00297: val_loss did not improve from 26.60841
Epoch 298/10000
4/4 - 0s - loss: 21.1434 - val_loss: 26.6120

Epoch 00298: val_loss did not improve from 26.60841
Epoch 299/10000
4/4 - 0s - loss: 21.1560 - val_loss: 26.6164

Epoch 00299: val_loss did not improve from 26.60841
Epoch 300/10000
4/4 - 0s - loss: 21.1494 - val_loss: 26.6350

Epoch 00300: val_loss did not improve from 26.60841
Epoch 301/10000
4/4 - 0s - loss: 21.1806 - val_loss: 26.6970

Epoch 00301: val_loss did not improve from 26.60841
Epoch 302/10000
4/4 - 0s - loss: 21.1590 - val_loss: 26.6223

Epoch 00302: val_loss did not improve from 26.60841
Epoch 303/10000
4/4 - 0s - loss: 21.1465 - val_loss: 26.6126

Epoch 00303: val_loss did not improve from 26.60841
Epoch 304/10000
4/4 - 0s - loss: 21.1620 - val_loss: 26.6466

Epoch 00304: val_loss did not improve from 26.60841
Epoch 305/10000
4/4 - 0s - loss: 21.1484 - val_loss: 26.6341

Epoch 00305: val_loss did not improve from 26.60841
Epoch 306/10000
4/4 - 0s - loss: 21.1486 - val_loss: 26.6392

Epoch 00306: val_loss did not improve from 26.60841
Epoch 307/10000
4/4 - 0s - loss: 21.1458 - val_loss: 26.6735

Epoch 00307: val_loss did not improve from 26.60841
Epoch 308/10000
4/4 - 0s - loss: 21.1610 - val_loss: 26.6543

Epoch 00308: val_loss did not improve from 26.60841
Epoch 309/10000
4/4 - 0s - loss: 21.1488 - val_loss: 26.6191

Epoch 00309: val_loss did not improve from 26.60841
Epoch 310/10000
4/4 - 0s - loss: 21.1502 - val_loss: 26.6393

Epoch 00310: val_loss did not improve from 26.60841
Epoch 311/10000
4/4 - 0s - loss: 21.1440 - val_loss: 26.6443

Epoch 00311: val_loss did not improve from 26.60841
Epoch 312/10000
4/4 - 0s - loss: 21.1434 - val_loss: 26.6359

Epoch 00312: val_loss did not improve from 26.60841
Epoch 313/10000
4/4 - 0s - loss: 21.1508 - val_loss: 26.6168

Epoch 00313: val_loss did not improve from 26.60841
Epoch 314/10000
4/4 - 0s - loss: 21.1527 - val_loss: 26.6219

Epoch 00314: val_loss did not improve from 26.60841
Epoch 315/10000
4/4 - 0s - loss: 21.1421 - val_loss: 26.6647

Epoch 00315: val_loss did not improve from 26.60841
Epoch 316/10000
4/4 - 0s - loss: 21.1623 - val_loss: 26.6609

Epoch 00316: val_loss did not improve from 26.60841
Epoch 317/10000
4/4 - 0s - loss: 21.1583 - val_loss: 26.6122

Epoch 00317: val_loss did not improve from 26.60841
Epoch 318/10000
4/4 - 0s - loss: 21.1572 - val_loss: 26.6323

Epoch 00318: val_loss did not improve from 26.60841
Epoch 319/10000
4/4 - 0s - loss: 21.1407 - val_loss: 26.6714

Epoch 00319: val_loss did not improve from 26.60841
Epoch 320/10000
4/4 - 0s - loss: 21.1563 - val_loss: 26.6404

Epoch 00320: val_loss did not improve from 26.60841
Epoch 321/10000
4/4 - 0s - loss: 21.1476 - val_loss: 26.6276

Epoch 00321: val_loss did not improve from 26.60841
Epoch 322/10000
4/4 - 0s - loss: 21.1444 - val_loss: 26.6452

Epoch 00322: val_loss did not improve from 26.60841
Epoch 323/10000
4/4 - 0s - loss: 21.1439 - val_loss: 26.6442

Epoch 00323: val_loss did not improve from 26.60841
Epoch 324/10000
4/4 - 0s - loss: 21.1671 - val_loss: 26.6232

Epoch 00324: val_loss did not improve from 26.60841
Epoch 325/10000
4/4 - 0s - loss: 21.1395 - val_loss: 26.6567

Epoch 00325: val_loss did not improve from 26.60841
Epoch 326/10000
4/4 - 0s - loss: 21.1527 - val_loss: 26.6894

Epoch 00326: val_loss did not improve from 26.60841
Epoch 327/10000
4/4 - 0s - loss: 21.1776 - val_loss: 26.6226

Epoch 00327: val_loss did not improve from 26.60841
Epoch 328/10000
4/4 - 0s - loss: 21.1462 - val_loss: 26.6320

Epoch 00328: val_loss did not improve from 26.60841
Epoch 329/10000
4/4 - 0s - loss: 21.1464 - val_loss: 26.6465

Epoch 00329: val_loss did not improve from 26.60841
Epoch 330/10000
4/4 - 0s - loss: 21.1555 - val_loss: 26.6333

Epoch 00330: val_loss did not improve from 26.60841
Epoch 331/10000
4/4 - 0s - loss: 21.1482 - val_loss: 26.6453

Epoch 00331: val_loss did not improve from 26.60841
Epoch 332/10000
4/4 - 0s - loss: 21.1576 - val_loss: 26.6152

Epoch 00332: val_loss did not improve from 26.60841
Epoch 333/10000
4/4 - 0s - loss: 21.1540 - val_loss: 26.6355

Epoch 00333: val_loss did not improve from 26.60841
Epoch 334/10000
4/4 - 0s - loss: 21.1504 - val_loss: 26.6246

Epoch 00334: val_loss did not improve from 26.60841
Epoch 00334: early stopping

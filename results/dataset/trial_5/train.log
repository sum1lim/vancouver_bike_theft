*************************** Fold #: 1 ***************************
Model: "sequential_40"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_440 (Dense)            (None, 30)                210       
_________________________________________________________________
dense_441 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_442 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_443 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_444 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_445 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_446 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_447 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_448 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_449 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_450 (Dense)            (None, 1)                 31        
=================================================================
Total params: 8,611
Trainable params: 8,611
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
4/4 - 0s - loss: 31.5184 - val_loss: 29.4765

Epoch 00001: val_loss improved from inf to 29.47650, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 2/10000
4/4 - 0s - loss: 31.4754 - val_loss: 29.4330

Epoch 00002: val_loss improved from 29.47650 to 29.43301, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 3/10000
4/4 - 0s - loss: 31.4266 - val_loss: 29.3835

Epoch 00003: val_loss improved from 29.43301 to 29.38352, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 4/10000
4/4 - 0s - loss: 31.3696 - val_loss: 29.3262

Epoch 00004: val_loss improved from 29.38352 to 29.32620, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 5/10000
4/4 - 0s - loss: 31.3040 - val_loss: 29.2581

Epoch 00005: val_loss improved from 29.32620 to 29.25810, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 6/10000
4/4 - 0s - loss: 31.2254 - val_loss: 29.1751

Epoch 00006: val_loss improved from 29.25810 to 29.17508, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 7/10000
4/4 - 0s - loss: 31.1265 - val_loss: 29.0710

Epoch 00007: val_loss improved from 29.17508 to 29.07095, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 8/10000
4/4 - 0s - loss: 31.0024 - val_loss: 28.9350

Epoch 00008: val_loss improved from 29.07095 to 28.93505, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 9/10000
4/4 - 0s - loss: 30.8426 - val_loss: 28.7498

Epoch 00009: val_loss improved from 28.93505 to 28.74982, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 10/10000
4/4 - 0s - loss: 30.6158 - val_loss: 28.4843

Epoch 00010: val_loss improved from 28.74982 to 28.48425, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 11/10000
4/4 - 0s - loss: 30.2760 - val_loss: 28.0814

Epoch 00011: val_loss improved from 28.48425 to 28.08141, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 12/10000
4/4 - 0s - loss: 29.7625 - val_loss: 27.4360

Epoch 00012: val_loss improved from 28.08141 to 27.43600, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 13/10000
4/4 - 0s - loss: 28.9191 - val_loss: 26.3627

Epoch 00013: val_loss improved from 27.43600 to 26.36267, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 14/10000
4/4 - 0s - loss: 27.4945 - val_loss: 24.6397

Epoch 00014: val_loss improved from 26.36267 to 24.63970, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 15/10000
4/4 - 0s - loss: 25.4317 - val_loss: 22.5977

Epoch 00015: val_loss improved from 24.63970 to 22.59769, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 16/10000
4/4 - 0s - loss: 23.3040 - val_loss: 23.2715

Epoch 00016: val_loss did not improve from 22.59769
Epoch 17/10000
4/4 - 0s - loss: 23.8383 - val_loss: 22.7429

Epoch 00017: val_loss did not improve from 22.59769
Epoch 18/10000
4/4 - 0s - loss: 22.9642 - val_loss: 22.0413

Epoch 00018: val_loss improved from 22.59769 to 22.04134, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 19/10000
4/4 - 0s - loss: 22.9166 - val_loss: 22.0745

Epoch 00019: val_loss did not improve from 22.04134
Epoch 20/10000
4/4 - 0s - loss: 22.9280 - val_loss: 21.9049

Epoch 00020: val_loss improved from 22.04134 to 21.90485, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 21/10000
4/4 - 0s - loss: 22.6139 - val_loss: 21.8046

Epoch 00021: val_loss improved from 21.90485 to 21.80456, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 22/10000
4/4 - 0s - loss: 22.3895 - val_loss: 21.8986

Epoch 00022: val_loss did not improve from 21.80456
Epoch 23/10000
4/4 - 0s - loss: 22.3040 - val_loss: 21.6924

Epoch 00023: val_loss improved from 21.80456 to 21.69238, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 24/10000
4/4 - 0s - loss: 22.1034 - val_loss: 21.4499

Epoch 00024: val_loss improved from 21.69238 to 21.44991, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 25/10000
4/4 - 0s - loss: 21.9190 - val_loss: 21.2867

Epoch 00025: val_loss improved from 21.44991 to 21.28669, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 26/10000
4/4 - 0s - loss: 21.7400 - val_loss: 21.1541

Epoch 00026: val_loss improved from 21.28669 to 21.15406, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 27/10000
4/4 - 0s - loss: 21.5191 - val_loss: 20.9910

Epoch 00027: val_loss improved from 21.15406 to 20.99098, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 28/10000
4/4 - 0s - loss: 21.3189 - val_loss: 20.8278

Epoch 00028: val_loss improved from 20.99098 to 20.82783, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 29/10000
4/4 - 0s - loss: 21.0996 - val_loss: 20.6277

Epoch 00029: val_loss improved from 20.82783 to 20.62773, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 30/10000
4/4 - 0s - loss: 20.8835 - val_loss: 20.3963

Epoch 00030: val_loss improved from 20.62773 to 20.39625, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 31/10000
4/4 - 0s - loss: 20.6867 - val_loss: 20.2316

Epoch 00031: val_loss improved from 20.39625 to 20.23164, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 32/10000
4/4 - 0s - loss: 20.4930 - val_loss: 20.0475

Epoch 00032: val_loss improved from 20.23164 to 20.04750, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 33/10000
4/4 - 0s - loss: 20.3136 - val_loss: 19.9352

Epoch 00033: val_loss improved from 20.04750 to 19.93516, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 34/10000
4/4 - 0s - loss: 20.1763 - val_loss: 19.7973

Epoch 00034: val_loss improved from 19.93516 to 19.79726, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 35/10000
4/4 - 0s - loss: 20.0529 - val_loss: 19.5946

Epoch 00035: val_loss improved from 19.79726 to 19.59460, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 36/10000
4/4 - 0s - loss: 19.9211 - val_loss: 19.4629

Epoch 00036: val_loss improved from 19.59460 to 19.46287, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 37/10000
4/4 - 0s - loss: 19.8332 - val_loss: 19.3573

Epoch 00037: val_loss improved from 19.46287 to 19.35734, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 38/10000
4/4 - 0s - loss: 19.7095 - val_loss: 19.2160

Epoch 00038: val_loss improved from 19.35734 to 19.21600, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 39/10000
4/4 - 0s - loss: 19.6049 - val_loss: 19.1436

Epoch 00039: val_loss improved from 19.21600 to 19.14361, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 40/10000
4/4 - 0s - loss: 19.5207 - val_loss: 19.0348

Epoch 00040: val_loss improved from 19.14361 to 19.03482, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 41/10000
4/4 - 0s - loss: 19.4177 - val_loss: 18.9363

Epoch 00041: val_loss improved from 19.03482 to 18.93626, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 42/10000
4/4 - 0s - loss: 19.3501 - val_loss: 18.8415

Epoch 00042: val_loss improved from 18.93626 to 18.84154, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 43/10000
4/4 - 0s - loss: 19.3132 - val_loss: 18.7949

Epoch 00043: val_loss improved from 18.84154 to 18.79489, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 44/10000
4/4 - 0s - loss: 19.2291 - val_loss: 18.7722

Epoch 00044: val_loss improved from 18.79489 to 18.77216, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 45/10000
4/4 - 0s - loss: 19.1732 - val_loss: 18.7389

Epoch 00045: val_loss improved from 18.77216 to 18.73894, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 46/10000
4/4 - 0s - loss: 19.1096 - val_loss: 18.6915

Epoch 00046: val_loss improved from 18.73894 to 18.69147, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 47/10000
4/4 - 0s - loss: 19.0606 - val_loss: 18.6449

Epoch 00047: val_loss improved from 18.69147 to 18.64488, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 48/10000
4/4 - 0s - loss: 19.0365 - val_loss: 18.6328

Epoch 00048: val_loss improved from 18.64488 to 18.63276, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 49/10000
4/4 - 0s - loss: 18.9930 - val_loss: 18.6408

Epoch 00049: val_loss did not improve from 18.63276
Epoch 50/10000
4/4 - 0s - loss: 19.0079 - val_loss: 18.6221

Epoch 00050: val_loss improved from 18.63276 to 18.62210, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 51/10000
4/4 - 0s - loss: 18.9428 - val_loss: 18.5772

Epoch 00051: val_loss improved from 18.62210 to 18.57719, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 52/10000
4/4 - 0s - loss: 18.9362 - val_loss: 18.5683

Epoch 00052: val_loss improved from 18.57719 to 18.56832, saving model to ./results/dataset/trial_5/ckpt_1
Epoch 53/10000
4/4 - 0s - loss: 18.9406 - val_loss: 18.5946

Epoch 00053: val_loss did not improve from 18.56832
Epoch 54/10000
4/4 - 0s - loss: 18.8632 - val_loss: 18.5776

Epoch 00054: val_loss did not improve from 18.56832
Epoch 55/10000
4/4 - 0s - loss: 18.9092 - val_loss: 18.5856

Epoch 00055: val_loss did not improve from 18.56832
Epoch 56/10000
4/4 - 0s - loss: 18.9124 - val_loss: 18.6827

Epoch 00056: val_loss did not improve from 18.56832
Epoch 57/10000
4/4 - 0s - loss: 18.8647 - val_loss: 18.5901

Epoch 00057: val_loss did not improve from 18.56832
Epoch 58/10000
4/4 - 0s - loss: 18.8625 - val_loss: 18.5886

Epoch 00058: val_loss did not improve from 18.56832
Epoch 59/10000
4/4 - 0s - loss: 18.8488 - val_loss: 18.6118

Epoch 00059: val_loss did not improve from 18.56832
Epoch 60/10000
4/4 - 0s - loss: 18.8328 - val_loss: 18.6263

Epoch 00060: val_loss did not improve from 18.56832
Epoch 61/10000
4/4 - 0s - loss: 18.8194 - val_loss: 18.5880

Epoch 00061: val_loss did not improve from 18.56832
Epoch 62/10000
4/4 - 0s - loss: 18.8230 - val_loss: 18.5945

Epoch 00062: val_loss did not improve from 18.56832
Epoch 63/10000
4/4 - 0s - loss: 18.8235 - val_loss: 18.6146

Epoch 00063: val_loss did not improve from 18.56832
Epoch 64/10000
4/4 - 0s - loss: 18.8246 - val_loss: 18.6815

Epoch 00064: val_loss did not improve from 18.56832
Epoch 65/10000
4/4 - 0s - loss: 18.8285 - val_loss: 18.6169

Epoch 00065: val_loss did not improve from 18.56832
Epoch 66/10000
4/4 - 0s - loss: 18.8524 - val_loss: 18.6097

Epoch 00066: val_loss did not improve from 18.56832
Epoch 67/10000
4/4 - 0s - loss: 18.8088 - val_loss: 18.6558

Epoch 00067: val_loss did not improve from 18.56832
Epoch 68/10000
4/4 - 0s - loss: 18.8274 - val_loss: 18.7697

Epoch 00068: val_loss did not improve from 18.56832
Epoch 69/10000
4/4 - 0s - loss: 18.8382 - val_loss: 18.6048

Epoch 00069: val_loss did not improve from 18.56832
Epoch 70/10000
4/4 - 0s - loss: 18.8630 - val_loss: 18.6168

Epoch 00070: val_loss did not improve from 18.56832
Epoch 71/10000
4/4 - 0s - loss: 18.8631 - val_loss: 18.6429

Epoch 00071: val_loss did not improve from 18.56832
Epoch 72/10000
4/4 - 0s - loss: 18.8041 - val_loss: 18.6451

Epoch 00072: val_loss did not improve from 18.56832
Epoch 73/10000
4/4 - 0s - loss: 18.7967 - val_loss: 18.6231

Epoch 00073: val_loss did not improve from 18.56832
Epoch 74/10000
4/4 - 0s - loss: 18.8144 - val_loss: 18.6267

Epoch 00074: val_loss did not improve from 18.56832
Epoch 75/10000
4/4 - 0s - loss: 18.8422 - val_loss: 18.6417

Epoch 00075: val_loss did not improve from 18.56832
Epoch 76/10000
4/4 - 0s - loss: 18.8666 - val_loss: 18.7159

Epoch 00076: val_loss did not improve from 18.56832
Epoch 77/10000
4/4 - 0s - loss: 18.8027 - val_loss: 18.6357

Epoch 00077: val_loss did not improve from 18.56832
Epoch 78/10000
4/4 - 0s - loss: 18.7958 - val_loss: 18.6368

Epoch 00078: val_loss did not improve from 18.56832
Epoch 79/10000
4/4 - 0s - loss: 18.7796 - val_loss: 18.6687

Epoch 00079: val_loss did not improve from 18.56832
Epoch 80/10000
4/4 - 0s - loss: 18.7925 - val_loss: 18.6740

Epoch 00080: val_loss did not improve from 18.56832
Epoch 81/10000
4/4 - 0s - loss: 18.7892 - val_loss: 18.6282

Epoch 00081: val_loss did not improve from 18.56832
Epoch 82/10000
4/4 - 0s - loss: 18.7891 - val_loss: 18.6438

Epoch 00082: val_loss did not improve from 18.56832
Epoch 83/10000
4/4 - 0s - loss: 18.8100 - val_loss: 18.7054

Epoch 00083: val_loss did not improve from 18.56832
Epoch 84/10000
4/4 - 0s - loss: 18.7831 - val_loss: 18.6379

Epoch 00084: val_loss did not improve from 18.56832
Epoch 85/10000
4/4 - 0s - loss: 18.7901 - val_loss: 18.6434

Epoch 00085: val_loss did not improve from 18.56832
Epoch 86/10000
4/4 - 0s - loss: 18.7846 - val_loss: 18.6479

Epoch 00086: val_loss did not improve from 18.56832
Epoch 87/10000
4/4 - 0s - loss: 18.7930 - val_loss: 18.7044

Epoch 00087: val_loss did not improve from 18.56832
Epoch 88/10000
4/4 - 0s - loss: 18.7809 - val_loss: 18.6504

Epoch 00088: val_loss did not improve from 18.56832
Epoch 89/10000
4/4 - 0s - loss: 18.7918 - val_loss: 18.6439

Epoch 00089: val_loss did not improve from 18.56832
Epoch 90/10000
4/4 - 0s - loss: 18.8504 - val_loss: 18.6702

Epoch 00090: val_loss did not improve from 18.56832
Epoch 91/10000
4/4 - 0s - loss: 18.7759 - val_loss: 18.6419

Epoch 00091: val_loss did not improve from 18.56832
Epoch 92/10000
4/4 - 0s - loss: 18.8019 - val_loss: 18.6548

Epoch 00092: val_loss did not improve from 18.56832
Epoch 93/10000
4/4 - 0s - loss: 18.7772 - val_loss: 18.7010

Epoch 00093: val_loss did not improve from 18.56832
Epoch 94/10000
4/4 - 0s - loss: 18.7723 - val_loss: 18.6767

Epoch 00094: val_loss did not improve from 18.56832
Epoch 95/10000
4/4 - 0s - loss: 18.7768 - val_loss: 18.6502

Epoch 00095: val_loss did not improve from 18.56832
Epoch 96/10000
4/4 - 0s - loss: 18.7992 - val_loss: 18.6588

Epoch 00096: val_loss did not improve from 18.56832
Epoch 97/10000
4/4 - 0s - loss: 18.7682 - val_loss: 18.6667

Epoch 00097: val_loss did not improve from 18.56832
Epoch 98/10000
4/4 - 0s - loss: 18.7592 - val_loss: 18.6857

Epoch 00098: val_loss did not improve from 18.56832
Epoch 99/10000
4/4 - 0s - loss: 18.7791 - val_loss: 18.7012

Epoch 00099: val_loss did not improve from 18.56832
Epoch 100/10000
4/4 - 0s - loss: 18.8311 - val_loss: 18.6600

Epoch 00100: val_loss did not improve from 18.56832
Epoch 101/10000
4/4 - 0s - loss: 18.7749 - val_loss: 18.7118

Epoch 00101: val_loss did not improve from 18.56832
Epoch 102/10000
4/4 - 0s - loss: 18.8307 - val_loss: 18.7192

Epoch 00102: val_loss did not improve from 18.56832
Epoch 103/10000
4/4 - 0s - loss: 18.7578 - val_loss: 18.6681

Epoch 00103: val_loss did not improve from 18.56832
Epoch 104/10000
4/4 - 0s - loss: 18.8332 - val_loss: 18.6648

Epoch 00104: val_loss did not improve from 18.56832
Epoch 105/10000
4/4 - 0s - loss: 18.7612 - val_loss: 18.7221

Epoch 00105: val_loss did not improve from 18.56832
Epoch 106/10000
4/4 - 0s - loss: 18.8984 - val_loss: 18.8224

Epoch 00106: val_loss did not improve from 18.56832
Epoch 107/10000
4/4 - 0s - loss: 18.7797 - val_loss: 18.6598

Epoch 00107: val_loss did not improve from 18.56832
Epoch 108/10000
4/4 - 0s - loss: 18.8264 - val_loss: 18.6655

Epoch 00108: val_loss did not improve from 18.56832
Epoch 109/10000
4/4 - 0s - loss: 18.7953 - val_loss: 18.7517

Epoch 00109: val_loss did not improve from 18.56832
Epoch 110/10000
4/4 - 0s - loss: 18.7772 - val_loss: 18.7066

Epoch 00110: val_loss did not improve from 18.56832
Epoch 111/10000
4/4 - 0s - loss: 18.7568 - val_loss: 18.6814

Epoch 00111: val_loss did not improve from 18.56832
Epoch 112/10000
4/4 - 0s - loss: 18.7501 - val_loss: 18.6787

Epoch 00112: val_loss did not improve from 18.56832
Epoch 113/10000
4/4 - 0s - loss: 18.7676 - val_loss: 18.6765

Epoch 00113: val_loss did not improve from 18.56832
Epoch 114/10000
4/4 - 0s - loss: 18.7611 - val_loss: 18.7120

Epoch 00114: val_loss did not improve from 18.56832
Epoch 115/10000
4/4 - 0s - loss: 18.7853 - val_loss: 18.7526

Epoch 00115: val_loss did not improve from 18.56832
Epoch 116/10000
4/4 - 0s - loss: 18.7643 - val_loss: 18.6727

Epoch 00116: val_loss did not improve from 18.56832
Epoch 117/10000
4/4 - 0s - loss: 18.7763 - val_loss: 18.6811

Epoch 00117: val_loss did not improve from 18.56832
Epoch 118/10000
4/4 - 0s - loss: 18.7736 - val_loss: 18.6757

Epoch 00118: val_loss did not improve from 18.56832
Epoch 119/10000
4/4 - 0s - loss: 18.7579 - val_loss: 18.6965

Epoch 00119: val_loss did not improve from 18.56832
Epoch 120/10000
4/4 - 0s - loss: 18.7582 - val_loss: 18.7490

Epoch 00120: val_loss did not improve from 18.56832
Epoch 121/10000
4/4 - 0s - loss: 18.7524 - val_loss: 18.6921

Epoch 00121: val_loss did not improve from 18.56832
Epoch 122/10000
4/4 - 0s - loss: 18.7543 - val_loss: 18.6771

Epoch 00122: val_loss did not improve from 18.56832
Epoch 123/10000
4/4 - 0s - loss: 18.7635 - val_loss: 18.6923

Epoch 00123: val_loss did not improve from 18.56832
Epoch 124/10000
4/4 - 0s - loss: 18.7594 - val_loss: 18.7416

Epoch 00124: val_loss did not improve from 18.56832
Epoch 125/10000
4/4 - 0s - loss: 18.7807 - val_loss: 18.8212

Epoch 00125: val_loss did not improve from 18.56832
Epoch 126/10000
4/4 - 0s - loss: 18.8003 - val_loss: 18.6747

Epoch 00126: val_loss did not improve from 18.56832
Epoch 127/10000
4/4 - 0s - loss: 18.7902 - val_loss: 18.6755

Epoch 00127: val_loss did not improve from 18.56832
Epoch 128/10000
4/4 - 0s - loss: 18.7377 - val_loss: 18.7787

Epoch 00128: val_loss did not improve from 18.56832
Epoch 129/10000
4/4 - 0s - loss: 18.7955 - val_loss: 18.7301

Epoch 00129: val_loss did not improve from 18.56832
Epoch 130/10000
4/4 - 0s - loss: 18.7575 - val_loss: 18.6816

Epoch 00130: val_loss did not improve from 18.56832
Epoch 131/10000
4/4 - 0s - loss: 18.7560 - val_loss: 18.6888

Epoch 00131: val_loss did not improve from 18.56832
Epoch 132/10000
4/4 - 0s - loss: 18.7565 - val_loss: 18.7119

Epoch 00132: val_loss did not improve from 18.56832
Epoch 133/10000
4/4 - 0s - loss: 18.7822 - val_loss: 18.7375

Epoch 00133: val_loss did not improve from 18.56832
Epoch 134/10000
4/4 - 0s - loss: 18.7787 - val_loss: 18.6906

Epoch 00134: val_loss did not improve from 18.56832
Epoch 135/10000
4/4 - 0s - loss: 18.7390 - val_loss: 18.7289

Epoch 00135: val_loss did not improve from 18.56832
Epoch 136/10000
4/4 - 0s - loss: 18.7567 - val_loss: 18.7419

Epoch 00136: val_loss did not improve from 18.56832
Epoch 137/10000
4/4 - 0s - loss: 18.7520 - val_loss: 18.7175

Epoch 00137: val_loss did not improve from 18.56832
Epoch 138/10000
4/4 - 0s - loss: 18.7444 - val_loss: 18.7004

Epoch 00138: val_loss did not improve from 18.56832
Epoch 139/10000
4/4 - 0s - loss: 18.7378 - val_loss: 18.7184

Epoch 00139: val_loss did not improve from 18.56832
Epoch 140/10000
4/4 - 0s - loss: 18.7414 - val_loss: 18.7214

Epoch 00140: val_loss did not improve from 18.56832
Epoch 141/10000
4/4 - 0s - loss: 18.7398 - val_loss: 18.7635

Epoch 00141: val_loss did not improve from 18.56832
Epoch 142/10000
4/4 - 0s - loss: 18.7529 - val_loss: 18.7104

Epoch 00142: val_loss did not improve from 18.56832
Epoch 143/10000
4/4 - 0s - loss: 18.7382 - val_loss: 18.6988

Epoch 00143: val_loss did not improve from 18.56832
Epoch 144/10000
4/4 - 0s - loss: 18.7463 - val_loss: 18.7358

Epoch 00144: val_loss did not improve from 18.56832
Epoch 145/10000
4/4 - 0s - loss: 18.7401 - val_loss: 18.7180

Epoch 00145: val_loss did not improve from 18.56832
Epoch 146/10000
4/4 - 0s - loss: 18.7365 - val_loss: 18.7261

Epoch 00146: val_loss did not improve from 18.56832
Epoch 147/10000
4/4 - 0s - loss: 18.7455 - val_loss: 18.7435

Epoch 00147: val_loss did not improve from 18.56832
Epoch 148/10000
4/4 - 0s - loss: 18.8009 - val_loss: 18.8095

Epoch 00148: val_loss did not improve from 18.56832
Epoch 149/10000
4/4 - 0s - loss: 18.7348 - val_loss: 18.6969

Epoch 00149: val_loss did not improve from 18.56832
Epoch 150/10000
4/4 - 0s - loss: 18.7686 - val_loss: 18.7028

Epoch 00150: val_loss did not improve from 18.56832
Epoch 151/10000
4/4 - 0s - loss: 18.7340 - val_loss: 18.7715

Epoch 00151: val_loss did not improve from 18.56832
Epoch 152/10000
4/4 - 0s - loss: 18.7689 - val_loss: 18.7924

Epoch 00152: val_loss did not improve from 18.56832
Epoch 153/10000
4/4 - 0s - loss: 18.7632 - val_loss: 18.7066

Epoch 00153: val_loss did not improve from 18.56832
Epoch 154/10000
4/4 - 0s - loss: 18.7762 - val_loss: 18.7209

Epoch 00154: val_loss did not improve from 18.56832
Epoch 155/10000
4/4 - 0s - loss: 18.7394 - val_loss: 18.7376

Epoch 00155: val_loss did not improve from 18.56832
Epoch 156/10000
4/4 - 0s - loss: 18.7302 - val_loss: 18.7685

Epoch 00156: val_loss did not improve from 18.56832
Epoch 157/10000
4/4 - 0s - loss: 18.7811 - val_loss: 18.7881

Epoch 00157: val_loss did not improve from 18.56832
Epoch 158/10000
4/4 - 0s - loss: 18.7816 - val_loss: 18.7028

Epoch 00158: val_loss did not improve from 18.56832
Epoch 159/10000
4/4 - 0s - loss: 18.7870 - val_loss: 18.7243

Epoch 00159: val_loss did not improve from 18.56832
Epoch 160/10000
4/4 - 0s - loss: 18.7308 - val_loss: 18.7082

Epoch 00160: val_loss did not improve from 18.56832
Epoch 161/10000
4/4 - 0s - loss: 18.7562 - val_loss: 18.7113

Epoch 00161: val_loss did not improve from 18.56832
Epoch 162/10000
4/4 - 0s - loss: 18.7322 - val_loss: 18.7639

Epoch 00162: val_loss did not improve from 18.56832
Epoch 163/10000
4/4 - 0s - loss: 18.7356 - val_loss: 18.8047

Epoch 00163: val_loss did not improve from 18.56832
Epoch 164/10000
4/4 - 0s - loss: 18.7580 - val_loss: 18.7314

Epoch 00164: val_loss did not improve from 18.56832
Epoch 165/10000
4/4 - 0s - loss: 18.7387 - val_loss: 18.7344

Epoch 00165: val_loss did not improve from 18.56832
Epoch 166/10000
4/4 - 0s - loss: 18.7507 - val_loss: 18.7193

Epoch 00166: val_loss did not improve from 18.56832
Epoch 167/10000
4/4 - 0s - loss: 18.7780 - val_loss: 18.8000

Epoch 00167: val_loss did not improve from 18.56832
Epoch 168/10000
4/4 - 0s - loss: 18.7397 - val_loss: 18.7379

Epoch 00168: val_loss did not improve from 18.56832
Epoch 169/10000
4/4 - 0s - loss: 18.7257 - val_loss: 18.7112

Epoch 00169: val_loss did not improve from 18.56832
Epoch 170/10000
4/4 - 0s - loss: 18.7620 - val_loss: 18.7122

Epoch 00170: val_loss did not improve from 18.56832
Epoch 171/10000
4/4 - 0s - loss: 18.7568 - val_loss: 18.7539

Epoch 00171: val_loss did not improve from 18.56832
Epoch 172/10000
4/4 - 0s - loss: 18.7438 - val_loss: 18.7544

Epoch 00172: val_loss did not improve from 18.56832
Epoch 173/10000
4/4 - 0s - loss: 18.7318 - val_loss: 18.7142

Epoch 00173: val_loss did not improve from 18.56832
Epoch 174/10000
4/4 - 0s - loss: 18.7521 - val_loss: 18.7303

Epoch 00174: val_loss did not improve from 18.56832
Epoch 175/10000
4/4 - 0s - loss: 18.7239 - val_loss: 18.7611

Epoch 00175: val_loss did not improve from 18.56832
Epoch 176/10000
4/4 - 0s - loss: 18.7354 - val_loss: 18.7501

Epoch 00176: val_loss did not improve from 18.56832
Epoch 177/10000
4/4 - 0s - loss: 18.7442 - val_loss: 18.7244

Epoch 00177: val_loss did not improve from 18.56832
Epoch 178/10000
4/4 - 0s - loss: 18.7256 - val_loss: 18.7220

Epoch 00178: val_loss did not improve from 18.56832
Epoch 179/10000
4/4 - 0s - loss: 18.7377 - val_loss: 18.7286

Epoch 00179: val_loss did not improve from 18.56832
Epoch 180/10000
4/4 - 0s - loss: 18.7734 - val_loss: 18.8000

Epoch 00180: val_loss did not improve from 18.56832
Epoch 181/10000
4/4 - 0s - loss: 18.7479 - val_loss: 18.7277

Epoch 00181: val_loss did not improve from 18.56832
Epoch 182/10000
4/4 - 0s - loss: 18.7318 - val_loss: 18.7462

Epoch 00182: val_loss did not improve from 18.56832
Epoch 183/10000
4/4 - 0s - loss: 18.7621 - val_loss: 18.7738

Epoch 00183: val_loss did not improve from 18.56832
Epoch 184/10000
4/4 - 0s - loss: 18.7519 - val_loss: 18.7252

Epoch 00184: val_loss did not improve from 18.56832
Epoch 185/10000
4/4 - 0s - loss: 18.7437 - val_loss: 18.7643

Epoch 00185: val_loss did not improve from 18.56832
Epoch 186/10000
4/4 - 0s - loss: 18.7308 - val_loss: 18.7516

Epoch 00186: val_loss did not improve from 18.56832
Epoch 187/10000
4/4 - 0s - loss: 18.7334 - val_loss: 18.7534

Epoch 00187: val_loss did not improve from 18.56832
Epoch 188/10000
4/4 - 0s - loss: 18.7358 - val_loss: 18.7388

Epoch 00188: val_loss did not improve from 18.56832
Epoch 189/10000
4/4 - 0s - loss: 18.7465 - val_loss: 18.7851

Epoch 00189: val_loss did not improve from 18.56832
Epoch 190/10000
4/4 - 0s - loss: 18.7495 - val_loss: 18.8017

Epoch 00190: val_loss did not improve from 18.56832
Epoch 191/10000
4/4 - 0s - loss: 18.7336 - val_loss: 18.7307

Epoch 00191: val_loss did not improve from 18.56832
Epoch 192/10000
4/4 - 0s - loss: 18.7336 - val_loss: 18.7390

Epoch 00192: val_loss did not improve from 18.56832
Epoch 193/10000
4/4 - 0s - loss: 18.7307 - val_loss: 18.7333

Epoch 00193: val_loss did not improve from 18.56832
Epoch 194/10000
4/4 - 0s - loss: 18.7301 - val_loss: 18.7468

Epoch 00194: val_loss did not improve from 18.56832
Epoch 195/10000
4/4 - 0s - loss: 18.7650 - val_loss: 18.7719

Epoch 00195: val_loss did not improve from 18.56832
Epoch 196/10000
4/4 - 0s - loss: 18.7308 - val_loss: 18.7348

Epoch 00196: val_loss did not improve from 18.56832
Epoch 197/10000
4/4 - 0s - loss: 18.7840 - val_loss: 18.7339

Epoch 00197: val_loss did not improve from 18.56832
Epoch 198/10000
4/4 - 0s - loss: 18.7502 - val_loss: 18.8257

Epoch 00198: val_loss did not improve from 18.56832
Epoch 199/10000
4/4 - 0s - loss: 18.7876 - val_loss: 18.7501

Epoch 00199: val_loss did not improve from 18.56832
Epoch 200/10000
4/4 - 0s - loss: 18.7216 - val_loss: 18.7855

Epoch 00200: val_loss did not improve from 18.56832
Epoch 201/10000
4/4 - 0s - loss: 18.7310 - val_loss: 18.7636

Epoch 00201: val_loss did not improve from 18.56832
Epoch 202/10000
4/4 - 0s - loss: 18.7269 - val_loss: 18.7294

Epoch 00202: val_loss did not improve from 18.56832
Epoch 203/10000
4/4 - 0s - loss: 18.7395 - val_loss: 18.7182

Epoch 00203: val_loss did not improve from 18.56832
Epoch 204/10000
4/4 - 0s - loss: 18.7425 - val_loss: 18.7412

Epoch 00204: val_loss did not improve from 18.56832
Epoch 205/10000
4/4 - 0s - loss: 18.7334 - val_loss: 18.8103

Epoch 00205: val_loss did not improve from 18.56832
Epoch 206/10000
4/4 - 0s - loss: 18.7518 - val_loss: 18.7520

Epoch 00206: val_loss did not improve from 18.56832
Epoch 207/10000
4/4 - 0s - loss: 18.7305 - val_loss: 18.7477

Epoch 00207: val_loss did not improve from 18.56832
Epoch 208/10000
4/4 - 0s - loss: 18.7154 - val_loss: 18.7900

Epoch 00208: val_loss did not improve from 18.56832
Epoch 209/10000
4/4 - 0s - loss: 18.7506 - val_loss: 18.7810

Epoch 00209: val_loss did not improve from 18.56832
Epoch 210/10000
4/4 - 0s - loss: 18.7633 - val_loss: 18.7263

Epoch 00210: val_loss did not improve from 18.56832
Epoch 211/10000
4/4 - 0s - loss: 18.7354 - val_loss: 18.7476

Epoch 00211: val_loss did not improve from 18.56832
Epoch 212/10000
4/4 - 0s - loss: 18.7519 - val_loss: 18.8054

Epoch 00212: val_loss did not improve from 18.56832
Epoch 213/10000
4/4 - 0s - loss: 18.7391 - val_loss: 18.7353

Epoch 00213: val_loss did not improve from 18.56832
Epoch 214/10000
4/4 - 0s - loss: 18.7420 - val_loss: 18.7199

Epoch 00214: val_loss did not improve from 18.56832
Epoch 215/10000
4/4 - 0s - loss: 18.7410 - val_loss: 18.7438

Epoch 00215: val_loss did not improve from 18.56832
Epoch 216/10000
4/4 - 0s - loss: 18.7425 - val_loss: 18.8164

Epoch 00216: val_loss did not improve from 18.56832
Epoch 217/10000
4/4 - 0s - loss: 18.7347 - val_loss: 18.7459

Epoch 00217: val_loss did not improve from 18.56832
Epoch 218/10000
4/4 - 0s - loss: 18.7832 - val_loss: 18.7229

Epoch 00218: val_loss did not improve from 18.56832
Epoch 219/10000
4/4 - 0s - loss: 18.7280 - val_loss: 18.7954

Epoch 00219: val_loss did not improve from 18.56832
Epoch 220/10000
4/4 - 0s - loss: 18.7675 - val_loss: 18.8329

Epoch 00220: val_loss did not improve from 18.56832
Epoch 221/10000
4/4 - 0s - loss: 18.7671 - val_loss: 18.7667

Epoch 00221: val_loss did not improve from 18.56832
Epoch 222/10000
4/4 - 0s - loss: 18.7372 - val_loss: 18.7194

Epoch 00222: val_loss did not improve from 18.56832
Epoch 223/10000
4/4 - 0s - loss: 18.7470 - val_loss: 18.7501

Epoch 00223: val_loss did not improve from 18.56832
Epoch 224/10000
4/4 - 0s - loss: 18.7309 - val_loss: 18.8221

Epoch 00224: val_loss did not improve from 18.56832
Epoch 225/10000
4/4 - 0s - loss: 18.7506 - val_loss: 18.7699

Epoch 00225: val_loss did not improve from 18.56832
Epoch 226/10000
4/4 - 0s - loss: 18.7044 - val_loss: 18.7332

Epoch 00226: val_loss did not improve from 18.56832
Epoch 227/10000
4/4 - 0s - loss: 18.7761 - val_loss: 18.7365

Epoch 00227: val_loss did not improve from 18.56832
Epoch 228/10000
4/4 - 0s - loss: 18.7303 - val_loss: 18.8314

Epoch 00228: val_loss did not improve from 18.56832
Epoch 229/10000
4/4 - 0s - loss: 18.7865 - val_loss: 18.7785

Epoch 00229: val_loss did not improve from 18.56832
Epoch 230/10000
4/4 - 0s - loss: 18.7272 - val_loss: 18.7400

Epoch 00230: val_loss did not improve from 18.56832
Epoch 231/10000
4/4 - 0s - loss: 18.7785 - val_loss: 18.7410

Epoch 00231: val_loss did not improve from 18.56832
Epoch 232/10000
4/4 - 0s - loss: 18.7229 - val_loss: 18.8052

Epoch 00232: val_loss did not improve from 18.56832
Epoch 233/10000
4/4 - 0s - loss: 18.7445 - val_loss: 18.7516

Epoch 00233: val_loss did not improve from 18.56832
Epoch 234/10000
4/4 - 0s - loss: 18.7202 - val_loss: 18.7565

Epoch 00234: val_loss did not improve from 18.56832
Epoch 235/10000
4/4 - 0s - loss: 18.7233 - val_loss: 18.7458

Epoch 00235: val_loss did not improve from 18.56832
Epoch 236/10000
4/4 - 0s - loss: 18.7189 - val_loss: 18.7500

Epoch 00236: val_loss did not improve from 18.56832
Epoch 237/10000
4/4 - 0s - loss: 18.7196 - val_loss: 18.7383

Epoch 00237: val_loss did not improve from 18.56832
Epoch 238/10000
4/4 - 0s - loss: 18.7187 - val_loss: 18.7538

Epoch 00238: val_loss did not improve from 18.56832
Epoch 239/10000
4/4 - 0s - loss: 18.7224 - val_loss: 18.7549

Epoch 00239: val_loss did not improve from 18.56832
Epoch 240/10000
4/4 - 0s - loss: 18.7208 - val_loss: 18.7329

Epoch 00240: val_loss did not improve from 18.56832
Epoch 241/10000
4/4 - 0s - loss: 18.7352 - val_loss: 18.7411

Epoch 00241: val_loss did not improve from 18.56832
Epoch 242/10000
4/4 - 0s - loss: 18.7162 - val_loss: 18.7454

Epoch 00242: val_loss did not improve from 18.56832
Epoch 243/10000
4/4 - 0s - loss: 18.7289 - val_loss: 18.7542

Epoch 00243: val_loss did not improve from 18.56832
Epoch 244/10000
4/4 - 0s - loss: 18.7194 - val_loss: 18.7674

Epoch 00244: val_loss did not improve from 18.56832
Epoch 245/10000
4/4 - 0s - loss: 18.7347 - val_loss: 18.7992

Epoch 00245: val_loss did not improve from 18.56832
Epoch 246/10000
4/4 - 0s - loss: 18.7357 - val_loss: 18.7256

Epoch 00246: val_loss did not improve from 18.56832
Epoch 247/10000
4/4 - 0s - loss: 18.7364 - val_loss: 18.7321

Epoch 00247: val_loss did not improve from 18.56832
Epoch 248/10000
4/4 - 0s - loss: 18.7477 - val_loss: 18.7284

Epoch 00248: val_loss did not improve from 18.56832
Epoch 249/10000
4/4 - 0s - loss: 18.7342 - val_loss: 18.8061

Epoch 00249: val_loss did not improve from 18.56832
Epoch 250/10000
4/4 - 0s - loss: 18.7322 - val_loss: 18.8081

Epoch 00250: val_loss did not improve from 18.56832
Epoch 251/10000
4/4 - 0s - loss: 18.7188 - val_loss: 18.7452

Epoch 00251: val_loss did not improve from 18.56832
Epoch 252/10000
4/4 - 0s - loss: 18.7173 - val_loss: 18.7315

Epoch 00252: val_loss did not improve from 18.56832
Epoch 00252: early stopping
*************************** Fold #: 2 ***************************
Model: "sequential_41"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_451 (Dense)            (None, 30)                210       
_________________________________________________________________
dense_452 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_453 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_454 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_455 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_456 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_457 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_458 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_459 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_460 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_461 (Dense)            (None, 1)                 31        
=================================================================
Total params: 8,611
Trainable params: 8,611
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
4/4 - 0s - loss: 30.4935 - val_loss: 38.7503

Epoch 00001: val_loss improved from inf to 38.75032, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 2/10000
4/4 - 0s - loss: 30.4640 - val_loss: 38.7174

Epoch 00002: val_loss improved from 38.75032 to 38.71738, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 3/10000
4/4 - 0s - loss: 30.4314 - val_loss: 38.6810

Epoch 00003: val_loss improved from 38.71738 to 38.68103, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 4/10000
4/4 - 0s - loss: 30.3949 - val_loss: 38.6404

Epoch 00004: val_loss improved from 38.68103 to 38.64038, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 5/10000
4/4 - 0s - loss: 30.3541 - val_loss: 38.5942

Epoch 00005: val_loss improved from 38.64038 to 38.59415, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 6/10000
4/4 - 0s - loss: 30.3071 - val_loss: 38.5408

Epoch 00006: val_loss improved from 38.59415 to 38.54084, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 7/10000
4/4 - 0s - loss: 30.2523 - val_loss: 38.4783

Epoch 00007: val_loss improved from 38.54084 to 38.47833, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 8/10000
4/4 - 0s - loss: 30.1894 - val_loss: 38.4034

Epoch 00008: val_loss improved from 38.47833 to 38.40340, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 9/10000
4/4 - 0s - loss: 30.1127 - val_loss: 38.3125

Epoch 00009: val_loss improved from 38.40340 to 38.31251, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 10/10000
4/4 - 0s - loss: 30.0181 - val_loss: 38.2009

Epoch 00010: val_loss improved from 38.31251 to 38.20086, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 11/10000
4/4 - 0s - loss: 29.9028 - val_loss: 38.0605

Epoch 00011: val_loss improved from 38.20086 to 38.06054, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 12/10000
4/4 - 0s - loss: 29.7574 - val_loss: 37.8808

Epoch 00012: val_loss improved from 38.06054 to 37.88077, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 13/10000
4/4 - 0s - loss: 29.5669 - val_loss: 37.6469

Epoch 00013: val_loss improved from 37.88077 to 37.64685, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 14/10000
4/4 - 0s - loss: 29.3203 - val_loss: 37.3358

Epoch 00014: val_loss improved from 37.64685 to 37.33576, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 15/10000
4/4 - 0s - loss: 28.9903 - val_loss: 36.9111

Epoch 00015: val_loss improved from 37.33576 to 36.91109, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 16/10000
4/4 - 0s - loss: 28.5371 - val_loss: 36.3125

Epoch 00016: val_loss improved from 36.91109 to 36.31252, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 17/10000
4/4 - 0s - loss: 27.8956 - val_loss: 35.4345

Epoch 00017: val_loss improved from 36.31252 to 35.43449, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 18/10000
4/4 - 0s - loss: 26.9034 - val_loss: 34.1021

Epoch 00018: val_loss improved from 35.43449 to 34.10214, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 19/10000
4/4 - 0s - loss: 25.4580 - val_loss: 32.1398

Epoch 00019: val_loss improved from 34.10214 to 32.13979, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 20/10000
4/4 - 0s - loss: 23.5501 - val_loss: 30.2129

Epoch 00020: val_loss improved from 32.13979 to 30.21291, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 21/10000
4/4 - 0s - loss: 22.5231 - val_loss: 30.6506

Epoch 00021: val_loss did not improve from 30.21291
Epoch 22/10000
4/4 - 0s - loss: 22.7954 - val_loss: 29.9281

Epoch 00022: val_loss improved from 30.21291 to 29.92808, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 23/10000
4/4 - 0s - loss: 22.1485 - val_loss: 29.9294

Epoch 00023: val_loss did not improve from 29.92808
Epoch 24/10000
4/4 - 0s - loss: 22.1982 - val_loss: 29.9780

Epoch 00024: val_loss did not improve from 29.92808
Epoch 25/10000
4/4 - 0s - loss: 22.1395 - val_loss: 29.6996

Epoch 00025: val_loss improved from 29.92808 to 29.69964, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 26/10000
4/4 - 0s - loss: 21.8996 - val_loss: 29.4347

Epoch 00026: val_loss improved from 29.69964 to 29.43474, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 27/10000
4/4 - 0s - loss: 21.7897 - val_loss: 29.3199

Epoch 00027: val_loss improved from 29.43474 to 29.31990, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 28/10000
4/4 - 0s - loss: 21.6627 - val_loss: 29.1659

Epoch 00028: val_loss improved from 29.31990 to 29.16587, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 29/10000
4/4 - 0s - loss: 21.5044 - val_loss: 29.0340

Epoch 00029: val_loss improved from 29.16587 to 29.03405, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 30/10000
4/4 - 0s - loss: 21.3701 - val_loss: 28.8815

Epoch 00030: val_loss improved from 29.03405 to 28.88153, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 31/10000
4/4 - 0s - loss: 21.2052 - val_loss: 28.6482

Epoch 00031: val_loss improved from 28.88153 to 28.64817, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 32/10000
4/4 - 0s - loss: 21.0106 - val_loss: 28.4079

Epoch 00032: val_loss improved from 28.64817 to 28.40792, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 33/10000
4/4 - 0s - loss: 20.8259 - val_loss: 28.1606

Epoch 00033: val_loss improved from 28.40792 to 28.16064, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 34/10000
4/4 - 0s - loss: 20.6343 - val_loss: 27.9119

Epoch 00034: val_loss improved from 28.16064 to 27.91191, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 35/10000
4/4 - 0s - loss: 20.4541 - val_loss: 27.7413

Epoch 00035: val_loss improved from 27.91191 to 27.74126, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 36/10000
4/4 - 0s - loss: 20.2568 - val_loss: 27.4850

Epoch 00036: val_loss improved from 27.74126 to 27.48503, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 37/10000
4/4 - 0s - loss: 20.0707 - val_loss: 27.2540

Epoch 00037: val_loss improved from 27.48503 to 27.25404, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 38/10000
4/4 - 0s - loss: 19.9618 - val_loss: 27.0121

Epoch 00038: val_loss improved from 27.25404 to 27.01206, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 39/10000
4/4 - 0s - loss: 19.7898 - val_loss: 26.9054

Epoch 00039: val_loss improved from 27.01206 to 26.90539, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 40/10000
4/4 - 0s - loss: 19.6590 - val_loss: 26.7238

Epoch 00040: val_loss improved from 26.90539 to 26.72380, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 41/10000
4/4 - 0s - loss: 19.5459 - val_loss: 26.5285

Epoch 00041: val_loss improved from 26.72380 to 26.52853, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 42/10000
4/4 - 0s - loss: 19.4433 - val_loss: 26.3787

Epoch 00042: val_loss improved from 26.52853 to 26.37868, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 43/10000
4/4 - 0s - loss: 19.4057 - val_loss: 26.1532

Epoch 00043: val_loss improved from 26.37868 to 26.15318, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 44/10000
4/4 - 0s - loss: 19.2371 - val_loss: 26.1225

Epoch 00044: val_loss improved from 26.15318 to 26.12247, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 45/10000
4/4 - 0s - loss: 19.1304 - val_loss: 26.0347

Epoch 00045: val_loss improved from 26.12247 to 26.03474, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 46/10000
4/4 - 0s - loss: 19.0500 - val_loss: 25.8330

Epoch 00046: val_loss improved from 26.03474 to 25.83300, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 47/10000
4/4 - 0s - loss: 18.9455 - val_loss: 25.6456

Epoch 00047: val_loss improved from 25.83300 to 25.64560, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 48/10000
4/4 - 0s - loss: 18.8414 - val_loss: 25.5198

Epoch 00048: val_loss improved from 25.64560 to 25.51982, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 49/10000
4/4 - 0s - loss: 18.7809 - val_loss: 25.3840

Epoch 00049: val_loss improved from 25.51982 to 25.38400, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 50/10000
4/4 - 0s - loss: 18.6766 - val_loss: 25.3349

Epoch 00050: val_loss improved from 25.38400 to 25.33488, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 51/10000
4/4 - 0s - loss: 18.6042 - val_loss: 25.2553

Epoch 00051: val_loss improved from 25.33488 to 25.25534, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 52/10000
4/4 - 0s - loss: 18.5436 - val_loss: 25.1439

Epoch 00052: val_loss improved from 25.25534 to 25.14391, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 53/10000
4/4 - 0s - loss: 18.4623 - val_loss: 24.9477

Epoch 00053: val_loss improved from 25.14391 to 24.94772, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 54/10000
4/4 - 0s - loss: 18.4252 - val_loss: 24.8663

Epoch 00054: val_loss improved from 24.94772 to 24.86626, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 55/10000
4/4 - 0s - loss: 18.3870 - val_loss: 24.8713

Epoch 00055: val_loss did not improve from 24.86626
Epoch 56/10000
4/4 - 0s - loss: 18.3353 - val_loss: 24.7780

Epoch 00056: val_loss improved from 24.86626 to 24.77805, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 57/10000
4/4 - 0s - loss: 18.3043 - val_loss: 24.6597

Epoch 00057: val_loss improved from 24.77805 to 24.65974, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 58/10000
4/4 - 0s - loss: 18.2886 - val_loss: 24.7001

Epoch 00058: val_loss did not improve from 24.65974
Epoch 59/10000
4/4 - 0s - loss: 18.2638 - val_loss: 24.6297

Epoch 00059: val_loss improved from 24.65974 to 24.62968, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 60/10000
4/4 - 0s - loss: 18.2427 - val_loss: 24.5437

Epoch 00060: val_loss improved from 24.62968 to 24.54375, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 61/10000
4/4 - 0s - loss: 18.2475 - val_loss: 24.4825

Epoch 00061: val_loss improved from 24.54375 to 24.48253, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 62/10000
4/4 - 0s - loss: 18.2279 - val_loss: 24.5718

Epoch 00062: val_loss did not improve from 24.48253
Epoch 63/10000
4/4 - 0s - loss: 18.2418 - val_loss: 24.6224

Epoch 00063: val_loss did not improve from 24.48253
Epoch 64/10000
4/4 - 0s - loss: 18.2166 - val_loss: 24.4730

Epoch 00064: val_loss improved from 24.48253 to 24.47299, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 65/10000
4/4 - 0s - loss: 18.2576 - val_loss: 24.3453

Epoch 00065: val_loss improved from 24.47299 to 24.34527, saving model to ./results/dataset/trial_5/ckpt_2
Epoch 66/10000
4/4 - 0s - loss: 18.2316 - val_loss: 24.5726

Epoch 00066: val_loss did not improve from 24.34527
Epoch 67/10000
4/4 - 0s - loss: 18.2393 - val_loss: 24.5644

Epoch 00067: val_loss did not improve from 24.34527
Epoch 68/10000
4/4 - 0s - loss: 18.1982 - val_loss: 24.4476

Epoch 00068: val_loss did not improve from 24.34527
Epoch 69/10000
4/4 - 0s - loss: 18.1946 - val_loss: 24.3986

Epoch 00069: val_loss did not improve from 24.34527
Epoch 70/10000
4/4 - 0s - loss: 18.2026 - val_loss: 24.4155

Epoch 00070: val_loss did not improve from 24.34527
Epoch 71/10000
4/4 - 0s - loss: 18.2087 - val_loss: 24.5396

Epoch 00071: val_loss did not improve from 24.34527
Epoch 72/10000
4/4 - 0s - loss: 18.1960 - val_loss: 24.3890

Epoch 00072: val_loss did not improve from 24.34527
Epoch 73/10000
4/4 - 0s - loss: 18.2101 - val_loss: 24.3860

Epoch 00073: val_loss did not improve from 24.34527
Epoch 74/10000
4/4 - 0s - loss: 18.2138 - val_loss: 24.6252

Epoch 00074: val_loss did not improve from 24.34527
Epoch 75/10000
4/4 - 0s - loss: 18.2064 - val_loss: 24.5726

Epoch 00075: val_loss did not improve from 24.34527
Epoch 76/10000
4/4 - 0s - loss: 18.1941 - val_loss: 24.4341

Epoch 00076: val_loss did not improve from 24.34527
Epoch 77/10000
4/4 - 0s - loss: 18.1749 - val_loss: 24.5237

Epoch 00077: val_loss did not improve from 24.34527
Epoch 78/10000
4/4 - 0s - loss: 18.2514 - val_loss: 24.7113

Epoch 00078: val_loss did not improve from 24.34527
Epoch 79/10000
4/4 - 0s - loss: 18.1883 - val_loss: 24.4027

Epoch 00079: val_loss did not improve from 24.34527
Epoch 80/10000
4/4 - 0s - loss: 18.1923 - val_loss: 24.4077

Epoch 00080: val_loss did not improve from 24.34527
Epoch 81/10000
4/4 - 0s - loss: 18.1959 - val_loss: 24.5443

Epoch 00081: val_loss did not improve from 24.34527
Epoch 82/10000
4/4 - 0s - loss: 18.2283 - val_loss: 24.6061

Epoch 00082: val_loss did not improve from 24.34527
Epoch 83/10000
4/4 - 0s - loss: 18.1631 - val_loss: 24.3869

Epoch 00083: val_loss did not improve from 24.34527
Epoch 84/10000
4/4 - 0s - loss: 18.1796 - val_loss: 24.3587

Epoch 00084: val_loss did not improve from 24.34527
Epoch 85/10000
4/4 - 0s - loss: 18.1770 - val_loss: 24.3994

Epoch 00085: val_loss did not improve from 24.34527
Epoch 86/10000
4/4 - 0s - loss: 18.1551 - val_loss: 24.4443

Epoch 00086: val_loss did not improve from 24.34527
Epoch 87/10000
4/4 - 0s - loss: 18.1598 - val_loss: 24.4836

Epoch 00087: val_loss did not improve from 24.34527
Epoch 88/10000
4/4 - 0s - loss: 18.1552 - val_loss: 24.4488

Epoch 00088: val_loss did not improve from 24.34527
Epoch 89/10000
4/4 - 0s - loss: 18.1658 - val_loss: 24.4367

Epoch 00089: val_loss did not improve from 24.34527
Epoch 90/10000
4/4 - 0s - loss: 18.1909 - val_loss: 24.4254

Epoch 00090: val_loss did not improve from 24.34527
Epoch 91/10000
4/4 - 0s - loss: 18.1386 - val_loss: 24.6579

Epoch 00091: val_loss did not improve from 24.34527
Epoch 92/10000
4/4 - 0s - loss: 18.2155 - val_loss: 24.6690

Epoch 00092: val_loss did not improve from 24.34527
Epoch 93/10000
4/4 - 0s - loss: 18.1260 - val_loss: 24.4375

Epoch 00093: val_loss did not improve from 24.34527
Epoch 94/10000
4/4 - 0s - loss: 18.3071 - val_loss: 24.3783

Epoch 00094: val_loss did not improve from 24.34527
Epoch 95/10000
4/4 - 0s - loss: 18.1569 - val_loss: 24.7267

Epoch 00095: val_loss did not improve from 24.34527
Epoch 96/10000
4/4 - 0s - loss: 18.2999 - val_loss: 24.8139

Epoch 00096: val_loss did not improve from 24.34527
Epoch 97/10000
4/4 - 0s - loss: 18.1761 - val_loss: 24.3967

Epoch 00097: val_loss did not improve from 24.34527
Epoch 98/10000
4/4 - 0s - loss: 18.2221 - val_loss: 24.3634

Epoch 00098: val_loss did not improve from 24.34527
Epoch 99/10000
4/4 - 0s - loss: 18.2193 - val_loss: 24.6227

Epoch 00099: val_loss did not improve from 24.34527
Epoch 100/10000
4/4 - 0s - loss: 18.1662 - val_loss: 24.5568

Epoch 00100: val_loss did not improve from 24.34527
Epoch 101/10000
4/4 - 0s - loss: 18.1374 - val_loss: 24.4482

Epoch 00101: val_loss did not improve from 24.34527
Epoch 102/10000
4/4 - 0s - loss: 18.1442 - val_loss: 24.4236

Epoch 00102: val_loss did not improve from 24.34527
Epoch 103/10000
4/4 - 0s - loss: 18.1405 - val_loss: 24.4495

Epoch 00103: val_loss did not improve from 24.34527
Epoch 104/10000
4/4 - 0s - loss: 18.1427 - val_loss: 24.5438

Epoch 00104: val_loss did not improve from 24.34527
Epoch 105/10000
4/4 - 0s - loss: 18.1601 - val_loss: 24.5542

Epoch 00105: val_loss did not improve from 24.34527
Epoch 106/10000
4/4 - 0s - loss: 18.1352 - val_loss: 24.4509

Epoch 00106: val_loss did not improve from 24.34527
Epoch 107/10000
4/4 - 0s - loss: 18.1382 - val_loss: 24.4563

Epoch 00107: val_loss did not improve from 24.34527
Epoch 108/10000
4/4 - 0s - loss: 18.1338 - val_loss: 24.4777

Epoch 00108: val_loss did not improve from 24.34527
Epoch 109/10000
4/4 - 0s - loss: 18.1446 - val_loss: 24.4229

Epoch 00109: val_loss did not improve from 24.34527
Epoch 110/10000
4/4 - 0s - loss: 18.1236 - val_loss: 24.5109

Epoch 00110: val_loss did not improve from 24.34527
Epoch 111/10000
4/4 - 0s - loss: 18.1754 - val_loss: 24.6341

Epoch 00111: val_loss did not improve from 24.34527
Epoch 112/10000
4/4 - 0s - loss: 18.1741 - val_loss: 24.3766

Epoch 00112: val_loss did not improve from 24.34527
Epoch 113/10000
4/4 - 0s - loss: 18.1477 - val_loss: 24.4099

Epoch 00113: val_loss did not improve from 24.34527
Epoch 114/10000
4/4 - 0s - loss: 18.1423 - val_loss: 24.4549

Epoch 00114: val_loss did not improve from 24.34527
Epoch 115/10000
4/4 - 0s - loss: 18.1336 - val_loss: 24.4051

Epoch 00115: val_loss did not improve from 24.34527
Epoch 116/10000
4/4 - 0s - loss: 18.1327 - val_loss: 24.4720

Epoch 00116: val_loss did not improve from 24.34527
Epoch 117/10000
4/4 - 0s - loss: 18.1268 - val_loss: 24.5235

Epoch 00117: val_loss did not improve from 24.34527
Epoch 118/10000
4/4 - 0s - loss: 18.1265 - val_loss: 24.5062

Epoch 00118: val_loss did not improve from 24.34527
Epoch 119/10000
4/4 - 0s - loss: 18.1263 - val_loss: 24.4444

Epoch 00119: val_loss did not improve from 24.34527
Epoch 120/10000
4/4 - 0s - loss: 18.1414 - val_loss: 24.4032

Epoch 00120: val_loss did not improve from 24.34527
Epoch 121/10000
4/4 - 0s - loss: 18.1348 - val_loss: 24.5181

Epoch 00121: val_loss did not improve from 24.34527
Epoch 122/10000
4/4 - 0s - loss: 18.1472 - val_loss: 24.4940

Epoch 00122: val_loss did not improve from 24.34527
Epoch 123/10000
4/4 - 0s - loss: 18.1150 - val_loss: 24.5557

Epoch 00123: val_loss did not improve from 24.34527
Epoch 124/10000
4/4 - 0s - loss: 18.1284 - val_loss: 24.5585

Epoch 00124: val_loss did not improve from 24.34527
Epoch 125/10000
4/4 - 0s - loss: 18.1235 - val_loss: 24.4650

Epoch 00125: val_loss did not improve from 24.34527
Epoch 126/10000
4/4 - 0s - loss: 18.1323 - val_loss: 24.4693

Epoch 00126: val_loss did not improve from 24.34527
Epoch 127/10000
4/4 - 0s - loss: 18.1356 - val_loss: 24.5980

Epoch 00127: val_loss did not improve from 24.34527
Epoch 128/10000
4/4 - 0s - loss: 18.1249 - val_loss: 24.4885

Epoch 00128: val_loss did not improve from 24.34527
Epoch 129/10000
4/4 - 0s - loss: 18.1494 - val_loss: 24.4248

Epoch 00129: val_loss did not improve from 24.34527
Epoch 130/10000
4/4 - 0s - loss: 18.1229 - val_loss: 24.5089

Epoch 00130: val_loss did not improve from 24.34527
Epoch 131/10000
4/4 - 0s - loss: 18.1138 - val_loss: 24.5377

Epoch 00131: val_loss did not improve from 24.34527
Epoch 132/10000
4/4 - 0s - loss: 18.1185 - val_loss: 24.5260

Epoch 00132: val_loss did not improve from 24.34527
Epoch 133/10000
4/4 - 0s - loss: 18.1141 - val_loss: 24.4449

Epoch 00133: val_loss did not improve from 24.34527
Epoch 134/10000
4/4 - 0s - loss: 18.1186 - val_loss: 24.4058

Epoch 00134: val_loss did not improve from 24.34527
Epoch 135/10000
4/4 - 0s - loss: 18.1222 - val_loss: 24.4464

Epoch 00135: val_loss did not improve from 24.34527
Epoch 136/10000
4/4 - 0s - loss: 18.1311 - val_loss: 24.5228

Epoch 00136: val_loss did not improve from 24.34527
Epoch 137/10000
4/4 - 0s - loss: 18.1245 - val_loss: 24.5005

Epoch 00137: val_loss did not improve from 24.34527
Epoch 138/10000
4/4 - 0s - loss: 18.1179 - val_loss: 24.3924

Epoch 00138: val_loss did not improve from 24.34527
Epoch 139/10000
4/4 - 0s - loss: 18.1424 - val_loss: 24.4350

Epoch 00139: val_loss did not improve from 24.34527
Epoch 140/10000
4/4 - 0s - loss: 18.1605 - val_loss: 24.5626

Epoch 00140: val_loss did not improve from 24.34527
Epoch 141/10000
4/4 - 0s - loss: 18.1296 - val_loss: 24.3995

Epoch 00141: val_loss did not improve from 24.34527
Epoch 142/10000
4/4 - 0s - loss: 18.1221 - val_loss: 24.4249

Epoch 00142: val_loss did not improve from 24.34527
Epoch 143/10000
4/4 - 0s - loss: 18.1018 - val_loss: 24.5231

Epoch 00143: val_loss did not improve from 24.34527
Epoch 144/10000
4/4 - 0s - loss: 18.1151 - val_loss: 24.5616

Epoch 00144: val_loss did not improve from 24.34527
Epoch 145/10000
4/4 - 0s - loss: 18.1458 - val_loss: 24.5919

Epoch 00145: val_loss did not improve from 24.34527
Epoch 146/10000
4/4 - 0s - loss: 18.1160 - val_loss: 24.4611

Epoch 00146: val_loss did not improve from 24.34527
Epoch 147/10000
4/4 - 0s - loss: 18.1164 - val_loss: 24.4163

Epoch 00147: val_loss did not improve from 24.34527
Epoch 148/10000
4/4 - 0s - loss: 18.1166 - val_loss: 24.4725

Epoch 00148: val_loss did not improve from 24.34527
Epoch 149/10000
4/4 - 0s - loss: 18.1499 - val_loss: 24.6424

Epoch 00149: val_loss did not improve from 24.34527
Epoch 150/10000
4/4 - 0s - loss: 18.1233 - val_loss: 24.4618

Epoch 00150: val_loss did not improve from 24.34527
Epoch 151/10000
4/4 - 0s - loss: 18.1493 - val_loss: 24.3993

Epoch 00151: val_loss did not improve from 24.34527
Epoch 152/10000
4/4 - 0s - loss: 18.1072 - val_loss: 24.5078

Epoch 00152: val_loss did not improve from 24.34527
Epoch 153/10000
4/4 - 0s - loss: 18.1082 - val_loss: 24.6365

Epoch 00153: val_loss did not improve from 24.34527
Epoch 154/10000
4/4 - 0s - loss: 18.1305 - val_loss: 24.5840

Epoch 00154: val_loss did not improve from 24.34527
Epoch 155/10000
4/4 - 0s - loss: 18.1206 - val_loss: 24.4669

Epoch 00155: val_loss did not improve from 24.34527
Epoch 156/10000
4/4 - 0s - loss: 18.1130 - val_loss: 24.4835

Epoch 00156: val_loss did not improve from 24.34527
Epoch 157/10000
4/4 - 0s - loss: 18.1017 - val_loss: 24.5316

Epoch 00157: val_loss did not improve from 24.34527
Epoch 158/10000
4/4 - 0s - loss: 18.1124 - val_loss: 24.5218

Epoch 00158: val_loss did not improve from 24.34527
Epoch 159/10000
4/4 - 0s - loss: 18.1094 - val_loss: 24.4728

Epoch 00159: val_loss did not improve from 24.34527
Epoch 160/10000
4/4 - 0s - loss: 18.1005 - val_loss: 24.3888

Epoch 00160: val_loss did not improve from 24.34527
Epoch 161/10000
4/4 - 0s - loss: 18.1212 - val_loss: 24.4308

Epoch 00161: val_loss did not improve from 24.34527
Epoch 162/10000
4/4 - 0s - loss: 18.1076 - val_loss: 24.5737

Epoch 00162: val_loss did not improve from 24.34527
Epoch 163/10000
4/4 - 0s - loss: 18.1194 - val_loss: 24.4816

Epoch 00163: val_loss did not improve from 24.34527
Epoch 164/10000
4/4 - 0s - loss: 18.1031 - val_loss: 24.4588

Epoch 00164: val_loss did not improve from 24.34527
Epoch 165/10000
4/4 - 0s - loss: 18.1027 - val_loss: 24.4462

Epoch 00165: val_loss did not improve from 24.34527
Epoch 166/10000
4/4 - 0s - loss: 18.1179 - val_loss: 24.5448

Epoch 00166: val_loss did not improve from 24.34527
Epoch 167/10000
4/4 - 0s - loss: 18.1056 - val_loss: 24.5451

Epoch 00167: val_loss did not improve from 24.34527
Epoch 168/10000
4/4 - 0s - loss: 18.1001 - val_loss: 24.4778

Epoch 00168: val_loss did not improve from 24.34527
Epoch 169/10000
4/4 - 0s - loss: 18.1925 - val_loss: 24.4113

Epoch 00169: val_loss did not improve from 24.34527
Epoch 170/10000
4/4 - 0s - loss: 18.0805 - val_loss: 24.6068

Epoch 00170: val_loss did not improve from 24.34527
Epoch 171/10000
4/4 - 0s - loss: 18.1626 - val_loss: 24.7490

Epoch 00171: val_loss did not improve from 24.34527
Epoch 172/10000
4/4 - 0s - loss: 18.1527 - val_loss: 24.5148

Epoch 00172: val_loss did not improve from 24.34527
Epoch 173/10000
4/4 - 0s - loss: 18.1103 - val_loss: 24.4617

Epoch 00173: val_loss did not improve from 24.34527
Epoch 174/10000
4/4 - 0s - loss: 18.1061 - val_loss: 24.5271

Epoch 00174: val_loss did not improve from 24.34527
Epoch 175/10000
4/4 - 0s - loss: 18.1077 - val_loss: 24.7124

Epoch 00175: val_loss did not improve from 24.34527
Epoch 176/10000
4/4 - 0s - loss: 18.1367 - val_loss: 24.5481

Epoch 00176: val_loss did not improve from 24.34527
Epoch 177/10000
4/4 - 0s - loss: 18.1252 - val_loss: 24.4740

Epoch 00177: val_loss did not improve from 24.34527
Epoch 178/10000
4/4 - 0s - loss: 18.1053 - val_loss: 24.5706

Epoch 00178: val_loss did not improve from 24.34527
Epoch 179/10000
4/4 - 0s - loss: 18.0974 - val_loss: 24.5532

Epoch 00179: val_loss did not improve from 24.34527
Epoch 180/10000
4/4 - 0s - loss: 18.1028 - val_loss: 24.4749

Epoch 00180: val_loss did not improve from 24.34527
Epoch 181/10000
4/4 - 0s - loss: 18.1155 - val_loss: 24.4984

Epoch 00181: val_loss did not improve from 24.34527
Epoch 182/10000
4/4 - 0s - loss: 18.1005 - val_loss: 24.5405

Epoch 00182: val_loss did not improve from 24.34527
Epoch 183/10000
4/4 - 0s - loss: 18.0969 - val_loss: 24.4999

Epoch 00183: val_loss did not improve from 24.34527
Epoch 184/10000
4/4 - 0s - loss: 18.0929 - val_loss: 24.4655

Epoch 00184: val_loss did not improve from 24.34527
Epoch 185/10000
4/4 - 0s - loss: 18.1018 - val_loss: 24.4658

Epoch 00185: val_loss did not improve from 24.34527
Epoch 186/10000
4/4 - 0s - loss: 18.1128 - val_loss: 24.5090

Epoch 00186: val_loss did not improve from 24.34527
Epoch 187/10000
4/4 - 0s - loss: 18.1025 - val_loss: 24.5100

Epoch 00187: val_loss did not improve from 24.34527
Epoch 188/10000
4/4 - 0s - loss: 18.1171 - val_loss: 24.6191

Epoch 00188: val_loss did not improve from 24.34527
Epoch 189/10000
4/4 - 0s - loss: 18.0981 - val_loss: 24.5020

Epoch 00189: val_loss did not improve from 24.34527
Epoch 190/10000
4/4 - 0s - loss: 18.1316 - val_loss: 24.4059

Epoch 00190: val_loss did not improve from 24.34527
Epoch 191/10000
4/4 - 0s - loss: 18.0979 - val_loss: 24.5257

Epoch 00191: val_loss did not improve from 24.34527
Epoch 192/10000
4/4 - 0s - loss: 18.1480 - val_loss: 24.7373

Epoch 00192: val_loss did not improve from 24.34527
Epoch 193/10000
4/4 - 0s - loss: 18.1214 - val_loss: 24.5094

Epoch 00193: val_loss did not improve from 24.34527
Epoch 194/10000
4/4 - 0s - loss: 18.0789 - val_loss: 24.4290

Epoch 00194: val_loss did not improve from 24.34527
Epoch 195/10000
4/4 - 0s - loss: 18.1822 - val_loss: 24.4199

Epoch 00195: val_loss did not improve from 24.34527
Epoch 196/10000
4/4 - 0s - loss: 18.0633 - val_loss: 24.6352

Epoch 00196: val_loss did not improve from 24.34527
Epoch 197/10000
4/4 - 0s - loss: 18.1356 - val_loss: 24.7484

Epoch 00197: val_loss did not improve from 24.34527
Epoch 198/10000
4/4 - 0s - loss: 18.1394 - val_loss: 24.5414

Epoch 00198: val_loss did not improve from 24.34527
Epoch 199/10000
4/4 - 0s - loss: 18.0728 - val_loss: 24.4207

Epoch 00199: val_loss did not improve from 24.34527
Epoch 200/10000
4/4 - 0s - loss: 18.1582 - val_loss: 24.4002

Epoch 00200: val_loss did not improve from 24.34527
Epoch 201/10000
4/4 - 0s - loss: 18.0984 - val_loss: 24.6321

Epoch 00201: val_loss did not improve from 24.34527
Epoch 202/10000
4/4 - 0s - loss: 18.1443 - val_loss: 24.6917

Epoch 00202: val_loss did not improve from 24.34527
Epoch 203/10000
4/4 - 0s - loss: 18.1173 - val_loss: 24.5192

Epoch 00203: val_loss did not improve from 24.34527
Epoch 204/10000
4/4 - 0s - loss: 18.1308 - val_loss: 24.4365

Epoch 00204: val_loss did not improve from 24.34527
Epoch 205/10000
4/4 - 0s - loss: 18.0867 - val_loss: 24.5783

Epoch 00205: val_loss did not improve from 24.34527
Epoch 206/10000
4/4 - 0s - loss: 18.1093 - val_loss: 24.6868

Epoch 00206: val_loss did not improve from 24.34527
Epoch 207/10000
4/4 - 0s - loss: 18.1081 - val_loss: 24.5239

Epoch 00207: val_loss did not improve from 24.34527
Epoch 208/10000
4/4 - 0s - loss: 18.1003 - val_loss: 24.4382

Epoch 00208: val_loss did not improve from 24.34527
Epoch 209/10000
4/4 - 0s - loss: 18.1055 - val_loss: 24.5137

Epoch 00209: val_loss did not improve from 24.34527
Epoch 210/10000
4/4 - 0s - loss: 18.1053 - val_loss: 24.6051

Epoch 00210: val_loss did not improve from 24.34527
Epoch 211/10000
4/4 - 0s - loss: 18.0936 - val_loss: 24.4990

Epoch 00211: val_loss did not improve from 24.34527
Epoch 212/10000
4/4 - 0s - loss: 18.0875 - val_loss: 24.4649

Epoch 00212: val_loss did not improve from 24.34527
Epoch 213/10000
4/4 - 0s - loss: 18.0944 - val_loss: 24.4991

Epoch 00213: val_loss did not improve from 24.34527
Epoch 214/10000
4/4 - 0s - loss: 18.0897 - val_loss: 24.5072

Epoch 00214: val_loss did not improve from 24.34527
Epoch 215/10000
4/4 - 0s - loss: 18.0871 - val_loss: 24.4658

Epoch 00215: val_loss did not improve from 24.34527
Epoch 216/10000
4/4 - 0s - loss: 18.1039 - val_loss: 24.4853

Epoch 00216: val_loss did not improve from 24.34527
Epoch 217/10000
4/4 - 0s - loss: 18.0869 - val_loss: 24.6616

Epoch 00217: val_loss did not improve from 24.34527
Epoch 218/10000
4/4 - 0s - loss: 18.1079 - val_loss: 24.5836

Epoch 00218: val_loss did not improve from 24.34527
Epoch 219/10000
4/4 - 0s - loss: 18.1055 - val_loss: 24.5061

Epoch 00219: val_loss did not improve from 24.34527
Epoch 220/10000
4/4 - 0s - loss: 18.0959 - val_loss: 24.5690

Epoch 00220: val_loss did not improve from 24.34527
Epoch 221/10000
4/4 - 0s - loss: 18.0944 - val_loss: 24.5265

Epoch 00221: val_loss did not improve from 24.34527
Epoch 222/10000
4/4 - 0s - loss: 18.0801 - val_loss: 24.4170

Epoch 00222: val_loss did not improve from 24.34527
Epoch 223/10000
4/4 - 0s - loss: 18.1905 - val_loss: 24.3925

Epoch 00223: val_loss did not improve from 24.34527
Epoch 224/10000
4/4 - 0s - loss: 18.0772 - val_loss: 24.7101

Epoch 00224: val_loss did not improve from 24.34527
Epoch 225/10000
4/4 - 0s - loss: 18.1717 - val_loss: 24.7279

Epoch 00225: val_loss did not improve from 24.34527
Epoch 226/10000
4/4 - 0s - loss: 18.1450 - val_loss: 24.4536

Epoch 00226: val_loss did not improve from 24.34527
Epoch 227/10000
4/4 - 0s - loss: 18.0951 - val_loss: 24.4754

Epoch 00227: val_loss did not improve from 24.34527
Epoch 228/10000
4/4 - 0s - loss: 18.0964 - val_loss: 24.5320

Epoch 00228: val_loss did not improve from 24.34527
Epoch 229/10000
4/4 - 0s - loss: 18.0899 - val_loss: 24.6726

Epoch 00229: val_loss did not improve from 24.34527
Epoch 230/10000
4/4 - 0s - loss: 18.1144 - val_loss: 24.6140

Epoch 00230: val_loss did not improve from 24.34527
Epoch 231/10000
4/4 - 0s - loss: 18.1230 - val_loss: 24.4625

Epoch 00231: val_loss did not improve from 24.34527
Epoch 232/10000
4/4 - 0s - loss: 18.0917 - val_loss: 24.5489

Epoch 00232: val_loss did not improve from 24.34527
Epoch 233/10000
4/4 - 0s - loss: 18.0959 - val_loss: 24.6442

Epoch 00233: val_loss did not improve from 24.34527
Epoch 234/10000
4/4 - 0s - loss: 18.0962 - val_loss: 24.6006

Epoch 00234: val_loss did not improve from 24.34527
Epoch 235/10000
4/4 - 0s - loss: 18.0844 - val_loss: 24.5052

Epoch 00235: val_loss did not improve from 24.34527
Epoch 236/10000
4/4 - 0s - loss: 18.1147 - val_loss: 24.4640

Epoch 00236: val_loss did not improve from 24.34527
Epoch 237/10000
4/4 - 0s - loss: 18.1147 - val_loss: 24.6539

Epoch 00237: val_loss did not improve from 24.34527
Epoch 238/10000
4/4 - 0s - loss: 18.0981 - val_loss: 24.5359

Epoch 00238: val_loss did not improve from 24.34527
Epoch 239/10000
4/4 - 0s - loss: 18.1009 - val_loss: 24.4926

Epoch 00239: val_loss did not improve from 24.34527
Epoch 240/10000
4/4 - 0s - loss: 18.0872 - val_loss: 24.5453

Epoch 00240: val_loss did not improve from 24.34527
Epoch 241/10000
4/4 - 0s - loss: 18.1092 - val_loss: 24.6317

Epoch 00241: val_loss did not improve from 24.34527
Epoch 242/10000
4/4 - 0s - loss: 18.0996 - val_loss: 24.4859

Epoch 00242: val_loss did not improve from 24.34527
Epoch 243/10000
4/4 - 0s - loss: 18.0897 - val_loss: 24.5188

Epoch 00243: val_loss did not improve from 24.34527
Epoch 244/10000
4/4 - 0s - loss: 18.0824 - val_loss: 24.5110

Epoch 00244: val_loss did not improve from 24.34527
Epoch 245/10000
4/4 - 0s - loss: 18.1120 - val_loss: 24.4892

Epoch 00245: val_loss did not improve from 24.34527
Epoch 246/10000
4/4 - 0s - loss: 18.0846 - val_loss: 24.5554

Epoch 00246: val_loss did not improve from 24.34527
Epoch 247/10000
4/4 - 0s - loss: 18.1033 - val_loss: 24.6235

Epoch 00247: val_loss did not improve from 24.34527
Epoch 248/10000
4/4 - 0s - loss: 18.0940 - val_loss: 24.5284

Epoch 00248: val_loss did not improve from 24.34527
Epoch 249/10000
4/4 - 0s - loss: 18.0895 - val_loss: 24.5405

Epoch 00249: val_loss did not improve from 24.34527
Epoch 250/10000
4/4 - 0s - loss: 18.0857 - val_loss: 24.4696

Epoch 00250: val_loss did not improve from 24.34527
Epoch 251/10000
4/4 - 0s - loss: 18.0848 - val_loss: 24.5076

Epoch 00251: val_loss did not improve from 24.34527
Epoch 252/10000
4/4 - 0s - loss: 18.0872 - val_loss: 24.5703

Epoch 00252: val_loss did not improve from 24.34527
Epoch 253/10000
4/4 - 0s - loss: 18.1137 - val_loss: 24.4784

Epoch 00253: val_loss did not improve from 24.34527
Epoch 254/10000
4/4 - 0s - loss: 18.0847 - val_loss: 24.5946

Epoch 00254: val_loss did not improve from 24.34527
Epoch 255/10000
4/4 - 0s - loss: 18.0879 - val_loss: 24.5863

Epoch 00255: val_loss did not improve from 24.34527
Epoch 256/10000
4/4 - 0s - loss: 18.0871 - val_loss: 24.5827

Epoch 00256: val_loss did not improve from 24.34527
Epoch 257/10000
4/4 - 0s - loss: 18.0866 - val_loss: 24.5491

Epoch 00257: val_loss did not improve from 24.34527
Epoch 258/10000
4/4 - 0s - loss: 18.0858 - val_loss: 24.4972

Epoch 00258: val_loss did not improve from 24.34527
Epoch 259/10000
4/4 - 0s - loss: 18.1388 - val_loss: 24.4656

Epoch 00259: val_loss did not improve from 24.34527
Epoch 260/10000
4/4 - 0s - loss: 18.1170 - val_loss: 24.7182

Epoch 00260: val_loss did not improve from 24.34527
Epoch 261/10000
4/4 - 0s - loss: 18.1248 - val_loss: 24.5319

Epoch 00261: val_loss did not improve from 24.34527
Epoch 262/10000
4/4 - 0s - loss: 18.1196 - val_loss: 24.4341

Epoch 00262: val_loss did not improve from 24.34527
Epoch 263/10000
4/4 - 0s - loss: 18.0875 - val_loss: 24.5420

Epoch 00263: val_loss did not improve from 24.34527
Epoch 264/10000
4/4 - 0s - loss: 18.0831 - val_loss: 24.5861

Epoch 00264: val_loss did not improve from 24.34527
Epoch 265/10000
4/4 - 0s - loss: 18.1184 - val_loss: 24.5833

Epoch 00265: val_loss did not improve from 24.34527
Epoch 00265: early stopping
*************************** Fold #: 3 ***************************
Model: "sequential_42"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_462 (Dense)            (None, 30)                210       
_________________________________________________________________
dense_463 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_464 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_465 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_466 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_467 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_468 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_469 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_470 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_471 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_472 (Dense)            (None, 1)                 31        
=================================================================
Total params: 8,611
Trainable params: 8,611
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
4/4 - 0s - loss: 29.5523 - val_loss: 47.2185

Epoch 00001: val_loss improved from inf to 47.21853, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 2/10000
4/4 - 0s - loss: 29.5227 - val_loss: 47.1819

Epoch 00002: val_loss improved from 47.21853 to 47.18188, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 3/10000
4/4 - 0s - loss: 29.4918 - val_loss: 47.1421

Epoch 00003: val_loss improved from 47.18188 to 47.14209, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 4/10000
4/4 - 0s - loss: 29.4572 - val_loss: 47.0987

Epoch 00004: val_loss improved from 47.14209 to 47.09865, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 5/10000
4/4 - 0s - loss: 29.4204 - val_loss: 47.0507

Epoch 00005: val_loss improved from 47.09865 to 47.05071, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 6/10000
4/4 - 0s - loss: 29.3788 - val_loss: 46.9977

Epoch 00006: val_loss improved from 47.05071 to 46.99768, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 7/10000
4/4 - 0s - loss: 29.3329 - val_loss: 46.9385

Epoch 00007: val_loss improved from 46.99768 to 46.93846, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 8/10000
4/4 - 0s - loss: 29.2821 - val_loss: 46.8717

Epoch 00008: val_loss improved from 46.93846 to 46.87171, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 9/10000
4/4 - 0s - loss: 29.2232 - val_loss: 46.7959

Epoch 00009: val_loss improved from 46.87171 to 46.79591, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 10/10000
4/4 - 0s - loss: 29.1576 - val_loss: 46.7084

Epoch 00010: val_loss improved from 46.79591 to 46.70844, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 11/10000
4/4 - 0s - loss: 29.0810 - val_loss: 46.6062

Epoch 00011: val_loss improved from 46.70844 to 46.60622, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 12/10000
4/4 - 0s - loss: 28.9900 - val_loss: 46.4843

Epoch 00012: val_loss improved from 46.60622 to 46.48431, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 13/10000
4/4 - 0s - loss: 28.8839 - val_loss: 46.3349

Epoch 00013: val_loss improved from 46.48431 to 46.33493, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 14/10000
4/4 - 0s - loss: 28.7511 - val_loss: 46.1473

Epoch 00014: val_loss improved from 46.33493 to 46.14729, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 15/10000
4/4 - 0s - loss: 28.5813 - val_loss: 45.9031

Epoch 00015: val_loss improved from 46.14729 to 45.90306, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 16/10000
4/4 - 0s - loss: 28.3594 - val_loss: 45.5686

Epoch 00016: val_loss improved from 45.90306 to 45.56857, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 17/10000
4/4 - 0s - loss: 28.0506 - val_loss: 45.0909

Epoch 00017: val_loss improved from 45.56857 to 45.09087, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 18/10000
4/4 - 0s - loss: 27.5985 - val_loss: 44.3752

Epoch 00018: val_loss improved from 45.09087 to 44.37523, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 19/10000
4/4 - 0s - loss: 26.9206 - val_loss: 43.2488

Epoch 00019: val_loss improved from 44.37523 to 43.24876, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 20/10000
4/4 - 0s - loss: 25.8596 - val_loss: 41.4343

Epoch 00020: val_loss improved from 43.24876 to 41.43431, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 21/10000
4/4 - 0s - loss: 24.2170 - val_loss: 38.7252

Epoch 00021: val_loss improved from 41.43431 to 38.72523, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 22/10000
4/4 - 0s - loss: 22.2218 - val_loss: 36.3875

Epoch 00022: val_loss improved from 38.72523 to 36.38745, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 23/10000
4/4 - 0s - loss: 22.1750 - val_loss: 36.2228

Epoch 00023: val_loss improved from 36.38745 to 36.22277, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 24/10000
4/4 - 0s - loss: 21.9373 - val_loss: 36.1271

Epoch 00024: val_loss improved from 36.22277 to 36.12708, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 25/10000
4/4 - 0s - loss: 21.4720 - val_loss: 36.5446

Epoch 00025: val_loss did not improve from 36.12708
Epoch 26/10000
4/4 - 0s - loss: 21.5147 - val_loss: 36.3976

Epoch 00026: val_loss did not improve from 36.12708
Epoch 27/10000
4/4 - 0s - loss: 21.3488 - val_loss: 35.7629

Epoch 00027: val_loss improved from 36.12708 to 35.76294, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 28/10000
4/4 - 0s - loss: 21.0994 - val_loss: 35.2382

Epoch 00028: val_loss improved from 35.76294 to 35.23822, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 29/10000
4/4 - 0s - loss: 20.9900 - val_loss: 34.9763

Epoch 00029: val_loss improved from 35.23822 to 34.97634, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 30/10000
4/4 - 0s - loss: 20.8687 - val_loss: 34.8596

Epoch 00030: val_loss improved from 34.97634 to 34.85962, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 31/10000
4/4 - 0s - loss: 20.6874 - val_loss: 34.7854

Epoch 00031: val_loss improved from 34.85962 to 34.78536, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 32/10000
4/4 - 0s - loss: 20.5430 - val_loss: 34.5817

Epoch 00032: val_loss improved from 34.78536 to 34.58171, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 33/10000
4/4 - 0s - loss: 20.3771 - val_loss: 34.2496

Epoch 00033: val_loss improved from 34.58171 to 34.24958, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 34/10000
4/4 - 0s - loss: 20.1941 - val_loss: 33.8002

Epoch 00034: val_loss improved from 34.24958 to 33.80017, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 35/10000
4/4 - 0s - loss: 20.0511 - val_loss: 33.4696

Epoch 00035: val_loss improved from 33.80017 to 33.46960, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 36/10000
4/4 - 0s - loss: 19.8419 - val_loss: 33.3603

Epoch 00036: val_loss improved from 33.46960 to 33.36032, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 37/10000
4/4 - 0s - loss: 19.6634 - val_loss: 33.1188

Epoch 00037: val_loss improved from 33.36032 to 33.11885, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 38/10000
4/4 - 0s - loss: 19.4970 - val_loss: 32.7978

Epoch 00038: val_loss improved from 33.11885 to 32.79784, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 39/10000
4/4 - 0s - loss: 19.3504 - val_loss: 32.4424

Epoch 00039: val_loss improved from 32.79784 to 32.44240, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 40/10000
4/4 - 0s - loss: 19.2102 - val_loss: 32.2515

Epoch 00040: val_loss improved from 32.44240 to 32.25151, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 41/10000
4/4 - 0s - loss: 19.0665 - val_loss: 32.2045

Epoch 00041: val_loss improved from 32.25151 to 32.20454, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 42/10000
4/4 - 0s - loss: 19.0006 - val_loss: 32.0864

Epoch 00042: val_loss improved from 32.20454 to 32.08635, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 43/10000
4/4 - 0s - loss: 18.8516 - val_loss: 31.6803

Epoch 00043: val_loss improved from 32.08635 to 31.68033, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 44/10000
4/4 - 0s - loss: 18.7959 - val_loss: 31.3592

Epoch 00044: val_loss improved from 31.68033 to 31.35917, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 45/10000
4/4 - 0s - loss: 18.6781 - val_loss: 31.3774

Epoch 00045: val_loss did not improve from 31.35917
Epoch 46/10000
4/4 - 0s - loss: 18.5607 - val_loss: 31.3747

Epoch 00046: val_loss did not improve from 31.35917
Epoch 47/10000
4/4 - 0s - loss: 18.4915 - val_loss: 31.1089

Epoch 00047: val_loss improved from 31.35917 to 31.10892, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 48/10000
4/4 - 0s - loss: 18.4039 - val_loss: 30.7505

Epoch 00048: val_loss improved from 31.10892 to 30.75048, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 49/10000
4/4 - 0s - loss: 18.3039 - val_loss: 30.6928

Epoch 00049: val_loss improved from 30.75048 to 30.69285, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 50/10000
4/4 - 0s - loss: 18.2052 - val_loss: 30.7204

Epoch 00050: val_loss did not improve from 30.69285
Epoch 51/10000
4/4 - 0s - loss: 18.1526 - val_loss: 30.5092

Epoch 00051: val_loss improved from 30.69285 to 30.50923, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 52/10000
4/4 - 0s - loss: 18.0610 - val_loss: 30.2850

Epoch 00052: val_loss improved from 30.50923 to 30.28495, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 53/10000
4/4 - 0s - loss: 18.0260 - val_loss: 30.1570

Epoch 00053: val_loss improved from 30.28495 to 30.15701, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 54/10000
4/4 - 0s - loss: 17.9445 - val_loss: 30.1840

Epoch 00054: val_loss did not improve from 30.15701
Epoch 55/10000
4/4 - 0s - loss: 17.9030 - val_loss: 30.0938

Epoch 00055: val_loss improved from 30.15701 to 30.09381, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 56/10000
4/4 - 0s - loss: 17.8606 - val_loss: 30.0197

Epoch 00056: val_loss improved from 30.09381 to 30.01965, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 57/10000
4/4 - 0s - loss: 17.8414 - val_loss: 29.8015

Epoch 00057: val_loss improved from 30.01965 to 29.80149, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 58/10000
4/4 - 0s - loss: 17.8093 - val_loss: 29.8775

Epoch 00058: val_loss did not improve from 29.80149
Epoch 59/10000
4/4 - 0s - loss: 17.7963 - val_loss: 29.7612

Epoch 00059: val_loss improved from 29.80149 to 29.76120, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 60/10000
4/4 - 0s - loss: 17.7587 - val_loss: 29.8182

Epoch 00060: val_loss did not improve from 29.76120
Epoch 61/10000
4/4 - 0s - loss: 17.7518 - val_loss: 29.7434

Epoch 00061: val_loss improved from 29.76120 to 29.74344, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 62/10000
4/4 - 0s - loss: 17.7440 - val_loss: 29.7331

Epoch 00062: val_loss improved from 29.74344 to 29.73310, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 63/10000
4/4 - 0s - loss: 17.7548 - val_loss: 29.8808

Epoch 00063: val_loss did not improve from 29.73310
Epoch 64/10000
4/4 - 0s - loss: 17.7150 - val_loss: 29.6058

Epoch 00064: val_loss improved from 29.73310 to 29.60580, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 65/10000
4/4 - 0s - loss: 17.7080 - val_loss: 29.5207

Epoch 00065: val_loss improved from 29.60580 to 29.52066, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 66/10000
4/4 - 0s - loss: 17.6972 - val_loss: 29.5700

Epoch 00066: val_loss did not improve from 29.52066
Epoch 67/10000
4/4 - 0s - loss: 17.6676 - val_loss: 29.6594

Epoch 00067: val_loss did not improve from 29.52066
Epoch 68/10000
4/4 - 0s - loss: 17.6928 - val_loss: 29.6923

Epoch 00068: val_loss did not improve from 29.52066
Epoch 69/10000
4/4 - 0s - loss: 17.6860 - val_loss: 29.5815

Epoch 00069: val_loss did not improve from 29.52066
Epoch 70/10000
4/4 - 0s - loss: 17.6685 - val_loss: 29.4221

Epoch 00070: val_loss improved from 29.52066 to 29.42208, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 71/10000
4/4 - 0s - loss: 17.7433 - val_loss: 29.6175

Epoch 00071: val_loss did not improve from 29.42208
Epoch 72/10000
4/4 - 0s - loss: 17.6629 - val_loss: 29.4614

Epoch 00072: val_loss did not improve from 29.42208
Epoch 73/10000
4/4 - 0s - loss: 17.6375 - val_loss: 29.5467

Epoch 00073: val_loss did not improve from 29.42208
Epoch 74/10000
4/4 - 0s - loss: 17.6364 - val_loss: 29.5698

Epoch 00074: val_loss did not improve from 29.42208
Epoch 75/10000
4/4 - 0s - loss: 17.6364 - val_loss: 29.5233

Epoch 00075: val_loss did not improve from 29.42208
Epoch 76/10000
4/4 - 0s - loss: 17.6363 - val_loss: 29.4789

Epoch 00076: val_loss did not improve from 29.42208
Epoch 77/10000
4/4 - 0s - loss: 17.6318 - val_loss: 29.4368

Epoch 00077: val_loss did not improve from 29.42208
Epoch 78/10000
4/4 - 0s - loss: 17.6244 - val_loss: 29.5457

Epoch 00078: val_loss did not improve from 29.42208
Epoch 79/10000
4/4 - 0s - loss: 17.6314 - val_loss: 29.4923

Epoch 00079: val_loss did not improve from 29.42208
Epoch 80/10000
4/4 - 0s - loss: 17.6553 - val_loss: 29.3652

Epoch 00080: val_loss improved from 29.42208 to 29.36524, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 81/10000
4/4 - 0s - loss: 17.6210 - val_loss: 29.5060

Epoch 00081: val_loss did not improve from 29.36524
Epoch 82/10000
4/4 - 0s - loss: 17.6560 - val_loss: 29.6349

Epoch 00082: val_loss did not improve from 29.36524
Epoch 83/10000
4/4 - 0s - loss: 17.6365 - val_loss: 29.4264

Epoch 00083: val_loss did not improve from 29.36524
Epoch 84/10000
4/4 - 0s - loss: 17.6155 - val_loss: 29.4290

Epoch 00084: val_loss did not improve from 29.36524
Epoch 85/10000
4/4 - 0s - loss: 17.6185 - val_loss: 29.3882

Epoch 00085: val_loss did not improve from 29.36524
Epoch 86/10000
4/4 - 0s - loss: 17.6131 - val_loss: 29.4647

Epoch 00086: val_loss did not improve from 29.36524
Epoch 87/10000
4/4 - 0s - loss: 17.6087 - val_loss: 29.5747

Epoch 00087: val_loss did not improve from 29.36524
Epoch 88/10000
4/4 - 0s - loss: 17.6188 - val_loss: 29.5263

Epoch 00088: val_loss did not improve from 29.36524
Epoch 89/10000
4/4 - 0s - loss: 17.6062 - val_loss: 29.4223

Epoch 00089: val_loss did not improve from 29.36524
Epoch 90/10000
4/4 - 0s - loss: 17.6107 - val_loss: 29.3979

Epoch 00090: val_loss did not improve from 29.36524
Epoch 91/10000
4/4 - 0s - loss: 17.5965 - val_loss: 29.5144

Epoch 00091: val_loss did not improve from 29.36524
Epoch 92/10000
4/4 - 0s - loss: 17.6148 - val_loss: 29.5475

Epoch 00092: val_loss did not improve from 29.36524
Epoch 93/10000
4/4 - 0s - loss: 17.6397 - val_loss: 29.3987

Epoch 00093: val_loss did not improve from 29.36524
Epoch 94/10000
4/4 - 0s - loss: 17.6125 - val_loss: 29.5705

Epoch 00094: val_loss did not improve from 29.36524
Epoch 95/10000
4/4 - 0s - loss: 17.6283 - val_loss: 29.5914

Epoch 00095: val_loss did not improve from 29.36524
Epoch 96/10000
4/4 - 0s - loss: 17.6333 - val_loss: 29.5386

Epoch 00096: val_loss did not improve from 29.36524
Epoch 97/10000
4/4 - 0s - loss: 17.5933 - val_loss: 29.3843

Epoch 00097: val_loss did not improve from 29.36524
Epoch 98/10000
4/4 - 0s - loss: 17.6115 - val_loss: 29.3702

Epoch 00098: val_loss did not improve from 29.36524
Epoch 99/10000
4/4 - 0s - loss: 17.6403 - val_loss: 29.3723

Epoch 00099: val_loss did not improve from 29.36524
Epoch 100/10000
4/4 - 0s - loss: 17.5849 - val_loss: 29.5830

Epoch 00100: val_loss did not improve from 29.36524
Epoch 101/10000
4/4 - 0s - loss: 17.6350 - val_loss: 29.6347

Epoch 00101: val_loss did not improve from 29.36524
Epoch 102/10000
4/4 - 0s - loss: 17.6337 - val_loss: 29.3538

Epoch 00102: val_loss improved from 29.36524 to 29.35382, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 103/10000
4/4 - 0s - loss: 17.6133 - val_loss: 29.3827

Epoch 00103: val_loss did not improve from 29.35382
Epoch 104/10000
4/4 - 0s - loss: 17.6606 - val_loss: 29.6256

Epoch 00104: val_loss did not improve from 29.35382
Epoch 105/10000
4/4 - 0s - loss: 17.6132 - val_loss: 29.3946

Epoch 00105: val_loss did not improve from 29.35382
Epoch 106/10000
4/4 - 0s - loss: 17.6042 - val_loss: 29.4228

Epoch 00106: val_loss did not improve from 29.35382
Epoch 107/10000
4/4 - 0s - loss: 17.6023 - val_loss: 29.5267

Epoch 00107: val_loss did not improve from 29.35382
Epoch 108/10000
4/4 - 0s - loss: 17.5980 - val_loss: 29.4024

Epoch 00108: val_loss did not improve from 29.35382
Epoch 109/10000
4/4 - 0s - loss: 17.5908 - val_loss: 29.4215

Epoch 00109: val_loss did not improve from 29.35382
Epoch 110/10000
4/4 - 0s - loss: 17.5929 - val_loss: 29.5406

Epoch 00110: val_loss did not improve from 29.35382
Epoch 111/10000
4/4 - 0s - loss: 17.6032 - val_loss: 29.4745

Epoch 00111: val_loss did not improve from 29.35382
Epoch 112/10000
4/4 - 0s - loss: 17.5926 - val_loss: 29.3887

Epoch 00112: val_loss did not improve from 29.35382
Epoch 113/10000
4/4 - 0s - loss: 17.6223 - val_loss: 29.3583

Epoch 00113: val_loss did not improve from 29.35382
Epoch 114/10000
4/4 - 0s - loss: 17.5828 - val_loss: 29.5327

Epoch 00114: val_loss did not improve from 29.35382
Epoch 115/10000
4/4 - 0s - loss: 17.5956 - val_loss: 29.5640

Epoch 00115: val_loss did not improve from 29.35382
Epoch 116/10000
4/4 - 0s - loss: 17.6102 - val_loss: 29.4933

Epoch 00116: val_loss did not improve from 29.35382
Epoch 117/10000
4/4 - 0s - loss: 17.5981 - val_loss: 29.2983

Epoch 00117: val_loss improved from 29.35382 to 29.29827, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 118/10000
4/4 - 0s - loss: 17.6423 - val_loss: 29.3655

Epoch 00118: val_loss did not improve from 29.29827
Epoch 119/10000
4/4 - 0s - loss: 17.5872 - val_loss: 29.6438

Epoch 00119: val_loss did not improve from 29.29827
Epoch 120/10000
4/4 - 0s - loss: 17.6149 - val_loss: 29.5763

Epoch 00120: val_loss did not improve from 29.29827
Epoch 121/10000
4/4 - 0s - loss: 17.5977 - val_loss: 29.3895

Epoch 00121: val_loss did not improve from 29.29827
Epoch 122/10000
4/4 - 0s - loss: 17.5850 - val_loss: 29.4113

Epoch 00122: val_loss did not improve from 29.29827
Epoch 123/10000
4/4 - 0s - loss: 17.5830 - val_loss: 29.4431

Epoch 00123: val_loss did not improve from 29.29827
Epoch 124/10000
4/4 - 0s - loss: 17.5794 - val_loss: 29.4424

Epoch 00124: val_loss did not improve from 29.29827
Epoch 125/10000
4/4 - 0s - loss: 17.5898 - val_loss: 29.4937

Epoch 00125: val_loss did not improve from 29.29827
Epoch 126/10000
4/4 - 0s - loss: 17.5687 - val_loss: 29.3827

Epoch 00126: val_loss did not improve from 29.29827
Epoch 127/10000
4/4 - 0s - loss: 17.6673 - val_loss: 29.3103

Epoch 00127: val_loss did not improve from 29.29827
Epoch 128/10000
4/4 - 0s - loss: 17.6007 - val_loss: 29.5885

Epoch 00128: val_loss did not improve from 29.29827
Epoch 129/10000
4/4 - 0s - loss: 17.5951 - val_loss: 29.6128

Epoch 00129: val_loss did not improve from 29.29827
Epoch 130/10000
4/4 - 0s - loss: 17.5853 - val_loss: 29.4452

Epoch 00130: val_loss did not improve from 29.29827
Epoch 131/10000
4/4 - 0s - loss: 17.5738 - val_loss: 29.3868

Epoch 00131: val_loss did not improve from 29.29827
Epoch 132/10000
4/4 - 0s - loss: 17.5926 - val_loss: 29.4249

Epoch 00132: val_loss did not improve from 29.29827
Epoch 133/10000
4/4 - 0s - loss: 17.5816 - val_loss: 29.4901

Epoch 00133: val_loss did not improve from 29.29827
Epoch 134/10000
4/4 - 0s - loss: 17.5814 - val_loss: 29.4542

Epoch 00134: val_loss did not improve from 29.29827
Epoch 135/10000
4/4 - 0s - loss: 17.5789 - val_loss: 29.4571

Epoch 00135: val_loss did not improve from 29.29827
Epoch 136/10000
4/4 - 0s - loss: 17.5826 - val_loss: 29.4143

Epoch 00136: val_loss did not improve from 29.29827
Epoch 137/10000
4/4 - 0s - loss: 17.5695 - val_loss: 29.5053

Epoch 00137: val_loss did not improve from 29.29827
Epoch 138/10000
4/4 - 0s - loss: 17.5777 - val_loss: 29.5032

Epoch 00138: val_loss did not improve from 29.29827
Epoch 139/10000
4/4 - 0s - loss: 17.5846 - val_loss: 29.3888

Epoch 00139: val_loss did not improve from 29.29827
Epoch 140/10000
4/4 - 0s - loss: 17.5779 - val_loss: 29.4211

Epoch 00140: val_loss did not improve from 29.29827
Epoch 141/10000
4/4 - 0s - loss: 17.5713 - val_loss: 29.5343

Epoch 00141: val_loss did not improve from 29.29827
Epoch 142/10000
4/4 - 0s - loss: 17.6447 - val_loss: 29.5957

Epoch 00142: val_loss did not improve from 29.29827
Epoch 143/10000
4/4 - 0s - loss: 17.5653 - val_loss: 29.3089

Epoch 00143: val_loss did not improve from 29.29827
Epoch 144/10000
4/4 - 0s - loss: 17.6735 - val_loss: 29.2869

Epoch 00144: val_loss improved from 29.29827 to 29.28687, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 145/10000
4/4 - 0s - loss: 17.5978 - val_loss: 29.5317

Epoch 00145: val_loss did not improve from 29.28687
Epoch 146/10000
4/4 - 0s - loss: 17.5895 - val_loss: 29.6336

Epoch 00146: val_loss did not improve from 29.28687
Epoch 147/10000
4/4 - 0s - loss: 17.5951 - val_loss: 29.5002

Epoch 00147: val_loss did not improve from 29.28687
Epoch 148/10000
4/4 - 0s - loss: 17.5616 - val_loss: 29.3752

Epoch 00148: val_loss did not improve from 29.28687
Epoch 149/10000
4/4 - 0s - loss: 17.5825 - val_loss: 29.4038

Epoch 00149: val_loss did not improve from 29.28687
Epoch 150/10000
4/4 - 0s - loss: 17.5577 - val_loss: 29.5512

Epoch 00150: val_loss did not improve from 29.28687
Epoch 151/10000
4/4 - 0s - loss: 17.5996 - val_loss: 29.6336

Epoch 00151: val_loss did not improve from 29.28687
Epoch 152/10000
4/4 - 0s - loss: 17.5894 - val_loss: 29.4905

Epoch 00152: val_loss did not improve from 29.28687
Epoch 153/10000
4/4 - 0s - loss: 17.5883 - val_loss: 29.4056

Epoch 00153: val_loss did not improve from 29.28687
Epoch 154/10000
4/4 - 0s - loss: 17.5719 - val_loss: 29.5007

Epoch 00154: val_loss did not improve from 29.28687
Epoch 155/10000
4/4 - 0s - loss: 17.5694 - val_loss: 29.4917

Epoch 00155: val_loss did not improve from 29.28687
Epoch 156/10000
4/4 - 0s - loss: 17.5617 - val_loss: 29.4214

Epoch 00156: val_loss did not improve from 29.28687
Epoch 157/10000
4/4 - 0s - loss: 17.5688 - val_loss: 29.4183

Epoch 00157: val_loss did not improve from 29.28687
Epoch 158/10000
4/4 - 0s - loss: 17.5634 - val_loss: 29.5119

Epoch 00158: val_loss did not improve from 29.28687
Epoch 159/10000
4/4 - 0s - loss: 17.5727 - val_loss: 29.4974

Epoch 00159: val_loss did not improve from 29.28687
Epoch 160/10000
4/4 - 0s - loss: 17.5725 - val_loss: 29.5442

Epoch 00160: val_loss did not improve from 29.28687
Epoch 161/10000
4/4 - 0s - loss: 17.5966 - val_loss: 29.4303

Epoch 00161: val_loss did not improve from 29.28687
Epoch 162/10000
4/4 - 0s - loss: 17.5613 - val_loss: 29.4720

Epoch 00162: val_loss did not improve from 29.28687
Epoch 163/10000
4/4 - 0s - loss: 17.5698 - val_loss: 29.5430

Epoch 00163: val_loss did not improve from 29.28687
Epoch 164/10000
4/4 - 0s - loss: 17.5706 - val_loss: 29.5653

Epoch 00164: val_loss did not improve from 29.28687
Epoch 165/10000
4/4 - 0s - loss: 17.5757 - val_loss: 29.4777

Epoch 00165: val_loss did not improve from 29.28687
Epoch 166/10000
4/4 - 0s - loss: 17.5665 - val_loss: 29.4840

Epoch 00166: val_loss did not improve from 29.28687
Epoch 167/10000
4/4 - 0s - loss: 17.5617 - val_loss: 29.5848

Epoch 00167: val_loss did not improve from 29.28687
Epoch 168/10000
4/4 - 0s - loss: 17.5715 - val_loss: 29.4910

Epoch 00168: val_loss did not improve from 29.28687
Epoch 169/10000
4/4 - 0s - loss: 17.5640 - val_loss: 29.3484

Epoch 00169: val_loss did not improve from 29.28687
Epoch 170/10000
4/4 - 0s - loss: 17.5854 - val_loss: 29.3505

Epoch 00170: val_loss did not improve from 29.28687
Epoch 171/10000
4/4 - 0s - loss: 17.5621 - val_loss: 29.4641

Epoch 00171: val_loss did not improve from 29.28687
Epoch 172/10000
4/4 - 0s - loss: 17.5707 - val_loss: 29.7012

Epoch 00172: val_loss did not improve from 29.28687
Epoch 173/10000
4/4 - 0s - loss: 17.6064 - val_loss: 29.5883

Epoch 00173: val_loss did not improve from 29.28687
Epoch 174/10000
4/4 - 0s - loss: 17.5647 - val_loss: 29.4420

Epoch 00174: val_loss did not improve from 29.28687
Epoch 175/10000
4/4 - 0s - loss: 17.5928 - val_loss: 29.4014

Epoch 00175: val_loss did not improve from 29.28687
Epoch 176/10000
4/4 - 0s - loss: 17.5655 - val_loss: 29.5524

Epoch 00176: val_loss did not improve from 29.28687
Epoch 177/10000
4/4 - 0s - loss: 17.5707 - val_loss: 29.5987

Epoch 00177: val_loss did not improve from 29.28687
Epoch 178/10000
4/4 - 0s - loss: 17.5701 - val_loss: 29.4687

Epoch 00178: val_loss did not improve from 29.28687
Epoch 179/10000
4/4 - 0s - loss: 17.5609 - val_loss: 29.3121

Epoch 00179: val_loss did not improve from 29.28687
Epoch 180/10000
4/4 - 0s - loss: 17.5954 - val_loss: 29.3585

Epoch 00180: val_loss did not improve from 29.28687
Epoch 181/10000
4/4 - 0s - loss: 17.5625 - val_loss: 29.4358

Epoch 00181: val_loss did not improve from 29.28687
Epoch 182/10000
4/4 - 0s - loss: 17.5607 - val_loss: 29.4828

Epoch 00182: val_loss did not improve from 29.28687
Epoch 183/10000
4/4 - 0s - loss: 17.5612 - val_loss: 29.4957

Epoch 00183: val_loss did not improve from 29.28687
Epoch 184/10000
4/4 - 0s - loss: 17.5637 - val_loss: 29.4365

Epoch 00184: val_loss did not improve from 29.28687
Epoch 185/10000
4/4 - 0s - loss: 17.5599 - val_loss: 29.4627

Epoch 00185: val_loss did not improve from 29.28687
Epoch 186/10000
4/4 - 0s - loss: 17.5775 - val_loss: 29.5905

Epoch 00186: val_loss did not improve from 29.28687
Epoch 187/10000
4/4 - 0s - loss: 17.5862 - val_loss: 29.5326

Epoch 00187: val_loss did not improve from 29.28687
Epoch 188/10000
4/4 - 0s - loss: 17.5499 - val_loss: 29.3688

Epoch 00188: val_loss did not improve from 29.28687
Epoch 189/10000
4/4 - 0s - loss: 17.5780 - val_loss: 29.3683

Epoch 00189: val_loss did not improve from 29.28687
Epoch 190/10000
4/4 - 0s - loss: 17.5739 - val_loss: 29.3894

Epoch 00190: val_loss did not improve from 29.28687
Epoch 191/10000
4/4 - 0s - loss: 17.5648 - val_loss: 29.5586

Epoch 00191: val_loss did not improve from 29.28687
Epoch 192/10000
4/4 - 0s - loss: 17.5713 - val_loss: 29.4664

Epoch 00192: val_loss did not improve from 29.28687
Epoch 193/10000
4/4 - 0s - loss: 17.5690 - val_loss: 29.3239

Epoch 00193: val_loss did not improve from 29.28687
Epoch 194/10000
4/4 - 0s - loss: 17.5791 - val_loss: 29.4401

Epoch 00194: val_loss did not improve from 29.28687
Epoch 195/10000
4/4 - 0s - loss: 17.5528 - val_loss: 29.5213

Epoch 00195: val_loss did not improve from 29.28687
Epoch 196/10000
4/4 - 0s - loss: 17.5639 - val_loss: 29.4934

Epoch 00196: val_loss did not improve from 29.28687
Epoch 197/10000
4/4 - 0s - loss: 17.5563 - val_loss: 29.4411

Epoch 00197: val_loss did not improve from 29.28687
Epoch 198/10000
4/4 - 0s - loss: 17.5549 - val_loss: 29.3839

Epoch 00198: val_loss did not improve from 29.28687
Epoch 199/10000
4/4 - 0s - loss: 17.5596 - val_loss: 29.3847

Epoch 00199: val_loss did not improve from 29.28687
Epoch 200/10000
4/4 - 0s - loss: 17.5585 - val_loss: 29.4134

Epoch 00200: val_loss did not improve from 29.28687
Epoch 201/10000
4/4 - 0s - loss: 17.5646 - val_loss: 29.3925

Epoch 00201: val_loss did not improve from 29.28687
Epoch 202/10000
4/4 - 0s - loss: 17.5616 - val_loss: 29.4902

Epoch 00202: val_loss did not improve from 29.28687
Epoch 203/10000
4/4 - 0s - loss: 17.5575 - val_loss: 29.4843

Epoch 00203: val_loss did not improve from 29.28687
Epoch 204/10000
4/4 - 0s - loss: 17.5609 - val_loss: 29.3925

Epoch 00204: val_loss did not improve from 29.28687
Epoch 205/10000
4/4 - 0s - loss: 17.5671 - val_loss: 29.4766

Epoch 00205: val_loss did not improve from 29.28687
Epoch 206/10000
4/4 - 0s - loss: 17.5548 - val_loss: 29.4775

Epoch 00206: val_loss did not improve from 29.28687
Epoch 207/10000
4/4 - 0s - loss: 17.6008 - val_loss: 29.4462

Epoch 00207: val_loss did not improve from 29.28687
Epoch 208/10000
4/4 - 0s - loss: 17.6048 - val_loss: 29.2788

Epoch 00208: val_loss improved from 29.28687 to 29.27878, saving model to ./results/dataset/trial_5/ckpt_3
Epoch 209/10000
4/4 - 0s - loss: 17.6246 - val_loss: 29.4267

Epoch 00209: val_loss did not improve from 29.27878
Epoch 210/10000
4/4 - 0s - loss: 17.5554 - val_loss: 29.5866

Epoch 00210: val_loss did not improve from 29.27878
Epoch 211/10000
4/4 - 0s - loss: 17.5770 - val_loss: 29.5101

Epoch 00211: val_loss did not improve from 29.27878
Epoch 212/10000
4/4 - 0s - loss: 17.5502 - val_loss: 29.4417

Epoch 00212: val_loss did not improve from 29.27878
Epoch 213/10000
4/4 - 0s - loss: 17.5577 - val_loss: 29.4258

Epoch 00213: val_loss did not improve from 29.27878
Epoch 214/10000
4/4 - 0s - loss: 17.5577 - val_loss: 29.4994

Epoch 00214: val_loss did not improve from 29.27878
Epoch 215/10000
4/4 - 0s - loss: 17.5537 - val_loss: 29.5618

Epoch 00215: val_loss did not improve from 29.27878
Epoch 216/10000
4/4 - 0s - loss: 17.5593 - val_loss: 29.4800

Epoch 00216: val_loss did not improve from 29.27878
Epoch 217/10000
4/4 - 0s - loss: 17.5532 - val_loss: 29.4439

Epoch 00217: val_loss did not improve from 29.27878
Epoch 218/10000
4/4 - 0s - loss: 17.5689 - val_loss: 29.5169

Epoch 00218: val_loss did not improve from 29.27878
Epoch 219/10000
4/4 - 0s - loss: 17.5889 - val_loss: 29.3913

Epoch 00219: val_loss did not improve from 29.27878
Epoch 220/10000
4/4 - 0s - loss: 17.5651 - val_loss: 29.4072

Epoch 00220: val_loss did not improve from 29.27878
Epoch 221/10000
4/4 - 0s - loss: 17.5530 - val_loss: 29.6076

Epoch 00221: val_loss did not improve from 29.27878
Epoch 222/10000
4/4 - 0s - loss: 17.5756 - val_loss: 29.5590

Epoch 00222: val_loss did not improve from 29.27878
Epoch 223/10000
4/4 - 0s - loss: 17.5557 - val_loss: 29.4788

Epoch 00223: val_loss did not improve from 29.27878
Epoch 224/10000
4/4 - 0s - loss: 17.5532 - val_loss: 29.4153

Epoch 00224: val_loss did not improve from 29.27878
Epoch 225/10000
4/4 - 0s - loss: 17.5601 - val_loss: 29.5200

Epoch 00225: val_loss did not improve from 29.27878
Epoch 226/10000
4/4 - 0s - loss: 17.5486 - val_loss: 29.5133

Epoch 00226: val_loss did not improve from 29.27878
Epoch 227/10000
4/4 - 0s - loss: 17.5480 - val_loss: 29.4641

Epoch 00227: val_loss did not improve from 29.27878
Epoch 228/10000
4/4 - 0s - loss: 17.5521 - val_loss: 29.4272

Epoch 00228: val_loss did not improve from 29.27878
Epoch 229/10000
4/4 - 0s - loss: 17.5479 - val_loss: 29.3525

Epoch 00229: val_loss did not improve from 29.27878
Epoch 230/10000
4/4 - 0s - loss: 17.5835 - val_loss: 29.3895

Epoch 00230: val_loss did not improve from 29.27878
Epoch 231/10000
4/4 - 0s - loss: 17.5293 - val_loss: 29.6173

Epoch 00231: val_loss did not improve from 29.27878
Epoch 232/10000
4/4 - 0s - loss: 17.5806 - val_loss: 29.5979

Epoch 00232: val_loss did not improve from 29.27878
Epoch 233/10000
4/4 - 0s - loss: 17.5684 - val_loss: 29.4095

Epoch 00233: val_loss did not improve from 29.27878
Epoch 234/10000
4/4 - 0s - loss: 17.5766 - val_loss: 29.4125

Epoch 00234: val_loss did not improve from 29.27878
Epoch 235/10000
4/4 - 0s - loss: 17.5597 - val_loss: 29.5465

Epoch 00235: val_loss did not improve from 29.27878
Epoch 236/10000
4/4 - 0s - loss: 17.5692 - val_loss: 29.4291

Epoch 00236: val_loss did not improve from 29.27878
Epoch 237/10000
4/4 - 0s - loss: 17.5455 - val_loss: 29.4463

Epoch 00237: val_loss did not improve from 29.27878
Epoch 238/10000
4/4 - 0s - loss: 17.5502 - val_loss: 29.4357

Epoch 00238: val_loss did not improve from 29.27878
Epoch 239/10000
4/4 - 0s - loss: 17.5471 - val_loss: 29.4766

Epoch 00239: val_loss did not improve from 29.27878
Epoch 240/10000
4/4 - 0s - loss: 17.5473 - val_loss: 29.4325

Epoch 00240: val_loss did not improve from 29.27878
Epoch 241/10000
4/4 - 0s - loss: 17.5466 - val_loss: 29.4849

Epoch 00241: val_loss did not improve from 29.27878
Epoch 242/10000
4/4 - 0s - loss: 17.5850 - val_loss: 29.4011

Epoch 00242: val_loss did not improve from 29.27878
Epoch 243/10000
4/4 - 0s - loss: 17.5475 - val_loss: 29.5211

Epoch 00243: val_loss did not improve from 29.27878
Epoch 244/10000
4/4 - 0s - loss: 17.5547 - val_loss: 29.4991

Epoch 00244: val_loss did not improve from 29.27878
Epoch 245/10000
4/4 - 0s - loss: 17.5473 - val_loss: 29.5170

Epoch 00245: val_loss did not improve from 29.27878
Epoch 246/10000
4/4 - 0s - loss: 17.5477 - val_loss: 29.5063

Epoch 00246: val_loss did not improve from 29.27878
Epoch 247/10000
4/4 - 0s - loss: 17.5605 - val_loss: 29.4819

Epoch 00247: val_loss did not improve from 29.27878
Epoch 248/10000
4/4 - 0s - loss: 17.5500 - val_loss: 29.3538

Epoch 00248: val_loss did not improve from 29.27878
Epoch 249/10000
4/4 - 0s - loss: 17.5672 - val_loss: 29.4166

Epoch 00249: val_loss did not improve from 29.27878
Epoch 250/10000
4/4 - 0s - loss: 17.5447 - val_loss: 29.4269

Epoch 00250: val_loss did not improve from 29.27878
Epoch 251/10000
4/4 - 0s - loss: 17.5430 - val_loss: 29.4726

Epoch 00251: val_loss did not improve from 29.27878
Epoch 252/10000
4/4 - 0s - loss: 17.5433 - val_loss: 29.4649

Epoch 00252: val_loss did not improve from 29.27878
Epoch 253/10000
4/4 - 0s - loss: 17.5444 - val_loss: 29.4148

Epoch 00253: val_loss did not improve from 29.27878
Epoch 254/10000
4/4 - 0s - loss: 17.5415 - val_loss: 29.4460

Epoch 00254: val_loss did not improve from 29.27878
Epoch 255/10000
4/4 - 0s - loss: 17.5598 - val_loss: 29.4964

Epoch 00255: val_loss did not improve from 29.27878
Epoch 256/10000
4/4 - 0s - loss: 17.5628 - val_loss: 29.4060

Epoch 00256: val_loss did not improve from 29.27878
Epoch 257/10000
4/4 - 0s - loss: 17.5481 - val_loss: 29.4238

Epoch 00257: val_loss did not improve from 29.27878
Epoch 258/10000
4/4 - 0s - loss: 17.5399 - val_loss: 29.4026

Epoch 00258: val_loss did not improve from 29.27878
Epoch 259/10000
4/4 - 0s - loss: 17.5440 - val_loss: 29.3910

Epoch 00259: val_loss did not improve from 29.27878
Epoch 260/10000
4/4 - 0s - loss: 17.5510 - val_loss: 29.4096

Epoch 00260: val_loss did not improve from 29.27878
Epoch 261/10000
4/4 - 0s - loss: 17.5386 - val_loss: 29.4411

Epoch 00261: val_loss did not improve from 29.27878
Epoch 262/10000
4/4 - 0s - loss: 17.5550 - val_loss: 29.4486

Epoch 00262: val_loss did not improve from 29.27878
Epoch 263/10000
4/4 - 0s - loss: 17.5531 - val_loss: 29.5955

Epoch 00263: val_loss did not improve from 29.27878
Epoch 264/10000
4/4 - 0s - loss: 17.5562 - val_loss: 29.4383

Epoch 00264: val_loss did not improve from 29.27878
Epoch 265/10000
4/4 - 0s - loss: 17.5544 - val_loss: 29.3676

Epoch 00265: val_loss did not improve from 29.27878
Epoch 266/10000
4/4 - 0s - loss: 17.5778 - val_loss: 29.4222

Epoch 00266: val_loss did not improve from 29.27878
Epoch 267/10000
4/4 - 0s - loss: 17.5409 - val_loss: 29.4072

Epoch 00267: val_loss did not improve from 29.27878
Epoch 268/10000
4/4 - 0s - loss: 17.5408 - val_loss: 29.4585

Epoch 00268: val_loss did not improve from 29.27878
Epoch 269/10000
4/4 - 0s - loss: 17.5388 - val_loss: 29.4433

Epoch 00269: val_loss did not improve from 29.27878
Epoch 270/10000
4/4 - 0s - loss: 17.5391 - val_loss: 29.4399

Epoch 00270: val_loss did not improve from 29.27878
Epoch 271/10000
4/4 - 0s - loss: 17.5379 - val_loss: 29.3966

Epoch 00271: val_loss did not improve from 29.27878
Epoch 272/10000
4/4 - 0s - loss: 17.5489 - val_loss: 29.4547

Epoch 00272: val_loss did not improve from 29.27878
Epoch 273/10000
4/4 - 0s - loss: 17.5356 - val_loss: 29.4080

Epoch 00273: val_loss did not improve from 29.27878
Epoch 274/10000
4/4 - 0s - loss: 17.5779 - val_loss: 29.3856

Epoch 00274: val_loss did not improve from 29.27878
Epoch 275/10000
4/4 - 0s - loss: 17.5322 - val_loss: 29.4883

Epoch 00275: val_loss did not improve from 29.27878
Epoch 276/10000
4/4 - 0s - loss: 17.5448 - val_loss: 29.5131

Epoch 00276: val_loss did not improve from 29.27878
Epoch 277/10000
4/4 - 0s - loss: 17.5503 - val_loss: 29.4057

Epoch 00277: val_loss did not improve from 29.27878
Epoch 278/10000
4/4 - 0s - loss: 17.5567 - val_loss: 29.3522

Epoch 00278: val_loss did not improve from 29.27878
Epoch 279/10000
4/4 - 0s - loss: 17.5611 - val_loss: 29.5220

Epoch 00279: val_loss did not improve from 29.27878
Epoch 280/10000
4/4 - 0s - loss: 17.5505 - val_loss: 29.4702

Epoch 00280: val_loss did not improve from 29.27878
Epoch 281/10000
4/4 - 0s - loss: 17.5416 - val_loss: 29.4157

Epoch 00281: val_loss did not improve from 29.27878
Epoch 282/10000
4/4 - 0s - loss: 17.5358 - val_loss: 29.4508

Epoch 00282: val_loss did not improve from 29.27878
Epoch 283/10000
4/4 - 0s - loss: 17.5352 - val_loss: 29.4631

Epoch 00283: val_loss did not improve from 29.27878
Epoch 284/10000
4/4 - 0s - loss: 17.5363 - val_loss: 29.5031

Epoch 00284: val_loss did not improve from 29.27878
Epoch 285/10000
4/4 - 0s - loss: 17.5363 - val_loss: 29.4284

Epoch 00285: val_loss did not improve from 29.27878
Epoch 286/10000
4/4 - 0s - loss: 17.5806 - val_loss: 29.3691

Epoch 00286: val_loss did not improve from 29.27878
Epoch 287/10000
4/4 - 0s - loss: 17.5428 - val_loss: 29.5216

Epoch 00287: val_loss did not improve from 29.27878
Epoch 288/10000
4/4 - 0s - loss: 17.5480 - val_loss: 29.4801

Epoch 00288: val_loss did not improve from 29.27878
Epoch 289/10000
4/4 - 0s - loss: 17.5352 - val_loss: 29.3963

Epoch 00289: val_loss did not improve from 29.27878
Epoch 290/10000
4/4 - 0s - loss: 17.5447 - val_loss: 29.3563

Epoch 00290: val_loss did not improve from 29.27878
Epoch 291/10000
4/4 - 0s - loss: 17.5387 - val_loss: 29.4822

Epoch 00291: val_loss did not improve from 29.27878
Epoch 292/10000
4/4 - 0s - loss: 17.5510 - val_loss: 29.5091

Epoch 00292: val_loss did not improve from 29.27878
Epoch 293/10000
4/4 - 0s - loss: 17.5459 - val_loss: 29.4569

Epoch 00293: val_loss did not improve from 29.27878
Epoch 294/10000
4/4 - 0s - loss: 17.5575 - val_loss: 29.3940

Epoch 00294: val_loss did not improve from 29.27878
Epoch 295/10000
4/4 - 0s - loss: 17.5447 - val_loss: 29.4760

Epoch 00295: val_loss did not improve from 29.27878
Epoch 296/10000
4/4 - 0s - loss: 17.5391 - val_loss: 29.4223

Epoch 00296: val_loss did not improve from 29.27878
Epoch 297/10000
4/4 - 0s - loss: 17.5361 - val_loss: 29.4715

Epoch 00297: val_loss did not improve from 29.27878
Epoch 298/10000
4/4 - 0s - loss: 17.5355 - val_loss: 29.4054

Epoch 00298: val_loss did not improve from 29.27878
Epoch 299/10000
4/4 - 0s - loss: 17.5430 - val_loss: 29.4256

Epoch 00299: val_loss did not improve from 29.27878
Epoch 300/10000
4/4 - 0s - loss: 17.5411 - val_loss: 29.3888

Epoch 00300: val_loss did not improve from 29.27878
Epoch 301/10000
4/4 - 0s - loss: 17.5291 - val_loss: 29.4876

Epoch 00301: val_loss did not improve from 29.27878
Epoch 302/10000
4/4 - 0s - loss: 17.5576 - val_loss: 29.5981

Epoch 00302: val_loss did not improve from 29.27878
Epoch 303/10000
4/4 - 0s - loss: 17.5647 - val_loss: 29.4406

Epoch 00303: val_loss did not improve from 29.27878
Epoch 304/10000
4/4 - 0s - loss: 17.5624 - val_loss: 29.4012

Epoch 00304: val_loss did not improve from 29.27878
Epoch 305/10000
4/4 - 0s - loss: 17.5373 - val_loss: 29.5080

Epoch 00305: val_loss did not improve from 29.27878
Epoch 306/10000
4/4 - 0s - loss: 17.5374 - val_loss: 29.4386

Epoch 00306: val_loss did not improve from 29.27878
Epoch 307/10000
4/4 - 0s - loss: 17.5556 - val_loss: 29.3372

Epoch 00307: val_loss did not improve from 29.27878
Epoch 308/10000
4/4 - 0s - loss: 17.5480 - val_loss: 29.4898

Epoch 00308: val_loss did not improve from 29.27878
Epoch 309/10000
4/4 - 0s - loss: 17.5386 - val_loss: 29.5142

Epoch 00309: val_loss did not improve from 29.27878
Epoch 310/10000
4/4 - 0s - loss: 17.5424 - val_loss: 29.5176

Epoch 00310: val_loss did not improve from 29.27878
Epoch 311/10000
4/4 - 0s - loss: 17.5492 - val_loss: 29.4077

Epoch 00311: val_loss did not improve from 29.27878
Epoch 312/10000
4/4 - 0s - loss: 17.5319 - val_loss: 29.4706

Epoch 00312: val_loss did not improve from 29.27878
Epoch 313/10000
4/4 - 0s - loss: 17.5346 - val_loss: 29.5068

Epoch 00313: val_loss did not improve from 29.27878
Epoch 314/10000
4/4 - 0s - loss: 17.5433 - val_loss: 29.4096

Epoch 00314: val_loss did not improve from 29.27878
Epoch 315/10000
4/4 - 0s - loss: 17.5376 - val_loss: 29.4253

Epoch 00315: val_loss did not improve from 29.27878
Epoch 316/10000
4/4 - 0s - loss: 17.5441 - val_loss: 29.3833

Epoch 00316: val_loss did not improve from 29.27878
Epoch 317/10000
4/4 - 0s - loss: 17.5314 - val_loss: 29.4906

Epoch 00317: val_loss did not improve from 29.27878
Epoch 318/10000
4/4 - 0s - loss: 17.5516 - val_loss: 29.4487

Epoch 00318: val_loss did not improve from 29.27878
Epoch 319/10000
4/4 - 0s - loss: 17.5335 - val_loss: 29.5188

Epoch 00319: val_loss did not improve from 29.27878
Epoch 320/10000
4/4 - 0s - loss: 17.5398 - val_loss: 29.4230

Epoch 00320: val_loss did not improve from 29.27878
Epoch 321/10000
4/4 - 0s - loss: 17.5470 - val_loss: 29.4406

Epoch 00321: val_loss did not improve from 29.27878
Epoch 322/10000
4/4 - 0s - loss: 17.5265 - val_loss: 29.3548

Epoch 00322: val_loss did not improve from 29.27878
Epoch 323/10000
4/4 - 0s - loss: 17.6116 - val_loss: 29.3126

Epoch 00323: val_loss did not improve from 29.27878
Epoch 324/10000
4/4 - 0s - loss: 17.5381 - val_loss: 29.6069

Epoch 00324: val_loss did not improve from 29.27878
Epoch 325/10000
4/4 - 0s - loss: 17.5680 - val_loss: 29.6123

Epoch 00325: val_loss did not improve from 29.27878
Epoch 326/10000
4/4 - 0s - loss: 17.5406 - val_loss: 29.4021

Epoch 00326: val_loss did not improve from 29.27878
Epoch 327/10000
4/4 - 0s - loss: 17.5514 - val_loss: 29.3619

Epoch 00327: val_loss did not improve from 29.27878
Epoch 328/10000
4/4 - 0s - loss: 17.5501 - val_loss: 29.4686

Epoch 00328: val_loss did not improve from 29.27878
Epoch 329/10000
4/4 - 0s - loss: 17.5302 - val_loss: 29.4467

Epoch 00329: val_loss did not improve from 29.27878
Epoch 330/10000
4/4 - 0s - loss: 17.5441 - val_loss: 29.3922

Epoch 00330: val_loss did not improve from 29.27878
Epoch 331/10000
4/4 - 0s - loss: 17.5302 - val_loss: 29.4464

Epoch 00331: val_loss did not improve from 29.27878
Epoch 332/10000
4/4 - 0s - loss: 17.5396 - val_loss: 29.4974

Epoch 00332: val_loss did not improve from 29.27878
Epoch 333/10000
4/4 - 0s - loss: 17.5356 - val_loss: 29.4515

Epoch 00333: val_loss did not improve from 29.27878
Epoch 334/10000
4/4 - 0s - loss: 17.5350 - val_loss: 29.3932

Epoch 00334: val_loss did not improve from 29.27878
Epoch 335/10000
4/4 - 0s - loss: 17.5344 - val_loss: 29.4297

Epoch 00335: val_loss did not improve from 29.27878
Epoch 336/10000
4/4 - 0s - loss: 17.5274 - val_loss: 29.4768

Epoch 00336: val_loss did not improve from 29.27878
Epoch 337/10000
4/4 - 0s - loss: 17.5565 - val_loss: 29.5544

Epoch 00337: val_loss did not improve from 29.27878
Epoch 338/10000
4/4 - 0s - loss: 17.5377 - val_loss: 29.4465

Epoch 00338: val_loss did not improve from 29.27878
Epoch 339/10000
4/4 - 0s - loss: 17.5517 - val_loss: 29.3687

Epoch 00339: val_loss did not improve from 29.27878
Epoch 340/10000
4/4 - 0s - loss: 17.5574 - val_loss: 29.5681

Epoch 00340: val_loss did not improve from 29.27878
Epoch 341/10000
4/4 - 0s - loss: 17.5681 - val_loss: 29.5545

Epoch 00341: val_loss did not improve from 29.27878
Epoch 342/10000
4/4 - 0s - loss: 17.6476 - val_loss: 29.3198

Epoch 00342: val_loss did not improve from 29.27878
Epoch 343/10000
4/4 - 0s - loss: 17.5590 - val_loss: 29.4732

Epoch 00343: val_loss did not improve from 29.27878
Epoch 344/10000
4/4 - 0s - loss: 17.5616 - val_loss: 29.5302

Epoch 00344: val_loss did not improve from 29.27878
Epoch 345/10000
4/4 - 0s - loss: 17.5357 - val_loss: 29.4458

Epoch 00345: val_loss did not improve from 29.27878
Epoch 346/10000
4/4 - 0s - loss: 17.5296 - val_loss: 29.3894

Epoch 00346: val_loss did not improve from 29.27878
Epoch 347/10000
4/4 - 0s - loss: 17.5734 - val_loss: 29.3397

Epoch 00347: val_loss did not improve from 29.27878
Epoch 348/10000
4/4 - 0s - loss: 17.5521 - val_loss: 29.5094

Epoch 00348: val_loss did not improve from 29.27878
Epoch 349/10000
4/4 - 0s - loss: 17.5807 - val_loss: 29.5194

Epoch 00349: val_loss did not improve from 29.27878
Epoch 350/10000
4/4 - 0s - loss: 17.5293 - val_loss: 29.3476

Epoch 00350: val_loss did not improve from 29.27878
Epoch 351/10000
4/4 - 0s - loss: 17.5444 - val_loss: 29.3718

Epoch 00351: val_loss did not improve from 29.27878
Epoch 352/10000
4/4 - 0s - loss: 17.5347 - val_loss: 29.4190

Epoch 00352: val_loss did not improve from 29.27878
Epoch 353/10000
4/4 - 0s - loss: 17.5382 - val_loss: 29.5093

Epoch 00353: val_loss did not improve from 29.27878
Epoch 354/10000
4/4 - 0s - loss: 17.5375 - val_loss: 29.3931

Epoch 00354: val_loss did not improve from 29.27878
Epoch 355/10000
4/4 - 0s - loss: 17.5337 - val_loss: 29.3998

Epoch 00355: val_loss did not improve from 29.27878
Epoch 356/10000
4/4 - 0s - loss: 17.5310 - val_loss: 29.4987

Epoch 00356: val_loss did not improve from 29.27878
Epoch 357/10000
4/4 - 0s - loss: 17.5347 - val_loss: 29.4719

Epoch 00357: val_loss did not improve from 29.27878
Epoch 358/10000
4/4 - 0s - loss: 17.5316 - val_loss: 29.4519

Epoch 00358: val_loss did not improve from 29.27878
Epoch 359/10000
4/4 - 0s - loss: 17.5294 - val_loss: 29.4342

Epoch 00359: val_loss did not improve from 29.27878
Epoch 360/10000
4/4 - 0s - loss: 17.5371 - val_loss: 29.4587

Epoch 00360: val_loss did not improve from 29.27878
Epoch 361/10000
4/4 - 0s - loss: 17.5339 - val_loss: 29.3629

Epoch 00361: val_loss did not improve from 29.27878
Epoch 362/10000
4/4 - 0s - loss: 17.5340 - val_loss: 29.4086

Epoch 00362: val_loss did not improve from 29.27878
Epoch 363/10000
4/4 - 0s - loss: 17.5285 - val_loss: 29.4151

Epoch 00363: val_loss did not improve from 29.27878
Epoch 364/10000
4/4 - 0s - loss: 17.5361 - val_loss: 29.4219

Epoch 00364: val_loss did not improve from 29.27878
Epoch 365/10000
4/4 - 0s - loss: 17.5552 - val_loss: 29.3565

Epoch 00365: val_loss did not improve from 29.27878
Epoch 366/10000
4/4 - 0s - loss: 17.5399 - val_loss: 29.4180

Epoch 00366: val_loss did not improve from 29.27878
Epoch 367/10000
4/4 - 0s - loss: 17.5271 - val_loss: 29.5176

Epoch 00367: val_loss did not improve from 29.27878
Epoch 368/10000
4/4 - 0s - loss: 17.5364 - val_loss: 29.4754

Epoch 00368: val_loss did not improve from 29.27878
Epoch 369/10000
4/4 - 0s - loss: 17.5487 - val_loss: 29.3537

Epoch 00369: val_loss did not improve from 29.27878
Epoch 370/10000
4/4 - 0s - loss: 17.5373 - val_loss: 29.4376

Epoch 00370: val_loss did not improve from 29.27878
Epoch 371/10000
4/4 - 0s - loss: 17.5369 - val_loss: 29.5601

Epoch 00371: val_loss did not improve from 29.27878
Epoch 372/10000
4/4 - 0s - loss: 17.5412 - val_loss: 29.4778

Epoch 00372: val_loss did not improve from 29.27878
Epoch 373/10000
4/4 - 0s - loss: 17.5286 - val_loss: 29.4293

Epoch 00373: val_loss did not improve from 29.27878
Epoch 374/10000
4/4 - 0s - loss: 17.5251 - val_loss: 29.3766

Epoch 00374: val_loss did not improve from 29.27878
Epoch 375/10000
4/4 - 0s - loss: 17.5363 - val_loss: 29.3820

Epoch 00375: val_loss did not improve from 29.27878
Epoch 376/10000
4/4 - 0s - loss: 17.5330 - val_loss: 29.3637

Epoch 00376: val_loss did not improve from 29.27878
Epoch 377/10000
4/4 - 0s - loss: 17.5293 - val_loss: 29.3652

Epoch 00377: val_loss did not improve from 29.27878
Epoch 378/10000
4/4 - 0s - loss: 17.5362 - val_loss: 29.4021

Epoch 00378: val_loss did not improve from 29.27878
Epoch 379/10000
4/4 - 0s - loss: 17.5333 - val_loss: 29.4552

Epoch 00379: val_loss did not improve from 29.27878
Epoch 380/10000
4/4 - 0s - loss: 17.5636 - val_loss: 29.4794

Epoch 00380: val_loss did not improve from 29.27878
Epoch 381/10000
4/4 - 0s - loss: 17.5135 - val_loss: 29.3013

Epoch 00381: val_loss did not improve from 29.27878
Epoch 382/10000
4/4 - 0s - loss: 17.5889 - val_loss: 29.3350

Epoch 00382: val_loss did not improve from 29.27878
Epoch 383/10000
4/4 - 0s - loss: 17.5244 - val_loss: 29.5439

Epoch 00383: val_loss did not improve from 29.27878
Epoch 384/10000
4/4 - 0s - loss: 17.5435 - val_loss: 29.5011

Epoch 00384: val_loss did not improve from 29.27878
Epoch 385/10000
4/4 - 0s - loss: 17.5303 - val_loss: 29.3717

Epoch 00385: val_loss did not improve from 29.27878
Epoch 386/10000
4/4 - 0s - loss: 17.5558 - val_loss: 29.3586

Epoch 00386: val_loss did not improve from 29.27878
Epoch 387/10000
4/4 - 0s - loss: 17.5203 - val_loss: 29.4666

Epoch 00387: val_loss did not improve from 29.27878
Epoch 388/10000
4/4 - 0s - loss: 17.5532 - val_loss: 29.6324

Epoch 00388: val_loss did not improve from 29.27878
Epoch 389/10000
4/4 - 0s - loss: 17.5572 - val_loss: 29.4537

Epoch 00389: val_loss did not improve from 29.27878
Epoch 390/10000
4/4 - 0s - loss: 17.5247 - val_loss: 29.3817

Epoch 00390: val_loss did not improve from 29.27878
Epoch 391/10000
4/4 - 0s - loss: 17.5297 - val_loss: 29.4091

Epoch 00391: val_loss did not improve from 29.27878
Epoch 392/10000
4/4 - 0s - loss: 17.5369 - val_loss: 29.5035

Epoch 00392: val_loss did not improve from 29.27878
Epoch 393/10000
4/4 - 0s - loss: 17.5298 - val_loss: 29.4840

Epoch 00393: val_loss did not improve from 29.27878
Epoch 394/10000
4/4 - 0s - loss: 17.5343 - val_loss: 29.3879

Epoch 00394: val_loss did not improve from 29.27878
Epoch 395/10000
4/4 - 0s - loss: 17.5388 - val_loss: 29.3876

Epoch 00395: val_loss did not improve from 29.27878
Epoch 396/10000
4/4 - 0s - loss: 17.5424 - val_loss: 29.3535

Epoch 00396: val_loss did not improve from 29.27878
Epoch 397/10000
4/4 - 0s - loss: 17.5548 - val_loss: 29.2950

Epoch 00397: val_loss did not improve from 29.27878
Epoch 398/10000
4/4 - 0s - loss: 17.5292 - val_loss: 29.4801

Epoch 00398: val_loss did not improve from 29.27878
Epoch 399/10000
4/4 - 0s - loss: 17.5726 - val_loss: 29.5927

Epoch 00399: val_loss did not improve from 29.27878
Epoch 400/10000
4/4 - 0s - loss: 17.5393 - val_loss: 29.4078

Epoch 00400: val_loss did not improve from 29.27878
Epoch 401/10000
4/4 - 0s - loss: 17.5316 - val_loss: 29.3550

Epoch 00401: val_loss did not improve from 29.27878
Epoch 402/10000
4/4 - 0s - loss: 17.5374 - val_loss: 29.4258

Epoch 00402: val_loss did not improve from 29.27878
Epoch 403/10000
4/4 - 0s - loss: 17.5212 - val_loss: 29.4838

Epoch 00403: val_loss did not improve from 29.27878
Epoch 404/10000
4/4 - 0s - loss: 17.5316 - val_loss: 29.4639

Epoch 00404: val_loss did not improve from 29.27878
Epoch 405/10000
4/4 - 0s - loss: 17.5304 - val_loss: 29.4538

Epoch 00405: val_loss did not improve from 29.27878
Epoch 406/10000
4/4 - 0s - loss: 17.5242 - val_loss: 29.4718

Epoch 00406: val_loss did not improve from 29.27878
Epoch 407/10000
4/4 - 0s - loss: 17.5246 - val_loss: 29.4767

Epoch 00407: val_loss did not improve from 29.27878
Epoch 408/10000
4/4 - 0s - loss: 17.5356 - val_loss: 29.4622

Epoch 00408: val_loss did not improve from 29.27878
Epoch 00408: early stopping
*************************** Fold #: 4 ***************************
Model: "sequential_43"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_473 (Dense)            (None, 30)                210       
_________________________________________________________________
dense_474 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_475 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_476 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_477 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_478 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_479 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_480 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_481 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_482 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_483 (Dense)            (None, 1)                 31        
=================================================================
Total params: 8,611
Trainable params: 8,611
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
4/4 - 0s - loss: 30.5490 - val_loss: 38.1996

Epoch 00001: val_loss improved from inf to 38.19962, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 2/10000
4/4 - 0s - loss: 30.5082 - val_loss: 38.1475

Epoch 00002: val_loss improved from 38.19962 to 38.14751, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 3/10000
4/4 - 0s - loss: 30.4608 - val_loss: 38.0873

Epoch 00003: val_loss improved from 38.14751 to 38.08727, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 4/10000
4/4 - 0s - loss: 30.4047 - val_loss: 38.0163

Epoch 00004: val_loss improved from 38.08727 to 38.01629, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 5/10000
4/4 - 0s - loss: 30.3401 - val_loss: 37.9305

Epoch 00005: val_loss improved from 38.01629 to 37.93054, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 6/10000
4/4 - 0s - loss: 30.2611 - val_loss: 37.8242

Epoch 00006: val_loss improved from 37.93054 to 37.82421, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 7/10000
4/4 - 0s - loss: 30.1613 - val_loss: 37.6882

Epoch 00007: val_loss improved from 37.82421 to 37.68824, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 8/10000
4/4 - 0s - loss: 30.0308 - val_loss: 37.5074

Epoch 00008: val_loss improved from 37.68824 to 37.50739, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 9/10000
4/4 - 0s - loss: 29.8572 - val_loss: 37.2567

Epoch 00009: val_loss improved from 37.50739 to 37.25674, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 10/10000
4/4 - 0s - loss: 29.6153 - val_loss: 36.8912

Epoch 00010: val_loss improved from 37.25674 to 36.89115, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 11/10000
4/4 - 0s - loss: 29.2460 - val_loss: 36.3245

Epoch 00011: val_loss improved from 36.89115 to 36.32447, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 12/10000
4/4 - 0s - loss: 28.6754 - val_loss: 35.3850

Epoch 00012: val_loss improved from 36.32447 to 35.38503, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 13/10000
4/4 - 0s - loss: 27.7375 - val_loss: 33.7604

Epoch 00013: val_loss improved from 35.38503 to 33.76044, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 14/10000
4/4 - 0s - loss: 26.1487 - val_loss: 31.0509

Epoch 00014: val_loss improved from 33.76044 to 31.05094, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 15/10000
4/4 - 0s - loss: 23.8447 - val_loss: 28.0147

Epoch 00015: val_loss improved from 31.05094 to 28.01466, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 16/10000
4/4 - 0s - loss: 23.0475 - val_loss: 27.9074

Epoch 00016: val_loss improved from 28.01466 to 27.90740, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 17/10000
4/4 - 0s - loss: 23.0494 - val_loss: 27.6243

Epoch 00017: val_loss improved from 27.90740 to 27.62433, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 18/10000
4/4 - 0s - loss: 22.5229 - val_loss: 28.1353

Epoch 00018: val_loss did not improve from 27.62433
Epoch 19/10000
4/4 - 0s - loss: 22.5509 - val_loss: 27.9160

Epoch 00019: val_loss did not improve from 27.62433
Epoch 20/10000
4/4 - 0s - loss: 22.3587 - val_loss: 27.4113

Epoch 00020: val_loss improved from 27.62433 to 27.41127, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 21/10000
4/4 - 0s - loss: 22.1802 - val_loss: 27.0320

Epoch 00021: val_loss improved from 27.41127 to 27.03197, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 22/10000
4/4 - 0s - loss: 22.0809 - val_loss: 26.8946

Epoch 00022: val_loss improved from 27.03197 to 26.89458, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 23/10000
4/4 - 0s - loss: 21.9448 - val_loss: 26.8853

Epoch 00023: val_loss improved from 26.89458 to 26.88534, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 24/10000
4/4 - 0s - loss: 21.8221 - val_loss: 26.8190

Epoch 00024: val_loss improved from 26.88534 to 26.81897, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 25/10000
4/4 - 0s - loss: 21.6991 - val_loss: 26.5278

Epoch 00025: val_loss improved from 26.81897 to 26.52782, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 26/10000
4/4 - 0s - loss: 21.5271 - val_loss: 26.3059

Epoch 00026: val_loss improved from 26.52782 to 26.30589, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 27/10000
4/4 - 0s - loss: 21.3768 - val_loss: 26.0571

Epoch 00027: val_loss improved from 26.30589 to 26.05710, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 28/10000
4/4 - 0s - loss: 21.2067 - val_loss: 25.8624

Epoch 00028: val_loss improved from 26.05710 to 25.86239, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 29/10000
4/4 - 0s - loss: 21.0287 - val_loss: 25.7341

Epoch 00029: val_loss improved from 25.86239 to 25.73406, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 30/10000
4/4 - 0s - loss: 20.8385 - val_loss: 25.3881

Epoch 00030: val_loss improved from 25.73406 to 25.38812, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 31/10000
4/4 - 0s - loss: 20.6429 - val_loss: 25.2644

Epoch 00031: val_loss improved from 25.38812 to 25.26443, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 32/10000
4/4 - 0s - loss: 20.4498 - val_loss: 24.9538

Epoch 00032: val_loss improved from 25.26443 to 24.95378, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 33/10000
4/4 - 0s - loss: 20.2853 - val_loss: 24.8131

Epoch 00033: val_loss improved from 24.95378 to 24.81310, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 34/10000
4/4 - 0s - loss: 20.1014 - val_loss: 24.7851

Epoch 00034: val_loss improved from 24.81310 to 24.78511, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 35/10000
4/4 - 0s - loss: 19.9564 - val_loss: 24.5203

Epoch 00035: val_loss improved from 24.78511 to 24.52027, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 36/10000
4/4 - 0s - loss: 19.8045 - val_loss: 24.2877

Epoch 00036: val_loss improved from 24.52027 to 24.28774, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 37/10000
4/4 - 0s - loss: 19.7731 - val_loss: 24.1574

Epoch 00037: val_loss improved from 24.28774 to 24.15737, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 38/10000
4/4 - 0s - loss: 19.5935 - val_loss: 24.3364

Epoch 00038: val_loss did not improve from 24.15737
Epoch 39/10000
4/4 - 0s - loss: 19.4895 - val_loss: 24.1246

Epoch 00039: val_loss improved from 24.15737 to 24.12455, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 40/10000
4/4 - 0s - loss: 19.3349 - val_loss: 23.9212

Epoch 00040: val_loss improved from 24.12455 to 23.92120, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 41/10000
4/4 - 0s - loss: 19.2224 - val_loss: 23.8343

Epoch 00041: val_loss improved from 23.92120 to 23.83435, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 42/10000
4/4 - 0s - loss: 19.1198 - val_loss: 23.7595

Epoch 00042: val_loss improved from 23.83435 to 23.75947, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 43/10000
4/4 - 0s - loss: 18.9936 - val_loss: 23.7990

Epoch 00043: val_loss did not improve from 23.75947
Epoch 44/10000
4/4 - 0s - loss: 18.8874 - val_loss: 23.6073

Epoch 00044: val_loss improved from 23.75947 to 23.60727, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 45/10000
4/4 - 0s - loss: 18.7958 - val_loss: 23.4863

Epoch 00045: val_loss improved from 23.60727 to 23.48633, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 46/10000
4/4 - 0s - loss: 18.6799 - val_loss: 23.5781

Epoch 00046: val_loss did not improve from 23.48633
Epoch 47/10000
4/4 - 0s - loss: 18.5829 - val_loss: 23.5599

Epoch 00047: val_loss did not improve from 23.48633
Epoch 48/10000
4/4 - 0s - loss: 18.5175 - val_loss: 23.6084

Epoch 00048: val_loss did not improve from 23.48633
Epoch 49/10000
4/4 - 0s - loss: 18.4981 - val_loss: 23.4303

Epoch 00049: val_loss improved from 23.48633 to 23.43027, saving model to ./results/dataset/trial_5/ckpt_4
Epoch 50/10000
4/4 - 0s - loss: 18.3846 - val_loss: 23.6885

Epoch 00050: val_loss did not improve from 23.43027
Epoch 51/10000
4/4 - 0s - loss: 18.4081 - val_loss: 23.7838

Epoch 00051: val_loss did not improve from 23.43027
Epoch 52/10000
4/4 - 0s - loss: 18.3904 - val_loss: 23.4594

Epoch 00052: val_loss did not improve from 23.43027
Epoch 53/10000
4/4 - 0s - loss: 18.3802 - val_loss: 23.5865

Epoch 00053: val_loss did not improve from 23.43027
Epoch 54/10000
4/4 - 0s - loss: 18.3139 - val_loss: 23.5664

Epoch 00054: val_loss did not improve from 23.43027
Epoch 55/10000
4/4 - 0s - loss: 18.3295 - val_loss: 23.5659

Epoch 00055: val_loss did not improve from 23.43027
Epoch 56/10000
4/4 - 0s - loss: 18.3153 - val_loss: 23.7149

Epoch 00056: val_loss did not improve from 23.43027
Epoch 57/10000
4/4 - 0s - loss: 18.3072 - val_loss: 23.6821

Epoch 00057: val_loss did not improve from 23.43027
Epoch 58/10000
4/4 - 0s - loss: 18.2931 - val_loss: 23.6173

Epoch 00058: val_loss did not improve from 23.43027
Epoch 59/10000
4/4 - 0s - loss: 18.3033 - val_loss: 23.7156

Epoch 00059: val_loss did not improve from 23.43027
Epoch 60/10000
4/4 - 0s - loss: 18.3139 - val_loss: 23.7275

Epoch 00060: val_loss did not improve from 23.43027
Epoch 61/10000
4/4 - 0s - loss: 18.2886 - val_loss: 23.6043

Epoch 00061: val_loss did not improve from 23.43027
Epoch 62/10000
4/4 - 0s - loss: 18.3249 - val_loss: 23.6777

Epoch 00062: val_loss did not improve from 23.43027
Epoch 63/10000
4/4 - 0s - loss: 18.2941 - val_loss: 23.8301

Epoch 00063: val_loss did not improve from 23.43027
Epoch 64/10000
4/4 - 0s - loss: 18.2915 - val_loss: 23.7273

Epoch 00064: val_loss did not improve from 23.43027
Epoch 65/10000
4/4 - 0s - loss: 18.2922 - val_loss: 23.6841

Epoch 00065: val_loss did not improve from 23.43027
Epoch 66/10000
4/4 - 0s - loss: 18.2770 - val_loss: 23.8265

Epoch 00066: val_loss did not improve from 23.43027
Epoch 67/10000
4/4 - 0s - loss: 18.2955 - val_loss: 23.7086

Epoch 00067: val_loss did not improve from 23.43027
Epoch 68/10000
4/4 - 0s - loss: 18.2856 - val_loss: 23.6791

Epoch 00068: val_loss did not improve from 23.43027
Epoch 69/10000
4/4 - 0s - loss: 18.2686 - val_loss: 23.6339

Epoch 00069: val_loss did not improve from 23.43027
Epoch 70/10000
4/4 - 0s - loss: 18.2885 - val_loss: 23.6753

Epoch 00070: val_loss did not improve from 23.43027
Epoch 71/10000
4/4 - 0s - loss: 18.2894 - val_loss: 23.7362

Epoch 00071: val_loss did not improve from 23.43027
Epoch 72/10000
4/4 - 0s - loss: 18.2903 - val_loss: 23.7401

Epoch 00072: val_loss did not improve from 23.43027
Epoch 73/10000
4/4 - 0s - loss: 18.2647 - val_loss: 23.6560

Epoch 00073: val_loss did not improve from 23.43027
Epoch 74/10000
4/4 - 0s - loss: 18.3366 - val_loss: 23.7109

Epoch 00074: val_loss did not improve from 23.43027
Epoch 75/10000
4/4 - 0s - loss: 18.3407 - val_loss: 24.0080

Epoch 00075: val_loss did not improve from 23.43027
Epoch 76/10000
4/4 - 0s - loss: 18.3239 - val_loss: 23.6756

Epoch 00076: val_loss did not improve from 23.43027
Epoch 77/10000
4/4 - 0s - loss: 18.2872 - val_loss: 23.6650

Epoch 00077: val_loss did not improve from 23.43027
Epoch 78/10000
4/4 - 0s - loss: 18.3093 - val_loss: 23.7027

Epoch 00078: val_loss did not improve from 23.43027
Epoch 79/10000
4/4 - 0s - loss: 18.2607 - val_loss: 23.8850

Epoch 00079: val_loss did not improve from 23.43027
Epoch 80/10000
4/4 - 0s - loss: 18.2781 - val_loss: 23.7560

Epoch 00080: val_loss did not improve from 23.43027
Epoch 81/10000
4/4 - 0s - loss: 18.3555 - val_loss: 23.6951

Epoch 00081: val_loss did not improve from 23.43027
Epoch 82/10000
4/4 - 0s - loss: 18.2788 - val_loss: 23.9215

Epoch 00082: val_loss did not improve from 23.43027
Epoch 83/10000
4/4 - 0s - loss: 18.2892 - val_loss: 23.7675

Epoch 00083: val_loss did not improve from 23.43027
Epoch 84/10000
4/4 - 0s - loss: 18.2468 - val_loss: 23.6329

Epoch 00084: val_loss did not improve from 23.43027
Epoch 85/10000
4/4 - 0s - loss: 18.2752 - val_loss: 23.6592

Epoch 00085: val_loss did not improve from 23.43027
Epoch 86/10000
4/4 - 0s - loss: 18.2606 - val_loss: 23.8426

Epoch 00086: val_loss did not improve from 23.43027
Epoch 87/10000
4/4 - 0s - loss: 18.2666 - val_loss: 23.7387

Epoch 00087: val_loss did not improve from 23.43027
Epoch 88/10000
4/4 - 0s - loss: 18.2430 - val_loss: 23.6476

Epoch 00088: val_loss did not improve from 23.43027
Epoch 89/10000
4/4 - 0s - loss: 18.2571 - val_loss: 23.6761

Epoch 00089: val_loss did not improve from 23.43027
Epoch 90/10000
4/4 - 0s - loss: 18.2573 - val_loss: 23.6799

Epoch 00090: val_loss did not improve from 23.43027
Epoch 91/10000
4/4 - 0s - loss: 18.2659 - val_loss: 23.7814

Epoch 00091: val_loss did not improve from 23.43027
Epoch 92/10000
4/4 - 0s - loss: 18.2527 - val_loss: 23.6736

Epoch 00092: val_loss did not improve from 23.43027
Epoch 93/10000
4/4 - 0s - loss: 18.2820 - val_loss: 23.7354

Epoch 00093: val_loss did not improve from 23.43027
Epoch 94/10000
4/4 - 0s - loss: 18.2454 - val_loss: 23.6850

Epoch 00094: val_loss did not improve from 23.43027
Epoch 95/10000
4/4 - 0s - loss: 18.2749 - val_loss: 23.6944

Epoch 00095: val_loss did not improve from 23.43027
Epoch 96/10000
4/4 - 0s - loss: 18.2350 - val_loss: 23.9149

Epoch 00096: val_loss did not improve from 23.43027
Epoch 97/10000
4/4 - 0s - loss: 18.2767 - val_loss: 23.7890

Epoch 00097: val_loss did not improve from 23.43027
Epoch 98/10000
4/4 - 0s - loss: 18.2683 - val_loss: 23.6357

Epoch 00098: val_loss did not improve from 23.43027
Epoch 99/10000
4/4 - 0s - loss: 18.2480 - val_loss: 23.7456

Epoch 00099: val_loss did not improve from 23.43027
Epoch 100/10000
4/4 - 0s - loss: 18.2595 - val_loss: 23.7641

Epoch 00100: val_loss did not improve from 23.43027
Epoch 101/10000
4/4 - 0s - loss: 18.3178 - val_loss: 23.6328

Epoch 00101: val_loss did not improve from 23.43027
Epoch 102/10000
4/4 - 0s - loss: 18.3154 - val_loss: 23.8328

Epoch 00102: val_loss did not improve from 23.43027
Epoch 103/10000
4/4 - 0s - loss: 18.2415 - val_loss: 23.6056

Epoch 00103: val_loss did not improve from 23.43027
Epoch 104/10000
4/4 - 0s - loss: 18.2841 - val_loss: 23.6107

Epoch 00104: val_loss did not improve from 23.43027
Epoch 105/10000
4/4 - 0s - loss: 18.2628 - val_loss: 23.8536

Epoch 00105: val_loss did not improve from 23.43027
Epoch 106/10000
4/4 - 0s - loss: 18.2727 - val_loss: 23.7505

Epoch 00106: val_loss did not improve from 23.43027
Epoch 107/10000
4/4 - 0s - loss: 18.2512 - val_loss: 23.6239

Epoch 00107: val_loss did not improve from 23.43027
Epoch 108/10000
4/4 - 0s - loss: 18.2708 - val_loss: 23.6495

Epoch 00108: val_loss did not improve from 23.43027
Epoch 109/10000
4/4 - 0s - loss: 18.2292 - val_loss: 23.8207

Epoch 00109: val_loss did not improve from 23.43027
Epoch 110/10000
4/4 - 0s - loss: 18.2634 - val_loss: 23.7487

Epoch 00110: val_loss did not improve from 23.43027
Epoch 111/10000
4/4 - 0s - loss: 18.2264 - val_loss: 23.6027

Epoch 00111: val_loss did not improve from 23.43027
Epoch 112/10000
4/4 - 0s - loss: 18.2862 - val_loss: 23.6055

Epoch 00112: val_loss did not improve from 23.43027
Epoch 113/10000
4/4 - 0s - loss: 18.2459 - val_loss: 23.8262

Epoch 00113: val_loss did not improve from 23.43027
Epoch 114/10000
4/4 - 0s - loss: 18.2599 - val_loss: 23.6758

Epoch 00114: val_loss did not improve from 23.43027
Epoch 115/10000
4/4 - 0s - loss: 18.2500 - val_loss: 23.5963

Epoch 00115: val_loss did not improve from 23.43027
Epoch 116/10000
4/4 - 0s - loss: 18.2687 - val_loss: 23.6717

Epoch 00116: val_loss did not improve from 23.43027
Epoch 117/10000
4/4 - 0s - loss: 18.2342 - val_loss: 23.7615

Epoch 00117: val_loss did not improve from 23.43027
Epoch 118/10000
4/4 - 0s - loss: 18.2595 - val_loss: 23.6876

Epoch 00118: val_loss did not improve from 23.43027
Epoch 119/10000
4/4 - 0s - loss: 18.2315 - val_loss: 23.7392

Epoch 00119: val_loss did not improve from 23.43027
Epoch 120/10000
4/4 - 0s - loss: 18.2357 - val_loss: 23.7173

Epoch 00120: val_loss did not improve from 23.43027
Epoch 121/10000
4/4 - 0s - loss: 18.2473 - val_loss: 23.6813

Epoch 00121: val_loss did not improve from 23.43027
Epoch 122/10000
4/4 - 0s - loss: 18.2297 - val_loss: 23.5801

Epoch 00122: val_loss did not improve from 23.43027
Epoch 123/10000
4/4 - 0s - loss: 18.2623 - val_loss: 23.6443

Epoch 00123: val_loss did not improve from 23.43027
Epoch 124/10000
4/4 - 0s - loss: 18.2418 - val_loss: 23.7534

Epoch 00124: val_loss did not improve from 23.43027
Epoch 125/10000
4/4 - 0s - loss: 18.2395 - val_loss: 23.7003

Epoch 00125: val_loss did not improve from 23.43027
Epoch 126/10000
4/4 - 0s - loss: 18.2359 - val_loss: 23.6957

Epoch 00126: val_loss did not improve from 23.43027
Epoch 127/10000
4/4 - 0s - loss: 18.2428 - val_loss: 23.7757

Epoch 00127: val_loss did not improve from 23.43027
Epoch 128/10000
4/4 - 0s - loss: 18.2343 - val_loss: 23.6241

Epoch 00128: val_loss did not improve from 23.43027
Epoch 129/10000
4/4 - 0s - loss: 18.2406 - val_loss: 23.6190

Epoch 00129: val_loss did not improve from 23.43027
Epoch 130/10000
4/4 - 0s - loss: 18.2523 - val_loss: 23.6831

Epoch 00130: val_loss did not improve from 23.43027
Epoch 131/10000
4/4 - 0s - loss: 18.2357 - val_loss: 23.7842

Epoch 00131: val_loss did not improve from 23.43027
Epoch 132/10000
4/4 - 0s - loss: 18.2762 - val_loss: 23.6458

Epoch 00132: val_loss did not improve from 23.43027
Epoch 133/10000
4/4 - 0s - loss: 18.2479 - val_loss: 23.7106

Epoch 00133: val_loss did not improve from 23.43027
Epoch 134/10000
4/4 - 0s - loss: 18.3070 - val_loss: 23.8608

Epoch 00134: val_loss did not improve from 23.43027
Epoch 135/10000
4/4 - 0s - loss: 18.2837 - val_loss: 23.6331

Epoch 00135: val_loss did not improve from 23.43027
Epoch 136/10000
4/4 - 0s - loss: 18.2613 - val_loss: 23.6943

Epoch 00136: val_loss did not improve from 23.43027
Epoch 137/10000
4/4 - 0s - loss: 18.2443 - val_loss: 23.7316

Epoch 00137: val_loss did not improve from 23.43027
Epoch 138/10000
4/4 - 0s - loss: 18.2346 - val_loss: 23.6485

Epoch 00138: val_loss did not improve from 23.43027
Epoch 139/10000
4/4 - 0s - loss: 18.2271 - val_loss: 23.6295

Epoch 00139: val_loss did not improve from 23.43027
Epoch 140/10000
4/4 - 0s - loss: 18.2638 - val_loss: 23.6654

Epoch 00140: val_loss did not improve from 23.43027
Epoch 141/10000
4/4 - 0s - loss: 18.2464 - val_loss: 23.8870

Epoch 00141: val_loss did not improve from 23.43027
Epoch 142/10000
4/4 - 0s - loss: 18.2507 - val_loss: 23.7573

Epoch 00142: val_loss did not improve from 23.43027
Epoch 143/10000
4/4 - 0s - loss: 18.2260 - val_loss: 23.6136

Epoch 00143: val_loss did not improve from 23.43027
Epoch 144/10000
4/4 - 0s - loss: 18.2660 - val_loss: 23.6494

Epoch 00144: val_loss did not improve from 23.43027
Epoch 145/10000
4/4 - 0s - loss: 18.2673 - val_loss: 23.8631

Epoch 00145: val_loss did not improve from 23.43027
Epoch 146/10000
4/4 - 0s - loss: 18.2436 - val_loss: 23.6836

Epoch 00146: val_loss did not improve from 23.43027
Epoch 147/10000
4/4 - 0s - loss: 18.2253 - val_loss: 23.6216

Epoch 00147: val_loss did not improve from 23.43027
Epoch 148/10000
4/4 - 0s - loss: 18.2923 - val_loss: 23.6026

Epoch 00148: val_loss did not improve from 23.43027
Epoch 149/10000
4/4 - 0s - loss: 18.2417 - val_loss: 23.7858

Epoch 00149: val_loss did not improve from 23.43027
Epoch 150/10000
4/4 - 0s - loss: 18.2313 - val_loss: 23.7280

Epoch 00150: val_loss did not improve from 23.43027
Epoch 151/10000
4/4 - 0s - loss: 18.2302 - val_loss: 23.6163

Epoch 00151: val_loss did not improve from 23.43027
Epoch 152/10000
4/4 - 0s - loss: 18.2649 - val_loss: 23.6704

Epoch 00152: val_loss did not improve from 23.43027
Epoch 153/10000
4/4 - 0s - loss: 18.2689 - val_loss: 23.8888

Epoch 00153: val_loss did not improve from 23.43027
Epoch 154/10000
4/4 - 0s - loss: 18.2615 - val_loss: 23.6776

Epoch 00154: val_loss did not improve from 23.43027
Epoch 155/10000
4/4 - 0s - loss: 18.2407 - val_loss: 23.6669

Epoch 00155: val_loss did not improve from 23.43027
Epoch 156/10000
4/4 - 0s - loss: 18.2191 - val_loss: 23.7005

Epoch 00156: val_loss did not improve from 23.43027
Epoch 157/10000
4/4 - 0s - loss: 18.2415 - val_loss: 23.7405

Epoch 00157: val_loss did not improve from 23.43027
Epoch 158/10000
4/4 - 0s - loss: 18.2293 - val_loss: 23.6550

Epoch 00158: val_loss did not improve from 23.43027
Epoch 159/10000
4/4 - 0s - loss: 18.2336 - val_loss: 23.6959

Epoch 00159: val_loss did not improve from 23.43027
Epoch 160/10000
4/4 - 0s - loss: 18.2634 - val_loss: 23.8155

Epoch 00160: val_loss did not improve from 23.43027
Epoch 161/10000
4/4 - 0s - loss: 18.2239 - val_loss: 23.6187

Epoch 00161: val_loss did not improve from 23.43027
Epoch 162/10000
4/4 - 0s - loss: 18.2605 - val_loss: 23.6250

Epoch 00162: val_loss did not improve from 23.43027
Epoch 163/10000
4/4 - 0s - loss: 18.2455 - val_loss: 23.8778

Epoch 00163: val_loss did not improve from 23.43027
Epoch 164/10000
4/4 - 0s - loss: 18.2543 - val_loss: 23.7339

Epoch 00164: val_loss did not improve from 23.43027
Epoch 165/10000
4/4 - 0s - loss: 18.2287 - val_loss: 23.6629

Epoch 00165: val_loss did not improve from 23.43027
Epoch 166/10000
4/4 - 0s - loss: 18.2192 - val_loss: 23.7175

Epoch 00166: val_loss did not improve from 23.43027
Epoch 167/10000
4/4 - 0s - loss: 18.2377 - val_loss: 23.7901

Epoch 00167: val_loss did not improve from 23.43027
Epoch 168/10000
4/4 - 0s - loss: 18.2511 - val_loss: 23.6571

Epoch 00168: val_loss did not improve from 23.43027
Epoch 169/10000
4/4 - 0s - loss: 18.2510 - val_loss: 23.6877

Epoch 00169: val_loss did not improve from 23.43027
Epoch 170/10000
4/4 - 0s - loss: 18.2382 - val_loss: 23.7491

Epoch 00170: val_loss did not improve from 23.43027
Epoch 171/10000
4/4 - 0s - loss: 18.2154 - val_loss: 23.8006

Epoch 00171: val_loss did not improve from 23.43027
Epoch 172/10000
4/4 - 0s - loss: 18.2571 - val_loss: 23.8091

Epoch 00172: val_loss did not improve from 23.43027
Epoch 173/10000
4/4 - 0s - loss: 18.2641 - val_loss: 23.6082

Epoch 00173: val_loss did not improve from 23.43027
Epoch 174/10000
4/4 - 0s - loss: 18.2363 - val_loss: 23.6568

Epoch 00174: val_loss did not improve from 23.43027
Epoch 175/10000
4/4 - 0s - loss: 18.2673 - val_loss: 23.7561

Epoch 00175: val_loss did not improve from 23.43027
Epoch 176/10000
4/4 - 0s - loss: 18.2663 - val_loss: 23.6176

Epoch 00176: val_loss did not improve from 23.43027
Epoch 177/10000
4/4 - 0s - loss: 18.2638 - val_loss: 23.7658

Epoch 00177: val_loss did not improve from 23.43027
Epoch 178/10000
4/4 - 0s - loss: 18.2575 - val_loss: 23.6895

Epoch 00178: val_loss did not improve from 23.43027
Epoch 179/10000
4/4 - 0s - loss: 18.2909 - val_loss: 23.5841

Epoch 00179: val_loss did not improve from 23.43027
Epoch 180/10000
4/4 - 0s - loss: 18.2301 - val_loss: 23.7701

Epoch 00180: val_loss did not improve from 23.43027
Epoch 181/10000
4/4 - 0s - loss: 18.2916 - val_loss: 23.9962

Epoch 00181: val_loss did not improve from 23.43027
Epoch 182/10000
4/4 - 0s - loss: 18.2661 - val_loss: 23.6721

Epoch 00182: val_loss did not improve from 23.43027
Epoch 183/10000
4/4 - 0s - loss: 18.2399 - val_loss: 23.6043

Epoch 00183: val_loss did not improve from 23.43027
Epoch 184/10000
4/4 - 0s - loss: 18.2174 - val_loss: 23.7678

Epoch 00184: val_loss did not improve from 23.43027
Epoch 185/10000
4/4 - 0s - loss: 18.2453 - val_loss: 23.8396

Epoch 00185: val_loss did not improve from 23.43027
Epoch 186/10000
4/4 - 0s - loss: 18.2446 - val_loss: 23.6454

Epoch 00186: val_loss did not improve from 23.43027
Epoch 187/10000
4/4 - 0s - loss: 18.2194 - val_loss: 23.6414

Epoch 00187: val_loss did not improve from 23.43027
Epoch 188/10000
4/4 - 0s - loss: 18.2161 - val_loss: 23.6994

Epoch 00188: val_loss did not improve from 23.43027
Epoch 189/10000
4/4 - 0s - loss: 18.2119 - val_loss: 23.7553

Epoch 00189: val_loss did not improve from 23.43027
Epoch 190/10000
4/4 - 0s - loss: 18.2309 - val_loss: 23.6703

Epoch 00190: val_loss did not improve from 23.43027
Epoch 191/10000
4/4 - 0s - loss: 18.2212 - val_loss: 23.5912

Epoch 00191: val_loss did not improve from 23.43027
Epoch 192/10000
4/4 - 0s - loss: 18.2229 - val_loss: 23.7063

Epoch 00192: val_loss did not improve from 23.43027
Epoch 193/10000
4/4 - 0s - loss: 18.2437 - val_loss: 23.8434

Epoch 00193: val_loss did not improve from 23.43027
Epoch 194/10000
4/4 - 0s - loss: 18.2541 - val_loss: 23.6229

Epoch 00194: val_loss did not improve from 23.43027
Epoch 195/10000
4/4 - 0s - loss: 18.2353 - val_loss: 23.6334

Epoch 00195: val_loss did not improve from 23.43027
Epoch 196/10000
4/4 - 0s - loss: 18.2166 - val_loss: 23.7664

Epoch 00196: val_loss did not improve from 23.43027
Epoch 197/10000
4/4 - 0s - loss: 18.2197 - val_loss: 23.7358

Epoch 00197: val_loss did not improve from 23.43027
Epoch 198/10000
4/4 - 0s - loss: 18.2222 - val_loss: 23.6435

Epoch 00198: val_loss did not improve from 23.43027
Epoch 199/10000
4/4 - 0s - loss: 18.2218 - val_loss: 23.6494

Epoch 00199: val_loss did not improve from 23.43027
Epoch 200/10000
4/4 - 0s - loss: 18.2037 - val_loss: 23.7491

Epoch 00200: val_loss did not improve from 23.43027
Epoch 201/10000
4/4 - 0s - loss: 18.2261 - val_loss: 23.7639

Epoch 00201: val_loss did not improve from 23.43027
Epoch 202/10000
4/4 - 0s - loss: 18.2248 - val_loss: 23.6242

Epoch 00202: val_loss did not improve from 23.43027
Epoch 203/10000
4/4 - 0s - loss: 18.2154 - val_loss: 23.6368

Epoch 00203: val_loss did not improve from 23.43027
Epoch 204/10000
4/4 - 0s - loss: 18.2420 - val_loss: 23.6942

Epoch 00204: val_loss did not improve from 23.43027
Epoch 205/10000
4/4 - 0s - loss: 18.2012 - val_loss: 23.5948

Epoch 00205: val_loss did not improve from 23.43027
Epoch 206/10000
4/4 - 0s - loss: 18.2839 - val_loss: 23.5965

Epoch 00206: val_loss did not improve from 23.43027
Epoch 207/10000
4/4 - 0s - loss: 18.1729 - val_loss: 23.9365

Epoch 00207: val_loss did not improve from 23.43027
Epoch 208/10000
4/4 - 0s - loss: 18.2991 - val_loss: 23.8683

Epoch 00208: val_loss did not improve from 23.43027
Epoch 209/10000
4/4 - 0s - loss: 18.2466 - val_loss: 23.5504

Epoch 00209: val_loss did not improve from 23.43027
Epoch 210/10000
4/4 - 0s - loss: 18.2426 - val_loss: 23.5584

Epoch 00210: val_loss did not improve from 23.43027
Epoch 211/10000
4/4 - 0s - loss: 18.1993 - val_loss: 23.7355

Epoch 00211: val_loss did not improve from 23.43027
Epoch 212/10000
4/4 - 0s - loss: 18.3185 - val_loss: 23.8834

Epoch 00212: val_loss did not improve from 23.43027
Epoch 213/10000
4/4 - 0s - loss: 18.2165 - val_loss: 23.5627

Epoch 00213: val_loss did not improve from 23.43027
Epoch 214/10000
4/4 - 0s - loss: 18.2444 - val_loss: 23.5399

Epoch 00214: val_loss did not improve from 23.43027
Epoch 215/10000
4/4 - 0s - loss: 18.2642 - val_loss: 23.7194

Epoch 00215: val_loss did not improve from 23.43027
Epoch 216/10000
4/4 - 0s - loss: 18.2578 - val_loss: 24.0123

Epoch 00216: val_loss did not improve from 23.43027
Epoch 217/10000
4/4 - 0s - loss: 18.2720 - val_loss: 23.7037

Epoch 00217: val_loss did not improve from 23.43027
Epoch 218/10000
4/4 - 0s - loss: 18.1825 - val_loss: 23.5420

Epoch 00218: val_loss did not improve from 23.43027
Epoch 219/10000
4/4 - 0s - loss: 18.3494 - val_loss: 23.5907

Epoch 00219: val_loss did not improve from 23.43027
Epoch 220/10000
4/4 - 0s - loss: 18.3774 - val_loss: 24.1958

Epoch 00220: val_loss did not improve from 23.43027
Epoch 221/10000
4/4 - 0s - loss: 18.3653 - val_loss: 23.6865

Epoch 00221: val_loss did not improve from 23.43027
Epoch 222/10000
4/4 - 0s - loss: 18.2202 - val_loss: 23.5109

Epoch 00222: val_loss did not improve from 23.43027
Epoch 223/10000
4/4 - 0s - loss: 18.2959 - val_loss: 23.5952

Epoch 00223: val_loss did not improve from 23.43027
Epoch 224/10000
4/4 - 0s - loss: 18.2471 - val_loss: 23.9302

Epoch 00224: val_loss did not improve from 23.43027
Epoch 225/10000
4/4 - 0s - loss: 18.3032 - val_loss: 23.7435

Epoch 00225: val_loss did not improve from 23.43027
Epoch 226/10000
4/4 - 0s - loss: 18.3282 - val_loss: 23.5310

Epoch 00226: val_loss did not improve from 23.43027
Epoch 227/10000
4/4 - 0s - loss: 18.2303 - val_loss: 23.6449

Epoch 00227: val_loss did not improve from 23.43027
Epoch 228/10000
4/4 - 0s - loss: 18.2188 - val_loss: 23.7100

Epoch 00228: val_loss did not improve from 23.43027
Epoch 229/10000
4/4 - 0s - loss: 18.2458 - val_loss: 23.6298

Epoch 00229: val_loss did not improve from 23.43027
Epoch 230/10000
4/4 - 0s - loss: 18.2054 - val_loss: 23.5339

Epoch 00230: val_loss did not improve from 23.43027
Epoch 231/10000
4/4 - 0s - loss: 18.2378 - val_loss: 23.5846

Epoch 00231: val_loss did not improve from 23.43027
Epoch 232/10000
4/4 - 0s - loss: 18.2232 - val_loss: 23.7604

Epoch 00232: val_loss did not improve from 23.43027
Epoch 233/10000
4/4 - 0s - loss: 18.2333 - val_loss: 23.6353

Epoch 00233: val_loss did not improve from 23.43027
Epoch 234/10000
4/4 - 0s - loss: 18.2391 - val_loss: 23.5732

Epoch 00234: val_loss did not improve from 23.43027
Epoch 235/10000
4/4 - 0s - loss: 18.2529 - val_loss: 23.6654

Epoch 00235: val_loss did not improve from 23.43027
Epoch 236/10000
4/4 - 0s - loss: 18.2077 - val_loss: 23.7277

Epoch 00236: val_loss did not improve from 23.43027
Epoch 237/10000
4/4 - 0s - loss: 18.2226 - val_loss: 23.7085

Epoch 00237: val_loss did not improve from 23.43027
Epoch 238/10000
4/4 - 0s - loss: 18.2005 - val_loss: 23.5775

Epoch 00238: val_loss did not improve from 23.43027
Epoch 239/10000
4/4 - 0s - loss: 18.2440 - val_loss: 23.5628

Epoch 00239: val_loss did not improve from 23.43027
Epoch 240/10000
4/4 - 0s - loss: 18.2209 - val_loss: 23.6032

Epoch 00240: val_loss did not improve from 23.43027
Epoch 241/10000
4/4 - 0s - loss: 18.2043 - val_loss: 23.6969

Epoch 00241: val_loss did not improve from 23.43027
Epoch 242/10000
4/4 - 0s - loss: 18.2147 - val_loss: 23.6763

Epoch 00242: val_loss did not improve from 23.43027
Epoch 243/10000
4/4 - 0s - loss: 18.2050 - val_loss: 23.5704

Epoch 00243: val_loss did not improve from 23.43027
Epoch 244/10000
4/4 - 0s - loss: 18.2470 - val_loss: 23.5550

Epoch 00244: val_loss did not improve from 23.43027
Epoch 245/10000
4/4 - 0s - loss: 18.2117 - val_loss: 23.7207

Epoch 00245: val_loss did not improve from 23.43027
Epoch 246/10000
4/4 - 0s - loss: 18.2207 - val_loss: 23.6777

Epoch 00246: val_loss did not improve from 23.43027
Epoch 247/10000
4/4 - 0s - loss: 18.2444 - val_loss: 23.5846

Epoch 00247: val_loss did not improve from 23.43027
Epoch 248/10000
4/4 - 0s - loss: 18.2109 - val_loss: 23.6821

Epoch 00248: val_loss did not improve from 23.43027
Epoch 249/10000
4/4 - 0s - loss: 18.2176 - val_loss: 23.6590

Epoch 00249: val_loss did not improve from 23.43027
Epoch 00249: early stopping
*************************** Fold #: 5 ***************************
Model: "sequential_44"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_484 (Dense)            (None, 30)                210       
_________________________________________________________________
dense_485 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_486 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_487 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_488 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_489 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_490 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_491 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_492 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_493 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_494 (Dense)            (None, 1)                 31        
=================================================================
Total params: 8,611
Trainable params: 8,611
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
4/4 - 0s - loss: 33.1008 - val_loss: 15.2648

Epoch 00001: val_loss improved from inf to 15.26482, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 2/10000
4/4 - 0s - loss: 33.0626 - val_loss: 15.2311

Epoch 00002: val_loss improved from 15.26482 to 15.23111, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 3/10000
4/4 - 0s - loss: 33.0211 - val_loss: 15.1935

Epoch 00003: val_loss improved from 15.23111 to 15.19349, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 4/10000
4/4 - 0s - loss: 32.9736 - val_loss: 15.1513

Epoch 00004: val_loss improved from 15.19349 to 15.15127, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 5/10000
4/4 - 0s - loss: 32.9210 - val_loss: 15.1031

Epoch 00005: val_loss improved from 15.15127 to 15.10311, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 6/10000
4/4 - 0s - loss: 32.8601 - val_loss: 15.0474

Epoch 00006: val_loss improved from 15.10311 to 15.04742, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 7/10000
4/4 - 0s - loss: 32.7899 - val_loss: 14.9814

Epoch 00007: val_loss improved from 15.04742 to 14.98139, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 8/10000
4/4 - 0s - loss: 32.7056 - val_loss: 14.9014

Epoch 00008: val_loss improved from 14.98139 to 14.90140, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 9/10000
4/4 - 0s - loss: 32.6003 - val_loss: 14.8013

Epoch 00009: val_loss improved from 14.90140 to 14.80125, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 10/10000
4/4 - 0s - loss: 32.4707 - val_loss: 14.6717

Epoch 00010: val_loss improved from 14.80125 to 14.67166, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 11/10000
4/4 - 0s - loss: 32.2970 - val_loss: 14.4978

Epoch 00011: val_loss improved from 14.67166 to 14.49775, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 12/10000
4/4 - 0s - loss: 32.0620 - val_loss: 14.2537

Epoch 00012: val_loss improved from 14.49775 to 14.25369, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 13/10000
4/4 - 0s - loss: 31.7225 - val_loss: 13.8931

Epoch 00013: val_loss improved from 14.25369 to 13.89311, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 14/10000
4/4 - 0s - loss: 31.2070 - val_loss: 13.3322

Epoch 00014: val_loss improved from 13.89311 to 13.33215, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 15/10000
4/4 - 0s - loss: 30.4053 - val_loss: 12.4303

Epoch 00015: val_loss improved from 13.33215 to 12.43025, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 16/10000
4/4 - 0s - loss: 29.0688 - val_loss: 11.0343

Epoch 00016: val_loss improved from 12.43025 to 11.03435, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 17/10000
4/4 - 0s - loss: 26.9786 - val_loss: 9.5362

Epoch 00017: val_loss improved from 11.03435 to 9.53624, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 18/10000
4/4 - 0s - loss: 24.9812 - val_loss: 10.8829

Epoch 00018: val_loss did not improve from 9.53624
Epoch 19/10000
4/4 - 0s - loss: 25.3669 - val_loss: 10.2807

Epoch 00019: val_loss did not improve from 9.53624
Epoch 20/10000
4/4 - 0s - loss: 24.5908 - val_loss: 9.3067

Epoch 00020: val_loss improved from 9.53624 to 9.30670, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 21/10000
4/4 - 0s - loss: 24.4209 - val_loss: 9.1646

Epoch 00021: val_loss improved from 9.30670 to 9.16459, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 22/10000
4/4 - 0s - loss: 24.3531 - val_loss: 9.1280

Epoch 00022: val_loss improved from 9.16459 to 9.12799, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 23/10000
4/4 - 0s - loss: 24.0620 - val_loss: 9.3121

Epoch 00023: val_loss did not improve from 9.12799
Epoch 24/10000
4/4 - 0s - loss: 23.9043 - val_loss: 9.5079

Epoch 00024: val_loss did not improve from 9.12799
Epoch 25/10000
4/4 - 0s - loss: 23.7173 - val_loss: 9.2226

Epoch 00025: val_loss did not improve from 9.12799
Epoch 26/10000
4/4 - 0s - loss: 23.5123 - val_loss: 9.0077

Epoch 00026: val_loss improved from 9.12799 to 9.00770, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 27/10000
4/4 - 0s - loss: 23.3317 - val_loss: 8.9352

Epoch 00027: val_loss improved from 9.00770 to 8.93525, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 28/10000
4/4 - 0s - loss: 23.1265 - val_loss: 8.9487

Epoch 00028: val_loss did not improve from 8.93525
Epoch 29/10000
4/4 - 0s - loss: 22.8948 - val_loss: 8.9464

Epoch 00029: val_loss did not improve from 8.93525
Epoch 30/10000
4/4 - 0s - loss: 22.6634 - val_loss: 8.8899

Epoch 00030: val_loss improved from 8.93525 to 8.88994, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 31/10000
4/4 - 0s - loss: 22.4382 - val_loss: 8.8096

Epoch 00031: val_loss improved from 8.88994 to 8.80963, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 32/10000
4/4 - 0s - loss: 22.2059 - val_loss: 8.6726

Epoch 00032: val_loss improved from 8.80963 to 8.67261, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 33/10000
4/4 - 0s - loss: 21.9936 - val_loss: 8.6449

Epoch 00033: val_loss improved from 8.67261 to 8.64487, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 34/10000
4/4 - 0s - loss: 21.7849 - val_loss: 8.6900

Epoch 00034: val_loss did not improve from 8.64487
Epoch 35/10000
4/4 - 0s - loss: 21.5919 - val_loss: 8.7286

Epoch 00035: val_loss did not improve from 8.64487
Epoch 36/10000
4/4 - 0s - loss: 21.4209 - val_loss: 8.8136

Epoch 00036: val_loss did not improve from 8.64487
Epoch 37/10000
4/4 - 0s - loss: 21.3026 - val_loss: 8.9309

Epoch 00037: val_loss did not improve from 8.64487
Epoch 38/10000
4/4 - 0s - loss: 21.1825 - val_loss: 8.7325

Epoch 00038: val_loss did not improve from 8.64487
Epoch 39/10000
4/4 - 0s - loss: 21.0414 - val_loss: 8.8291

Epoch 00039: val_loss did not improve from 8.64487
Epoch 40/10000
4/4 - 0s - loss: 20.9166 - val_loss: 8.7092

Epoch 00040: val_loss did not improve from 8.64487
Epoch 41/10000
4/4 - 0s - loss: 20.8102 - val_loss: 8.7675

Epoch 00041: val_loss did not improve from 8.64487
Epoch 42/10000
4/4 - 0s - loss: 20.7154 - val_loss: 9.0067

Epoch 00042: val_loss did not improve from 8.64487
Epoch 43/10000
4/4 - 0s - loss: 20.5960 - val_loss: 8.8292

Epoch 00043: val_loss did not improve from 8.64487
Epoch 44/10000
4/4 - 0s - loss: 20.5176 - val_loss: 8.7286

Epoch 00044: val_loss did not improve from 8.64487
Epoch 45/10000
4/4 - 0s - loss: 20.4383 - val_loss: 8.9504

Epoch 00045: val_loss did not improve from 8.64487
Epoch 46/10000
4/4 - 0s - loss: 20.3219 - val_loss: 8.6412

Epoch 00046: val_loss improved from 8.64487 to 8.64121, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 47/10000
4/4 - 0s - loss: 20.2602 - val_loss: 8.6710

Epoch 00047: val_loss did not improve from 8.64121
Epoch 48/10000
4/4 - 0s - loss: 20.2174 - val_loss: 8.8907

Epoch 00048: val_loss did not improve from 8.64121
Epoch 49/10000
4/4 - 0s - loss: 20.1478 - val_loss: 8.6360

Epoch 00049: val_loss improved from 8.64121 to 8.63596, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 50/10000
4/4 - 0s - loss: 20.1214 - val_loss: 8.7377

Epoch 00050: val_loss did not improve from 8.63596
Epoch 51/10000
4/4 - 0s - loss: 20.0901 - val_loss: 8.6569

Epoch 00051: val_loss did not improve from 8.63596
Epoch 52/10000
4/4 - 0s - loss: 20.0692 - val_loss: 8.4009

Epoch 00052: val_loss improved from 8.63596 to 8.40089, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 53/10000
4/4 - 0s - loss: 20.0528 - val_loss: 8.6602

Epoch 00053: val_loss did not improve from 8.40089
Epoch 54/10000
4/4 - 0s - loss: 20.0183 - val_loss: 8.7946

Epoch 00054: val_loss did not improve from 8.40089
Epoch 55/10000
4/4 - 0s - loss: 20.0112 - val_loss: 8.7251

Epoch 00055: val_loss did not improve from 8.40089
Epoch 56/10000
4/4 - 0s - loss: 20.0006 - val_loss: 8.7789

Epoch 00056: val_loss did not improve from 8.40089
Epoch 57/10000
4/4 - 0s - loss: 20.0383 - val_loss: 8.9578

Epoch 00057: val_loss did not improve from 8.40089
Epoch 58/10000
4/4 - 0s - loss: 19.9940 - val_loss: 8.4438

Epoch 00058: val_loss did not improve from 8.40089
Epoch 59/10000
4/4 - 0s - loss: 19.9991 - val_loss: 8.7199

Epoch 00059: val_loss did not improve from 8.40089
Epoch 60/10000
4/4 - 0s - loss: 19.9660 - val_loss: 8.9233

Epoch 00060: val_loss did not improve from 8.40089
Epoch 61/10000
4/4 - 0s - loss: 19.9866 - val_loss: 8.5834

Epoch 00061: val_loss did not improve from 8.40089
Epoch 62/10000
4/4 - 0s - loss: 19.9668 - val_loss: 8.5676

Epoch 00062: val_loss did not improve from 8.40089
Epoch 63/10000
4/4 - 0s - loss: 19.9462 - val_loss: 8.8633

Epoch 00063: val_loss did not improve from 8.40089
Epoch 64/10000
4/4 - 0s - loss: 20.0239 - val_loss: 8.9434

Epoch 00064: val_loss did not improve from 8.40089
Epoch 65/10000
4/4 - 0s - loss: 20.1049 - val_loss: 8.2317

Epoch 00065: val_loss improved from 8.40089 to 8.23166, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 66/10000
4/4 - 0s - loss: 19.9991 - val_loss: 8.7845

Epoch 00066: val_loss did not improve from 8.23166
Epoch 67/10000
4/4 - 0s - loss: 20.0814 - val_loss: 9.2182

Epoch 00067: val_loss did not improve from 8.23166
Epoch 68/10000
4/4 - 0s - loss: 20.0937 - val_loss: 8.2252

Epoch 00068: val_loss improved from 8.23166 to 8.22517, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 69/10000
4/4 - 0s - loss: 20.0080 - val_loss: 8.5877

Epoch 00069: val_loss did not improve from 8.22517
Epoch 70/10000
4/4 - 0s - loss: 19.9811 - val_loss: 9.3023

Epoch 00070: val_loss did not improve from 8.22517
Epoch 71/10000
4/4 - 0s - loss: 19.9974 - val_loss: 8.5736

Epoch 00071: val_loss did not improve from 8.22517
Epoch 72/10000
4/4 - 0s - loss: 19.9747 - val_loss: 8.3362

Epoch 00072: val_loss did not improve from 8.22517
Epoch 73/10000
4/4 - 0s - loss: 19.9556 - val_loss: 8.7385

Epoch 00073: val_loss did not improve from 8.22517
Epoch 74/10000
4/4 - 0s - loss: 19.9724 - val_loss: 9.0070

Epoch 00074: val_loss did not improve from 8.22517
Epoch 75/10000
4/4 - 0s - loss: 19.9462 - val_loss: 8.5524

Epoch 00075: val_loss did not improve from 8.22517
Epoch 76/10000
4/4 - 0s - loss: 19.9295 - val_loss: 8.5568

Epoch 00076: val_loss did not improve from 8.22517
Epoch 77/10000
4/4 - 0s - loss: 19.9286 - val_loss: 8.6634

Epoch 00077: val_loss did not improve from 8.22517
Epoch 78/10000
4/4 - 0s - loss: 19.9715 - val_loss: 8.8526

Epoch 00078: val_loss did not improve from 8.22517
Epoch 79/10000
4/4 - 0s - loss: 19.9143 - val_loss: 8.5799

Epoch 00079: val_loss did not improve from 8.22517
Epoch 80/10000
4/4 - 0s - loss: 19.9207 - val_loss: 8.4888

Epoch 00080: val_loss did not improve from 8.22517
Epoch 81/10000
4/4 - 0s - loss: 19.9508 - val_loss: 8.5063

Epoch 00081: val_loss did not improve from 8.22517
Epoch 82/10000
4/4 - 0s - loss: 19.9431 - val_loss: 9.0237

Epoch 00082: val_loss did not improve from 8.22517
Epoch 83/10000
4/4 - 0s - loss: 19.9422 - val_loss: 8.7178

Epoch 00083: val_loss did not improve from 8.22517
Epoch 84/10000
4/4 - 0s - loss: 19.9378 - val_loss: 8.4543

Epoch 00084: val_loss did not improve from 8.22517
Epoch 85/10000
4/4 - 0s - loss: 19.9310 - val_loss: 8.6190

Epoch 00085: val_loss did not improve from 8.22517
Epoch 86/10000
4/4 - 0s - loss: 19.9250 - val_loss: 8.9632

Epoch 00086: val_loss did not improve from 8.22517
Epoch 87/10000
4/4 - 0s - loss: 19.9574 - val_loss: 9.0918

Epoch 00087: val_loss did not improve from 8.22517
Epoch 88/10000
4/4 - 0s - loss: 19.9343 - val_loss: 8.6759

Epoch 00088: val_loss did not improve from 8.22517
Epoch 89/10000
4/4 - 0s - loss: 19.9393 - val_loss: 8.6359

Epoch 00089: val_loss did not improve from 8.22517
Epoch 90/10000
4/4 - 0s - loss: 19.9162 - val_loss: 8.5079

Epoch 00090: val_loss did not improve from 8.22517
Epoch 91/10000
4/4 - 0s - loss: 19.9317 - val_loss: 8.7171

Epoch 00091: val_loss did not improve from 8.22517
Epoch 92/10000
4/4 - 0s - loss: 19.9226 - val_loss: 8.7735

Epoch 00092: val_loss did not improve from 8.22517
Epoch 93/10000
4/4 - 0s - loss: 19.8902 - val_loss: 8.4284

Epoch 00093: val_loss did not improve from 8.22517
Epoch 94/10000
4/4 - 0s - loss: 19.9155 - val_loss: 8.3580

Epoch 00094: val_loss did not improve from 8.22517
Epoch 95/10000
4/4 - 0s - loss: 19.9190 - val_loss: 8.5637

Epoch 00095: val_loss did not improve from 8.22517
Epoch 96/10000
4/4 - 0s - loss: 19.9128 - val_loss: 8.8319

Epoch 00096: val_loss did not improve from 8.22517
Epoch 97/10000
4/4 - 0s - loss: 19.9169 - val_loss: 8.6245

Epoch 00097: val_loss did not improve from 8.22517
Epoch 98/10000
4/4 - 0s - loss: 19.9137 - val_loss: 8.5615

Epoch 00098: val_loss did not improve from 8.22517
Epoch 99/10000
4/4 - 0s - loss: 19.9144 - val_loss: 8.6317

Epoch 00099: val_loss did not improve from 8.22517
Epoch 100/10000
4/4 - 0s - loss: 19.9168 - val_loss: 8.8871

Epoch 00100: val_loss did not improve from 8.22517
Epoch 101/10000
4/4 - 0s - loss: 19.9063 - val_loss: 8.6313

Epoch 00101: val_loss did not improve from 8.22517
Epoch 102/10000
4/4 - 0s - loss: 19.8985 - val_loss: 8.4423

Epoch 00102: val_loss did not improve from 8.22517
Epoch 103/10000
4/4 - 0s - loss: 19.9112 - val_loss: 8.6186

Epoch 00103: val_loss did not improve from 8.22517
Epoch 104/10000
4/4 - 0s - loss: 19.9011 - val_loss: 8.6845

Epoch 00104: val_loss did not improve from 8.22517
Epoch 105/10000
4/4 - 0s - loss: 19.8975 - val_loss: 8.5469

Epoch 00105: val_loss did not improve from 8.22517
Epoch 106/10000
4/4 - 0s - loss: 19.8996 - val_loss: 8.5927

Epoch 00106: val_loss did not improve from 8.22517
Epoch 107/10000
4/4 - 0s - loss: 19.9106 - val_loss: 8.5574

Epoch 00107: val_loss did not improve from 8.22517
Epoch 108/10000
4/4 - 0s - loss: 19.9140 - val_loss: 8.7260

Epoch 00108: val_loss did not improve from 8.22517
Epoch 109/10000
4/4 - 0s - loss: 19.8896 - val_loss: 8.5722

Epoch 00109: val_loss did not improve from 8.22517
Epoch 110/10000
4/4 - 0s - loss: 19.9003 - val_loss: 8.5309

Epoch 00110: val_loss did not improve from 8.22517
Epoch 111/10000
4/4 - 0s - loss: 19.9465 - val_loss: 8.5063

Epoch 00111: val_loss did not improve from 8.22517
Epoch 112/10000
4/4 - 0s - loss: 19.9060 - val_loss: 8.9850

Epoch 00112: val_loss did not improve from 8.22517
Epoch 113/10000
4/4 - 0s - loss: 19.9558 - val_loss: 8.7939

Epoch 00113: val_loss did not improve from 8.22517
Epoch 114/10000
4/4 - 0s - loss: 19.9037 - val_loss: 8.9085

Epoch 00114: val_loss did not improve from 8.22517
Epoch 115/10000
4/4 - 0s - loss: 19.8973 - val_loss: 8.6847

Epoch 00115: val_loss did not improve from 8.22517
Epoch 116/10000
4/4 - 0s - loss: 19.9187 - val_loss: 8.6239

Epoch 00116: val_loss did not improve from 8.22517
Epoch 117/10000
4/4 - 0s - loss: 19.8940 - val_loss: 9.0930

Epoch 00117: val_loss did not improve from 8.22517
Epoch 118/10000
4/4 - 0s - loss: 19.9401 - val_loss: 8.8865

Epoch 00118: val_loss did not improve from 8.22517
Epoch 119/10000
4/4 - 0s - loss: 19.9046 - val_loss: 8.8067

Epoch 00119: val_loss did not improve from 8.22517
Epoch 120/10000
4/4 - 0s - loss: 19.8990 - val_loss: 8.4812

Epoch 00120: val_loss did not improve from 8.22517
Epoch 121/10000
4/4 - 0s - loss: 19.9460 - val_loss: 8.2190

Epoch 00121: val_loss improved from 8.22517 to 8.21904, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 122/10000
4/4 - 0s - loss: 20.0012 - val_loss: 8.2926

Epoch 00122: val_loss did not improve from 8.21904
Epoch 123/10000
4/4 - 0s - loss: 19.9111 - val_loss: 8.9940

Epoch 00123: val_loss did not improve from 8.21904
Epoch 124/10000
4/4 - 0s - loss: 19.9599 - val_loss: 8.7435

Epoch 00124: val_loss did not improve from 8.21904
Epoch 125/10000
4/4 - 0s - loss: 19.8941 - val_loss: 8.5558

Epoch 00125: val_loss did not improve from 8.21904
Epoch 126/10000
4/4 - 0s - loss: 19.8813 - val_loss: 8.4524

Epoch 00126: val_loss did not improve from 8.21904
Epoch 127/10000
4/4 - 0s - loss: 19.9211 - val_loss: 8.3863

Epoch 00127: val_loss did not improve from 8.21904
Epoch 128/10000
4/4 - 0s - loss: 19.9479 - val_loss: 8.8082

Epoch 00128: val_loss did not improve from 8.21904
Epoch 129/10000
4/4 - 0s - loss: 19.8908 - val_loss: 8.5857

Epoch 00129: val_loss did not improve from 8.21904
Epoch 130/10000
4/4 - 0s - loss: 19.8811 - val_loss: 8.5178

Epoch 00130: val_loss did not improve from 8.21904
Epoch 131/10000
4/4 - 0s - loss: 19.8813 - val_loss: 8.5159

Epoch 00131: val_loss did not improve from 8.21904
Epoch 132/10000
4/4 - 0s - loss: 19.8903 - val_loss: 8.6338

Epoch 00132: val_loss did not improve from 8.21904
Epoch 133/10000
4/4 - 0s - loss: 19.8793 - val_loss: 8.6401

Epoch 00133: val_loss did not improve from 8.21904
Epoch 134/10000
4/4 - 0s - loss: 19.8777 - val_loss: 8.7033

Epoch 00134: val_loss did not improve from 8.21904
Epoch 135/10000
4/4 - 0s - loss: 19.9038 - val_loss: 8.4894

Epoch 00135: val_loss did not improve from 8.21904
Epoch 136/10000
4/4 - 0s - loss: 19.8953 - val_loss: 8.6473

Epoch 00136: val_loss did not improve from 8.21904
Epoch 137/10000
4/4 - 0s - loss: 19.8714 - val_loss: 8.5408

Epoch 00137: val_loss did not improve from 8.21904
Epoch 138/10000
4/4 - 0s - loss: 19.9080 - val_loss: 8.3917

Epoch 00138: val_loss did not improve from 8.21904
Epoch 139/10000
4/4 - 0s - loss: 19.8803 - val_loss: 8.7086

Epoch 00139: val_loss did not improve from 8.21904
Epoch 140/10000
4/4 - 0s - loss: 19.8877 - val_loss: 8.8294

Epoch 00140: val_loss did not improve from 8.21904
Epoch 141/10000
4/4 - 0s - loss: 19.8962 - val_loss: 8.7779

Epoch 00141: val_loss did not improve from 8.21904
Epoch 142/10000
4/4 - 0s - loss: 19.8625 - val_loss: 8.4807

Epoch 00142: val_loss did not improve from 8.21904
Epoch 143/10000
4/4 - 0s - loss: 19.8952 - val_loss: 8.4216

Epoch 00143: val_loss did not improve from 8.21904
Epoch 144/10000
4/4 - 0s - loss: 19.8697 - val_loss: 8.7316

Epoch 00144: val_loss did not improve from 8.21904
Epoch 145/10000
4/4 - 0s - loss: 19.9193 - val_loss: 8.8826

Epoch 00145: val_loss did not improve from 8.21904
Epoch 146/10000
4/4 - 0s - loss: 19.9132 - val_loss: 8.3694

Epoch 00146: val_loss did not improve from 8.21904
Epoch 147/10000
4/4 - 0s - loss: 19.8944 - val_loss: 8.4745

Epoch 00147: val_loss did not improve from 8.21904
Epoch 148/10000
4/4 - 0s - loss: 19.8862 - val_loss: 8.7442

Epoch 00148: val_loss did not improve from 8.21904
Epoch 149/10000
4/4 - 0s - loss: 19.9178 - val_loss: 8.8074

Epoch 00149: val_loss did not improve from 8.21904
Epoch 150/10000
4/4 - 0s - loss: 19.8420 - val_loss: 8.3295

Epoch 00150: val_loss did not improve from 8.21904
Epoch 151/10000
4/4 - 0s - loss: 19.9329 - val_loss: 8.3187

Epoch 00151: val_loss did not improve from 8.21904
Epoch 152/10000
4/4 - 0s - loss: 19.8861 - val_loss: 8.6052

Epoch 00152: val_loss did not improve from 8.21904
Epoch 153/10000
4/4 - 0s - loss: 19.9541 - val_loss: 9.1180

Epoch 00153: val_loss did not improve from 8.21904
Epoch 154/10000
4/4 - 0s - loss: 19.8898 - val_loss: 8.4964

Epoch 00154: val_loss did not improve from 8.21904
Epoch 155/10000
4/4 - 0s - loss: 19.8788 - val_loss: 8.3901

Epoch 00155: val_loss did not improve from 8.21904
Epoch 156/10000
4/4 - 0s - loss: 19.9378 - val_loss: 8.3483

Epoch 00156: val_loss did not improve from 8.21904
Epoch 157/10000
4/4 - 0s - loss: 19.8620 - val_loss: 9.0582

Epoch 00157: val_loss did not improve from 8.21904
Epoch 158/10000
4/4 - 0s - loss: 19.9516 - val_loss: 9.1542

Epoch 00158: val_loss did not improve from 8.21904
Epoch 159/10000
4/4 - 0s - loss: 19.9509 - val_loss: 8.3866

Epoch 00159: val_loss did not improve from 8.21904
Epoch 160/10000
4/4 - 0s - loss: 19.8995 - val_loss: 8.4716

Epoch 00160: val_loss did not improve from 8.21904
Epoch 161/10000
4/4 - 0s - loss: 19.8665 - val_loss: 8.6928

Epoch 00161: val_loss did not improve from 8.21904
Epoch 162/10000
4/4 - 0s - loss: 19.8669 - val_loss: 8.7030

Epoch 00162: val_loss did not improve from 8.21904
Epoch 163/10000
4/4 - 0s - loss: 19.9154 - val_loss: 8.8613

Epoch 00163: val_loss did not improve from 8.21904
Epoch 164/10000
4/4 - 0s - loss: 19.8406 - val_loss: 8.4292

Epoch 00164: val_loss did not improve from 8.21904
Epoch 165/10000
4/4 - 0s - loss: 19.9303 - val_loss: 8.1969

Epoch 00165: val_loss improved from 8.21904 to 8.19692, saving model to ./results/dataset/trial_5/ckpt_5
Epoch 166/10000
4/4 - 0s - loss: 19.9168 - val_loss: 8.4862

Epoch 00166: val_loss did not improve from 8.19692
Epoch 167/10000
4/4 - 0s - loss: 19.8708 - val_loss: 8.9406

Epoch 00167: val_loss did not improve from 8.19692
Epoch 168/10000
4/4 - 0s - loss: 19.9169 - val_loss: 8.6047

Epoch 00168: val_loss did not improve from 8.19692
Epoch 169/10000
4/4 - 0s - loss: 19.8683 - val_loss: 8.6872

Epoch 00169: val_loss did not improve from 8.19692
Epoch 170/10000
4/4 - 0s - loss: 19.8602 - val_loss: 8.6547

Epoch 00170: val_loss did not improve from 8.19692
Epoch 171/10000
4/4 - 0s - loss: 19.8648 - val_loss: 8.6798

Epoch 00171: val_loss did not improve from 8.19692
Epoch 172/10000
4/4 - 0s - loss: 19.8745 - val_loss: 8.5748

Epoch 00172: val_loss did not improve from 8.19692
Epoch 173/10000
4/4 - 0s - loss: 19.8613 - val_loss: 8.5250

Epoch 00173: val_loss did not improve from 8.19692
Epoch 174/10000
4/4 - 0s - loss: 19.8773 - val_loss: 8.5546

Epoch 00174: val_loss did not improve from 8.19692
Epoch 175/10000
4/4 - 0s - loss: 19.8447 - val_loss: 8.8687

Epoch 00175: val_loss did not improve from 8.19692
Epoch 176/10000
4/4 - 0s - loss: 19.8821 - val_loss: 8.7860

Epoch 00176: val_loss did not improve from 8.19692
Epoch 177/10000
4/4 - 0s - loss: 19.8693 - val_loss: 8.7087

Epoch 00177: val_loss did not improve from 8.19692
Epoch 178/10000
4/4 - 0s - loss: 19.8552 - val_loss: 8.4464

Epoch 00178: val_loss did not improve from 8.19692
Epoch 179/10000
4/4 - 0s - loss: 19.8708 - val_loss: 8.5737

Epoch 00179: val_loss did not improve from 8.19692
Epoch 180/10000
4/4 - 0s - loss: 19.8838 - val_loss: 8.7018

Epoch 00180: val_loss did not improve from 8.19692
Epoch 181/10000
4/4 - 0s - loss: 19.8623 - val_loss: 8.4258

Epoch 00181: val_loss did not improve from 8.19692
Epoch 182/10000
4/4 - 0s - loss: 19.8614 - val_loss: 8.5691

Epoch 00182: val_loss did not improve from 8.19692
Epoch 183/10000
4/4 - 0s - loss: 19.8661 - val_loss: 8.6971

Epoch 00183: val_loss did not improve from 8.19692
Epoch 184/10000
4/4 - 0s - loss: 19.8724 - val_loss: 8.8131

Epoch 00184: val_loss did not improve from 8.19692
Epoch 185/10000
4/4 - 0s - loss: 19.8704 - val_loss: 8.5635

Epoch 00185: val_loss did not improve from 8.19692
Epoch 186/10000
4/4 - 0s - loss: 19.8602 - val_loss: 8.6167

Epoch 00186: val_loss did not improve from 8.19692
Epoch 187/10000
4/4 - 0s - loss: 19.8763 - val_loss: 8.7361

Epoch 00187: val_loss did not improve from 8.19692
Epoch 188/10000
4/4 - 0s - loss: 19.8744 - val_loss: 9.0212

Epoch 00188: val_loss did not improve from 8.19692
Epoch 189/10000
4/4 - 0s - loss: 19.8733 - val_loss: 8.6729

Epoch 00189: val_loss did not improve from 8.19692
Epoch 190/10000
4/4 - 0s - loss: 19.9542 - val_loss: 8.2695

Epoch 00190: val_loss did not improve from 8.19692
Epoch 191/10000
4/4 - 0s - loss: 19.8918 - val_loss: 8.7074

Epoch 00191: val_loss did not improve from 8.19692
Epoch 192/10000
4/4 - 0s - loss: 19.8617 - val_loss: 8.8263

Epoch 00192: val_loss did not improve from 8.19692
Epoch 193/10000
4/4 - 0s - loss: 19.8537 - val_loss: 8.5432

Epoch 00193: val_loss did not improve from 8.19692
Epoch 194/10000
4/4 - 0s - loss: 19.8500 - val_loss: 8.3142

Epoch 00194: val_loss did not improve from 8.19692
Epoch 195/10000
4/4 - 0s - loss: 19.8920 - val_loss: 8.4197

Epoch 00195: val_loss did not improve from 8.19692
Epoch 196/10000
4/4 - 0s - loss: 19.8418 - val_loss: 8.7317

Epoch 00196: val_loss did not improve from 8.19692
Epoch 197/10000
4/4 - 0s - loss: 19.8938 - val_loss: 8.8980

Epoch 00197: val_loss did not improve from 8.19692
Epoch 198/10000
4/4 - 0s - loss: 19.8800 - val_loss: 8.4466

Epoch 00198: val_loss did not improve from 8.19692
Epoch 199/10000
4/4 - 0s - loss: 19.8585 - val_loss: 8.4879

Epoch 00199: val_loss did not improve from 8.19692
Epoch 200/10000
4/4 - 0s - loss: 19.8638 - val_loss: 8.7704

Epoch 00200: val_loss did not improve from 8.19692
Epoch 201/10000
4/4 - 0s - loss: 19.8527 - val_loss: 8.6405

Epoch 00201: val_loss did not improve from 8.19692
Epoch 202/10000
4/4 - 0s - loss: 19.8471 - val_loss: 8.6313

Epoch 00202: val_loss did not improve from 8.19692
Epoch 203/10000
4/4 - 0s - loss: 19.8512 - val_loss: 8.6908

Epoch 00203: val_loss did not improve from 8.19692
Epoch 204/10000
4/4 - 0s - loss: 19.8504 - val_loss: 8.6788

Epoch 00204: val_loss did not improve from 8.19692
Epoch 205/10000
4/4 - 0s - loss: 19.8501 - val_loss: 8.6080

Epoch 00205: val_loss did not improve from 8.19692
Epoch 206/10000
4/4 - 0s - loss: 19.8603 - val_loss: 8.4598

Epoch 00206: val_loss did not improve from 8.19692
Epoch 207/10000
4/4 - 0s - loss: 19.8531 - val_loss: 8.5713

Epoch 00207: val_loss did not improve from 8.19692
Epoch 208/10000
4/4 - 0s - loss: 19.8509 - val_loss: 8.7487

Epoch 00208: val_loss did not improve from 8.19692
Epoch 209/10000
4/4 - 0s - loss: 19.8705 - val_loss: 8.5200

Epoch 00209: val_loss did not improve from 8.19692
Epoch 210/10000
4/4 - 0s - loss: 19.8530 - val_loss: 8.6046

Epoch 00210: val_loss did not improve from 8.19692
Epoch 211/10000
4/4 - 0s - loss: 19.8540 - val_loss: 8.6227

Epoch 00211: val_loss did not improve from 8.19692
Epoch 212/10000
4/4 - 0s - loss: 19.8627 - val_loss: 8.5681

Epoch 00212: val_loss did not improve from 8.19692
Epoch 213/10000
4/4 - 0s - loss: 19.8627 - val_loss: 8.3836

Epoch 00213: val_loss did not improve from 8.19692
Epoch 214/10000
4/4 - 0s - loss: 19.8532 - val_loss: 8.5893

Epoch 00214: val_loss did not improve from 8.19692
Epoch 215/10000
4/4 - 0s - loss: 19.8539 - val_loss: 8.6798

Epoch 00215: val_loss did not improve from 8.19692
Epoch 216/10000
4/4 - 0s - loss: 19.8632 - val_loss: 8.4674

Epoch 00216: val_loss did not improve from 8.19692
Epoch 217/10000
4/4 - 0s - loss: 19.8453 - val_loss: 8.6124

Epoch 00217: val_loss did not improve from 8.19692
Epoch 218/10000
4/4 - 0s - loss: 19.8546 - val_loss: 8.7979

Epoch 00218: val_loss did not improve from 8.19692
Epoch 219/10000
4/4 - 0s - loss: 19.8491 - val_loss: 8.5936

Epoch 00219: val_loss did not improve from 8.19692
Epoch 220/10000
4/4 - 0s - loss: 19.8515 - val_loss: 8.5820

Epoch 00220: val_loss did not improve from 8.19692
Epoch 221/10000
4/4 - 0s - loss: 19.8749 - val_loss: 8.6153

Epoch 00221: val_loss did not improve from 8.19692
Epoch 222/10000
4/4 - 0s - loss: 19.8387 - val_loss: 8.4270

Epoch 00222: val_loss did not improve from 8.19692
Epoch 223/10000
4/4 - 0s - loss: 19.8978 - val_loss: 8.3977

Epoch 00223: val_loss did not improve from 8.19692
Epoch 224/10000
4/4 - 0s - loss: 19.8447 - val_loss: 8.7068

Epoch 00224: val_loss did not improve from 8.19692
Epoch 225/10000
4/4 - 0s - loss: 19.8558 - val_loss: 8.9147

Epoch 00225: val_loss did not improve from 8.19692
Epoch 226/10000
4/4 - 0s - loss: 19.8495 - val_loss: 8.5712

Epoch 00226: val_loss did not improve from 8.19692
Epoch 227/10000
4/4 - 0s - loss: 19.8742 - val_loss: 8.2698

Epoch 00227: val_loss did not improve from 8.19692
Epoch 228/10000
4/4 - 0s - loss: 19.8781 - val_loss: 8.5723

Epoch 00228: val_loss did not improve from 8.19692
Epoch 229/10000
4/4 - 0s - loss: 19.8503 - val_loss: 8.9239

Epoch 00229: val_loss did not improve from 8.19692
Epoch 230/10000
4/4 - 0s - loss: 19.8697 - val_loss: 8.7189

Epoch 00230: val_loss did not improve from 8.19692
Epoch 231/10000
4/4 - 0s - loss: 19.8580 - val_loss: 8.4943

Epoch 00231: val_loss did not improve from 8.19692
Epoch 232/10000
4/4 - 0s - loss: 19.8439 - val_loss: 8.6522

Epoch 00232: val_loss did not improve from 8.19692
Epoch 233/10000
4/4 - 0s - loss: 19.8550 - val_loss: 8.8579

Epoch 00233: val_loss did not improve from 8.19692
Epoch 234/10000
4/4 - 0s - loss: 19.8620 - val_loss: 8.7918

Epoch 00234: val_loss did not improve from 8.19692
Epoch 235/10000
4/4 - 0s - loss: 19.8452 - val_loss: 8.4147

Epoch 00235: val_loss did not improve from 8.19692
Epoch 236/10000
4/4 - 0s - loss: 19.8943 - val_loss: 8.3595

Epoch 00236: val_loss did not improve from 8.19692
Epoch 237/10000
4/4 - 0s - loss: 19.8929 - val_loss: 8.7822

Epoch 00237: val_loss did not improve from 8.19692
Epoch 238/10000
4/4 - 0s - loss: 19.8499 - val_loss: 8.5804

Epoch 00238: val_loss did not improve from 8.19692
Epoch 239/10000
4/4 - 0s - loss: 19.8503 - val_loss: 8.3858

Epoch 00239: val_loss did not improve from 8.19692
Epoch 240/10000
4/4 - 0s - loss: 19.8472 - val_loss: 8.6173

Epoch 00240: val_loss did not improve from 8.19692
Epoch 241/10000
4/4 - 0s - loss: 19.8493 - val_loss: 8.8701

Epoch 00241: val_loss did not improve from 8.19692
Epoch 242/10000
4/4 - 0s - loss: 19.8621 - val_loss: 8.7603

Epoch 00242: val_loss did not improve from 8.19692
Epoch 243/10000
4/4 - 0s - loss: 19.8276 - val_loss: 8.4321

Epoch 00243: val_loss did not improve from 8.19692
Epoch 244/10000
4/4 - 0s - loss: 19.8942 - val_loss: 8.3642

Epoch 00244: val_loss did not improve from 8.19692
Epoch 245/10000
4/4 - 0s - loss: 19.8631 - val_loss: 8.8149

Epoch 00245: val_loss did not improve from 8.19692
Epoch 246/10000
4/4 - 0s - loss: 19.8593 - val_loss: 8.6312

Epoch 00246: val_loss did not improve from 8.19692
Epoch 247/10000
4/4 - 0s - loss: 19.8457 - val_loss: 8.6193

Epoch 00247: val_loss did not improve from 8.19692
Epoch 248/10000
4/4 - 0s - loss: 19.8474 - val_loss: 8.5851

Epoch 00248: val_loss did not improve from 8.19692
Epoch 249/10000
4/4 - 0s - loss: 19.8446 - val_loss: 8.5309

Epoch 00249: val_loss did not improve from 8.19692
Epoch 250/10000
4/4 - 0s - loss: 19.8832 - val_loss: 8.7205

Epoch 00250: val_loss did not improve from 8.19692
Epoch 251/10000
4/4 - 0s - loss: 19.8454 - val_loss: 8.4574

Epoch 00251: val_loss did not improve from 8.19692
Epoch 252/10000
4/4 - 0s - loss: 19.8744 - val_loss: 8.3979

Epoch 00252: val_loss did not improve from 8.19692
Epoch 253/10000
4/4 - 0s - loss: 19.8537 - val_loss: 8.6281

Epoch 00253: val_loss did not improve from 8.19692
Epoch 254/10000
4/4 - 0s - loss: 19.8390 - val_loss: 8.8389

Epoch 00254: val_loss did not improve from 8.19692
Epoch 255/10000
4/4 - 0s - loss: 19.8538 - val_loss: 8.7222

Epoch 00255: val_loss did not improve from 8.19692
Epoch 256/10000
4/4 - 0s - loss: 19.8389 - val_loss: 8.6257

Epoch 00256: val_loss did not improve from 8.19692
Epoch 257/10000
4/4 - 0s - loss: 19.8608 - val_loss: 8.5575

Epoch 00257: val_loss did not improve from 8.19692
Epoch 258/10000
4/4 - 0s - loss: 19.8570 - val_loss: 8.8847

Epoch 00258: val_loss did not improve from 8.19692
Epoch 259/10000
4/4 - 0s - loss: 19.8462 - val_loss: 8.5327

Epoch 00259: val_loss did not improve from 8.19692
Epoch 260/10000
4/4 - 0s - loss: 19.8615 - val_loss: 8.3745

Epoch 00260: val_loss did not improve from 8.19692
Epoch 261/10000
4/4 - 0s - loss: 19.8386 - val_loss: 8.7205

Epoch 00261: val_loss did not improve from 8.19692
Epoch 262/10000
4/4 - 0s - loss: 19.8415 - val_loss: 8.7681

Epoch 00262: val_loss did not improve from 8.19692
Epoch 263/10000
4/4 - 0s - loss: 19.8418 - val_loss: 8.7231

Epoch 00263: val_loss did not improve from 8.19692
Epoch 264/10000
4/4 - 0s - loss: 19.8372 - val_loss: 8.6007

Epoch 00264: val_loss did not improve from 8.19692
Epoch 265/10000
4/4 - 0s - loss: 19.8391 - val_loss: 8.6283

Epoch 00265: val_loss did not improve from 8.19692
Epoch 266/10000
4/4 - 0s - loss: 19.8425 - val_loss: 8.7226

Epoch 00266: val_loss did not improve from 8.19692
Epoch 267/10000
4/4 - 0s - loss: 19.8445 - val_loss: 8.4816

Epoch 00267: val_loss did not improve from 8.19692
Epoch 268/10000
4/4 - 0s - loss: 19.8454 - val_loss: 8.5863

Epoch 00268: val_loss did not improve from 8.19692
Epoch 269/10000
4/4 - 0s - loss: 19.8354 - val_loss: 8.6255

Epoch 00269: val_loss did not improve from 8.19692
Epoch 270/10000
4/4 - 0s - loss: 19.8359 - val_loss: 8.5819

Epoch 00270: val_loss did not improve from 8.19692
Epoch 271/10000
4/4 - 0s - loss: 19.8392 - val_loss: 8.5532

Epoch 00271: val_loss did not improve from 8.19692
Epoch 272/10000
4/4 - 0s - loss: 19.8564 - val_loss: 8.7386

Epoch 00272: val_loss did not improve from 8.19692
Epoch 273/10000
4/4 - 0s - loss: 19.8422 - val_loss: 8.6676

Epoch 00273: val_loss did not improve from 8.19692
Epoch 274/10000
4/4 - 0s - loss: 19.8561 - val_loss: 8.5224

Epoch 00274: val_loss did not improve from 8.19692
Epoch 275/10000
4/4 - 0s - loss: 19.8784 - val_loss: 8.8258

Epoch 00275: val_loss did not improve from 8.19692
Epoch 276/10000
4/4 - 0s - loss: 19.9534 - val_loss: 8.3749

Epoch 00276: val_loss did not improve from 8.19692
Epoch 277/10000
4/4 - 0s - loss: 19.9203 - val_loss: 9.0609

Epoch 00277: val_loss did not improve from 8.19692
Epoch 278/10000
4/4 - 0s - loss: 19.8898 - val_loss: 8.6088

Epoch 00278: val_loss did not improve from 8.19692
Epoch 279/10000
4/4 - 0s - loss: 19.8475 - val_loss: 8.5728

Epoch 00279: val_loss did not improve from 8.19692
Epoch 280/10000
4/4 - 0s - loss: 19.8842 - val_loss: 8.8390

Epoch 00280: val_loss did not improve from 8.19692
Epoch 281/10000
4/4 - 0s - loss: 19.8629 - val_loss: 8.4435

Epoch 00281: val_loss did not improve from 8.19692
Epoch 282/10000
4/4 - 0s - loss: 19.8413 - val_loss: 8.6586

Epoch 00282: val_loss did not improve from 8.19692
Epoch 283/10000
4/4 - 0s - loss: 19.8364 - val_loss: 8.6572

Epoch 00283: val_loss did not improve from 8.19692
Epoch 284/10000
4/4 - 0s - loss: 19.8447 - val_loss: 8.7601

Epoch 00284: val_loss did not improve from 8.19692
Epoch 285/10000
4/4 - 0s - loss: 19.8488 - val_loss: 8.4763

Epoch 00285: val_loss did not improve from 8.19692
Epoch 286/10000
4/4 - 0s - loss: 19.8719 - val_loss: 8.4721

Epoch 00286: val_loss did not improve from 8.19692
Epoch 287/10000
4/4 - 0s - loss: 19.8432 - val_loss: 8.8845

Epoch 00287: val_loss did not improve from 8.19692
Epoch 288/10000
4/4 - 0s - loss: 19.8600 - val_loss: 8.6683

Epoch 00288: val_loss did not improve from 8.19692
Epoch 289/10000
4/4 - 0s - loss: 19.8517 - val_loss: 8.7027

Epoch 00289: val_loss did not improve from 8.19692
Epoch 290/10000
4/4 - 0s - loss: 19.8324 - val_loss: 8.5147

Epoch 00290: val_loss did not improve from 8.19692
Epoch 291/10000
4/4 - 0s - loss: 19.8539 - val_loss: 8.4523

Epoch 00291: val_loss did not improve from 8.19692
Epoch 292/10000
4/4 - 0s - loss: 19.8388 - val_loss: 8.5876

Epoch 00292: val_loss did not improve from 8.19692
Epoch 293/10000
4/4 - 0s - loss: 19.8515 - val_loss: 8.6040

Epoch 00293: val_loss did not improve from 8.19692
Epoch 294/10000
4/4 - 0s - loss: 19.8338 - val_loss: 8.5371

Epoch 00294: val_loss did not improve from 8.19692
Epoch 295/10000
4/4 - 0s - loss: 19.8367 - val_loss: 8.5880

Epoch 00295: val_loss did not improve from 8.19692
Epoch 296/10000
4/4 - 0s - loss: 19.8578 - val_loss: 8.8595

Epoch 00296: val_loss did not improve from 8.19692
Epoch 297/10000
4/4 - 0s - loss: 19.8457 - val_loss: 8.4921

Epoch 00297: val_loss did not improve from 8.19692
Epoch 298/10000
4/4 - 0s - loss: 19.8385 - val_loss: 8.5206

Epoch 00298: val_loss did not improve from 8.19692
Epoch 299/10000
4/4 - 0s - loss: 19.8563 - val_loss: 8.6394

Epoch 00299: val_loss did not improve from 8.19692
Epoch 300/10000
4/4 - 0s - loss: 19.8362 - val_loss: 8.4229

Epoch 00300: val_loss did not improve from 8.19692
Epoch 301/10000
4/4 - 0s - loss: 19.8567 - val_loss: 8.4942

Epoch 00301: val_loss did not improve from 8.19692
Epoch 302/10000
4/4 - 0s - loss: 19.8338 - val_loss: 8.7742

Epoch 00302: val_loss did not improve from 8.19692
Epoch 303/10000
4/4 - 0s - loss: 19.8398 - val_loss: 8.7394

Epoch 00303: val_loss did not improve from 8.19692
Epoch 304/10000
4/4 - 0s - loss: 19.8355 - val_loss: 8.5874

Epoch 00304: val_loss did not improve from 8.19692
Epoch 305/10000
4/4 - 0s - loss: 19.8422 - val_loss: 8.5606

Epoch 00305: val_loss did not improve from 8.19692
Epoch 306/10000
4/4 - 0s - loss: 19.8395 - val_loss: 8.5648

Epoch 00306: val_loss did not improve from 8.19692
Epoch 307/10000
4/4 - 0s - loss: 19.8294 - val_loss: 8.5819

Epoch 00307: val_loss did not improve from 8.19692
Epoch 308/10000
4/4 - 0s - loss: 19.8374 - val_loss: 8.5703

Epoch 00308: val_loss did not improve from 8.19692
Epoch 309/10000
4/4 - 0s - loss: 19.8327 - val_loss: 8.5937

Epoch 00309: val_loss did not improve from 8.19692
Epoch 310/10000
4/4 - 0s - loss: 19.8279 - val_loss: 8.6625

Epoch 00310: val_loss did not improve from 8.19692
Epoch 311/10000
4/4 - 0s - loss: 19.8342 - val_loss: 8.7820

Epoch 00311: val_loss did not improve from 8.19692
Epoch 312/10000
4/4 - 0s - loss: 19.8391 - val_loss: 8.7089

Epoch 00312: val_loss did not improve from 8.19692
Epoch 313/10000
4/4 - 0s - loss: 19.8398 - val_loss: 8.6009

Epoch 00313: val_loss did not improve from 8.19692
Epoch 314/10000
4/4 - 0s - loss: 19.8373 - val_loss: 8.6968

Epoch 00314: val_loss did not improve from 8.19692
Epoch 315/10000
4/4 - 0s - loss: 19.8562 - val_loss: 8.7465

Epoch 00315: val_loss did not improve from 8.19692
Epoch 316/10000
4/4 - 0s - loss: 19.8147 - val_loss: 8.4132

Epoch 00316: val_loss did not improve from 8.19692
Epoch 317/10000
4/4 - 0s - loss: 19.8633 - val_loss: 8.3737

Epoch 00317: val_loss did not improve from 8.19692
Epoch 318/10000
4/4 - 0s - loss: 19.8729 - val_loss: 8.7874

Epoch 00318: val_loss did not improve from 8.19692
Epoch 319/10000
4/4 - 0s - loss: 19.8468 - val_loss: 8.6212

Epoch 00319: val_loss did not improve from 8.19692
Epoch 320/10000
4/4 - 0s - loss: 19.8295 - val_loss: 8.6214

Epoch 00320: val_loss did not improve from 8.19692
Epoch 321/10000
4/4 - 0s - loss: 19.8383 - val_loss: 8.5784

Epoch 00321: val_loss did not improve from 8.19692
Epoch 322/10000
4/4 - 0s - loss: 19.9027 - val_loss: 8.9124

Epoch 00322: val_loss did not improve from 8.19692
Epoch 323/10000
4/4 - 0s - loss: 19.8270 - val_loss: 8.4712

Epoch 00323: val_loss did not improve from 8.19692
Epoch 324/10000
4/4 - 0s - loss: 19.8396 - val_loss: 8.3329

Epoch 00324: val_loss did not improve from 8.19692
Epoch 325/10000
4/4 - 0s - loss: 19.8680 - val_loss: 8.5886

Epoch 00325: val_loss did not improve from 8.19692
Epoch 326/10000
4/4 - 0s - loss: 19.8409 - val_loss: 8.5451

Epoch 00326: val_loss did not improve from 8.19692
Epoch 327/10000
4/4 - 0s - loss: 19.8348 - val_loss: 8.5494

Epoch 00327: val_loss did not improve from 8.19692
Epoch 328/10000
4/4 - 0s - loss: 19.8431 - val_loss: 8.7125

Epoch 00328: val_loss did not improve from 8.19692
Epoch 329/10000
4/4 - 0s - loss: 19.8326 - val_loss: 8.5426

Epoch 00329: val_loss did not improve from 8.19692
Epoch 330/10000
4/4 - 0s - loss: 19.8338 - val_loss: 8.6618

Epoch 00330: val_loss did not improve from 8.19692
Epoch 331/10000
4/4 - 0s - loss: 19.8381 - val_loss: 8.7789

Epoch 00331: val_loss did not improve from 8.19692
Epoch 332/10000
4/4 - 0s - loss: 19.8430 - val_loss: 8.8745

Epoch 00332: val_loss did not improve from 8.19692
Epoch 333/10000
4/4 - 0s - loss: 19.8301 - val_loss: 8.5592

Epoch 00333: val_loss did not improve from 8.19692
Epoch 334/10000
4/4 - 0s - loss: 19.8222 - val_loss: 8.3700

Epoch 00334: val_loss did not improve from 8.19692
Epoch 335/10000
4/4 - 0s - loss: 19.8580 - val_loss: 8.4520

Epoch 00335: val_loss did not improve from 8.19692
Epoch 336/10000
4/4 - 0s - loss: 19.8346 - val_loss: 8.7060

Epoch 00336: val_loss did not improve from 8.19692
Epoch 337/10000
4/4 - 0s - loss: 19.8428 - val_loss: 8.7230

Epoch 00337: val_loss did not improve from 8.19692
Epoch 338/10000
4/4 - 0s - loss: 19.8369 - val_loss: 8.5646

Epoch 00338: val_loss did not improve from 8.19692
Epoch 339/10000
4/4 - 0s - loss: 19.8337 - val_loss: 8.6682

Epoch 00339: val_loss did not improve from 8.19692
Epoch 340/10000
4/4 - 0s - loss: 19.8267 - val_loss: 8.6658

Epoch 00340: val_loss did not improve from 8.19692
Epoch 341/10000
4/4 - 0s - loss: 19.8307 - val_loss: 8.6329

Epoch 00341: val_loss did not improve from 8.19692
Epoch 342/10000
4/4 - 0s - loss: 19.8367 - val_loss: 8.6011

Epoch 00342: val_loss did not improve from 8.19692
Epoch 343/10000
4/4 - 0s - loss: 19.8420 - val_loss: 8.8419

Epoch 00343: val_loss did not improve from 8.19692
Epoch 344/10000
4/4 - 0s - loss: 19.8355 - val_loss: 8.5567

Epoch 00344: val_loss did not improve from 8.19692
Epoch 345/10000
4/4 - 0s - loss: 19.8465 - val_loss: 8.5564

Epoch 00345: val_loss did not improve from 8.19692
Epoch 346/10000
4/4 - 0s - loss: 19.8332 - val_loss: 8.5370

Epoch 00346: val_loss did not improve from 8.19692
Epoch 347/10000
4/4 - 0s - loss: 19.8362 - val_loss: 8.6640

Epoch 00347: val_loss did not improve from 8.19692
Epoch 348/10000
4/4 - 0s - loss: 19.8369 - val_loss: 8.6211

Epoch 00348: val_loss did not improve from 8.19692
Epoch 349/10000
4/4 - 0s - loss: 19.8631 - val_loss: 8.6639

Epoch 00349: val_loss did not improve from 8.19692
Epoch 350/10000
4/4 - 0s - loss: 19.8397 - val_loss: 8.3190

Epoch 00350: val_loss did not improve from 8.19692
Epoch 351/10000
4/4 - 0s - loss: 19.8562 - val_loss: 8.4468

Epoch 00351: val_loss did not improve from 8.19692
Epoch 352/10000
4/4 - 0s - loss: 19.8901 - val_loss: 8.9164

Epoch 00352: val_loss did not improve from 8.19692
Epoch 353/10000
4/4 - 0s - loss: 19.8686 - val_loss: 8.4847

Epoch 00353: val_loss did not improve from 8.19692
Epoch 354/10000
4/4 - 0s - loss: 19.8681 - val_loss: 8.4835

Epoch 00354: val_loss did not improve from 8.19692
Epoch 355/10000
4/4 - 0s - loss: 19.8338 - val_loss: 8.9495

Epoch 00355: val_loss did not improve from 8.19692
Epoch 356/10000
4/4 - 0s - loss: 19.8535 - val_loss: 8.7697

Epoch 00356: val_loss did not improve from 8.19692
Epoch 357/10000
4/4 - 0s - loss: 19.8281 - val_loss: 8.6313

Epoch 00357: val_loss did not improve from 8.19692
Epoch 358/10000
4/4 - 0s - loss: 19.8400 - val_loss: 8.5170

Epoch 00358: val_loss did not improve from 8.19692
Epoch 359/10000
4/4 - 0s - loss: 19.8227 - val_loss: 8.8104

Epoch 00359: val_loss did not improve from 8.19692
Epoch 360/10000
4/4 - 0s - loss: 19.8340 - val_loss: 8.7897

Epoch 00360: val_loss did not improve from 8.19692
Epoch 361/10000
4/4 - 0s - loss: 19.8265 - val_loss: 8.6003

Epoch 00361: val_loss did not improve from 8.19692
Epoch 362/10000
4/4 - 0s - loss: 19.8470 - val_loss: 8.5320

Epoch 00362: val_loss did not improve from 8.19692
Epoch 363/10000
4/4 - 0s - loss: 19.8347 - val_loss: 8.8311

Epoch 00363: val_loss did not improve from 8.19692
Epoch 364/10000
4/4 - 0s - loss: 19.8438 - val_loss: 8.8283

Epoch 00364: val_loss did not improve from 8.19692
Epoch 365/10000
4/4 - 0s - loss: 19.8578 - val_loss: 8.5333

Epoch 00365: val_loss did not improve from 8.19692
Epoch 00365: early stopping
*************************** Fold #: 6 ***************************
Model: "sequential_45"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_495 (Dense)            (None, 30)                210       
_________________________________________________________________
dense_496 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_497 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_498 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_499 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_500 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_501 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_502 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_503 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_504 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_505 (Dense)            (None, 1)                 31        
=================================================================
Total params: 8,611
Trainable params: 8,611
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
4/4 - 0s - loss: 28.5285 - val_loss: 56.4243

Epoch 00001: val_loss improved from inf to 56.42433, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 2/10000
4/4 - 0s - loss: 28.4971 - val_loss: 56.3844

Epoch 00002: val_loss improved from 56.42433 to 56.38438, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 3/10000
4/4 - 0s - loss: 28.4617 - val_loss: 56.3396

Epoch 00003: val_loss improved from 56.38438 to 56.33959, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 4/10000
4/4 - 0s - loss: 28.4216 - val_loss: 56.2879

Epoch 00004: val_loss improved from 56.33959 to 56.28785, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 5/10000
4/4 - 0s - loss: 28.3759 - val_loss: 56.2273

Epoch 00005: val_loss improved from 56.28785 to 56.22733, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 6/10000
4/4 - 0s - loss: 28.3216 - val_loss: 56.1565

Epoch 00006: val_loss improved from 56.22733 to 56.15652, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 7/10000
4/4 - 0s - loss: 28.2585 - val_loss: 56.0725

Epoch 00007: val_loss improved from 56.15652 to 56.07251, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 8/10000
4/4 - 0s - loss: 28.1820 - val_loss: 55.9718

Epoch 00008: val_loss improved from 56.07251 to 55.97177, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 9/10000
4/4 - 0s - loss: 28.0900 - val_loss: 55.8494

Epoch 00009: val_loss improved from 55.97177 to 55.84940, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 10/10000
4/4 - 0s - loss: 27.9796 - val_loss: 55.6982

Epoch 00010: val_loss improved from 55.84940 to 55.69824, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 11/10000
4/4 - 0s - loss: 27.8429 - val_loss: 55.5098

Epoch 00011: val_loss improved from 55.69824 to 55.50980, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 12/10000
4/4 - 0s - loss: 27.6686 - val_loss: 55.2714

Epoch 00012: val_loss improved from 55.50980 to 55.27140, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 13/10000
4/4 - 0s - loss: 27.4506 - val_loss: 54.9618

Epoch 00013: val_loss improved from 55.27140 to 54.96183, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 14/10000
4/4 - 0s - loss: 27.1616 - val_loss: 54.5468

Epoch 00014: val_loss improved from 54.96183 to 54.54679, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 15/10000
4/4 - 0s - loss: 26.7800 - val_loss: 53.9622

Epoch 00015: val_loss improved from 54.54679 to 53.96218, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 16/10000
4/4 - 0s - loss: 26.2117 - val_loss: 53.0943

Epoch 00016: val_loss improved from 53.96218 to 53.09433, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 17/10000
4/4 - 0s - loss: 25.3907 - val_loss: 51.7274

Epoch 00017: val_loss improved from 53.09433 to 51.72738, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 18/10000
4/4 - 0s - loss: 24.0435 - val_loss: 49.5665

Epoch 00018: val_loss improved from 51.72738 to 49.56653, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 19/10000
4/4 - 0s - loss: 22.2157 - val_loss: 46.7827

Epoch 00019: val_loss improved from 49.56653 to 46.78274, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 20/10000
4/4 - 0s - loss: 20.7751 - val_loss: 46.0095

Epoch 00020: val_loss improved from 46.78274 to 46.00954, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 21/10000
4/4 - 0s - loss: 21.2073 - val_loss: 45.5763

Epoch 00021: val_loss improved from 46.00954 to 45.57632, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 22/10000
4/4 - 0s - loss: 20.4768 - val_loss: 45.8870

Epoch 00022: val_loss did not improve from 45.57632
Epoch 23/10000
4/4 - 0s - loss: 20.4537 - val_loss: 46.0061

Epoch 00023: val_loss did not improve from 45.57632
Epoch 24/10000
4/4 - 0s - loss: 20.4059 - val_loss: 45.5843

Epoch 00024: val_loss did not improve from 45.57632
Epoch 25/10000
4/4 - 0s - loss: 20.1603 - val_loss: 44.9695

Epoch 00025: val_loss improved from 45.57632 to 44.96947, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 26/10000
4/4 - 0s - loss: 20.0558 - val_loss: 44.6016

Epoch 00026: val_loss improved from 44.96947 to 44.60162, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 27/10000
4/4 - 0s - loss: 19.9784 - val_loss: 44.4674

Epoch 00027: val_loss improved from 44.60162 to 44.46738, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 28/10000
4/4 - 0s - loss: 19.7955 - val_loss: 44.4557

Epoch 00028: val_loss improved from 44.46738 to 44.45570, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 29/10000
4/4 - 0s - loss: 19.6890 - val_loss: 44.3043

Epoch 00029: val_loss improved from 44.45570 to 44.30433, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 30/10000
4/4 - 0s - loss: 19.5335 - val_loss: 43.8791

Epoch 00030: val_loss improved from 44.30433 to 43.87911, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 31/10000
4/4 - 0s - loss: 19.3728 - val_loss: 43.3800

Epoch 00031: val_loss improved from 43.87911 to 43.38003, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 32/10000
4/4 - 0s - loss: 19.2325 - val_loss: 43.0625

Epoch 00032: val_loss improved from 43.38003 to 43.06251, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 33/10000
4/4 - 0s - loss: 19.0566 - val_loss: 42.8570

Epoch 00033: val_loss improved from 43.06251 to 42.85704, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 34/10000
4/4 - 0s - loss: 18.8873 - val_loss: 42.5820

Epoch 00034: val_loss improved from 42.85704 to 42.58203, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 35/10000
4/4 - 0s - loss: 18.7199 - val_loss: 42.0939

Epoch 00035: val_loss improved from 42.58203 to 42.09395, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 36/10000
4/4 - 0s - loss: 18.5515 - val_loss: 41.6856

Epoch 00036: val_loss improved from 42.09395 to 41.68559, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 37/10000
4/4 - 0s - loss: 18.4523 - val_loss: 41.3023

Epoch 00037: val_loss improved from 41.68559 to 41.30234, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 38/10000
4/4 - 0s - loss: 18.2970 - val_loss: 41.2753

Epoch 00038: val_loss improved from 41.30234 to 41.27526, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 39/10000
4/4 - 0s - loss: 18.1940 - val_loss: 40.9428

Epoch 00039: val_loss improved from 41.27526 to 40.94279, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 40/10000
4/4 - 0s - loss: 18.0903 - val_loss: 40.6653

Epoch 00040: val_loss improved from 40.94279 to 40.66528, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 41/10000
4/4 - 0s - loss: 17.9965 - val_loss: 40.3559

Epoch 00041: val_loss improved from 40.66528 to 40.35586, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 42/10000
4/4 - 0s - loss: 17.9355 - val_loss: 39.9821

Epoch 00042: val_loss improved from 40.35586 to 39.98212, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 43/10000
4/4 - 0s - loss: 17.8411 - val_loss: 40.0683

Epoch 00043: val_loss did not improve from 39.98212
Epoch 44/10000
4/4 - 0s - loss: 17.7615 - val_loss: 39.8636

Epoch 00044: val_loss improved from 39.98212 to 39.86359, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 45/10000
4/4 - 0s - loss: 17.6785 - val_loss: 39.4409

Epoch 00045: val_loss improved from 39.86359 to 39.44086, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 46/10000
4/4 - 0s - loss: 17.6424 - val_loss: 39.0284

Epoch 00046: val_loss improved from 39.44086 to 39.02841, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 47/10000
4/4 - 0s - loss: 17.5225 - val_loss: 39.2829

Epoch 00047: val_loss did not improve from 39.02841
Epoch 48/10000
4/4 - 0s - loss: 17.4576 - val_loss: 39.0207

Epoch 00048: val_loss improved from 39.02841 to 39.02071, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 49/10000
4/4 - 0s - loss: 17.3789 - val_loss: 38.5493

Epoch 00049: val_loss improved from 39.02071 to 38.54927, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 50/10000
4/4 - 0s - loss: 17.3299 - val_loss: 38.3243

Epoch 00050: val_loss improved from 38.54927 to 38.32434, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 51/10000
4/4 - 0s - loss: 17.2500 - val_loss: 38.6076

Epoch 00051: val_loss did not improve from 38.32434
Epoch 52/10000
4/4 - 0s - loss: 17.2082 - val_loss: 38.3373

Epoch 00052: val_loss did not improve from 38.32434
Epoch 53/10000
4/4 - 0s - loss: 17.1327 - val_loss: 38.0185

Epoch 00053: val_loss improved from 38.32434 to 38.01846, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 54/10000
4/4 - 0s - loss: 17.1110 - val_loss: 37.7742

Epoch 00054: val_loss improved from 38.01846 to 37.77417, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 55/10000
4/4 - 0s - loss: 17.0471 - val_loss: 37.6888

Epoch 00055: val_loss improved from 37.77417 to 37.68884, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 56/10000
4/4 - 0s - loss: 17.0040 - val_loss: 37.8004

Epoch 00056: val_loss did not improve from 37.68884
Epoch 57/10000
4/4 - 0s - loss: 16.9804 - val_loss: 37.7978

Epoch 00057: val_loss did not improve from 37.68884
Epoch 58/10000
4/4 - 0s - loss: 16.9621 - val_loss: 37.8532

Epoch 00058: val_loss did not improve from 37.68884
Epoch 59/10000
4/4 - 0s - loss: 16.9370 - val_loss: 37.5519

Epoch 00059: val_loss improved from 37.68884 to 37.55188, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 60/10000
4/4 - 0s - loss: 16.9054 - val_loss: 37.2884

Epoch 00060: val_loss improved from 37.55188 to 37.28838, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 61/10000
4/4 - 0s - loss: 16.9168 - val_loss: 37.5361

Epoch 00061: val_loss did not improve from 37.28838
Epoch 62/10000
4/4 - 0s - loss: 16.8646 - val_loss: 37.2618

Epoch 00062: val_loss improved from 37.28838 to 37.26180, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 63/10000
4/4 - 0s - loss: 16.8873 - val_loss: 37.0561

Epoch 00063: val_loss improved from 37.26180 to 37.05605, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 64/10000
4/4 - 0s - loss: 16.8575 - val_loss: 37.4905

Epoch 00064: val_loss did not improve from 37.05605
Epoch 65/10000
4/4 - 0s - loss: 16.8388 - val_loss: 37.3363

Epoch 00065: val_loss did not improve from 37.05605
Epoch 66/10000
4/4 - 0s - loss: 16.8436 - val_loss: 37.0452

Epoch 00066: val_loss improved from 37.05605 to 37.04515, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 67/10000
4/4 - 0s - loss: 16.8224 - val_loss: 37.2302

Epoch 00067: val_loss did not improve from 37.04515
Epoch 68/10000
4/4 - 0s - loss: 16.8121 - val_loss: 37.1970

Epoch 00068: val_loss did not improve from 37.04515
Epoch 69/10000
4/4 - 0s - loss: 16.8006 - val_loss: 36.9217

Epoch 00069: val_loss improved from 37.04515 to 36.92170, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 70/10000
4/4 - 0s - loss: 16.7986 - val_loss: 37.1967

Epoch 00070: val_loss did not improve from 36.92170
Epoch 71/10000
4/4 - 0s - loss: 16.7911 - val_loss: 37.6329

Epoch 00071: val_loss did not improve from 36.92170
Epoch 72/10000
4/4 - 0s - loss: 16.8165 - val_loss: 37.3144

Epoch 00072: val_loss did not improve from 36.92170
Epoch 73/10000
4/4 - 0s - loss: 16.7685 - val_loss: 36.9485

Epoch 00073: val_loss did not improve from 36.92170
Epoch 74/10000
4/4 - 0s - loss: 16.8004 - val_loss: 36.8766

Epoch 00074: val_loss improved from 36.92170 to 36.87664, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 75/10000
4/4 - 0s - loss: 16.7831 - val_loss: 37.1477

Epoch 00075: val_loss did not improve from 36.87664
Epoch 76/10000
4/4 - 0s - loss: 16.7707 - val_loss: 37.2326

Epoch 00076: val_loss did not improve from 36.87664
Epoch 77/10000
4/4 - 0s - loss: 16.7800 - val_loss: 37.1577

Epoch 00077: val_loss did not improve from 36.87664
Epoch 78/10000
4/4 - 0s - loss: 16.7743 - val_loss: 37.0810

Epoch 00078: val_loss did not improve from 36.87664
Epoch 79/10000
4/4 - 0s - loss: 16.7692 - val_loss: 37.4348

Epoch 00079: val_loss did not improve from 36.87664
Epoch 80/10000
4/4 - 0s - loss: 16.7631 - val_loss: 37.0910

Epoch 00080: val_loss did not improve from 36.87664
Epoch 81/10000
4/4 - 0s - loss: 16.7648 - val_loss: 37.0509

Epoch 00081: val_loss did not improve from 36.87664
Epoch 82/10000
4/4 - 0s - loss: 16.7490 - val_loss: 37.3710

Epoch 00082: val_loss did not improve from 36.87664
Epoch 83/10000
4/4 - 0s - loss: 16.7794 - val_loss: 37.3009

Epoch 00083: val_loss did not improve from 36.87664
Epoch 84/10000
4/4 - 0s - loss: 16.7479 - val_loss: 36.9063

Epoch 00084: val_loss did not improve from 36.87664
Epoch 85/10000
4/4 - 0s - loss: 16.7552 - val_loss: 37.0910

Epoch 00085: val_loss did not improve from 36.87664
Epoch 86/10000
4/4 - 0s - loss: 16.7527 - val_loss: 37.4121

Epoch 00086: val_loss did not improve from 36.87664
Epoch 87/10000
4/4 - 0s - loss: 16.7555 - val_loss: 37.2226

Epoch 00087: val_loss did not improve from 36.87664
Epoch 88/10000
4/4 - 0s - loss: 16.7592 - val_loss: 36.9707

Epoch 00088: val_loss did not improve from 36.87664
Epoch 89/10000
4/4 - 0s - loss: 16.7488 - val_loss: 37.1768

Epoch 00089: val_loss did not improve from 36.87664
Epoch 90/10000
4/4 - 0s - loss: 16.7506 - val_loss: 37.1128

Epoch 00090: val_loss did not improve from 36.87664
Epoch 91/10000
4/4 - 0s - loss: 16.7756 - val_loss: 36.8845

Epoch 00091: val_loss did not improve from 36.87664
Epoch 92/10000
4/4 - 0s - loss: 16.7271 - val_loss: 37.3352

Epoch 00092: val_loss did not improve from 36.87664
Epoch 93/10000
4/4 - 0s - loss: 16.7578 - val_loss: 37.5052

Epoch 00093: val_loss did not improve from 36.87664
Epoch 94/10000
4/4 - 0s - loss: 16.7426 - val_loss: 37.0699

Epoch 00094: val_loss did not improve from 36.87664
Epoch 95/10000
4/4 - 0s - loss: 16.7902 - val_loss: 36.8357

Epoch 00095: val_loss improved from 36.87664 to 36.83572, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 96/10000
4/4 - 0s - loss: 16.8572 - val_loss: 37.7280

Epoch 00096: val_loss did not improve from 36.83572
Epoch 97/10000
4/4 - 0s - loss: 16.7953 - val_loss: 37.3666

Epoch 00097: val_loss did not improve from 36.83572
Epoch 98/10000
4/4 - 0s - loss: 16.7766 - val_loss: 36.6642

Epoch 00098: val_loss improved from 36.83572 to 36.66422, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 99/10000
4/4 - 0s - loss: 16.7987 - val_loss: 37.1439

Epoch 00099: val_loss did not improve from 36.66422
Epoch 100/10000
4/4 - 0s - loss: 16.7384 - val_loss: 37.1895

Epoch 00100: val_loss did not improve from 36.66422
Epoch 101/10000
4/4 - 0s - loss: 16.7325 - val_loss: 37.1814

Epoch 00101: val_loss did not improve from 36.66422
Epoch 102/10000
4/4 - 0s - loss: 16.7355 - val_loss: 36.9813

Epoch 00102: val_loss did not improve from 36.66422
Epoch 103/10000
4/4 - 0s - loss: 16.7543 - val_loss: 37.1866

Epoch 00103: val_loss did not improve from 36.66422
Epoch 104/10000
4/4 - 0s - loss: 16.7354 - val_loss: 36.8970

Epoch 00104: val_loss did not improve from 36.66422
Epoch 105/10000
4/4 - 0s - loss: 16.7388 - val_loss: 37.1735

Epoch 00105: val_loss did not improve from 36.66422
Epoch 106/10000
4/4 - 0s - loss: 16.7310 - val_loss: 37.2695

Epoch 00106: val_loss did not improve from 36.66422
Epoch 107/10000
4/4 - 0s - loss: 16.7319 - val_loss: 37.3453

Epoch 00107: val_loss did not improve from 36.66422
Epoch 108/10000
4/4 - 0s - loss: 16.7317 - val_loss: 37.1352

Epoch 00108: val_loss did not improve from 36.66422
Epoch 109/10000
4/4 - 0s - loss: 16.7198 - val_loss: 37.1535

Epoch 00109: val_loss did not improve from 36.66422
Epoch 110/10000
4/4 - 0s - loss: 16.7179 - val_loss: 37.0877

Epoch 00110: val_loss did not improve from 36.66422
Epoch 111/10000
4/4 - 0s - loss: 16.7357 - val_loss: 37.1527

Epoch 00111: val_loss did not improve from 36.66422
Epoch 112/10000
4/4 - 0s - loss: 16.7676 - val_loss: 36.8499

Epoch 00112: val_loss did not improve from 36.66422
Epoch 113/10000
4/4 - 0s - loss: 16.7311 - val_loss: 37.2976

Epoch 00113: val_loss did not improve from 36.66422
Epoch 114/10000
4/4 - 0s - loss: 16.7299 - val_loss: 37.2358

Epoch 00114: val_loss did not improve from 36.66422
Epoch 115/10000
4/4 - 0s - loss: 16.7111 - val_loss: 36.9077

Epoch 00115: val_loss did not improve from 36.66422
Epoch 116/10000
4/4 - 0s - loss: 16.7329 - val_loss: 37.0106

Epoch 00116: val_loss did not improve from 36.66422
Epoch 117/10000
4/4 - 0s - loss: 16.7173 - val_loss: 37.2749

Epoch 00117: val_loss did not improve from 36.66422
Epoch 118/10000
4/4 - 0s - loss: 16.7306 - val_loss: 37.4595

Epoch 00118: val_loss did not improve from 36.66422
Epoch 119/10000
4/4 - 0s - loss: 16.7542 - val_loss: 36.9508

Epoch 00119: val_loss did not improve from 36.66422
Epoch 120/10000
4/4 - 0s - loss: 16.7190 - val_loss: 37.1033

Epoch 00120: val_loss did not improve from 36.66422
Epoch 121/10000
4/4 - 0s - loss: 16.7445 - val_loss: 37.3635

Epoch 00121: val_loss did not improve from 36.66422
Epoch 122/10000
4/4 - 0s - loss: 16.7145 - val_loss: 37.0976

Epoch 00122: val_loss did not improve from 36.66422
Epoch 123/10000
4/4 - 0s - loss: 16.7092 - val_loss: 36.8244

Epoch 00123: val_loss did not improve from 36.66422
Epoch 124/10000
4/4 - 0s - loss: 16.7388 - val_loss: 36.9591

Epoch 00124: val_loss did not improve from 36.66422
Epoch 125/10000
4/4 - 0s - loss: 16.7086 - val_loss: 37.2447

Epoch 00125: val_loss did not improve from 36.66422
Epoch 126/10000
4/4 - 0s - loss: 16.7410 - val_loss: 37.4801

Epoch 00126: val_loss did not improve from 36.66422
Epoch 127/10000
4/4 - 0s - loss: 16.7175 - val_loss: 37.0766

Epoch 00127: val_loss did not improve from 36.66422
Epoch 128/10000
4/4 - 0s - loss: 16.7370 - val_loss: 36.8295

Epoch 00128: val_loss did not improve from 36.66422
Epoch 129/10000
4/4 - 0s - loss: 16.7290 - val_loss: 37.3966

Epoch 00129: val_loss did not improve from 36.66422
Epoch 130/10000
4/4 - 0s - loss: 16.7178 - val_loss: 37.3100

Epoch 00130: val_loss did not improve from 36.66422
Epoch 131/10000
4/4 - 0s - loss: 16.7134 - val_loss: 37.0144

Epoch 00131: val_loss did not improve from 36.66422
Epoch 132/10000
4/4 - 0s - loss: 16.7284 - val_loss: 36.8853

Epoch 00132: val_loss did not improve from 36.66422
Epoch 133/10000
4/4 - 0s - loss: 16.7116 - val_loss: 37.0803

Epoch 00133: val_loss did not improve from 36.66422
Epoch 134/10000
4/4 - 0s - loss: 16.7150 - val_loss: 37.4068

Epoch 00134: val_loss did not improve from 36.66422
Epoch 135/10000
4/4 - 0s - loss: 16.7244 - val_loss: 37.3598

Epoch 00135: val_loss did not improve from 36.66422
Epoch 136/10000
4/4 - 0s - loss: 16.7206 - val_loss: 37.0251

Epoch 00136: val_loss did not improve from 36.66422
Epoch 137/10000
4/4 - 0s - loss: 16.7088 - val_loss: 36.9584

Epoch 00137: val_loss did not improve from 36.66422
Epoch 138/10000
4/4 - 0s - loss: 16.7039 - val_loss: 37.1765

Epoch 00138: val_loss did not improve from 36.66422
Epoch 139/10000
4/4 - 0s - loss: 16.7090 - val_loss: 37.2827

Epoch 00139: val_loss did not improve from 36.66422
Epoch 140/10000
4/4 - 0s - loss: 16.7175 - val_loss: 37.0535

Epoch 00140: val_loss did not improve from 36.66422
Epoch 141/10000
4/4 - 0s - loss: 16.7135 - val_loss: 37.2558

Epoch 00141: val_loss did not improve from 36.66422
Epoch 142/10000
4/4 - 0s - loss: 16.6971 - val_loss: 37.0194

Epoch 00142: val_loss did not improve from 36.66422
Epoch 143/10000
4/4 - 0s - loss: 16.7415 - val_loss: 36.9429

Epoch 00143: val_loss did not improve from 36.66422
Epoch 144/10000
4/4 - 0s - loss: 16.7113 - val_loss: 37.2822

Epoch 00144: val_loss did not improve from 36.66422
Epoch 145/10000
4/4 - 0s - loss: 16.7137 - val_loss: 37.1077

Epoch 00145: val_loss did not improve from 36.66422
Epoch 146/10000
4/4 - 0s - loss: 16.7037 - val_loss: 36.9747

Epoch 00146: val_loss did not improve from 36.66422
Epoch 147/10000
4/4 - 0s - loss: 16.6998 - val_loss: 37.1334

Epoch 00147: val_loss did not improve from 36.66422
Epoch 148/10000
4/4 - 0s - loss: 16.7032 - val_loss: 37.4835

Epoch 00148: val_loss did not improve from 36.66422
Epoch 149/10000
4/4 - 0s - loss: 16.7195 - val_loss: 37.2299

Epoch 00149: val_loss did not improve from 36.66422
Epoch 150/10000
4/4 - 0s - loss: 16.6998 - val_loss: 36.9709

Epoch 00150: val_loss did not improve from 36.66422
Epoch 151/10000
4/4 - 0s - loss: 16.7187 - val_loss: 37.1309

Epoch 00151: val_loss did not improve from 36.66422
Epoch 152/10000
4/4 - 0s - loss: 16.6983 - val_loss: 37.2208

Epoch 00152: val_loss did not improve from 36.66422
Epoch 153/10000
4/4 - 0s - loss: 16.7037 - val_loss: 37.2545

Epoch 00153: val_loss did not improve from 36.66422
Epoch 154/10000
4/4 - 0s - loss: 16.7632 - val_loss: 37.0468

Epoch 00154: val_loss did not improve from 36.66422
Epoch 155/10000
4/4 - 0s - loss: 16.7258 - val_loss: 37.5743

Epoch 00155: val_loss did not improve from 36.66422
Epoch 156/10000
4/4 - 0s - loss: 16.7216 - val_loss: 37.1665

Epoch 00156: val_loss did not improve from 36.66422
Epoch 157/10000
4/4 - 0s - loss: 16.6931 - val_loss: 37.0891

Epoch 00157: val_loss did not improve from 36.66422
Epoch 158/10000
4/4 - 0s - loss: 16.7530 - val_loss: 36.9894

Epoch 00158: val_loss did not improve from 36.66422
Epoch 159/10000
4/4 - 0s - loss: 16.6993 - val_loss: 37.4423

Epoch 00159: val_loss did not improve from 36.66422
Epoch 160/10000
4/4 - 0s - loss: 16.7204 - val_loss: 37.3090

Epoch 00160: val_loss did not improve from 36.66422
Epoch 161/10000
4/4 - 0s - loss: 16.7192 - val_loss: 36.8187

Epoch 00161: val_loss did not improve from 36.66422
Epoch 162/10000
4/4 - 0s - loss: 16.7179 - val_loss: 37.2073

Epoch 00162: val_loss did not improve from 36.66422
Epoch 163/10000
4/4 - 0s - loss: 16.6972 - val_loss: 37.1513

Epoch 00163: val_loss did not improve from 36.66422
Epoch 164/10000
4/4 - 0s - loss: 16.7012 - val_loss: 37.1794

Epoch 00164: val_loss did not improve from 36.66422
Epoch 165/10000
4/4 - 0s - loss: 16.7015 - val_loss: 37.3363

Epoch 00165: val_loss did not improve from 36.66422
Epoch 166/10000
4/4 - 0s - loss: 16.6988 - val_loss: 37.1835

Epoch 00166: val_loss did not improve from 36.66422
Epoch 167/10000
4/4 - 0s - loss: 16.7096 - val_loss: 37.1713

Epoch 00167: val_loss did not improve from 36.66422
Epoch 168/10000
4/4 - 0s - loss: 16.6896 - val_loss: 37.5767

Epoch 00168: val_loss did not improve from 36.66422
Epoch 169/10000
4/4 - 0s - loss: 16.7448 - val_loss: 37.5110

Epoch 00169: val_loss did not improve from 36.66422
Epoch 170/10000
4/4 - 0s - loss: 16.6814 - val_loss: 36.8350

Epoch 00170: val_loss did not improve from 36.66422
Epoch 171/10000
4/4 - 0s - loss: 16.7424 - val_loss: 36.8665

Epoch 00171: val_loss did not improve from 36.66422
Epoch 172/10000
4/4 - 0s - loss: 16.6867 - val_loss: 37.2441

Epoch 00172: val_loss did not improve from 36.66422
Epoch 173/10000
4/4 - 0s - loss: 16.7126 - val_loss: 37.5018

Epoch 00173: val_loss did not improve from 36.66422
Epoch 174/10000
4/4 - 0s - loss: 16.7163 - val_loss: 37.0466

Epoch 00174: val_loss did not improve from 36.66422
Epoch 175/10000
4/4 - 0s - loss: 16.7259 - val_loss: 36.6482

Epoch 00175: val_loss improved from 36.66422 to 36.64824, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 176/10000
4/4 - 0s - loss: 16.7314 - val_loss: 37.2161

Epoch 00176: val_loss did not improve from 36.64824
Epoch 177/10000
4/4 - 0s - loss: 16.7955 - val_loss: 37.7899

Epoch 00177: val_loss did not improve from 36.64824
Epoch 178/10000
4/4 - 0s - loss: 16.7132 - val_loss: 36.9564

Epoch 00178: val_loss did not improve from 36.64824
Epoch 179/10000
4/4 - 0s - loss: 16.7271 - val_loss: 36.6040

Epoch 00179: val_loss improved from 36.64824 to 36.60405, saving model to ./results/dataset/trial_5/ckpt_6
Epoch 180/10000
4/4 - 0s - loss: 16.7504 - val_loss: 36.9267

Epoch 00180: val_loss did not improve from 36.60405
Epoch 181/10000
4/4 - 0s - loss: 16.6927 - val_loss: 37.2972

Epoch 00181: val_loss did not improve from 36.60405
Epoch 182/10000
4/4 - 0s - loss: 16.7124 - val_loss: 37.1815

Epoch 00182: val_loss did not improve from 36.60405
Epoch 183/10000
4/4 - 0s - loss: 16.6970 - val_loss: 37.1406

Epoch 00183: val_loss did not improve from 36.60405
Epoch 184/10000
4/4 - 0s - loss: 16.6848 - val_loss: 37.2763

Epoch 00184: val_loss did not improve from 36.60405
Epoch 185/10000
4/4 - 0s - loss: 16.6915 - val_loss: 37.2281

Epoch 00185: val_loss did not improve from 36.60405
Epoch 186/10000
4/4 - 0s - loss: 16.6882 - val_loss: 37.1570

Epoch 00186: val_loss did not improve from 36.60405
Epoch 187/10000
4/4 - 0s - loss: 16.6845 - val_loss: 37.2911

Epoch 00187: val_loss did not improve from 36.60405
Epoch 188/10000
4/4 - 0s - loss: 16.6990 - val_loss: 37.2052

Epoch 00188: val_loss did not improve from 36.60405
Epoch 189/10000
4/4 - 0s - loss: 16.6919 - val_loss: 37.3106

Epoch 00189: val_loss did not improve from 36.60405
Epoch 190/10000
4/4 - 0s - loss: 16.7159 - val_loss: 37.0911

Epoch 00190: val_loss did not improve from 36.60405
Epoch 191/10000
4/4 - 0s - loss: 16.6791 - val_loss: 37.3169

Epoch 00191: val_loss did not improve from 36.60405
Epoch 192/10000
4/4 - 0s - loss: 16.6888 - val_loss: 37.4293

Epoch 00192: val_loss did not improve from 36.60405
Epoch 193/10000
4/4 - 0s - loss: 16.6913 - val_loss: 37.2743

Epoch 00193: val_loss did not improve from 36.60405
Epoch 194/10000
4/4 - 0s - loss: 16.6869 - val_loss: 37.0506

Epoch 00194: val_loss did not improve from 36.60405
Epoch 195/10000
4/4 - 0s - loss: 16.7017 - val_loss: 37.1828

Epoch 00195: val_loss did not improve from 36.60405
Epoch 196/10000
4/4 - 0s - loss: 16.6830 - val_loss: 37.0208

Epoch 00196: val_loss did not improve from 36.60405
Epoch 197/10000
4/4 - 0s - loss: 16.6972 - val_loss: 37.0929

Epoch 00197: val_loss did not improve from 36.60405
Epoch 198/10000
4/4 - 0s - loss: 16.7272 - val_loss: 36.8985

Epoch 00198: val_loss did not improve from 36.60405
Epoch 199/10000
4/4 - 0s - loss: 16.6731 - val_loss: 37.3799

Epoch 00199: val_loss did not improve from 36.60405
Epoch 200/10000
4/4 - 0s - loss: 16.7014 - val_loss: 37.4727

Epoch 00200: val_loss did not improve from 36.60405
Epoch 201/10000
4/4 - 0s - loss: 16.7040 - val_loss: 37.2239

Epoch 00201: val_loss did not improve from 36.60405
Epoch 202/10000
4/4 - 0s - loss: 16.6881 - val_loss: 37.1457

Epoch 00202: val_loss did not improve from 36.60405
Epoch 203/10000
4/4 - 0s - loss: 16.6899 - val_loss: 37.2729

Epoch 00203: val_loss did not improve from 36.60405
Epoch 204/10000
4/4 - 0s - loss: 16.7520 - val_loss: 37.5611

Epoch 00204: val_loss did not improve from 36.60405
Epoch 205/10000
4/4 - 0s - loss: 16.7061 - val_loss: 36.8696

Epoch 00205: val_loss did not improve from 36.60405
Epoch 206/10000
4/4 - 0s - loss: 16.7065 - val_loss: 36.9896

Epoch 00206: val_loss did not improve from 36.60405
Epoch 207/10000
4/4 - 0s - loss: 16.6765 - val_loss: 37.2400

Epoch 00207: val_loss did not improve from 36.60405
Epoch 208/10000
4/4 - 0s - loss: 16.7129 - val_loss: 37.4561

Epoch 00208: val_loss did not improve from 36.60405
Epoch 209/10000
4/4 - 0s - loss: 16.6923 - val_loss: 37.0223

Epoch 00209: val_loss did not improve from 36.60405
Epoch 210/10000
4/4 - 0s - loss: 16.6893 - val_loss: 36.9763

Epoch 00210: val_loss did not improve from 36.60405
Epoch 211/10000
4/4 - 0s - loss: 16.6851 - val_loss: 37.1877

Epoch 00211: val_loss did not improve from 36.60405
Epoch 212/10000
4/4 - 0s - loss: 16.6770 - val_loss: 37.3001

Epoch 00212: val_loss did not improve from 36.60405
Epoch 213/10000
4/4 - 0s - loss: 16.6938 - val_loss: 37.2476

Epoch 00213: val_loss did not improve from 36.60405
Epoch 214/10000
4/4 - 0s - loss: 16.6819 - val_loss: 37.2282

Epoch 00214: val_loss did not improve from 36.60405
Epoch 215/10000
4/4 - 0s - loss: 16.6890 - val_loss: 37.2298

Epoch 00215: val_loss did not improve from 36.60405
Epoch 216/10000
4/4 - 0s - loss: 16.6708 - val_loss: 36.9745

Epoch 00216: val_loss did not improve from 36.60405
Epoch 217/10000
4/4 - 0s - loss: 16.6965 - val_loss: 36.9482

Epoch 00217: val_loss did not improve from 36.60405
Epoch 218/10000
4/4 - 0s - loss: 16.6955 - val_loss: 36.9998

Epoch 00218: val_loss did not improve from 36.60405
Epoch 219/10000
4/4 - 0s - loss: 16.6901 - val_loss: 37.4397

Epoch 00219: val_loss did not improve from 36.60405
Epoch 220/10000
4/4 - 0s - loss: 16.7188 - val_loss: 37.1699

Epoch 00220: val_loss did not improve from 36.60405
Epoch 221/10000
4/4 - 0s - loss: 16.6853 - val_loss: 37.1457

Epoch 00221: val_loss did not improve from 36.60405
Epoch 222/10000
4/4 - 0s - loss: 16.6815 - val_loss: 37.3318

Epoch 00222: val_loss did not improve from 36.60405
Epoch 223/10000
4/4 - 0s - loss: 16.6927 - val_loss: 37.2479

Epoch 00223: val_loss did not improve from 36.60405
Epoch 224/10000
4/4 - 0s - loss: 16.6814 - val_loss: 37.3511

Epoch 00224: val_loss did not improve from 36.60405
Epoch 225/10000
4/4 - 0s - loss: 16.6927 - val_loss: 37.1581

Epoch 00225: val_loss did not improve from 36.60405
Epoch 226/10000
4/4 - 0s - loss: 16.6850 - val_loss: 37.3006

Epoch 00226: val_loss did not improve from 36.60405
Epoch 227/10000
4/4 - 0s - loss: 16.6990 - val_loss: 37.0351

Epoch 00227: val_loss did not improve from 36.60405
Epoch 228/10000
4/4 - 0s - loss: 16.6838 - val_loss: 37.1166

Epoch 00228: val_loss did not improve from 36.60405
Epoch 229/10000
4/4 - 0s - loss: 16.6690 - val_loss: 37.4140

Epoch 00229: val_loss did not improve from 36.60405
Epoch 230/10000
4/4 - 0s - loss: 16.7209 - val_loss: 37.5294

Epoch 00230: val_loss did not improve from 36.60405
Epoch 231/10000
4/4 - 0s - loss: 16.6893 - val_loss: 37.0246

Epoch 00231: val_loss did not improve from 36.60405
Epoch 232/10000
4/4 - 0s - loss: 16.7457 - val_loss: 36.9363

Epoch 00232: val_loss did not improve from 36.60405
Epoch 233/10000
4/4 - 0s - loss: 16.7026 - val_loss: 37.5487

Epoch 00233: val_loss did not improve from 36.60405
Epoch 234/10000
4/4 - 0s - loss: 16.7054 - val_loss: 37.2461

Epoch 00234: val_loss did not improve from 36.60405
Epoch 235/10000
4/4 - 0s - loss: 16.6757 - val_loss: 37.0912

Epoch 00235: val_loss did not improve from 36.60405
Epoch 236/10000
4/4 - 0s - loss: 16.6886 - val_loss: 37.1491

Epoch 00236: val_loss did not improve from 36.60405
Epoch 237/10000
4/4 - 0s - loss: 16.6754 - val_loss: 37.0596

Epoch 00237: val_loss did not improve from 36.60405
Epoch 238/10000
4/4 - 0s - loss: 16.6956 - val_loss: 37.0538

Epoch 00238: val_loss did not improve from 36.60405
Epoch 239/10000
4/4 - 0s - loss: 16.6902 - val_loss: 37.0996

Epoch 00239: val_loss did not improve from 36.60405
Epoch 240/10000
4/4 - 0s - loss: 16.6854 - val_loss: 37.4150

Epoch 00240: val_loss did not improve from 36.60405
Epoch 241/10000
4/4 - 0s - loss: 16.6981 - val_loss: 37.2811

Epoch 00241: val_loss did not improve from 36.60405
Epoch 242/10000
4/4 - 0s - loss: 16.6764 - val_loss: 37.0636

Epoch 00242: val_loss did not improve from 36.60405
Epoch 243/10000
4/4 - 0s - loss: 16.7048 - val_loss: 37.0015

Epoch 00243: val_loss did not improve from 36.60405
Epoch 244/10000
4/4 - 0s - loss: 16.7338 - val_loss: 37.5476

Epoch 00244: val_loss did not improve from 36.60405
Epoch 245/10000
4/4 - 0s - loss: 16.7184 - val_loss: 37.0399

Epoch 00245: val_loss did not improve from 36.60405
Epoch 246/10000
4/4 - 0s - loss: 16.6777 - val_loss: 37.1352

Epoch 00246: val_loss did not improve from 36.60405
Epoch 247/10000
4/4 - 0s - loss: 16.6756 - val_loss: 37.1896

Epoch 00247: val_loss did not improve from 36.60405
Epoch 248/10000
4/4 - 0s - loss: 16.6784 - val_loss: 37.1020

Epoch 00248: val_loss did not improve from 36.60405
Epoch 249/10000
4/4 - 0s - loss: 16.6892 - val_loss: 37.1317

Epoch 00249: val_loss did not improve from 36.60405
Epoch 250/10000
4/4 - 0s - loss: 16.6784 - val_loss: 37.4519

Epoch 00250: val_loss did not improve from 36.60405
Epoch 251/10000
4/4 - 0s - loss: 16.6892 - val_loss: 37.2481

Epoch 00251: val_loss did not improve from 36.60405
Epoch 252/10000
4/4 - 0s - loss: 16.7083 - val_loss: 37.0775

Epoch 00252: val_loss did not improve from 36.60405
Epoch 253/10000
4/4 - 0s - loss: 16.7022 - val_loss: 37.2404

Epoch 00253: val_loss did not improve from 36.60405
Epoch 254/10000
4/4 - 0s - loss: 16.6952 - val_loss: 37.1310

Epoch 00254: val_loss did not improve from 36.60405
Epoch 255/10000
4/4 - 0s - loss: 16.7143 - val_loss: 37.5402

Epoch 00255: val_loss did not improve from 36.60405
Epoch 256/10000
4/4 - 0s - loss: 16.6852 - val_loss: 37.1182

Epoch 00256: val_loss did not improve from 36.60405
Epoch 257/10000
4/4 - 0s - loss: 16.7001 - val_loss: 36.9202

Epoch 00257: val_loss did not improve from 36.60405
Epoch 258/10000
4/4 - 0s - loss: 16.7107 - val_loss: 37.3307

Epoch 00258: val_loss did not improve from 36.60405
Epoch 259/10000
4/4 - 0s - loss: 16.6795 - val_loss: 37.1244

Epoch 00259: val_loss did not improve from 36.60405
Epoch 260/10000
4/4 - 0s - loss: 16.6848 - val_loss: 37.0505

Epoch 00260: val_loss did not improve from 36.60405
Epoch 261/10000
4/4 - 0s - loss: 16.6700 - val_loss: 37.4016

Epoch 00261: val_loss did not improve from 36.60405
Epoch 262/10000
4/4 - 0s - loss: 16.6839 - val_loss: 37.4639

Epoch 00262: val_loss did not improve from 36.60405
Epoch 263/10000
4/4 - 0s - loss: 16.6907 - val_loss: 37.2302

Epoch 00263: val_loss did not improve from 36.60405
Epoch 264/10000
4/4 - 0s - loss: 16.6732 - val_loss: 37.2583

Epoch 00264: val_loss did not improve from 36.60405
Epoch 265/10000
4/4 - 0s - loss: 16.6777 - val_loss: 37.2858

Epoch 00265: val_loss did not improve from 36.60405
Epoch 266/10000
4/4 - 0s - loss: 16.6752 - val_loss: 37.2509

Epoch 00266: val_loss did not improve from 36.60405
Epoch 267/10000
4/4 - 0s - loss: 16.6773 - val_loss: 37.2733

Epoch 00267: val_loss did not improve from 36.60405
Epoch 268/10000
4/4 - 0s - loss: 16.6795 - val_loss: 37.1050

Epoch 00268: val_loss did not improve from 36.60405
Epoch 269/10000
4/4 - 0s - loss: 16.6774 - val_loss: 37.0751

Epoch 00269: val_loss did not improve from 36.60405
Epoch 270/10000
4/4 - 0s - loss: 16.6857 - val_loss: 37.2907

Epoch 00270: val_loss did not improve from 36.60405
Epoch 271/10000
4/4 - 0s - loss: 16.6728 - val_loss: 37.1312

Epoch 00271: val_loss did not improve from 36.60405
Epoch 272/10000
4/4 - 0s - loss: 16.6744 - val_loss: 37.1279

Epoch 00272: val_loss did not improve from 36.60405
Epoch 273/10000
4/4 - 0s - loss: 16.6733 - val_loss: 37.2712

Epoch 00273: val_loss did not improve from 36.60405
Epoch 274/10000
4/4 - 0s - loss: 16.6748 - val_loss: 37.3846

Epoch 00274: val_loss did not improve from 36.60405
Epoch 275/10000
4/4 - 0s - loss: 16.6811 - val_loss: 37.2259

Epoch 00275: val_loss did not improve from 36.60405
Epoch 276/10000
4/4 - 0s - loss: 16.6809 - val_loss: 37.1847

Epoch 00276: val_loss did not improve from 36.60405
Epoch 277/10000
4/4 - 0s - loss: 16.6773 - val_loss: 37.4237

Epoch 00277: val_loss did not improve from 36.60405
Epoch 278/10000
4/4 - 0s - loss: 16.6944 - val_loss: 37.1314

Epoch 00278: val_loss did not improve from 36.60405
Epoch 279/10000
4/4 - 0s - loss: 16.6993 - val_loss: 37.1124

Epoch 00279: val_loss did not improve from 36.60405
Epoch 280/10000
4/4 - 0s - loss: 16.6699 - val_loss: 37.2471

Epoch 00280: val_loss did not improve from 36.60405
Epoch 281/10000
4/4 - 0s - loss: 16.6915 - val_loss: 37.4524

Epoch 00281: val_loss did not improve from 36.60405
Epoch 282/10000
4/4 - 0s - loss: 16.6833 - val_loss: 37.2627

Epoch 00282: val_loss did not improve from 36.60405
Epoch 283/10000
4/4 - 0s - loss: 16.6753 - val_loss: 37.1877

Epoch 00283: val_loss did not improve from 36.60405
Epoch 284/10000
4/4 - 0s - loss: 16.6818 - val_loss: 37.0780

Epoch 00284: val_loss did not improve from 36.60405
Epoch 285/10000
4/4 - 0s - loss: 16.6857 - val_loss: 36.9980

Epoch 00285: val_loss did not improve from 36.60405
Epoch 286/10000
4/4 - 0s - loss: 16.6828 - val_loss: 37.3308

Epoch 00286: val_loss did not improve from 36.60405
Epoch 287/10000
4/4 - 0s - loss: 16.6917 - val_loss: 37.1406

Epoch 00287: val_loss did not improve from 36.60405
Epoch 288/10000
4/4 - 0s - loss: 16.6707 - val_loss: 37.1664

Epoch 00288: val_loss did not improve from 36.60405
Epoch 289/10000
4/4 - 0s - loss: 16.6708 - val_loss: 37.2304

Epoch 00289: val_loss did not improve from 36.60405
Epoch 290/10000
4/4 - 0s - loss: 16.6901 - val_loss: 37.2512

Epoch 00290: val_loss did not improve from 36.60405
Epoch 291/10000
4/4 - 0s - loss: 16.6894 - val_loss: 36.9277

Epoch 00291: val_loss did not improve from 36.60405
Epoch 292/10000
4/4 - 0s - loss: 16.6796 - val_loss: 37.2228

Epoch 00292: val_loss did not improve from 36.60405
Epoch 293/10000
4/4 - 0s - loss: 16.6745 - val_loss: 37.5292

Epoch 00293: val_loss did not improve from 36.60405
Epoch 294/10000
4/4 - 0s - loss: 16.6869 - val_loss: 37.2767

Epoch 00294: val_loss did not improve from 36.60405
Epoch 295/10000
4/4 - 0s - loss: 16.6672 - val_loss: 36.9227

Epoch 00295: val_loss did not improve from 36.60405
Epoch 296/10000
4/4 - 0s - loss: 16.6938 - val_loss: 37.0202

Epoch 00296: val_loss did not improve from 36.60405
Epoch 297/10000
4/4 - 0s - loss: 16.6718 - val_loss: 37.2390

Epoch 00297: val_loss did not improve from 36.60405
Epoch 298/10000
4/4 - 0s - loss: 16.7271 - val_loss: 37.5007

Epoch 00298: val_loss did not improve from 36.60405
Epoch 299/10000
4/4 - 0s - loss: 16.7093 - val_loss: 36.8319

Epoch 00299: val_loss did not improve from 36.60405
Epoch 300/10000
4/4 - 0s - loss: 16.7059 - val_loss: 37.0661

Epoch 00300: val_loss did not improve from 36.60405
Epoch 301/10000
4/4 - 0s - loss: 16.6634 - val_loss: 37.5329

Epoch 00301: val_loss did not improve from 36.60405
Epoch 302/10000
4/4 - 0s - loss: 16.7112 - val_loss: 37.4827

Epoch 00302: val_loss did not improve from 36.60405
Epoch 303/10000
4/4 - 0s - loss: 16.6655 - val_loss: 36.9783

Epoch 00303: val_loss did not improve from 36.60405
Epoch 304/10000
4/4 - 0s - loss: 16.7455 - val_loss: 36.8399

Epoch 00304: val_loss did not improve from 36.60405
Epoch 305/10000
4/4 - 0s - loss: 16.6830 - val_loss: 37.4548

Epoch 00305: val_loss did not improve from 36.60405
Epoch 306/10000
4/4 - 0s - loss: 16.7204 - val_loss: 37.4386

Epoch 00306: val_loss did not improve from 36.60405
Epoch 307/10000
4/4 - 0s - loss: 16.6672 - val_loss: 37.0218

Epoch 00307: val_loss did not improve from 36.60405
Epoch 308/10000
4/4 - 0s - loss: 16.6945 - val_loss: 36.8512

Epoch 00308: val_loss did not improve from 36.60405
Epoch 309/10000
4/4 - 0s - loss: 16.6774 - val_loss: 37.2755

Epoch 00309: val_loss did not improve from 36.60405
Epoch 310/10000
4/4 - 0s - loss: 16.6739 - val_loss: 37.6460

Epoch 00310: val_loss did not improve from 36.60405
Epoch 311/10000
4/4 - 0s - loss: 16.7101 - val_loss: 37.4168

Epoch 00311: val_loss did not improve from 36.60405
Epoch 312/10000
4/4 - 0s - loss: 16.7158 - val_loss: 36.9663

Epoch 00312: val_loss did not improve from 36.60405
Epoch 313/10000
4/4 - 0s - loss: 16.6984 - val_loss: 37.2834

Epoch 00313: val_loss did not improve from 36.60405
Epoch 314/10000
4/4 - 0s - loss: 16.7004 - val_loss: 37.6284

Epoch 00314: val_loss did not improve from 36.60405
Epoch 315/10000
4/4 - 0s - loss: 16.6858 - val_loss: 37.2543

Epoch 00315: val_loss did not improve from 36.60405
Epoch 316/10000
4/4 - 0s - loss: 16.6789 - val_loss: 36.7998

Epoch 00316: val_loss did not improve from 36.60405
Epoch 317/10000
4/4 - 0s - loss: 16.7412 - val_loss: 36.9628

Epoch 00317: val_loss did not improve from 36.60405
Epoch 318/10000
4/4 - 0s - loss: 16.6532 - val_loss: 37.3976

Epoch 00318: val_loss did not improve from 36.60405
Epoch 319/10000
4/4 - 0s - loss: 16.7136 - val_loss: 37.6122

Epoch 00319: val_loss did not improve from 36.60405
Epoch 320/10000
4/4 - 0s - loss: 16.6874 - val_loss: 37.1707

Epoch 00320: val_loss did not improve from 36.60405
Epoch 321/10000
4/4 - 0s - loss: 16.7136 - val_loss: 36.9011

Epoch 00321: val_loss did not improve from 36.60405
Epoch 322/10000
4/4 - 0s - loss: 16.6927 - val_loss: 37.3943

Epoch 00322: val_loss did not improve from 36.60405
Epoch 323/10000
4/4 - 0s - loss: 16.6813 - val_loss: 37.4898

Epoch 00323: val_loss did not improve from 36.60405
Epoch 324/10000
4/4 - 0s - loss: 16.6819 - val_loss: 37.1872

Epoch 00324: val_loss did not improve from 36.60405
Epoch 325/10000
4/4 - 0s - loss: 16.6713 - val_loss: 36.9511

Epoch 00325: val_loss did not improve from 36.60405
Epoch 326/10000
4/4 - 0s - loss: 16.6859 - val_loss: 36.9940

Epoch 00326: val_loss did not improve from 36.60405
Epoch 327/10000
4/4 - 0s - loss: 16.6791 - val_loss: 37.3386

Epoch 00327: val_loss did not improve from 36.60405
Epoch 328/10000
4/4 - 0s - loss: 16.6863 - val_loss: 37.4748

Epoch 00328: val_loss did not improve from 36.60405
Epoch 329/10000
4/4 - 0s - loss: 16.7042 - val_loss: 37.1680

Epoch 00329: val_loss did not improve from 36.60405
Epoch 330/10000
4/4 - 0s - loss: 16.6825 - val_loss: 37.2662

Epoch 00330: val_loss did not improve from 36.60405
Epoch 331/10000
4/4 - 0s - loss: 16.6743 - val_loss: 37.6706

Epoch 00331: val_loss did not improve from 36.60405
Epoch 332/10000
4/4 - 0s - loss: 16.7216 - val_loss: 37.3952

Epoch 00332: val_loss did not improve from 36.60405
Epoch 333/10000
4/4 - 0s - loss: 16.6929 - val_loss: 37.5209

Epoch 00333: val_loss did not improve from 36.60405
Epoch 334/10000
4/4 - 0s - loss: 16.6810 - val_loss: 37.3442

Epoch 00334: val_loss did not improve from 36.60405
Epoch 335/10000
4/4 - 0s - loss: 16.6760 - val_loss: 37.2182

Epoch 00335: val_loss did not improve from 36.60405
Epoch 336/10000
4/4 - 0s - loss: 16.6729 - val_loss: 37.2775

Epoch 00336: val_loss did not improve from 36.60405
Epoch 337/10000
4/4 - 0s - loss: 16.6743 - val_loss: 37.2048

Epoch 00337: val_loss did not improve from 36.60405
Epoch 338/10000
4/4 - 0s - loss: 16.6728 - val_loss: 37.1657

Epoch 00338: val_loss did not improve from 36.60405
Epoch 339/10000
4/4 - 0s - loss: 16.6726 - val_loss: 37.2443

Epoch 00339: val_loss did not improve from 36.60405
Epoch 340/10000
4/4 - 0s - loss: 16.6715 - val_loss: 37.4161

Epoch 00340: val_loss did not improve from 36.60405
Epoch 341/10000
4/4 - 0s - loss: 16.6903 - val_loss: 37.3102

Epoch 00341: val_loss did not improve from 36.60405
Epoch 342/10000
4/4 - 0s - loss: 16.7005 - val_loss: 36.9626

Epoch 00342: val_loss did not improve from 36.60405
Epoch 343/10000
4/4 - 0s - loss: 16.6770 - val_loss: 37.3665

Epoch 00343: val_loss did not improve from 36.60405
Epoch 344/10000
4/4 - 0s - loss: 16.6753 - val_loss: 37.5764

Epoch 00344: val_loss did not improve from 36.60405
Epoch 345/10000
4/4 - 0s - loss: 16.6863 - val_loss: 37.3480

Epoch 00345: val_loss did not improve from 36.60405
Epoch 346/10000
4/4 - 0s - loss: 16.7036 - val_loss: 37.0098

Epoch 00346: val_loss did not improve from 36.60405
Epoch 347/10000
4/4 - 0s - loss: 16.6854 - val_loss: 37.4017

Epoch 00347: val_loss did not improve from 36.60405
Epoch 348/10000
4/4 - 0s - loss: 16.6764 - val_loss: 37.2799

Epoch 00348: val_loss did not improve from 36.60405
Epoch 349/10000
4/4 - 0s - loss: 16.6811 - val_loss: 37.2563

Epoch 00349: val_loss did not improve from 36.60405
Epoch 350/10000
4/4 - 0s - loss: 16.6672 - val_loss: 37.1673

Epoch 00350: val_loss did not improve from 36.60405
Epoch 351/10000
4/4 - 0s - loss: 16.7120 - val_loss: 36.9738

Epoch 00351: val_loss did not improve from 36.60405
Epoch 352/10000
4/4 - 0s - loss: 16.6780 - val_loss: 37.4998

Epoch 00352: val_loss did not improve from 36.60405
Epoch 353/10000
4/4 - 0s - loss: 16.6896 - val_loss: 37.4895

Epoch 00353: val_loss did not improve from 36.60405
Epoch 354/10000
4/4 - 0s - loss: 16.6782 - val_loss: 37.2125

Epoch 00354: val_loss did not improve from 36.60405
Epoch 355/10000
4/4 - 0s - loss: 16.6705 - val_loss: 37.2070

Epoch 00355: val_loss did not improve from 36.60405
Epoch 356/10000
4/4 - 0s - loss: 16.6793 - val_loss: 37.2051

Epoch 00356: val_loss did not improve from 36.60405
Epoch 357/10000
4/4 - 0s - loss: 16.6728 - val_loss: 37.5193

Epoch 00357: val_loss did not improve from 36.60405
Epoch 358/10000
4/4 - 0s - loss: 16.6864 - val_loss: 37.3986

Epoch 00358: val_loss did not improve from 36.60405
Epoch 359/10000
4/4 - 0s - loss: 16.6680 - val_loss: 37.1138

Epoch 00359: val_loss did not improve from 36.60405
Epoch 360/10000
4/4 - 0s - loss: 16.6730 - val_loss: 37.1171

Epoch 00360: val_loss did not improve from 36.60405
Epoch 361/10000
4/4 - 0s - loss: 16.6687 - val_loss: 37.2546

Epoch 00361: val_loss did not improve from 36.60405
Epoch 362/10000
4/4 - 0s - loss: 16.6647 - val_loss: 37.4095

Epoch 00362: val_loss did not improve from 36.60405
Epoch 363/10000
4/4 - 0s - loss: 16.6769 - val_loss: 37.3800

Epoch 00363: val_loss did not improve from 36.60405
Epoch 364/10000
4/4 - 0s - loss: 16.6750 - val_loss: 37.1123

Epoch 00364: val_loss did not improve from 36.60405
Epoch 365/10000
4/4 - 0s - loss: 16.6744 - val_loss: 37.2192

Epoch 00365: val_loss did not improve from 36.60405
Epoch 366/10000
4/4 - 0s - loss: 16.6766 - val_loss: 37.3175

Epoch 00366: val_loss did not improve from 36.60405
Epoch 367/10000
4/4 - 0s - loss: 16.6763 - val_loss: 36.9930

Epoch 00367: val_loss did not improve from 36.60405
Epoch 368/10000
4/4 - 0s - loss: 16.6727 - val_loss: 37.0847

Epoch 00368: val_loss did not improve from 36.60405
Epoch 369/10000
4/4 - 0s - loss: 16.6763 - val_loss: 37.1019

Epoch 00369: val_loss did not improve from 36.60405
Epoch 370/10000
4/4 - 0s - loss: 16.6717 - val_loss: 37.1308

Epoch 00370: val_loss did not improve from 36.60405
Epoch 371/10000
4/4 - 0s - loss: 16.6822 - val_loss: 36.9812

Epoch 00371: val_loss did not improve from 36.60405
Epoch 372/10000
4/4 - 0s - loss: 16.6821 - val_loss: 37.2072

Epoch 00372: val_loss did not improve from 36.60405
Epoch 373/10000
4/4 - 0s - loss: 16.6810 - val_loss: 37.3185

Epoch 00373: val_loss did not improve from 36.60405
Epoch 374/10000
4/4 - 0s - loss: 16.6698 - val_loss: 37.1871

Epoch 00374: val_loss did not improve from 36.60405
Epoch 375/10000
4/4 - 0s - loss: 16.6732 - val_loss: 37.2626

Epoch 00375: val_loss did not improve from 36.60405
Epoch 376/10000
4/4 - 0s - loss: 16.6660 - val_loss: 37.1491

Epoch 00376: val_loss did not improve from 36.60405
Epoch 377/10000
4/4 - 0s - loss: 16.6779 - val_loss: 36.9375

Epoch 00377: val_loss did not improve from 36.60405
Epoch 378/10000
4/4 - 0s - loss: 16.6943 - val_loss: 37.2691

Epoch 00378: val_loss did not improve from 36.60405
Epoch 379/10000
4/4 - 0s - loss: 16.6673 - val_loss: 37.2629

Epoch 00379: val_loss did not improve from 36.60405
Epoch 00379: early stopping
*************************** Fold #: 7 ***************************
Model: "sequential_46"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_506 (Dense)            (None, 30)                210       
_________________________________________________________________
dense_507 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_508 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_509 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_510 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_511 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_512 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_513 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_514 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_515 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_516 (Dense)            (None, 1)                 31        
=================================================================
Total params: 8,611
Trainable params: 8,611
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
4/4 - 0s - loss: 31.7534 - val_loss: 27.4031

Epoch 00001: val_loss improved from inf to 27.40311, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 2/10000
4/4 - 0s - loss: 31.7201 - val_loss: 27.3698

Epoch 00002: val_loss improved from 27.40311 to 27.36975, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 3/10000
4/4 - 0s - loss: 31.6826 - val_loss: 27.3325

Epoch 00003: val_loss improved from 27.36975 to 27.33253, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 4/10000
4/4 - 0s - loss: 31.6404 - val_loss: 27.2906

Epoch 00004: val_loss improved from 27.33253 to 27.29060, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 5/10000
4/4 - 0s - loss: 31.5921 - val_loss: 27.2430

Epoch 00005: val_loss improved from 27.29060 to 27.24297, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 6/10000
4/4 - 0s - loss: 31.5373 - val_loss: 27.1883

Epoch 00006: val_loss improved from 27.24297 to 27.18829, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 7/10000
4/4 - 0s - loss: 31.4753 - val_loss: 27.1246

Epoch 00007: val_loss improved from 27.18829 to 27.12464, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 8/10000
4/4 - 0s - loss: 31.4022 - val_loss: 27.0497

Epoch 00008: val_loss improved from 27.12464 to 27.04967, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 9/10000
4/4 - 0s - loss: 31.3147 - val_loss: 26.9598

Epoch 00009: val_loss improved from 27.04967 to 26.95983, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 10/10000
4/4 - 0s - loss: 31.2109 - val_loss: 26.8493

Epoch 00010: val_loss improved from 26.95983 to 26.84931, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 11/10000
4/4 - 0s - loss: 31.0793 - val_loss: 26.7073

Epoch 00011: val_loss improved from 26.84931 to 26.70729, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 12/10000
4/4 - 0s - loss: 30.9083 - val_loss: 26.5188

Epoch 00012: val_loss improved from 26.70729 to 26.51882, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 13/10000
4/4 - 0s - loss: 30.6785 - val_loss: 26.2580

Epoch 00013: val_loss improved from 26.51882 to 26.25805, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 14/10000
4/4 - 0s - loss: 30.3574 - val_loss: 25.8743

Epoch 00014: val_loss improved from 26.25805 to 25.87427, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 15/10000
4/4 - 0s - loss: 29.8726 - val_loss: 25.2708

Epoch 00015: val_loss improved from 25.87427 to 25.27085, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 16/10000
4/4 - 0s - loss: 29.0995 - val_loss: 24.2735

Epoch 00016: val_loss improved from 25.27085 to 24.27349, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 17/10000
4/4 - 0s - loss: 27.7875 - val_loss: 22.6508

Epoch 00017: val_loss improved from 24.27349 to 22.65078, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 18/10000
4/4 - 0s - loss: 25.7772 - val_loss: 20.6526

Epoch 00018: val_loss improved from 22.65078 to 20.65256, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 19/10000
4/4 - 0s - loss: 23.9280 - val_loss: 21.1457

Epoch 00019: val_loss did not improve from 20.65256
Epoch 20/10000
4/4 - 0s - loss: 24.2483 - val_loss: 20.6294

Epoch 00020: val_loss improved from 20.65256 to 20.62944, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 21/10000
4/4 - 0s - loss: 23.5042 - val_loss: 20.0601

Epoch 00021: val_loss improved from 20.62944 to 20.06011, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 22/10000
4/4 - 0s - loss: 23.3276 - val_loss: 20.0434

Epoch 00022: val_loss improved from 20.06011 to 20.04343, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 23/10000
4/4 - 0s - loss: 23.2557 - val_loss: 19.8845

Epoch 00023: val_loss improved from 20.04343 to 19.88445, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 24/10000
4/4 - 0s - loss: 22.9664 - val_loss: 19.8363

Epoch 00024: val_loss improved from 19.88445 to 19.83629, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 25/10000
4/4 - 0s - loss: 22.7880 - val_loss: 19.8679

Epoch 00025: val_loss did not improve from 19.83629
Epoch 26/10000
4/4 - 0s - loss: 22.6651 - val_loss: 19.6812

Epoch 00026: val_loss improved from 19.83629 to 19.68123, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 27/10000
4/4 - 0s - loss: 22.4506 - val_loss: 19.4899

Epoch 00027: val_loss improved from 19.68123 to 19.48995, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 28/10000
4/4 - 0s - loss: 22.2730 - val_loss: 19.3592

Epoch 00028: val_loss improved from 19.48995 to 19.35919, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 29/10000
4/4 - 0s - loss: 22.0847 - val_loss: 19.2503

Epoch 00029: val_loss improved from 19.35919 to 19.25025, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 30/10000
4/4 - 0s - loss: 21.8604 - val_loss: 19.1544

Epoch 00030: val_loss improved from 19.25025 to 19.15445, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 31/10000
4/4 - 0s - loss: 21.6308 - val_loss: 19.0185

Epoch 00031: val_loss improved from 19.15445 to 19.01854, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 32/10000
4/4 - 0s - loss: 21.4003 - val_loss: 18.9248

Epoch 00032: val_loss improved from 19.01854 to 18.92481, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 33/10000
4/4 - 0s - loss: 21.1678 - val_loss: 18.8353

Epoch 00033: val_loss improved from 18.92481 to 18.83532, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 34/10000
4/4 - 0s - loss: 20.9564 - val_loss: 18.7120

Epoch 00034: val_loss improved from 18.83532 to 18.71198, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 35/10000
4/4 - 0s - loss: 20.7386 - val_loss: 18.5975

Epoch 00035: val_loss improved from 18.71198 to 18.59754, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 36/10000
4/4 - 0s - loss: 20.5163 - val_loss: 18.5254

Epoch 00036: val_loss improved from 18.59754 to 18.52535, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 37/10000
4/4 - 0s - loss: 20.3543 - val_loss: 18.5578

Epoch 00037: val_loss did not improve from 18.52535
Epoch 38/10000
4/4 - 0s - loss: 20.1907 - val_loss: 18.5381

Epoch 00038: val_loss did not improve from 18.52535
Epoch 39/10000
4/4 - 0s - loss: 20.0454 - val_loss: 18.4343

Epoch 00039: val_loss improved from 18.52535 to 18.43426, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 40/10000
4/4 - 0s - loss: 19.9074 - val_loss: 18.4769

Epoch 00040: val_loss did not improve from 18.43426
Epoch 41/10000
4/4 - 0s - loss: 19.8091 - val_loss: 18.5532

Epoch 00041: val_loss did not improve from 18.43426
Epoch 42/10000
4/4 - 0s - loss: 19.6806 - val_loss: 18.3623

Epoch 00042: val_loss improved from 18.43426 to 18.36232, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 43/10000
4/4 - 0s - loss: 19.6078 - val_loss: 18.3184

Epoch 00043: val_loss improved from 18.36232 to 18.31838, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 44/10000
4/4 - 0s - loss: 19.4589 - val_loss: 18.4909

Epoch 00044: val_loss did not improve from 18.31838
Epoch 45/10000
4/4 - 0s - loss: 19.4056 - val_loss: 18.3889

Epoch 00045: val_loss did not improve from 18.31838
Epoch 46/10000
4/4 - 0s - loss: 19.2605 - val_loss: 18.2796

Epoch 00046: val_loss improved from 18.31838 to 18.27962, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 47/10000
4/4 - 0s - loss: 19.2241 - val_loss: 18.2391

Epoch 00047: val_loss improved from 18.27962 to 18.23907, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 48/10000
4/4 - 0s - loss: 19.1354 - val_loss: 18.3702

Epoch 00048: val_loss did not improve from 18.23907
Epoch 49/10000
4/4 - 0s - loss: 19.0958 - val_loss: 18.3301

Epoch 00049: val_loss did not improve from 18.23907
Epoch 50/10000
4/4 - 0s - loss: 19.0169 - val_loss: 18.2474

Epoch 00050: val_loss did not improve from 18.23907
Epoch 51/10000
4/4 - 0s - loss: 19.0005 - val_loss: 18.2707

Epoch 00051: val_loss did not improve from 18.23907
Epoch 52/10000
4/4 - 0s - loss: 18.9459 - val_loss: 18.3914

Epoch 00052: val_loss did not improve from 18.23907
Epoch 53/10000
4/4 - 0s - loss: 18.9661 - val_loss: 18.4609

Epoch 00053: val_loss did not improve from 18.23907
Epoch 54/10000
4/4 - 0s - loss: 18.9282 - val_loss: 18.2809

Epoch 00054: val_loss did not improve from 18.23907
Epoch 55/10000
4/4 - 0s - loss: 18.9357 - val_loss: 18.2970

Epoch 00055: val_loss did not improve from 18.23907
Epoch 56/10000
4/4 - 0s - loss: 18.9211 - val_loss: 18.4491

Epoch 00056: val_loss did not improve from 18.23907
Epoch 57/10000
4/4 - 0s - loss: 18.9079 - val_loss: 18.3719

Epoch 00057: val_loss did not improve from 18.23907
Epoch 58/10000
4/4 - 0s - loss: 18.9241 - val_loss: 18.2811

Epoch 00058: val_loss did not improve from 18.23907
Epoch 59/10000
4/4 - 0s - loss: 18.9122 - val_loss: 18.3968

Epoch 00059: val_loss did not improve from 18.23907
Epoch 60/10000
4/4 - 0s - loss: 18.8993 - val_loss: 18.3982

Epoch 00060: val_loss did not improve from 18.23907
Epoch 61/10000
4/4 - 0s - loss: 18.8848 - val_loss: 18.3189

Epoch 00061: val_loss did not improve from 18.23907
Epoch 62/10000
4/4 - 0s - loss: 18.8850 - val_loss: 18.3696

Epoch 00062: val_loss did not improve from 18.23907
Epoch 63/10000
4/4 - 0s - loss: 18.8864 - val_loss: 18.3754

Epoch 00063: val_loss did not improve from 18.23907
Epoch 64/10000
4/4 - 0s - loss: 18.8679 - val_loss: 18.4446

Epoch 00064: val_loss did not improve from 18.23907
Epoch 65/10000
4/4 - 0s - loss: 18.9273 - val_loss: 18.4585

Epoch 00065: val_loss did not improve from 18.23907
Epoch 66/10000
4/4 - 0s - loss: 18.8671 - val_loss: 18.3111

Epoch 00066: val_loss did not improve from 18.23907
Epoch 67/10000
4/4 - 0s - loss: 18.9123 - val_loss: 18.3493

Epoch 00067: val_loss did not improve from 18.23907
Epoch 68/10000
4/4 - 0s - loss: 18.8793 - val_loss: 18.4545

Epoch 00068: val_loss did not improve from 18.23907
Epoch 69/10000
4/4 - 0s - loss: 18.8770 - val_loss: 18.3456

Epoch 00069: val_loss did not improve from 18.23907
Epoch 70/10000
4/4 - 0s - loss: 18.8519 - val_loss: 18.2645

Epoch 00070: val_loss did not improve from 18.23907
Epoch 71/10000
4/4 - 0s - loss: 18.9040 - val_loss: 18.3044

Epoch 00071: val_loss did not improve from 18.23907
Epoch 72/10000
4/4 - 0s - loss: 18.8579 - val_loss: 18.4862

Epoch 00072: val_loss did not improve from 18.23907
Epoch 73/10000
4/4 - 0s - loss: 18.8997 - val_loss: 18.3935

Epoch 00073: val_loss did not improve from 18.23907
Epoch 74/10000
4/4 - 0s - loss: 18.8540 - val_loss: 18.3276

Epoch 00074: val_loss did not improve from 18.23907
Epoch 75/10000
4/4 - 0s - loss: 18.8749 - val_loss: 18.3351

Epoch 00075: val_loss did not improve from 18.23907
Epoch 76/10000
4/4 - 0s - loss: 18.8582 - val_loss: 18.3878

Epoch 00076: val_loss did not improve from 18.23907
Epoch 77/10000
4/4 - 0s - loss: 18.8523 - val_loss: 18.3607

Epoch 00077: val_loss did not improve from 18.23907
Epoch 78/10000
4/4 - 0s - loss: 18.8552 - val_loss: 18.3313

Epoch 00078: val_loss did not improve from 18.23907
Epoch 79/10000
4/4 - 0s - loss: 18.8602 - val_loss: 18.3178

Epoch 00079: val_loss did not improve from 18.23907
Epoch 80/10000
4/4 - 0s - loss: 18.8464 - val_loss: 18.3769

Epoch 00080: val_loss did not improve from 18.23907
Epoch 81/10000
4/4 - 0s - loss: 18.8676 - val_loss: 18.4120

Epoch 00081: val_loss did not improve from 18.23907
Epoch 82/10000
4/4 - 0s - loss: 18.8488 - val_loss: 18.3293

Epoch 00082: val_loss did not improve from 18.23907
Epoch 83/10000
4/4 - 0s - loss: 18.8540 - val_loss: 18.3271

Epoch 00083: val_loss did not improve from 18.23907
Epoch 84/10000
4/4 - 0s - loss: 18.8559 - val_loss: 18.3156

Epoch 00084: val_loss did not improve from 18.23907
Epoch 85/10000
4/4 - 0s - loss: 18.8523 - val_loss: 18.3422

Epoch 00085: val_loss did not improve from 18.23907
Epoch 86/10000
4/4 - 0s - loss: 18.8759 - val_loss: 18.3823

Epoch 00086: val_loss did not improve from 18.23907
Epoch 87/10000
4/4 - 0s - loss: 18.8318 - val_loss: 18.2794

Epoch 00087: val_loss did not improve from 18.23907
Epoch 88/10000
4/4 - 0s - loss: 18.8561 - val_loss: 18.2716

Epoch 00088: val_loss did not improve from 18.23907
Epoch 89/10000
4/4 - 0s - loss: 18.8560 - val_loss: 18.3083

Epoch 00089: val_loss did not improve from 18.23907
Epoch 90/10000
4/4 - 0s - loss: 18.8962 - val_loss: 18.4328

Epoch 00090: val_loss did not improve from 18.23907
Epoch 91/10000
4/4 - 0s - loss: 18.8999 - val_loss: 18.2298

Epoch 00091: val_loss improved from 18.23907 to 18.22984, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 92/10000
4/4 - 0s - loss: 18.8758 - val_loss: 18.2894

Epoch 00092: val_loss did not improve from 18.22984
Epoch 93/10000
4/4 - 0s - loss: 18.8490 - val_loss: 18.3409

Epoch 00093: val_loss did not improve from 18.22984
Epoch 94/10000
4/4 - 0s - loss: 18.8636 - val_loss: 18.3132

Epoch 00094: val_loss did not improve from 18.22984
Epoch 95/10000
4/4 - 0s - loss: 18.8368 - val_loss: 18.3299

Epoch 00095: val_loss did not improve from 18.22984
Epoch 96/10000
4/4 - 0s - loss: 18.8449 - val_loss: 18.3419

Epoch 00096: val_loss did not improve from 18.22984
Epoch 97/10000
4/4 - 0s - loss: 18.8354 - val_loss: 18.3919

Epoch 00097: val_loss did not improve from 18.22984
Epoch 98/10000
4/4 - 0s - loss: 18.8741 - val_loss: 18.3931

Epoch 00098: val_loss did not improve from 18.22984
Epoch 99/10000
4/4 - 0s - loss: 18.8325 - val_loss: 18.2466

Epoch 00099: val_loss did not improve from 18.22984
Epoch 100/10000
4/4 - 0s - loss: 18.8725 - val_loss: 18.2676

Epoch 00100: val_loss did not improve from 18.22984
Epoch 101/10000
4/4 - 0s - loss: 18.8733 - val_loss: 18.4723

Epoch 00101: val_loss did not improve from 18.22984
Epoch 102/10000
4/4 - 0s - loss: 18.8612 - val_loss: 18.2914

Epoch 00102: val_loss did not improve from 18.22984
Epoch 103/10000
4/4 - 0s - loss: 18.8382 - val_loss: 18.2407

Epoch 00103: val_loss did not improve from 18.22984
Epoch 104/10000
4/4 - 0s - loss: 18.8499 - val_loss: 18.3332

Epoch 00104: val_loss did not improve from 18.22984
Epoch 105/10000
4/4 - 0s - loss: 18.8406 - val_loss: 18.3463

Epoch 00105: val_loss did not improve from 18.22984
Epoch 106/10000
4/4 - 0s - loss: 18.8457 - val_loss: 18.3355

Epoch 00106: val_loss did not improve from 18.22984
Epoch 107/10000
4/4 - 0s - loss: 18.8449 - val_loss: 18.3608

Epoch 00107: val_loss did not improve from 18.22984
Epoch 108/10000
4/4 - 0s - loss: 18.8346 - val_loss: 18.3365

Epoch 00108: val_loss did not improve from 18.22984
Epoch 109/10000
4/4 - 0s - loss: 18.8323 - val_loss: 18.3352

Epoch 00109: val_loss did not improve from 18.22984
Epoch 110/10000
4/4 - 0s - loss: 18.8451 - val_loss: 18.3926

Epoch 00110: val_loss did not improve from 18.22984
Epoch 111/10000
4/4 - 0s - loss: 18.8296 - val_loss: 18.3193

Epoch 00111: val_loss did not improve from 18.22984
Epoch 112/10000
4/4 - 0s - loss: 18.8274 - val_loss: 18.2691

Epoch 00112: val_loss did not improve from 18.22984
Epoch 113/10000
4/4 - 0s - loss: 18.8421 - val_loss: 18.3056

Epoch 00113: val_loss did not improve from 18.22984
Epoch 114/10000
4/4 - 0s - loss: 18.8407 - val_loss: 18.3128

Epoch 00114: val_loss did not improve from 18.22984
Epoch 115/10000
4/4 - 0s - loss: 18.8292 - val_loss: 18.2460

Epoch 00115: val_loss did not improve from 18.22984
Epoch 116/10000
4/4 - 0s - loss: 18.8452 - val_loss: 18.2692

Epoch 00116: val_loss did not improve from 18.22984
Epoch 117/10000
4/4 - 0s - loss: 18.8456 - val_loss: 18.3711

Epoch 00117: val_loss did not improve from 18.22984
Epoch 118/10000
4/4 - 0s - loss: 18.8619 - val_loss: 18.2836

Epoch 00118: val_loss did not improve from 18.22984
Epoch 119/10000
4/4 - 0s - loss: 18.8262 - val_loss: 18.2959

Epoch 00119: val_loss did not improve from 18.22984
Epoch 120/10000
4/4 - 0s - loss: 18.8182 - val_loss: 18.3673

Epoch 00120: val_loss did not improve from 18.22984
Epoch 121/10000
4/4 - 0s - loss: 18.8387 - val_loss: 18.3721

Epoch 00121: val_loss did not improve from 18.22984
Epoch 122/10000
4/4 - 0s - loss: 18.8246 - val_loss: 18.3058

Epoch 00122: val_loss did not improve from 18.22984
Epoch 123/10000
4/4 - 0s - loss: 18.8290 - val_loss: 18.3120

Epoch 00123: val_loss did not improve from 18.22984
Epoch 124/10000
4/4 - 0s - loss: 18.8208 - val_loss: 18.3490

Epoch 00124: val_loss did not improve from 18.22984
Epoch 125/10000
4/4 - 0s - loss: 18.8207 - val_loss: 18.3242

Epoch 00125: val_loss did not improve from 18.22984
Epoch 126/10000
4/4 - 0s - loss: 18.8231 - val_loss: 18.3128

Epoch 00126: val_loss did not improve from 18.22984
Epoch 127/10000
4/4 - 0s - loss: 18.8301 - val_loss: 18.2855

Epoch 00127: val_loss did not improve from 18.22984
Epoch 128/10000
4/4 - 0s - loss: 18.8351 - val_loss: 18.2617

Epoch 00128: val_loss did not improve from 18.22984
Epoch 129/10000
4/4 - 0s - loss: 18.8507 - val_loss: 18.3469

Epoch 00129: val_loss did not improve from 18.22984
Epoch 130/10000
4/4 - 0s - loss: 18.8185 - val_loss: 18.2801

Epoch 00130: val_loss did not improve from 18.22984
Epoch 131/10000
4/4 - 0s - loss: 18.8496 - val_loss: 18.2383

Epoch 00131: val_loss did not improve from 18.22984
Epoch 132/10000
4/4 - 0s - loss: 18.8301 - val_loss: 18.3955

Epoch 00132: val_loss did not improve from 18.22984
Epoch 133/10000
4/4 - 0s - loss: 18.8418 - val_loss: 18.3791

Epoch 00133: val_loss did not improve from 18.22984
Epoch 134/10000
4/4 - 0s - loss: 18.8988 - val_loss: 18.3651

Epoch 00134: val_loss did not improve from 18.22984
Epoch 135/10000
4/4 - 0s - loss: 18.9149 - val_loss: 18.2204

Epoch 00135: val_loss improved from 18.22984 to 18.22036, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 136/10000
4/4 - 0s - loss: 18.8825 - val_loss: 18.3034

Epoch 00136: val_loss did not improve from 18.22036
Epoch 137/10000
4/4 - 0s - loss: 18.8370 - val_loss: 18.4543

Epoch 00137: val_loss did not improve from 18.22036
Epoch 138/10000
4/4 - 0s - loss: 18.8746 - val_loss: 18.2646

Epoch 00138: val_loss did not improve from 18.22036
Epoch 139/10000
4/4 - 0s - loss: 18.8328 - val_loss: 18.2704

Epoch 00139: val_loss did not improve from 18.22036
Epoch 140/10000
4/4 - 0s - loss: 18.8055 - val_loss: 18.3724

Epoch 00140: val_loss did not improve from 18.22036
Epoch 141/10000
4/4 - 0s - loss: 18.8256 - val_loss: 18.4410

Epoch 00141: val_loss did not improve from 18.22036
Epoch 142/10000
4/4 - 0s - loss: 18.8459 - val_loss: 18.3563

Epoch 00142: val_loss did not improve from 18.22036
Epoch 143/10000
4/4 - 0s - loss: 18.8128 - val_loss: 18.2840

Epoch 00143: val_loss did not improve from 18.22036
Epoch 144/10000
4/4 - 0s - loss: 18.8292 - val_loss: 18.3106

Epoch 00144: val_loss did not improve from 18.22036
Epoch 145/10000
4/4 - 0s - loss: 18.8167 - val_loss: 18.4243

Epoch 00145: val_loss did not improve from 18.22036
Epoch 146/10000
4/4 - 0s - loss: 18.8379 - val_loss: 18.3646

Epoch 00146: val_loss did not improve from 18.22036
Epoch 147/10000
4/4 - 0s - loss: 18.8354 - val_loss: 18.2355

Epoch 00147: val_loss did not improve from 18.22036
Epoch 148/10000
4/4 - 0s - loss: 18.8390 - val_loss: 18.2919

Epoch 00148: val_loss did not improve from 18.22036
Epoch 149/10000
4/4 - 0s - loss: 18.8442 - val_loss: 18.3896

Epoch 00149: val_loss did not improve from 18.22036
Epoch 150/10000
4/4 - 0s - loss: 18.8731 - val_loss: 18.2772

Epoch 00150: val_loss did not improve from 18.22036
Epoch 151/10000
4/4 - 0s - loss: 18.8048 - val_loss: 18.3537

Epoch 00151: val_loss did not improve from 18.22036
Epoch 152/10000
4/4 - 0s - loss: 18.8742 - val_loss: 18.4102

Epoch 00152: val_loss did not improve from 18.22036
Epoch 153/10000
4/4 - 0s - loss: 18.8272 - val_loss: 18.2554

Epoch 00153: val_loss did not improve from 18.22036
Epoch 154/10000
4/4 - 0s - loss: 18.8399 - val_loss: 18.2941

Epoch 00154: val_loss did not improve from 18.22036
Epoch 155/10000
4/4 - 0s - loss: 18.8132 - val_loss: 18.3372

Epoch 00155: val_loss did not improve from 18.22036
Epoch 156/10000
4/4 - 0s - loss: 18.8109 - val_loss: 18.3102

Epoch 00156: val_loss did not improve from 18.22036
Epoch 157/10000
4/4 - 0s - loss: 18.8148 - val_loss: 18.3036

Epoch 00157: val_loss did not improve from 18.22036
Epoch 158/10000
4/4 - 0s - loss: 18.8096 - val_loss: 18.2465

Epoch 00158: val_loss did not improve from 18.22036
Epoch 159/10000
4/4 - 0s - loss: 18.8208 - val_loss: 18.2562

Epoch 00159: val_loss did not improve from 18.22036
Epoch 160/10000
4/4 - 0s - loss: 18.8237 - val_loss: 18.3201

Epoch 00160: val_loss did not improve from 18.22036
Epoch 161/10000
4/4 - 0s - loss: 18.8100 - val_loss: 18.2822

Epoch 00161: val_loss did not improve from 18.22036
Epoch 162/10000
4/4 - 0s - loss: 18.8076 - val_loss: 18.3017

Epoch 00162: val_loss did not improve from 18.22036
Epoch 163/10000
4/4 - 0s - loss: 18.8141 - val_loss: 18.3383

Epoch 00163: val_loss did not improve from 18.22036
Epoch 164/10000
4/4 - 0s - loss: 18.8148 - val_loss: 18.3325

Epoch 00164: val_loss did not improve from 18.22036
Epoch 165/10000
4/4 - 0s - loss: 18.8432 - val_loss: 18.2411

Epoch 00165: val_loss did not improve from 18.22036
Epoch 166/10000
4/4 - 0s - loss: 18.8131 - val_loss: 18.3394

Epoch 00166: val_loss did not improve from 18.22036
Epoch 167/10000
4/4 - 0s - loss: 18.8712 - val_loss: 18.5137

Epoch 00167: val_loss did not improve from 18.22036
Epoch 168/10000
4/4 - 0s - loss: 18.8432 - val_loss: 18.3130

Epoch 00168: val_loss did not improve from 18.22036
Epoch 169/10000
4/4 - 0s - loss: 18.8125 - val_loss: 18.2487

Epoch 00169: val_loss did not improve from 18.22036
Epoch 170/10000
4/4 - 0s - loss: 18.8533 - val_loss: 18.2851

Epoch 00170: val_loss did not improve from 18.22036
Epoch 171/10000
4/4 - 0s - loss: 18.9143 - val_loss: 18.4491

Epoch 00171: val_loss did not improve from 18.22036
Epoch 172/10000
4/4 - 0s - loss: 18.7993 - val_loss: 18.2528

Epoch 00172: val_loss did not improve from 18.22036
Epoch 173/10000
4/4 - 0s - loss: 18.8582 - val_loss: 18.2095

Epoch 00173: val_loss improved from 18.22036 to 18.20954, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 174/10000
4/4 - 0s - loss: 18.8289 - val_loss: 18.3232

Epoch 00174: val_loss did not improve from 18.20954
Epoch 175/10000
4/4 - 0s - loss: 18.8454 - val_loss: 18.4271

Epoch 00175: val_loss did not improve from 18.20954
Epoch 176/10000
4/4 - 0s - loss: 18.8307 - val_loss: 18.2604

Epoch 00176: val_loss did not improve from 18.20954
Epoch 177/10000
4/4 - 0s - loss: 18.8167 - val_loss: 18.2861

Epoch 00177: val_loss did not improve from 18.20954
Epoch 178/10000
4/4 - 0s - loss: 18.8117 - val_loss: 18.3057

Epoch 00178: val_loss did not improve from 18.20954
Epoch 179/10000
4/4 - 0s - loss: 18.8388 - val_loss: 18.2649

Epoch 00179: val_loss did not improve from 18.20954
Epoch 180/10000
4/4 - 0s - loss: 18.8225 - val_loss: 18.4175

Epoch 00180: val_loss did not improve from 18.20954
Epoch 181/10000
4/4 - 0s - loss: 18.8310 - val_loss: 18.3140

Epoch 00181: val_loss did not improve from 18.20954
Epoch 182/10000
4/4 - 0s - loss: 18.8045 - val_loss: 18.2885

Epoch 00182: val_loss did not improve from 18.20954
Epoch 183/10000
4/4 - 0s - loss: 18.8135 - val_loss: 18.2578

Epoch 00183: val_loss did not improve from 18.20954
Epoch 184/10000
4/4 - 0s - loss: 18.8062 - val_loss: 18.3164

Epoch 00184: val_loss did not improve from 18.20954
Epoch 185/10000
4/4 - 0s - loss: 18.7976 - val_loss: 18.3857

Epoch 00185: val_loss did not improve from 18.20954
Epoch 186/10000
4/4 - 0s - loss: 18.8152 - val_loss: 18.3428

Epoch 00186: val_loss did not improve from 18.20954
Epoch 187/10000
4/4 - 0s - loss: 18.8005 - val_loss: 18.2691

Epoch 00187: val_loss did not improve from 18.20954
Epoch 188/10000
4/4 - 0s - loss: 18.8385 - val_loss: 18.3028

Epoch 00188: val_loss did not improve from 18.20954
Epoch 189/10000
4/4 - 0s - loss: 18.8130 - val_loss: 18.2676

Epoch 00189: val_loss did not improve from 18.20954
Epoch 190/10000
4/4 - 0s - loss: 18.7996 - val_loss: 18.3575

Epoch 00190: val_loss did not improve from 18.20954
Epoch 191/10000
4/4 - 0s - loss: 18.8426 - val_loss: 18.4311

Epoch 00191: val_loss did not improve from 18.20954
Epoch 192/10000
4/4 - 0s - loss: 18.8232 - val_loss: 18.2996

Epoch 00192: val_loss did not improve from 18.20954
Epoch 193/10000
4/4 - 0s - loss: 18.8170 - val_loss: 18.3140

Epoch 00193: val_loss did not improve from 18.20954
Epoch 194/10000
4/4 - 0s - loss: 18.8063 - val_loss: 18.2777

Epoch 00194: val_loss did not improve from 18.20954
Epoch 195/10000
4/4 - 0s - loss: 18.8259 - val_loss: 18.2660

Epoch 00195: val_loss did not improve from 18.20954
Epoch 196/10000
4/4 - 0s - loss: 18.8209 - val_loss: 18.4405

Epoch 00196: val_loss did not improve from 18.20954
Epoch 197/10000
4/4 - 0s - loss: 18.8235 - val_loss: 18.3158

Epoch 00197: val_loss did not improve from 18.20954
Epoch 198/10000
4/4 - 0s - loss: 18.8413 - val_loss: 18.2369

Epoch 00198: val_loss did not improve from 18.20954
Epoch 199/10000
4/4 - 0s - loss: 18.8214 - val_loss: 18.2919

Epoch 00199: val_loss did not improve from 18.20954
Epoch 200/10000
4/4 - 0s - loss: 18.7970 - val_loss: 18.3228

Epoch 00200: val_loss did not improve from 18.20954
Epoch 201/10000
4/4 - 0s - loss: 18.8092 - val_loss: 18.3563

Epoch 00201: val_loss did not improve from 18.20954
Epoch 202/10000
4/4 - 0s - loss: 18.8072 - val_loss: 18.3066

Epoch 00202: val_loss did not improve from 18.20954
Epoch 203/10000
4/4 - 0s - loss: 18.7930 - val_loss: 18.2544

Epoch 00203: val_loss did not improve from 18.20954
Epoch 204/10000
4/4 - 0s - loss: 18.8066 - val_loss: 18.2846

Epoch 00204: val_loss did not improve from 18.20954
Epoch 205/10000
4/4 - 0s - loss: 18.7966 - val_loss: 18.3118

Epoch 00205: val_loss did not improve from 18.20954
Epoch 206/10000
4/4 - 0s - loss: 18.8024 - val_loss: 18.3300

Epoch 00206: val_loss did not improve from 18.20954
Epoch 207/10000
4/4 - 0s - loss: 18.7984 - val_loss: 18.3244

Epoch 00207: val_loss did not improve from 18.20954
Epoch 208/10000
4/4 - 0s - loss: 18.7990 - val_loss: 18.2968

Epoch 00208: val_loss did not improve from 18.20954
Epoch 209/10000
4/4 - 0s - loss: 18.8052 - val_loss: 18.2480

Epoch 00209: val_loss did not improve from 18.20954
Epoch 210/10000
4/4 - 0s - loss: 18.8017 - val_loss: 18.3199

Epoch 00210: val_loss did not improve from 18.20954
Epoch 211/10000
4/4 - 0s - loss: 18.7996 - val_loss: 18.4123

Epoch 00211: val_loss did not improve from 18.20954
Epoch 212/10000
4/4 - 0s - loss: 18.8107 - val_loss: 18.3083

Epoch 00212: val_loss did not improve from 18.20954
Epoch 213/10000
4/4 - 0s - loss: 18.8978 - val_loss: 18.2547

Epoch 00213: val_loss did not improve from 18.20954
Epoch 214/10000
4/4 - 0s - loss: 18.7878 - val_loss: 18.4169

Epoch 00214: val_loss did not improve from 18.20954
Epoch 215/10000
4/4 - 0s - loss: 18.8241 - val_loss: 18.4445

Epoch 00215: val_loss did not improve from 18.20954
Epoch 216/10000
4/4 - 0s - loss: 18.7903 - val_loss: 18.2778

Epoch 00216: val_loss did not improve from 18.20954
Epoch 217/10000
4/4 - 0s - loss: 18.8528 - val_loss: 18.2245

Epoch 00217: val_loss did not improve from 18.20954
Epoch 218/10000
4/4 - 0s - loss: 18.8218 - val_loss: 18.3291

Epoch 00218: val_loss did not improve from 18.20954
Epoch 219/10000
4/4 - 0s - loss: 18.7885 - val_loss: 18.4819

Epoch 00219: val_loss did not improve from 18.20954
Epoch 220/10000
4/4 - 0s - loss: 18.8319 - val_loss: 18.3261

Epoch 00220: val_loss did not improve from 18.20954
Epoch 221/10000
4/4 - 0s - loss: 18.8025 - val_loss: 18.2617

Epoch 00221: val_loss did not improve from 18.20954
Epoch 222/10000
4/4 - 0s - loss: 18.8237 - val_loss: 18.2885

Epoch 00222: val_loss did not improve from 18.20954
Epoch 223/10000
4/4 - 0s - loss: 18.7932 - val_loss: 18.3163

Epoch 00223: val_loss did not improve from 18.20954
Epoch 224/10000
4/4 - 0s - loss: 18.7902 - val_loss: 18.3231

Epoch 00224: val_loss did not improve from 18.20954
Epoch 225/10000
4/4 - 0s - loss: 18.7981 - val_loss: 18.3237

Epoch 00225: val_loss did not improve from 18.20954
Epoch 226/10000
4/4 - 0s - loss: 18.7938 - val_loss: 18.3271

Epoch 00226: val_loss did not improve from 18.20954
Epoch 227/10000
4/4 - 0s - loss: 18.7987 - val_loss: 18.2858

Epoch 00227: val_loss did not improve from 18.20954
Epoch 228/10000
4/4 - 0s - loss: 18.8046 - val_loss: 18.3094

Epoch 00228: val_loss did not improve from 18.20954
Epoch 229/10000
4/4 - 0s - loss: 18.8195 - val_loss: 18.2426

Epoch 00229: val_loss did not improve from 18.20954
Epoch 230/10000
4/4 - 0s - loss: 18.8762 - val_loss: 18.3663

Epoch 00230: val_loss did not improve from 18.20954
Epoch 231/10000
4/4 - 0s - loss: 18.8235 - val_loss: 18.2486

Epoch 00231: val_loss did not improve from 18.20954
Epoch 232/10000
4/4 - 0s - loss: 18.8022 - val_loss: 18.3181

Epoch 00232: val_loss did not improve from 18.20954
Epoch 233/10000
4/4 - 0s - loss: 18.8104 - val_loss: 18.3730

Epoch 00233: val_loss did not improve from 18.20954
Epoch 234/10000
4/4 - 0s - loss: 18.7798 - val_loss: 18.2622

Epoch 00234: val_loss did not improve from 18.20954
Epoch 235/10000
4/4 - 0s - loss: 18.8387 - val_loss: 18.2215

Epoch 00235: val_loss did not improve from 18.20954
Epoch 236/10000
4/4 - 0s - loss: 18.7971 - val_loss: 18.3306

Epoch 00236: val_loss did not improve from 18.20954
Epoch 237/10000
4/4 - 0s - loss: 18.8056 - val_loss: 18.3959

Epoch 00237: val_loss did not improve from 18.20954
Epoch 238/10000
4/4 - 0s - loss: 18.8101 - val_loss: 18.2542

Epoch 00238: val_loss did not improve from 18.20954
Epoch 239/10000
4/4 - 0s - loss: 18.8049 - val_loss: 18.2406

Epoch 00239: val_loss did not improve from 18.20954
Epoch 240/10000
4/4 - 0s - loss: 18.7921 - val_loss: 18.3426

Epoch 00240: val_loss did not improve from 18.20954
Epoch 241/10000
4/4 - 0s - loss: 18.7998 - val_loss: 18.3416

Epoch 00241: val_loss did not improve from 18.20954
Epoch 242/10000
4/4 - 0s - loss: 18.7882 - val_loss: 18.2715

Epoch 00242: val_loss did not improve from 18.20954
Epoch 243/10000
4/4 - 0s - loss: 18.7924 - val_loss: 18.2197

Epoch 00243: val_loss did not improve from 18.20954
Epoch 244/10000
4/4 - 0s - loss: 18.8100 - val_loss: 18.2565

Epoch 00244: val_loss did not improve from 18.20954
Epoch 245/10000
4/4 - 0s - loss: 18.7864 - val_loss: 18.3138

Epoch 00245: val_loss did not improve from 18.20954
Epoch 246/10000
4/4 - 0s - loss: 18.7953 - val_loss: 18.3899

Epoch 00246: val_loss did not improve from 18.20954
Epoch 247/10000
4/4 - 0s - loss: 18.7994 - val_loss: 18.3022

Epoch 00247: val_loss did not improve from 18.20954
Epoch 248/10000
4/4 - 0s - loss: 18.7904 - val_loss: 18.2379

Epoch 00248: val_loss did not improve from 18.20954
Epoch 249/10000
4/4 - 0s - loss: 18.8288 - val_loss: 18.2649

Epoch 00249: val_loss did not improve from 18.20954
Epoch 250/10000
4/4 - 0s - loss: 18.7985 - val_loss: 18.4776

Epoch 00250: val_loss did not improve from 18.20954
Epoch 251/10000
4/4 - 0s - loss: 18.8196 - val_loss: 18.3251

Epoch 00251: val_loss did not improve from 18.20954
Epoch 252/10000
4/4 - 0s - loss: 18.8307 - val_loss: 18.2109

Epoch 00252: val_loss did not improve from 18.20954
Epoch 253/10000
4/4 - 0s - loss: 18.8292 - val_loss: 18.2708

Epoch 00253: val_loss did not improve from 18.20954
Epoch 254/10000
4/4 - 0s - loss: 18.7978 - val_loss: 18.5269

Epoch 00254: val_loss did not improve from 18.20954
Epoch 255/10000
4/4 - 0s - loss: 18.8417 - val_loss: 18.3346

Epoch 00255: val_loss did not improve from 18.20954
Epoch 256/10000
4/4 - 0s - loss: 18.8149 - val_loss: 18.2186

Epoch 00256: val_loss did not improve from 18.20954
Epoch 257/10000
4/4 - 0s - loss: 18.8196 - val_loss: 18.2925

Epoch 00257: val_loss did not improve from 18.20954
Epoch 258/10000
4/4 - 0s - loss: 18.7993 - val_loss: 18.3936

Epoch 00258: val_loss did not improve from 18.20954
Epoch 259/10000
4/4 - 0s - loss: 18.8198 - val_loss: 18.3978

Epoch 00259: val_loss did not improve from 18.20954
Epoch 260/10000
4/4 - 0s - loss: 18.8042 - val_loss: 18.2939

Epoch 00260: val_loss did not improve from 18.20954
Epoch 261/10000
4/4 - 0s - loss: 18.8187 - val_loss: 18.2030

Epoch 00261: val_loss improved from 18.20954 to 18.20302, saving model to ./results/dataset/trial_5/ckpt_7
Epoch 262/10000
4/4 - 0s - loss: 18.8262 - val_loss: 18.2887

Epoch 00262: val_loss did not improve from 18.20302
Epoch 263/10000
4/4 - 0s - loss: 18.8611 - val_loss: 18.4131

Epoch 00263: val_loss did not improve from 18.20302
Epoch 264/10000
4/4 - 0s - loss: 18.8097 - val_loss: 18.2226

Epoch 00264: val_loss did not improve from 18.20302
Epoch 265/10000
4/4 - 0s - loss: 18.8132 - val_loss: 18.2279

Epoch 00265: val_loss did not improve from 18.20302
Epoch 266/10000
4/4 - 0s - loss: 18.7962 - val_loss: 18.3463

Epoch 00266: val_loss did not improve from 18.20302
Epoch 267/10000
4/4 - 0s - loss: 18.8082 - val_loss: 18.3478

Epoch 00267: val_loss did not improve from 18.20302
Epoch 268/10000
4/4 - 0s - loss: 18.7938 - val_loss: 18.2686

Epoch 00268: val_loss did not improve from 18.20302
Epoch 269/10000
4/4 - 0s - loss: 18.7950 - val_loss: 18.2303

Epoch 00269: val_loss did not improve from 18.20302
Epoch 270/10000
4/4 - 0s - loss: 18.8100 - val_loss: 18.2622

Epoch 00270: val_loss did not improve from 18.20302
Epoch 271/10000
4/4 - 0s - loss: 18.7871 - val_loss: 18.3469

Epoch 00271: val_loss did not improve from 18.20302
Epoch 272/10000
4/4 - 0s - loss: 18.8117 - val_loss: 18.2734

Epoch 00272: val_loss did not improve from 18.20302
Epoch 273/10000
4/4 - 0s - loss: 18.7857 - val_loss: 18.2743

Epoch 00273: val_loss did not improve from 18.20302
Epoch 274/10000
4/4 - 0s - loss: 18.7973 - val_loss: 18.2483

Epoch 00274: val_loss did not improve from 18.20302
Epoch 275/10000
4/4 - 0s - loss: 18.7840 - val_loss: 18.2738

Epoch 00275: val_loss did not improve from 18.20302
Epoch 276/10000
4/4 - 0s - loss: 18.7827 - val_loss: 18.2948

Epoch 00276: val_loss did not improve from 18.20302
Epoch 277/10000
4/4 - 0s - loss: 18.7879 - val_loss: 18.2960

Epoch 00277: val_loss did not improve from 18.20302
Epoch 278/10000
4/4 - 0s - loss: 18.8220 - val_loss: 18.3580

Epoch 00278: val_loss did not improve from 18.20302
Epoch 279/10000
4/4 - 0s - loss: 18.8118 - val_loss: 18.2237

Epoch 00279: val_loss did not improve from 18.20302
Epoch 280/10000
4/4 - 0s - loss: 18.8207 - val_loss: 18.2350

Epoch 00280: val_loss did not improve from 18.20302
Epoch 281/10000
4/4 - 0s - loss: 18.7838 - val_loss: 18.3912

Epoch 00281: val_loss did not improve from 18.20302
Epoch 282/10000
4/4 - 0s - loss: 18.8019 - val_loss: 18.3330

Epoch 00282: val_loss did not improve from 18.20302
Epoch 283/10000
4/4 - 0s - loss: 18.8311 - val_loss: 18.2533

Epoch 00283: val_loss did not improve from 18.20302
Epoch 284/10000
4/4 - 0s - loss: 18.7901 - val_loss: 18.3885

Epoch 00284: val_loss did not improve from 18.20302
Epoch 285/10000
4/4 - 0s - loss: 18.7950 - val_loss: 18.3671

Epoch 00285: val_loss did not improve from 18.20302
Epoch 286/10000
4/4 - 0s - loss: 18.8030 - val_loss: 18.2990

Epoch 00286: val_loss did not improve from 18.20302
Epoch 287/10000
4/4 - 0s - loss: 18.7853 - val_loss: 18.3421

Epoch 00287: val_loss did not improve from 18.20302
Epoch 288/10000
4/4 - 0s - loss: 18.8104 - val_loss: 18.3215

Epoch 00288: val_loss did not improve from 18.20302
Epoch 289/10000
4/4 - 0s - loss: 18.8199 - val_loss: 18.2244

Epoch 00289: val_loss did not improve from 18.20302
Epoch 290/10000
4/4 - 0s - loss: 18.7957 - val_loss: 18.3005

Epoch 00290: val_loss did not improve from 18.20302
Epoch 291/10000
4/4 - 0s - loss: 18.8593 - val_loss: 18.3632

Epoch 00291: val_loss did not improve from 18.20302
Epoch 292/10000
4/4 - 0s - loss: 18.7936 - val_loss: 18.2258

Epoch 00292: val_loss did not improve from 18.20302
Epoch 293/10000
4/4 - 0s - loss: 18.8270 - val_loss: 18.2558

Epoch 00293: val_loss did not improve from 18.20302
Epoch 294/10000
4/4 - 0s - loss: 18.7875 - val_loss: 18.3159

Epoch 00294: val_loss did not improve from 18.20302
Epoch 295/10000
4/4 - 0s - loss: 18.7969 - val_loss: 18.3148

Epoch 00295: val_loss did not improve from 18.20302
Epoch 296/10000
4/4 - 0s - loss: 18.8385 - val_loss: 18.4158

Epoch 00296: val_loss did not improve from 18.20302
Epoch 297/10000
4/4 - 0s - loss: 18.8141 - val_loss: 18.2471

Epoch 00297: val_loss did not improve from 18.20302
Epoch 298/10000
4/4 - 0s - loss: 18.7985 - val_loss: 18.2475

Epoch 00298: val_loss did not improve from 18.20302
Epoch 299/10000
4/4 - 0s - loss: 18.8115 - val_loss: 18.3142

Epoch 00299: val_loss did not improve from 18.20302
Epoch 300/10000
4/4 - 0s - loss: 18.7822 - val_loss: 18.2736

Epoch 00300: val_loss did not improve from 18.20302
Epoch 301/10000
4/4 - 0s - loss: 18.7796 - val_loss: 18.2639

Epoch 00301: val_loss did not improve from 18.20302
Epoch 302/10000
4/4 - 0s - loss: 18.7889 - val_loss: 18.2576

Epoch 00302: val_loss did not improve from 18.20302
Epoch 303/10000
4/4 - 0s - loss: 18.7857 - val_loss: 18.2725

Epoch 00303: val_loss did not improve from 18.20302
Epoch 304/10000
4/4 - 0s - loss: 18.7789 - val_loss: 18.2769

Epoch 00304: val_loss did not improve from 18.20302
Epoch 305/10000
4/4 - 0s - loss: 18.7867 - val_loss: 18.2527

Epoch 00305: val_loss did not improve from 18.20302
Epoch 306/10000
4/4 - 0s - loss: 18.7761 - val_loss: 18.3401

Epoch 00306: val_loss did not improve from 18.20302
Epoch 307/10000
4/4 - 0s - loss: 18.7964 - val_loss: 18.3568

Epoch 00307: val_loss did not improve from 18.20302
Epoch 308/10000
4/4 - 0s - loss: 18.7931 - val_loss: 18.3259

Epoch 00308: val_loss did not improve from 18.20302
Epoch 309/10000
4/4 - 0s - loss: 18.7956 - val_loss: 18.3579

Epoch 00309: val_loss did not improve from 18.20302
Epoch 310/10000
4/4 - 0s - loss: 18.8066 - val_loss: 18.2666

Epoch 00310: val_loss did not improve from 18.20302
Epoch 311/10000
4/4 - 0s - loss: 18.7878 - val_loss: 18.3569

Epoch 00311: val_loss did not improve from 18.20302
Epoch 312/10000
4/4 - 0s - loss: 18.7954 - val_loss: 18.3248

Epoch 00312: val_loss did not improve from 18.20302
Epoch 313/10000
4/4 - 0s - loss: 18.7867 - val_loss: 18.2519

Epoch 00313: val_loss did not improve from 18.20302
Epoch 314/10000
4/4 - 0s - loss: 18.8273 - val_loss: 18.2829

Epoch 00314: val_loss did not improve from 18.20302
Epoch 315/10000
4/4 - 0s - loss: 18.7771 - val_loss: 18.2317

Epoch 00315: val_loss did not improve from 18.20302
Epoch 316/10000
4/4 - 0s - loss: 18.8014 - val_loss: 18.2772

Epoch 00316: val_loss did not improve from 18.20302
Epoch 317/10000
4/4 - 0s - loss: 18.7784 - val_loss: 18.2525

Epoch 00317: val_loss did not improve from 18.20302
Epoch 318/10000
4/4 - 0s - loss: 18.7836 - val_loss: 18.2411

Epoch 00318: val_loss did not improve from 18.20302
Epoch 319/10000
4/4 - 0s - loss: 18.8018 - val_loss: 18.2874

Epoch 00319: val_loss did not improve from 18.20302
Epoch 320/10000
4/4 - 0s - loss: 18.7836 - val_loss: 18.5169

Epoch 00320: val_loss did not improve from 18.20302
Epoch 321/10000
4/4 - 0s - loss: 18.8238 - val_loss: 18.3697

Epoch 00321: val_loss did not improve from 18.20302
Epoch 322/10000
4/4 - 0s - loss: 18.7750 - val_loss: 18.2913

Epoch 00322: val_loss did not improve from 18.20302
Epoch 323/10000
4/4 - 0s - loss: 18.8248 - val_loss: 18.2781

Epoch 00323: val_loss did not improve from 18.20302
Epoch 324/10000
4/4 - 0s - loss: 18.8282 - val_loss: 18.2405

Epoch 00324: val_loss did not improve from 18.20302
Epoch 325/10000
4/4 - 0s - loss: 18.9180 - val_loss: 18.4409

Epoch 00325: val_loss did not improve from 18.20302
Epoch 326/10000
4/4 - 0s - loss: 18.8025 - val_loss: 18.2221

Epoch 00326: val_loss did not improve from 18.20302
Epoch 327/10000
4/4 - 0s - loss: 18.8112 - val_loss: 18.2052

Epoch 00327: val_loss did not improve from 18.20302
Epoch 328/10000
4/4 - 0s - loss: 18.7884 - val_loss: 18.2929

Epoch 00328: val_loss did not improve from 18.20302
Epoch 329/10000
4/4 - 0s - loss: 18.8139 - val_loss: 18.3987

Epoch 00329: val_loss did not improve from 18.20302
Epoch 330/10000
4/4 - 0s - loss: 18.8025 - val_loss: 18.3105

Epoch 00330: val_loss did not improve from 18.20302
Epoch 331/10000
4/4 - 0s - loss: 18.7781 - val_loss: 18.3137

Epoch 00331: val_loss did not improve from 18.20302
Epoch 332/10000
4/4 - 0s - loss: 18.7779 - val_loss: 18.3193

Epoch 00332: val_loss did not improve from 18.20302
Epoch 333/10000
4/4 - 0s - loss: 18.8193 - val_loss: 18.3418

Epoch 00333: val_loss did not improve from 18.20302
Epoch 334/10000
4/4 - 0s - loss: 18.7822 - val_loss: 18.2232

Epoch 00334: val_loss did not improve from 18.20302
Epoch 335/10000
4/4 - 0s - loss: 18.8304 - val_loss: 18.2195

Epoch 00335: val_loss did not improve from 18.20302
Epoch 336/10000
4/4 - 0s - loss: 18.8077 - val_loss: 18.4432

Epoch 00336: val_loss did not improve from 18.20302
Epoch 337/10000
4/4 - 0s - loss: 18.8199 - val_loss: 18.3120

Epoch 00337: val_loss did not improve from 18.20302
Epoch 338/10000
4/4 - 0s - loss: 18.7928 - val_loss: 18.2362

Epoch 00338: val_loss did not improve from 18.20302
Epoch 339/10000
4/4 - 0s - loss: 18.8028 - val_loss: 18.2973

Epoch 00339: val_loss did not improve from 18.20302
Epoch 340/10000
4/4 - 0s - loss: 18.7988 - val_loss: 18.3730

Epoch 00340: val_loss did not improve from 18.20302
Epoch 341/10000
4/4 - 0s - loss: 18.7762 - val_loss: 18.2922

Epoch 00341: val_loss did not improve from 18.20302
Epoch 342/10000
4/4 - 0s - loss: 18.7942 - val_loss: 18.2278

Epoch 00342: val_loss did not improve from 18.20302
Epoch 343/10000
4/4 - 0s - loss: 18.7902 - val_loss: 18.2910

Epoch 00343: val_loss did not improve from 18.20302
Epoch 344/10000
4/4 - 0s - loss: 18.7817 - val_loss: 18.3923

Epoch 00344: val_loss did not improve from 18.20302
Epoch 345/10000
4/4 - 0s - loss: 18.7999 - val_loss: 18.3139

Epoch 00345: val_loss did not improve from 18.20302
Epoch 346/10000
4/4 - 0s - loss: 18.7795 - val_loss: 18.2401

Epoch 00346: val_loss did not improve from 18.20302
Epoch 347/10000
4/4 - 0s - loss: 18.8062 - val_loss: 18.2717

Epoch 00347: val_loss did not improve from 18.20302
Epoch 348/10000
4/4 - 0s - loss: 18.8138 - val_loss: 18.4713

Epoch 00348: val_loss did not improve from 18.20302
Epoch 349/10000
4/4 - 0s - loss: 18.8300 - val_loss: 18.3220

Epoch 00349: val_loss did not improve from 18.20302
Epoch 350/10000
4/4 - 0s - loss: 18.7795 - val_loss: 18.3597

Epoch 00350: val_loss did not improve from 18.20302
Epoch 351/10000
4/4 - 0s - loss: 18.7785 - val_loss: 18.3533

Epoch 00351: val_loss did not improve from 18.20302
Epoch 352/10000
4/4 - 0s - loss: 18.7787 - val_loss: 18.3074

Epoch 00352: val_loss did not improve from 18.20302
Epoch 353/10000
4/4 - 0s - loss: 18.7757 - val_loss: 18.3164

Epoch 00353: val_loss did not improve from 18.20302
Epoch 354/10000
4/4 - 0s - loss: 18.7856 - val_loss: 18.3597

Epoch 00354: val_loss did not improve from 18.20302
Epoch 355/10000
4/4 - 0s - loss: 18.7761 - val_loss: 18.3016

Epoch 00355: val_loss did not improve from 18.20302
Epoch 356/10000
4/4 - 0s - loss: 18.7779 - val_loss: 18.2727

Epoch 00356: val_loss did not improve from 18.20302
Epoch 357/10000
4/4 - 0s - loss: 18.7862 - val_loss: 18.2978

Epoch 00357: val_loss did not improve from 18.20302
Epoch 358/10000
4/4 - 0s - loss: 18.7807 - val_loss: 18.2848

Epoch 00358: val_loss did not improve from 18.20302
Epoch 359/10000
4/4 - 0s - loss: 18.7921 - val_loss: 18.2438

Epoch 00359: val_loss did not improve from 18.20302
Epoch 360/10000
4/4 - 0s - loss: 18.7791 - val_loss: 18.3287

Epoch 00360: val_loss did not improve from 18.20302
Epoch 361/10000
4/4 - 0s - loss: 18.7985 - val_loss: 18.3547

Epoch 00361: val_loss did not improve from 18.20302
Epoch 362/10000
4/4 - 0s - loss: 18.7875 - val_loss: 18.2743

Epoch 00362: val_loss did not improve from 18.20302
Epoch 363/10000
4/4 - 0s - loss: 18.7781 - val_loss: 18.2960

Epoch 00363: val_loss did not improve from 18.20302
Epoch 364/10000
4/4 - 0s - loss: 18.7912 - val_loss: 18.3659

Epoch 00364: val_loss did not improve from 18.20302
Epoch 365/10000
4/4 - 0s - loss: 18.8089 - val_loss: 18.2373

Epoch 00365: val_loss did not improve from 18.20302
Epoch 366/10000
4/4 - 0s - loss: 18.7835 - val_loss: 18.2776

Epoch 00366: val_loss did not improve from 18.20302
Epoch 367/10000
4/4 - 0s - loss: 18.7878 - val_loss: 18.3635

Epoch 00367: val_loss did not improve from 18.20302
Epoch 368/10000
4/4 - 0s - loss: 18.8152 - val_loss: 18.3267

Epoch 00368: val_loss did not improve from 18.20302
Epoch 369/10000
4/4 - 0s - loss: 18.7969 - val_loss: 18.2293

Epoch 00369: val_loss did not improve from 18.20302
Epoch 370/10000
4/4 - 0s - loss: 18.8021 - val_loss: 18.2631

Epoch 00370: val_loss did not improve from 18.20302
Epoch 371/10000
4/4 - 0s - loss: 18.7708 - val_loss: 18.3285

Epoch 00371: val_loss did not improve from 18.20302
Epoch 372/10000
4/4 - 0s - loss: 18.8005 - val_loss: 18.3911

Epoch 00372: val_loss did not improve from 18.20302
Epoch 373/10000
4/4 - 0s - loss: 18.7786 - val_loss: 18.2985

Epoch 00373: val_loss did not improve from 18.20302
Epoch 374/10000
4/4 - 0s - loss: 18.7745 - val_loss: 18.2730

Epoch 00374: val_loss did not improve from 18.20302
Epoch 375/10000
4/4 - 0s - loss: 18.7897 - val_loss: 18.3092

Epoch 00375: val_loss did not improve from 18.20302
Epoch 376/10000
4/4 - 0s - loss: 18.7789 - val_loss: 18.2688

Epoch 00376: val_loss did not improve from 18.20302
Epoch 377/10000
4/4 - 0s - loss: 18.8050 - val_loss: 18.3431

Epoch 00377: val_loss did not improve from 18.20302
Epoch 378/10000
4/4 - 0s - loss: 18.7743 - val_loss: 18.2823

Epoch 00378: val_loss did not improve from 18.20302
Epoch 379/10000
4/4 - 0s - loss: 18.7736 - val_loss: 18.2961

Epoch 00379: val_loss did not improve from 18.20302
Epoch 380/10000
4/4 - 0s - loss: 18.7788 - val_loss: 18.3005

Epoch 00380: val_loss did not improve from 18.20302
Epoch 381/10000
4/4 - 0s - loss: 18.7833 - val_loss: 18.3725

Epoch 00381: val_loss did not improve from 18.20302
Epoch 382/10000
4/4 - 0s - loss: 18.8348 - val_loss: 18.2721

Epoch 00382: val_loss did not improve from 18.20302
Epoch 383/10000
4/4 - 0s - loss: 18.8236 - val_loss: 18.4193

Epoch 00383: val_loss did not improve from 18.20302
Epoch 384/10000
4/4 - 0s - loss: 18.7874 - val_loss: 18.2900

Epoch 00384: val_loss did not improve from 18.20302
Epoch 385/10000
4/4 - 0s - loss: 18.7854 - val_loss: 18.2704

Epoch 00385: val_loss did not improve from 18.20302
Epoch 386/10000
4/4 - 0s - loss: 18.7840 - val_loss: 18.2970

Epoch 00386: val_loss did not improve from 18.20302
Epoch 387/10000
4/4 - 0s - loss: 18.7825 - val_loss: 18.3182

Epoch 00387: val_loss did not improve from 18.20302
Epoch 388/10000
4/4 - 0s - loss: 18.7885 - val_loss: 18.2613

Epoch 00388: val_loss did not improve from 18.20302
Epoch 389/10000
4/4 - 0s - loss: 18.7802 - val_loss: 18.2807

Epoch 00389: val_loss did not improve from 18.20302
Epoch 390/10000
4/4 - 0s - loss: 18.7706 - val_loss: 18.3293

Epoch 00390: val_loss did not improve from 18.20302
Epoch 391/10000
4/4 - 0s - loss: 18.8127 - val_loss: 18.3632

Epoch 00391: val_loss did not improve from 18.20302
Epoch 392/10000
4/4 - 0s - loss: 18.7963 - val_loss: 18.2742

Epoch 00392: val_loss did not improve from 18.20302
Epoch 393/10000
4/4 - 0s - loss: 18.7901 - val_loss: 18.2610

Epoch 00393: val_loss did not improve from 18.20302
Epoch 394/10000
4/4 - 0s - loss: 18.7830 - val_loss: 18.2982

Epoch 00394: val_loss did not improve from 18.20302
Epoch 395/10000
4/4 - 0s - loss: 18.7648 - val_loss: 18.4461

Epoch 00395: val_loss did not improve from 18.20302
Epoch 396/10000
4/4 - 0s - loss: 18.8281 - val_loss: 18.3890

Epoch 00396: val_loss did not improve from 18.20302
Epoch 397/10000
4/4 - 0s - loss: 18.7799 - val_loss: 18.2466

Epoch 00397: val_loss did not improve from 18.20302
Epoch 398/10000
4/4 - 0s - loss: 18.8568 - val_loss: 18.2586

Epoch 00398: val_loss did not improve from 18.20302
Epoch 399/10000
4/4 - 0s - loss: 18.7862 - val_loss: 18.3822

Epoch 00399: val_loss did not improve from 18.20302
Epoch 400/10000
4/4 - 0s - loss: 18.8023 - val_loss: 18.3689

Epoch 00400: val_loss did not improve from 18.20302
Epoch 401/10000
4/4 - 0s - loss: 18.7895 - val_loss: 18.2849

Epoch 00401: val_loss did not improve from 18.20302
Epoch 402/10000
4/4 - 0s - loss: 18.7768 - val_loss: 18.3002

Epoch 00402: val_loss did not improve from 18.20302
Epoch 403/10000
4/4 - 0s - loss: 18.7788 - val_loss: 18.2761

Epoch 00403: val_loss did not improve from 18.20302
Epoch 404/10000
4/4 - 0s - loss: 18.7807 - val_loss: 18.2890

Epoch 00404: val_loss did not improve from 18.20302
Epoch 405/10000
4/4 - 0s - loss: 18.7861 - val_loss: 18.4004

Epoch 00405: val_loss did not improve from 18.20302
Epoch 406/10000
4/4 - 0s - loss: 18.7958 - val_loss: 18.3180

Epoch 00406: val_loss did not improve from 18.20302
Epoch 407/10000
4/4 - 0s - loss: 18.7583 - val_loss: 18.2255

Epoch 00407: val_loss did not improve from 18.20302
Epoch 408/10000
4/4 - 0s - loss: 18.8245 - val_loss: 18.2281

Epoch 00408: val_loss did not improve from 18.20302
Epoch 409/10000
4/4 - 0s - loss: 18.7924 - val_loss: 18.3784

Epoch 00409: val_loss did not improve from 18.20302
Epoch 410/10000
4/4 - 0s - loss: 18.7959 - val_loss: 18.3050

Epoch 00410: val_loss did not improve from 18.20302
Epoch 411/10000
4/4 - 0s - loss: 18.7795 - val_loss: 18.2974

Epoch 00411: val_loss did not improve from 18.20302
Epoch 412/10000
4/4 - 0s - loss: 18.7747 - val_loss: 18.2633

Epoch 00412: val_loss did not improve from 18.20302
Epoch 413/10000
4/4 - 0s - loss: 18.7804 - val_loss: 18.3020

Epoch 00413: val_loss did not improve from 18.20302
Epoch 414/10000
4/4 - 0s - loss: 18.7679 - val_loss: 18.3902

Epoch 00414: val_loss did not improve from 18.20302
Epoch 415/10000
4/4 - 0s - loss: 18.7885 - val_loss: 18.3217

Epoch 00415: val_loss did not improve from 18.20302
Epoch 416/10000
4/4 - 0s - loss: 18.7966 - val_loss: 18.3096

Epoch 00416: val_loss did not improve from 18.20302
Epoch 417/10000
4/4 - 0s - loss: 18.7960 - val_loss: 18.4407

Epoch 00417: val_loss did not improve from 18.20302
Epoch 418/10000
4/4 - 0s - loss: 18.7849 - val_loss: 18.2972

Epoch 00418: val_loss did not improve from 18.20302
Epoch 419/10000
4/4 - 0s - loss: 18.8017 - val_loss: 18.2802

Epoch 00419: val_loss did not improve from 18.20302
Epoch 420/10000
4/4 - 0s - loss: 18.7959 - val_loss: 18.2565

Epoch 00420: val_loss did not improve from 18.20302
Epoch 421/10000
4/4 - 0s - loss: 18.8308 - val_loss: 18.3591

Epoch 00421: val_loss did not improve from 18.20302
Epoch 422/10000
4/4 - 0s - loss: 18.7573 - val_loss: 18.2469

Epoch 00422: val_loss did not improve from 18.20302
Epoch 423/10000
4/4 - 0s - loss: 18.7825 - val_loss: 18.2142

Epoch 00423: val_loss did not improve from 18.20302
Epoch 424/10000
4/4 - 0s - loss: 18.8344 - val_loss: 18.2249

Epoch 00424: val_loss did not improve from 18.20302
Epoch 425/10000
4/4 - 0s - loss: 18.7674 - val_loss: 18.5076

Epoch 00425: val_loss did not improve from 18.20302
Epoch 426/10000
4/4 - 0s - loss: 18.8361 - val_loss: 18.3903

Epoch 00426: val_loss did not improve from 18.20302
Epoch 427/10000
4/4 - 0s - loss: 18.8633 - val_loss: 18.2371

Epoch 00427: val_loss did not improve from 18.20302
Epoch 428/10000
4/4 - 0s - loss: 18.8246 - val_loss: 18.3028

Epoch 00428: val_loss did not improve from 18.20302
Epoch 429/10000
4/4 - 0s - loss: 18.8840 - val_loss: 18.5661

Epoch 00429: val_loss did not improve from 18.20302
Epoch 430/10000
4/4 - 0s - loss: 18.8149 - val_loss: 18.3412

Epoch 00430: val_loss did not improve from 18.20302
Epoch 431/10000
4/4 - 0s - loss: 18.8207 - val_loss: 18.2336

Epoch 00431: val_loss did not improve from 18.20302
Epoch 432/10000
4/4 - 0s - loss: 18.8313 - val_loss: 18.2690

Epoch 00432: val_loss did not improve from 18.20302
Epoch 433/10000
4/4 - 0s - loss: 18.7860 - val_loss: 18.4338

Epoch 00433: val_loss did not improve from 18.20302
Epoch 434/10000
4/4 - 0s - loss: 18.8051 - val_loss: 18.3441

Epoch 00434: val_loss did not improve from 18.20302
Epoch 435/10000
4/4 - 0s - loss: 18.7633 - val_loss: 18.2263

Epoch 00435: val_loss did not improve from 18.20302
Epoch 436/10000
4/4 - 0s - loss: 18.8150 - val_loss: 18.2410

Epoch 00436: val_loss did not improve from 18.20302
Epoch 437/10000
4/4 - 0s - loss: 18.7847 - val_loss: 18.3094

Epoch 00437: val_loss did not improve from 18.20302
Epoch 438/10000
4/4 - 0s - loss: 18.7714 - val_loss: 18.3097

Epoch 00438: val_loss did not improve from 18.20302
Epoch 439/10000
4/4 - 0s - loss: 18.7888 - val_loss: 18.2974

Epoch 00439: val_loss did not improve from 18.20302
Epoch 440/10000
4/4 - 0s - loss: 18.7879 - val_loss: 18.2232

Epoch 00440: val_loss did not improve from 18.20302
Epoch 441/10000
4/4 - 0s - loss: 18.8397 - val_loss: 18.3218

Epoch 00441: val_loss did not improve from 18.20302
Epoch 442/10000
4/4 - 0s - loss: 18.7707 - val_loss: 18.2888

Epoch 00442: val_loss did not improve from 18.20302
Epoch 443/10000
4/4 - 0s - loss: 18.7709 - val_loss: 18.2738

Epoch 00443: val_loss did not improve from 18.20302
Epoch 444/10000
4/4 - 0s - loss: 18.7758 - val_loss: 18.3013

Epoch 00444: val_loss did not improve from 18.20302
Epoch 445/10000
4/4 - 0s - loss: 18.7778 - val_loss: 18.4164

Epoch 00445: val_loss did not improve from 18.20302
Epoch 446/10000
4/4 - 0s - loss: 18.7813 - val_loss: 18.3230

Epoch 00446: val_loss did not improve from 18.20302
Epoch 447/10000
4/4 - 0s - loss: 18.7971 - val_loss: 18.2744

Epoch 00447: val_loss did not improve from 18.20302
Epoch 448/10000
4/4 - 0s - loss: 18.7890 - val_loss: 18.3565

Epoch 00448: val_loss did not improve from 18.20302
Epoch 449/10000
4/4 - 0s - loss: 18.7693 - val_loss: 18.3342

Epoch 00449: val_loss did not improve from 18.20302
Epoch 450/10000
4/4 - 0s - loss: 18.7770 - val_loss: 18.2741

Epoch 00450: val_loss did not improve from 18.20302
Epoch 451/10000
4/4 - 0s - loss: 18.7733 - val_loss: 18.3144

Epoch 00451: val_loss did not improve from 18.20302
Epoch 452/10000
4/4 - 0s - loss: 18.7924 - val_loss: 18.3258

Epoch 00452: val_loss did not improve from 18.20302
Epoch 453/10000
4/4 - 0s - loss: 18.7747 - val_loss: 18.3284

Epoch 00453: val_loss did not improve from 18.20302
Epoch 454/10000
4/4 - 0s - loss: 18.7638 - val_loss: 18.2814

Epoch 00454: val_loss did not improve from 18.20302
Epoch 455/10000
4/4 - 0s - loss: 18.8044 - val_loss: 18.2589

Epoch 00455: val_loss did not improve from 18.20302
Epoch 456/10000
4/4 - 0s - loss: 18.8048 - val_loss: 18.4344

Epoch 00456: val_loss did not improve from 18.20302
Epoch 457/10000
4/4 - 0s - loss: 18.7925 - val_loss: 18.3650

Epoch 00457: val_loss did not improve from 18.20302
Epoch 458/10000
4/4 - 0s - loss: 18.7682 - val_loss: 18.3326

Epoch 00458: val_loss did not improve from 18.20302
Epoch 459/10000
4/4 - 0s - loss: 18.7809 - val_loss: 18.3040

Epoch 00459: val_loss did not improve from 18.20302
Epoch 460/10000
4/4 - 0s - loss: 18.7802 - val_loss: 18.3869

Epoch 00460: val_loss did not improve from 18.20302
Epoch 461/10000
4/4 - 0s - loss: 18.7814 - val_loss: 18.4014

Epoch 00461: val_loss did not improve from 18.20302
Epoch 00461: early stopping
*************************** Fold #: 8 ***************************
Model: "sequential_47"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_517 (Dense)            (None, 30)                210       
_________________________________________________________________
dense_518 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_519 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_520 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_521 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_522 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_523 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_524 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_525 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_526 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_527 (Dense)            (None, 1)                 31        
=================================================================
Total params: 8,611
Trainable params: 8,611
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
4/4 - 0s - loss: 32.3592 - val_loss: 21.9480

Epoch 00001: val_loss improved from inf to 21.94803, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 2/10000
4/4 - 0s - loss: 32.3246 - val_loss: 21.9116

Epoch 00002: val_loss improved from 21.94803 to 21.91162, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 3/10000
4/4 - 0s - loss: 32.2864 - val_loss: 21.8709

Epoch 00003: val_loss improved from 21.91162 to 21.87089, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 4/10000
4/4 - 0s - loss: 32.2424 - val_loss: 21.8250

Epoch 00004: val_loss improved from 21.87089 to 21.82500, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 5/10000
4/4 - 0s - loss: 32.1931 - val_loss: 21.7725

Epoch 00005: val_loss improved from 21.82500 to 21.77250, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 6/10000
4/4 - 0s - loss: 32.1364 - val_loss: 21.7117

Epoch 00006: val_loss improved from 21.77250 to 21.71171, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 7/10000
4/4 - 0s - loss: 32.0712 - val_loss: 21.6405

Epoch 00007: val_loss improved from 21.71171 to 21.64050, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 8/10000
4/4 - 0s - loss: 31.9948 - val_loss: 21.5567

Epoch 00008: val_loss improved from 21.64050 to 21.55669, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 9/10000
4/4 - 0s - loss: 31.9039 - val_loss: 21.4575

Epoch 00009: val_loss improved from 21.55669 to 21.45749, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 10/10000
4/4 - 0s - loss: 31.7957 - val_loss: 21.3383

Epoch 00010: val_loss improved from 21.45749 to 21.33825, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 11/10000
4/4 - 0s - loss: 31.6641 - val_loss: 21.1942

Epoch 00011: val_loss improved from 21.33825 to 21.19415, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 12/10000
4/4 - 0s - loss: 31.5064 - val_loss: 21.0181

Epoch 00012: val_loss improved from 21.19415 to 21.01808, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 13/10000
4/4 - 0s - loss: 31.3113 - val_loss: 20.8028

Epoch 00013: val_loss improved from 21.01808 to 20.80277, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 14/10000
4/4 - 0s - loss: 31.0721 - val_loss: 20.5385

Epoch 00014: val_loss improved from 20.80277 to 20.53845, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 15/10000
4/4 - 0s - loss: 30.7845 - val_loss: 20.2115

Epoch 00015: val_loss improved from 20.53845 to 20.21147, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 16/10000
4/4 - 0s - loss: 30.4226 - val_loss: 19.8050

Epoch 00016: val_loss improved from 20.21147 to 19.80499, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 17/10000
4/4 - 0s - loss: 29.9714 - val_loss: 19.2977

Epoch 00017: val_loss improved from 19.80499 to 19.29770, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 18/10000
4/4 - 0s - loss: 29.4059 - val_loss: 18.6618

Epoch 00018: val_loss improved from 19.29770 to 18.66183, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 19/10000
4/4 - 0s - loss: 28.7012 - val_loss: 17.8596

Epoch 00019: val_loss improved from 18.66183 to 17.85961, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 20/10000
4/4 - 0s - loss: 27.8187 - val_loss: 16.8495

Epoch 00020: val_loss improved from 17.85961 to 16.84952, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 21/10000
4/4 - 0s - loss: 26.6931 - val_loss: 15.6381

Epoch 00021: val_loss improved from 16.84952 to 15.63807, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 22/10000
4/4 - 0s - loss: 25.3638 - val_loss: 14.4925

Epoch 00022: val_loss improved from 15.63807 to 14.49254, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 23/10000
4/4 - 0s - loss: 24.3799 - val_loss: 14.4303

Epoch 00023: val_loss improved from 14.49254 to 14.43034, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 24/10000
4/4 - 0s - loss: 24.3911 - val_loss: 14.5924

Epoch 00024: val_loss did not improve from 14.43034
Epoch 25/10000
4/4 - 0s - loss: 24.2575 - val_loss: 14.1312

Epoch 00025: val_loss improved from 14.43034 to 14.13118, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 26/10000
4/4 - 0s - loss: 23.9989 - val_loss: 14.0350

Epoch 00026: val_loss improved from 14.13118 to 14.03499, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 27/10000
4/4 - 0s - loss: 23.9750 - val_loss: 14.0136

Epoch 00027: val_loss improved from 14.03499 to 14.01359, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 28/10000
4/4 - 0s - loss: 23.9417 - val_loss: 13.9449

Epoch 00028: val_loss improved from 14.01359 to 13.94492, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 29/10000
4/4 - 0s - loss: 23.8413 - val_loss: 13.8822

Epoch 00029: val_loss improved from 13.94492 to 13.88221, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 30/10000
4/4 - 0s - loss: 23.7398 - val_loss: 13.8564

Epoch 00030: val_loss improved from 13.88221 to 13.85641, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 31/10000
4/4 - 0s - loss: 23.6653 - val_loss: 13.8007

Epoch 00031: val_loss improved from 13.85641 to 13.80075, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 32/10000
4/4 - 0s - loss: 23.5578 - val_loss: 13.6849

Epoch 00032: val_loss improved from 13.80075 to 13.68486, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 33/10000
4/4 - 0s - loss: 23.4187 - val_loss: 13.5491

Epoch 00033: val_loss improved from 13.68486 to 13.54913, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 34/10000
4/4 - 0s - loss: 23.2511 - val_loss: 13.3987

Epoch 00034: val_loss improved from 13.54913 to 13.39873, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 35/10000
4/4 - 0s - loss: 23.0540 - val_loss: 13.2603

Epoch 00035: val_loss improved from 13.39873 to 13.26028, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 36/10000
4/4 - 0s - loss: 22.8248 - val_loss: 13.0688

Epoch 00036: val_loss improved from 13.26028 to 13.06884, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 37/10000
4/4 - 0s - loss: 22.5658 - val_loss: 12.8409

Epoch 00037: val_loss improved from 13.06884 to 12.84085, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 38/10000
4/4 - 0s - loss: 22.2879 - val_loss: 12.6181

Epoch 00038: val_loss improved from 12.84085 to 12.61805, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 39/10000
4/4 - 0s - loss: 21.9822 - val_loss: 12.3965

Epoch 00039: val_loss improved from 12.61805 to 12.39655, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 40/10000
4/4 - 0s - loss: 21.7095 - val_loss: 12.2406

Epoch 00040: val_loss improved from 12.39655 to 12.24061, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 41/10000
4/4 - 0s - loss: 21.4499 - val_loss: 12.0619

Epoch 00041: val_loss improved from 12.24061 to 12.06191, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 42/10000
4/4 - 0s - loss: 21.2495 - val_loss: 11.9100

Epoch 00042: val_loss improved from 12.06191 to 11.91000, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 43/10000
4/4 - 0s - loss: 21.0753 - val_loss: 11.8370

Epoch 00043: val_loss improved from 11.91000 to 11.83701, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 44/10000
4/4 - 0s - loss: 20.9334 - val_loss: 11.7496

Epoch 00044: val_loss improved from 11.83701 to 11.74962, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 45/10000
4/4 - 0s - loss: 20.7965 - val_loss: 11.6427

Epoch 00045: val_loss improved from 11.74962 to 11.64270, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 46/10000
4/4 - 0s - loss: 20.6834 - val_loss: 11.5558

Epoch 00046: val_loss improved from 11.64270 to 11.55579, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 47/10000
4/4 - 0s - loss: 20.5641 - val_loss: 11.5326

Epoch 00047: val_loss improved from 11.55579 to 11.53259, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 48/10000
4/4 - 0s - loss: 20.4653 - val_loss: 11.4409

Epoch 00048: val_loss improved from 11.53259 to 11.44088, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 49/10000
4/4 - 0s - loss: 20.3542 - val_loss: 11.2599

Epoch 00049: val_loss improved from 11.44088 to 11.25992, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 50/10000
4/4 - 0s - loss: 20.2621 - val_loss: 11.2058

Epoch 00050: val_loss improved from 11.25992 to 11.20576, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 51/10000
4/4 - 0s - loss: 20.1377 - val_loss: 11.3239

Epoch 00051: val_loss did not improve from 11.20576
Epoch 52/10000
4/4 - 0s - loss: 20.1173 - val_loss: 11.1353

Epoch 00052: val_loss improved from 11.20576 to 11.13528, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 53/10000
4/4 - 0s - loss: 20.1157 - val_loss: 10.9509

Epoch 00053: val_loss improved from 11.13528 to 10.95085, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 54/10000
4/4 - 0s - loss: 20.0381 - val_loss: 10.9950

Epoch 00054: val_loss did not improve from 10.95085
Epoch 55/10000
4/4 - 0s - loss: 19.9138 - val_loss: 11.1042

Epoch 00055: val_loss did not improve from 10.95085
Epoch 56/10000
4/4 - 0s - loss: 19.8861 - val_loss: 10.9305

Epoch 00056: val_loss improved from 10.95085 to 10.93051, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 57/10000
4/4 - 0s - loss: 19.8496 - val_loss: 10.8590

Epoch 00057: val_loss improved from 10.93051 to 10.85896, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 58/10000
4/4 - 0s - loss: 19.8631 - val_loss: 10.8966

Epoch 00058: val_loss did not improve from 10.85896
Epoch 59/10000
4/4 - 0s - loss: 19.8065 - val_loss: 10.8500

Epoch 00059: val_loss improved from 10.85896 to 10.84997, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 60/10000
4/4 - 0s - loss: 19.8098 - val_loss: 10.8413

Epoch 00060: val_loss improved from 10.84997 to 10.84130, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 61/10000
4/4 - 0s - loss: 19.7781 - val_loss: 10.8119

Epoch 00061: val_loss improved from 10.84130 to 10.81186, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 62/10000
4/4 - 0s - loss: 19.7842 - val_loss: 10.8535

Epoch 00062: val_loss did not improve from 10.81186
Epoch 63/10000
4/4 - 0s - loss: 19.8051 - val_loss: 10.8093

Epoch 00063: val_loss improved from 10.81186 to 10.80935, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 64/10000
4/4 - 0s - loss: 19.7926 - val_loss: 10.7061

Epoch 00064: val_loss improved from 10.80935 to 10.70611, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 65/10000
4/4 - 0s - loss: 19.8249 - val_loss: 10.7523

Epoch 00065: val_loss did not improve from 10.70611
Epoch 66/10000
4/4 - 0s - loss: 19.7549 - val_loss: 10.9372

Epoch 00066: val_loss did not improve from 10.70611
Epoch 67/10000
4/4 - 0s - loss: 19.7540 - val_loss: 10.8415

Epoch 00067: val_loss did not improve from 10.70611
Epoch 68/10000
4/4 - 0s - loss: 19.8470 - val_loss: 10.7211

Epoch 00068: val_loss did not improve from 10.70611
Epoch 69/10000
4/4 - 0s - loss: 19.7260 - val_loss: 10.9881

Epoch 00069: val_loss did not improve from 10.70611
Epoch 70/10000
4/4 - 0s - loss: 19.7532 - val_loss: 10.8652

Epoch 00070: val_loss did not improve from 10.70611
Epoch 71/10000
4/4 - 0s - loss: 19.7093 - val_loss: 10.7156

Epoch 00071: val_loss did not improve from 10.70611
Epoch 72/10000
4/4 - 0s - loss: 19.7281 - val_loss: 10.7111

Epoch 00072: val_loss did not improve from 10.70611
Epoch 73/10000
4/4 - 0s - loss: 19.7012 - val_loss: 10.8383

Epoch 00073: val_loss did not improve from 10.70611
Epoch 74/10000
4/4 - 0s - loss: 19.7144 - val_loss: 10.8649

Epoch 00074: val_loss did not improve from 10.70611
Epoch 75/10000
4/4 - 0s - loss: 19.7091 - val_loss: 10.7747

Epoch 00075: val_loss did not improve from 10.70611
Epoch 76/10000
4/4 - 0s - loss: 19.6981 - val_loss: 10.7166

Epoch 00076: val_loss did not improve from 10.70611
Epoch 77/10000
4/4 - 0s - loss: 19.7027 - val_loss: 10.7571

Epoch 00077: val_loss did not improve from 10.70611
Epoch 78/10000
4/4 - 0s - loss: 19.6868 - val_loss: 10.7945

Epoch 00078: val_loss did not improve from 10.70611
Epoch 79/10000
4/4 - 0s - loss: 19.6975 - val_loss: 10.7798

Epoch 00079: val_loss did not improve from 10.70611
Epoch 80/10000
4/4 - 0s - loss: 19.6935 - val_loss: 10.7669

Epoch 00080: val_loss did not improve from 10.70611
Epoch 81/10000
4/4 - 0s - loss: 19.6893 - val_loss: 10.7264

Epoch 00081: val_loss did not improve from 10.70611
Epoch 82/10000
4/4 - 0s - loss: 19.6923 - val_loss: 10.6860

Epoch 00082: val_loss improved from 10.70611 to 10.68602, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 83/10000
4/4 - 0s - loss: 19.6963 - val_loss: 10.7335

Epoch 00083: val_loss did not improve from 10.68602
Epoch 84/10000
4/4 - 0s - loss: 19.6929 - val_loss: 10.7634

Epoch 00084: val_loss did not improve from 10.68602
Epoch 85/10000
4/4 - 0s - loss: 19.6700 - val_loss: 10.6863

Epoch 00085: val_loss did not improve from 10.68602
Epoch 86/10000
4/4 - 0s - loss: 19.6930 - val_loss: 10.6947

Epoch 00086: val_loss did not improve from 10.68602
Epoch 87/10000
4/4 - 0s - loss: 19.6887 - val_loss: 10.6737

Epoch 00087: val_loss improved from 10.68602 to 10.67368, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 88/10000
4/4 - 0s - loss: 19.6746 - val_loss: 10.7255

Epoch 00088: val_loss did not improve from 10.67368
Epoch 89/10000
4/4 - 0s - loss: 19.6781 - val_loss: 10.7730

Epoch 00089: val_loss did not improve from 10.67368
Epoch 90/10000
4/4 - 0s - loss: 19.6764 - val_loss: 10.7203

Epoch 00090: val_loss did not improve from 10.67368
Epoch 91/10000
4/4 - 0s - loss: 19.6573 - val_loss: 10.6606

Epoch 00091: val_loss improved from 10.67368 to 10.66061, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 92/10000
4/4 - 0s - loss: 19.6904 - val_loss: 10.6586

Epoch 00092: val_loss improved from 10.66061 to 10.65856, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 93/10000
4/4 - 0s - loss: 19.6769 - val_loss: 10.7099

Epoch 00093: val_loss did not improve from 10.65856
Epoch 94/10000
4/4 - 0s - loss: 19.6645 - val_loss: 10.7576

Epoch 00094: val_loss did not improve from 10.65856
Epoch 95/10000
4/4 - 0s - loss: 19.6641 - val_loss: 10.7093

Epoch 00095: val_loss did not improve from 10.65856
Epoch 96/10000
4/4 - 0s - loss: 19.6608 - val_loss: 10.6632

Epoch 00096: val_loss did not improve from 10.65856
Epoch 97/10000
4/4 - 0s - loss: 19.6685 - val_loss: 10.7057

Epoch 00097: val_loss did not improve from 10.65856
Epoch 98/10000
4/4 - 0s - loss: 19.6590 - val_loss: 10.7560

Epoch 00098: val_loss did not improve from 10.65856
Epoch 99/10000
4/4 - 0s - loss: 19.6696 - val_loss: 10.7296

Epoch 00099: val_loss did not improve from 10.65856
Epoch 100/10000
4/4 - 0s - loss: 19.6785 - val_loss: 10.7884

Epoch 00100: val_loss did not improve from 10.65856
Epoch 101/10000
4/4 - 0s - loss: 19.6684 - val_loss: 10.6737

Epoch 00101: val_loss did not improve from 10.65856
Epoch 102/10000
4/4 - 0s - loss: 19.6665 - val_loss: 10.6924

Epoch 00102: val_loss did not improve from 10.65856
Epoch 103/10000
4/4 - 0s - loss: 19.6705 - val_loss: 10.6796

Epoch 00103: val_loss did not improve from 10.65856
Epoch 104/10000
4/4 - 0s - loss: 19.6605 - val_loss: 10.7904

Epoch 00104: val_loss did not improve from 10.65856
Epoch 105/10000
4/4 - 0s - loss: 19.6600 - val_loss: 10.7400

Epoch 00105: val_loss did not improve from 10.65856
Epoch 106/10000
4/4 - 0s - loss: 19.6674 - val_loss: 10.7056

Epoch 00106: val_loss did not improve from 10.65856
Epoch 107/10000
4/4 - 0s - loss: 19.6507 - val_loss: 10.7978

Epoch 00107: val_loss did not improve from 10.65856
Epoch 108/10000
4/4 - 0s - loss: 19.6708 - val_loss: 10.8038

Epoch 00108: val_loss did not improve from 10.65856
Epoch 109/10000
4/4 - 0s - loss: 19.6539 - val_loss: 10.7106

Epoch 00109: val_loss did not improve from 10.65856
Epoch 110/10000
4/4 - 0s - loss: 19.6485 - val_loss: 10.6875

Epoch 00110: val_loss did not improve from 10.65856
Epoch 111/10000
4/4 - 0s - loss: 19.6814 - val_loss: 10.6467

Epoch 00111: val_loss improved from 10.65856 to 10.64666, saving model to ./results/dataset/trial_5/ckpt_8
Epoch 112/10000
4/4 - 0s - loss: 19.7118 - val_loss: 10.7600

Epoch 00112: val_loss did not improve from 10.64666
Epoch 113/10000
4/4 - 0s - loss: 19.6590 - val_loss: 10.6932

Epoch 00113: val_loss did not improve from 10.64666
Epoch 114/10000
4/4 - 0s - loss: 19.6552 - val_loss: 10.6828

Epoch 00114: val_loss did not improve from 10.64666
Epoch 115/10000
4/4 - 0s - loss: 19.6555 - val_loss: 10.6693

Epoch 00115: val_loss did not improve from 10.64666
Epoch 116/10000
4/4 - 0s - loss: 19.6480 - val_loss: 10.7215

Epoch 00116: val_loss did not improve from 10.64666
Epoch 117/10000
4/4 - 0s - loss: 19.6440 - val_loss: 10.7148

Epoch 00117: val_loss did not improve from 10.64666
Epoch 118/10000
4/4 - 0s - loss: 19.6414 - val_loss: 10.7532

Epoch 00118: val_loss did not improve from 10.64666
Epoch 119/10000
4/4 - 0s - loss: 19.6674 - val_loss: 10.7207

Epoch 00119: val_loss did not improve from 10.64666
Epoch 120/10000
4/4 - 0s - loss: 19.6493 - val_loss: 10.7889

Epoch 00120: val_loss did not improve from 10.64666
Epoch 121/10000
4/4 - 0s - loss: 19.6425 - val_loss: 10.7423

Epoch 00121: val_loss did not improve from 10.64666
Epoch 122/10000
4/4 - 0s - loss: 19.6382 - val_loss: 10.7115

Epoch 00122: val_loss did not improve from 10.64666
Epoch 123/10000
4/4 - 0s - loss: 19.6863 - val_loss: 10.6615

Epoch 00123: val_loss did not improve from 10.64666
Epoch 124/10000
4/4 - 0s - loss: 19.6255 - val_loss: 10.8117

Epoch 00124: val_loss did not improve from 10.64666
Epoch 125/10000
4/4 - 0s - loss: 19.6777 - val_loss: 10.8814

Epoch 00125: val_loss did not improve from 10.64666
Epoch 126/10000
4/4 - 0s - loss: 19.6698 - val_loss: 10.6974

Epoch 00126: val_loss did not improve from 10.64666
Epoch 127/10000
4/4 - 0s - loss: 19.6729 - val_loss: 10.6849

Epoch 00127: val_loss did not improve from 10.64666
Epoch 128/10000
4/4 - 0s - loss: 19.6226 - val_loss: 10.8228

Epoch 00128: val_loss did not improve from 10.64666
Epoch 129/10000
4/4 - 0s - loss: 19.6783 - val_loss: 10.8839

Epoch 00129: val_loss did not improve from 10.64666
Epoch 130/10000
4/4 - 0s - loss: 19.6884 - val_loss: 10.6817

Epoch 00130: val_loss did not improve from 10.64666
Epoch 131/10000
4/4 - 0s - loss: 19.6606 - val_loss: 10.7206

Epoch 00131: val_loss did not improve from 10.64666
Epoch 132/10000
4/4 - 0s - loss: 19.6336 - val_loss: 10.7675

Epoch 00132: val_loss did not improve from 10.64666
Epoch 133/10000
4/4 - 0s - loss: 19.6430 - val_loss: 10.8613

Epoch 00133: val_loss did not improve from 10.64666
Epoch 134/10000
4/4 - 0s - loss: 19.6579 - val_loss: 10.7689

Epoch 00134: val_loss did not improve from 10.64666
Epoch 135/10000
4/4 - 0s - loss: 19.6360 - val_loss: 10.7603

Epoch 00135: val_loss did not improve from 10.64666
Epoch 136/10000
4/4 - 0s - loss: 19.6429 - val_loss: 10.6925

Epoch 00136: val_loss did not improve from 10.64666
Epoch 137/10000
4/4 - 0s - loss: 19.6392 - val_loss: 10.7134

Epoch 00137: val_loss did not improve from 10.64666
Epoch 138/10000
4/4 - 0s - loss: 19.6347 - val_loss: 10.7409

Epoch 00138: val_loss did not improve from 10.64666
Epoch 139/10000
4/4 - 0s - loss: 19.6484 - val_loss: 10.8256

Epoch 00139: val_loss did not improve from 10.64666
Epoch 140/10000
4/4 - 0s - loss: 19.6518 - val_loss: 10.7527

Epoch 00140: val_loss did not improve from 10.64666
Epoch 141/10000
4/4 - 0s - loss: 19.6668 - val_loss: 10.8167

Epoch 00141: val_loss did not improve from 10.64666
Epoch 142/10000
4/4 - 0s - loss: 19.6359 - val_loss: 10.7567

Epoch 00142: val_loss did not improve from 10.64666
Epoch 143/10000
4/4 - 0s - loss: 19.6258 - val_loss: 10.6779

Epoch 00143: val_loss did not improve from 10.64666
Epoch 144/10000
4/4 - 0s - loss: 19.6441 - val_loss: 10.6750

Epoch 00144: val_loss did not improve from 10.64666
Epoch 145/10000
4/4 - 0s - loss: 19.6467 - val_loss: 10.7344

Epoch 00145: val_loss did not improve from 10.64666
Epoch 146/10000
4/4 - 0s - loss: 19.6311 - val_loss: 10.7194

Epoch 00146: val_loss did not improve from 10.64666
Epoch 147/10000
4/4 - 0s - loss: 19.6269 - val_loss: 10.6945

Epoch 00147: val_loss did not improve from 10.64666
Epoch 148/10000
4/4 - 0s - loss: 19.6385 - val_loss: 10.6800

Epoch 00148: val_loss did not improve from 10.64666
Epoch 149/10000
4/4 - 0s - loss: 19.6389 - val_loss: 10.7603

Epoch 00149: val_loss did not improve from 10.64666
Epoch 150/10000
4/4 - 0s - loss: 19.6297 - val_loss: 10.7843

Epoch 00150: val_loss did not improve from 10.64666
Epoch 151/10000
4/4 - 0s - loss: 19.6306 - val_loss: 10.7755

Epoch 00151: val_loss did not improve from 10.64666
Epoch 152/10000
4/4 - 0s - loss: 19.6325 - val_loss: 10.7523

Epoch 00152: val_loss did not improve from 10.64666
Epoch 153/10000
4/4 - 0s - loss: 19.6376 - val_loss: 10.7273

Epoch 00153: val_loss did not improve from 10.64666
Epoch 154/10000
4/4 - 0s - loss: 19.6294 - val_loss: 10.7198

Epoch 00154: val_loss did not improve from 10.64666
Epoch 155/10000
4/4 - 0s - loss: 19.6294 - val_loss: 10.7287

Epoch 00155: val_loss did not improve from 10.64666
Epoch 156/10000
4/4 - 0s - loss: 19.6275 - val_loss: 10.7319

Epoch 00156: val_loss did not improve from 10.64666
Epoch 157/10000
4/4 - 0s - loss: 19.6305 - val_loss: 10.7461

Epoch 00157: val_loss did not improve from 10.64666
Epoch 158/10000
4/4 - 0s - loss: 19.6292 - val_loss: 10.7457

Epoch 00158: val_loss did not improve from 10.64666
Epoch 159/10000
4/4 - 0s - loss: 19.6276 - val_loss: 10.7357

Epoch 00159: val_loss did not improve from 10.64666
Epoch 160/10000
4/4 - 0s - loss: 19.6324 - val_loss: 10.7260

Epoch 00160: val_loss did not improve from 10.64666
Epoch 161/10000
4/4 - 0s - loss: 19.6250 - val_loss: 10.7873

Epoch 00161: val_loss did not improve from 10.64666
Epoch 162/10000
4/4 - 0s - loss: 19.6275 - val_loss: 10.7523

Epoch 00162: val_loss did not improve from 10.64666
Epoch 163/10000
4/4 - 0s - loss: 19.6266 - val_loss: 10.7185

Epoch 00163: val_loss did not improve from 10.64666
Epoch 164/10000
4/4 - 0s - loss: 19.6353 - val_loss: 10.7627

Epoch 00164: val_loss did not improve from 10.64666
Epoch 165/10000
4/4 - 0s - loss: 19.6440 - val_loss: 10.7170

Epoch 00165: val_loss did not improve from 10.64666
Epoch 166/10000
4/4 - 0s - loss: 19.6293 - val_loss: 10.7546

Epoch 00166: val_loss did not improve from 10.64666
Epoch 167/10000
4/4 - 0s - loss: 19.6317 - val_loss: 10.8080

Epoch 00167: val_loss did not improve from 10.64666
Epoch 168/10000
4/4 - 0s - loss: 19.6273 - val_loss: 10.7169

Epoch 00168: val_loss did not improve from 10.64666
Epoch 169/10000
4/4 - 0s - loss: 19.6289 - val_loss: 10.7158

Epoch 00169: val_loss did not improve from 10.64666
Epoch 170/10000
4/4 - 0s - loss: 19.6214 - val_loss: 10.7737

Epoch 00170: val_loss did not improve from 10.64666
Epoch 171/10000
4/4 - 0s - loss: 19.6602 - val_loss: 10.8226

Epoch 00171: val_loss did not improve from 10.64666
Epoch 172/10000
4/4 - 0s - loss: 19.6513 - val_loss: 10.6712

Epoch 00172: val_loss did not improve from 10.64666
Epoch 173/10000
4/4 - 0s - loss: 19.6361 - val_loss: 10.7156

Epoch 00173: val_loss did not improve from 10.64666
Epoch 174/10000
4/4 - 0s - loss: 19.6673 - val_loss: 10.8819

Epoch 00174: val_loss did not improve from 10.64666
Epoch 175/10000
4/4 - 0s - loss: 19.6327 - val_loss: 10.7626

Epoch 00175: val_loss did not improve from 10.64666
Epoch 176/10000
4/4 - 0s - loss: 19.6478 - val_loss: 10.6693

Epoch 00176: val_loss did not improve from 10.64666
Epoch 177/10000
4/4 - 0s - loss: 19.6637 - val_loss: 10.6755

Epoch 00177: val_loss did not improve from 10.64666
Epoch 178/10000
4/4 - 0s - loss: 19.6289 - val_loss: 10.8113

Epoch 00178: val_loss did not improve from 10.64666
Epoch 179/10000
4/4 - 0s - loss: 19.6690 - val_loss: 10.8046

Epoch 00179: val_loss did not improve from 10.64666
Epoch 180/10000
4/4 - 0s - loss: 19.6437 - val_loss: 10.9461

Epoch 00180: val_loss did not improve from 10.64666
Epoch 181/10000
4/4 - 0s - loss: 19.6519 - val_loss: 10.7663

Epoch 00181: val_loss did not improve from 10.64666
Epoch 182/10000
4/4 - 0s - loss: 19.6454 - val_loss: 10.7052

Epoch 00182: val_loss did not improve from 10.64666
Epoch 183/10000
4/4 - 0s - loss: 19.6335 - val_loss: 10.7732

Epoch 00183: val_loss did not improve from 10.64666
Epoch 184/10000
4/4 - 0s - loss: 19.6238 - val_loss: 10.8038

Epoch 00184: val_loss did not improve from 10.64666
Epoch 185/10000
4/4 - 0s - loss: 19.6334 - val_loss: 10.7960

Epoch 00185: val_loss did not improve from 10.64666
Epoch 186/10000
4/4 - 0s - loss: 19.6436 - val_loss: 10.6790

Epoch 00186: val_loss did not improve from 10.64666
Epoch 187/10000
4/4 - 0s - loss: 19.6553 - val_loss: 10.7013

Epoch 00187: val_loss did not improve from 10.64666
Epoch 188/10000
4/4 - 0s - loss: 19.6185 - val_loss: 10.7622

Epoch 00188: val_loss did not improve from 10.64666
Epoch 189/10000
4/4 - 0s - loss: 19.6242 - val_loss: 10.7855

Epoch 00189: val_loss did not improve from 10.64666
Epoch 190/10000
4/4 - 0s - loss: 19.6180 - val_loss: 10.7329

Epoch 00190: val_loss did not improve from 10.64666
Epoch 191/10000
4/4 - 0s - loss: 19.6555 - val_loss: 10.6851

Epoch 00191: val_loss did not improve from 10.64666
Epoch 192/10000
4/4 - 0s - loss: 19.6331 - val_loss: 10.8301

Epoch 00192: val_loss did not improve from 10.64666
Epoch 193/10000
4/4 - 0s - loss: 19.6321 - val_loss: 10.8117

Epoch 00193: val_loss did not improve from 10.64666
Epoch 194/10000
4/4 - 0s - loss: 19.6241 - val_loss: 10.7296

Epoch 00194: val_loss did not improve from 10.64666
Epoch 195/10000
4/4 - 0s - loss: 19.6303 - val_loss: 10.6945

Epoch 00195: val_loss did not improve from 10.64666
Epoch 196/10000
4/4 - 0s - loss: 19.6300 - val_loss: 10.7688

Epoch 00196: val_loss did not improve from 10.64666
Epoch 197/10000
4/4 - 0s - loss: 19.6398 - val_loss: 10.8246

Epoch 00197: val_loss did not improve from 10.64666
Epoch 198/10000
4/4 - 0s - loss: 19.6173 - val_loss: 10.6953

Epoch 00198: val_loss did not improve from 10.64666
Epoch 199/10000
4/4 - 0s - loss: 19.6232 - val_loss: 10.6840

Epoch 00199: val_loss did not improve from 10.64666
Epoch 200/10000
4/4 - 0s - loss: 19.6430 - val_loss: 10.7351

Epoch 00200: val_loss did not improve from 10.64666
Epoch 201/10000
4/4 - 0s - loss: 19.6500 - val_loss: 10.6888

Epoch 00201: val_loss did not improve from 10.64666
Epoch 202/10000
4/4 - 0s - loss: 19.6268 - val_loss: 10.8167

Epoch 00202: val_loss did not improve from 10.64666
Epoch 203/10000
4/4 - 0s - loss: 19.6374 - val_loss: 10.8174

Epoch 00203: val_loss did not improve from 10.64666
Epoch 204/10000
4/4 - 0s - loss: 19.6221 - val_loss: 10.7262

Epoch 00204: val_loss did not improve from 10.64666
Epoch 205/10000
4/4 - 0s - loss: 19.6289 - val_loss: 10.7027

Epoch 00205: val_loss did not improve from 10.64666
Epoch 206/10000
4/4 - 0s - loss: 19.6117 - val_loss: 10.7687

Epoch 00206: val_loss did not improve from 10.64666
Epoch 207/10000
4/4 - 0s - loss: 19.6654 - val_loss: 10.8670

Epoch 00207: val_loss did not improve from 10.64666
Epoch 208/10000
4/4 - 0s - loss: 19.6775 - val_loss: 10.6626

Epoch 00208: val_loss did not improve from 10.64666
Epoch 209/10000
4/4 - 0s - loss: 19.6430 - val_loss: 10.6966

Epoch 00209: val_loss did not improve from 10.64666
Epoch 210/10000
4/4 - 0s - loss: 19.6279 - val_loss: 10.7058

Epoch 00210: val_loss did not improve from 10.64666
Epoch 211/10000
4/4 - 0s - loss: 19.6304 - val_loss: 10.7444

Epoch 00211: val_loss did not improve from 10.64666
Epoch 212/10000
4/4 - 0s - loss: 19.6116 - val_loss: 10.6894

Epoch 00212: val_loss did not improve from 10.64666
Epoch 213/10000
4/4 - 0s - loss: 19.6511 - val_loss: 10.6588

Epoch 00213: val_loss did not improve from 10.64666
Epoch 214/10000
4/4 - 0s - loss: 19.6484 - val_loss: 10.7727

Epoch 00214: val_loss did not improve from 10.64666
Epoch 215/10000
4/4 - 0s - loss: 19.6448 - val_loss: 10.7921

Epoch 00215: val_loss did not improve from 10.64666
Epoch 216/10000
4/4 - 0s - loss: 19.6171 - val_loss: 10.7463

Epoch 00216: val_loss did not improve from 10.64666
Epoch 217/10000
4/4 - 0s - loss: 19.6240 - val_loss: 10.7050

Epoch 00217: val_loss did not improve from 10.64666
Epoch 218/10000
4/4 - 0s - loss: 19.6413 - val_loss: 10.7940

Epoch 00218: val_loss did not improve from 10.64666
Epoch 219/10000
4/4 - 0s - loss: 19.6305 - val_loss: 10.7398

Epoch 00219: val_loss did not improve from 10.64666
Epoch 220/10000
4/4 - 0s - loss: 19.6336 - val_loss: 10.7951

Epoch 00220: val_loss did not improve from 10.64666
Epoch 221/10000
4/4 - 0s - loss: 19.6371 - val_loss: 10.8196

Epoch 00221: val_loss did not improve from 10.64666
Epoch 222/10000
4/4 - 0s - loss: 19.6162 - val_loss: 10.7743

Epoch 00222: val_loss did not improve from 10.64666
Epoch 223/10000
4/4 - 0s - loss: 19.6135 - val_loss: 10.7491

Epoch 00223: val_loss did not improve from 10.64666
Epoch 224/10000
4/4 - 0s - loss: 19.6333 - val_loss: 10.7107

Epoch 00224: val_loss did not improve from 10.64666
Epoch 225/10000
4/4 - 0s - loss: 19.6417 - val_loss: 10.7826

Epoch 00225: val_loss did not improve from 10.64666
Epoch 226/10000
4/4 - 0s - loss: 19.6422 - val_loss: 10.7012

Epoch 00226: val_loss did not improve from 10.64666
Epoch 227/10000
4/4 - 0s - loss: 19.6177 - val_loss: 10.8032

Epoch 00227: val_loss did not improve from 10.64666
Epoch 228/10000
4/4 - 0s - loss: 19.6259 - val_loss: 10.8100

Epoch 00228: val_loss did not improve from 10.64666
Epoch 229/10000
4/4 - 0s - loss: 19.6284 - val_loss: 10.7713

Epoch 00229: val_loss did not improve from 10.64666
Epoch 230/10000
4/4 - 0s - loss: 19.6399 - val_loss: 10.7991

Epoch 00230: val_loss did not improve from 10.64666
Epoch 231/10000
4/4 - 0s - loss: 19.6089 - val_loss: 10.7442

Epoch 00231: val_loss did not improve from 10.64666
Epoch 232/10000
4/4 - 0s - loss: 19.6174 - val_loss: 10.6845

Epoch 00232: val_loss did not improve from 10.64666
Epoch 233/10000
4/4 - 0s - loss: 19.6299 - val_loss: 10.7043

Epoch 00233: val_loss did not improve from 10.64666
Epoch 234/10000
4/4 - 0s - loss: 19.6155 - val_loss: 10.7466

Epoch 00234: val_loss did not improve from 10.64666
Epoch 235/10000
4/4 - 0s - loss: 19.6126 - val_loss: 10.7577

Epoch 00235: val_loss did not improve from 10.64666
Epoch 236/10000
4/4 - 0s - loss: 19.6108 - val_loss: 10.7532

Epoch 00236: val_loss did not improve from 10.64666
Epoch 237/10000
4/4 - 0s - loss: 19.6151 - val_loss: 10.7587

Epoch 00237: val_loss did not improve from 10.64666
Epoch 238/10000
4/4 - 0s - loss: 19.6111 - val_loss: 10.7588

Epoch 00238: val_loss did not improve from 10.64666
Epoch 239/10000
4/4 - 0s - loss: 19.6112 - val_loss: 10.7440

Epoch 00239: val_loss did not improve from 10.64666
Epoch 240/10000
4/4 - 0s - loss: 19.6227 - val_loss: 10.7913

Epoch 00240: val_loss did not improve from 10.64666
Epoch 241/10000
4/4 - 0s - loss: 19.6127 - val_loss: 10.7542

Epoch 00241: val_loss did not improve from 10.64666
Epoch 242/10000
4/4 - 0s - loss: 19.6591 - val_loss: 10.7047

Epoch 00242: val_loss did not improve from 10.64666
Epoch 243/10000
4/4 - 0s - loss: 19.6347 - val_loss: 10.8287

Epoch 00243: val_loss did not improve from 10.64666
Epoch 244/10000
4/4 - 0s - loss: 19.6194 - val_loss: 10.8084

Epoch 00244: val_loss did not improve from 10.64666
Epoch 245/10000
4/4 - 0s - loss: 19.6417 - val_loss: 10.7124

Epoch 00245: val_loss did not improve from 10.64666
Epoch 246/10000
4/4 - 0s - loss: 19.6363 - val_loss: 10.8016

Epoch 00246: val_loss did not improve from 10.64666
Epoch 247/10000
4/4 - 0s - loss: 19.6161 - val_loss: 10.7477

Epoch 00247: val_loss did not improve from 10.64666
Epoch 248/10000
4/4 - 0s - loss: 19.6206 - val_loss: 10.7130

Epoch 00248: val_loss did not improve from 10.64666
Epoch 249/10000
4/4 - 0s - loss: 19.6079 - val_loss: 10.7813

Epoch 00249: val_loss did not improve from 10.64666
Epoch 250/10000
4/4 - 0s - loss: 19.6200 - val_loss: 10.8016

Epoch 00250: val_loss did not improve from 10.64666
Epoch 251/10000
4/4 - 0s - loss: 19.6182 - val_loss: 10.7308

Epoch 00251: val_loss did not improve from 10.64666
Epoch 252/10000
4/4 - 0s - loss: 19.6192 - val_loss: 10.7468

Epoch 00252: val_loss did not improve from 10.64666
Epoch 253/10000
4/4 - 0s - loss: 19.6076 - val_loss: 10.7118

Epoch 00253: val_loss did not improve from 10.64666
Epoch 254/10000
4/4 - 0s - loss: 19.6133 - val_loss: 10.7049

Epoch 00254: val_loss did not improve from 10.64666
Epoch 255/10000
4/4 - 0s - loss: 19.6187 - val_loss: 10.6970

Epoch 00255: val_loss did not improve from 10.64666
Epoch 256/10000
4/4 - 0s - loss: 19.6080 - val_loss: 10.7569

Epoch 00256: val_loss did not improve from 10.64666
Epoch 257/10000
4/4 - 0s - loss: 19.6095 - val_loss: 10.8320

Epoch 00257: val_loss did not improve from 10.64666
Epoch 258/10000
4/4 - 0s - loss: 19.6372 - val_loss: 10.8516

Epoch 00258: val_loss did not improve from 10.64666
Epoch 259/10000
4/4 - 0s - loss: 19.6480 - val_loss: 10.7194

Epoch 00259: val_loss did not improve from 10.64666
Epoch 260/10000
4/4 - 0s - loss: 19.6171 - val_loss: 10.7597

Epoch 00260: val_loss did not improve from 10.64666
Epoch 261/10000
4/4 - 0s - loss: 19.6062 - val_loss: 10.8859

Epoch 00261: val_loss did not improve from 10.64666
Epoch 262/10000
4/4 - 0s - loss: 19.6393 - val_loss: 10.8132

Epoch 00262: val_loss did not improve from 10.64666
Epoch 263/10000
4/4 - 0s - loss: 19.6118 - val_loss: 10.7650

Epoch 00263: val_loss did not improve from 10.64666
Epoch 264/10000
4/4 - 0s - loss: 19.6500 - val_loss: 10.7027

Epoch 00264: val_loss did not improve from 10.64666
Epoch 265/10000
4/4 - 0s - loss: 19.6687 - val_loss: 10.8028

Epoch 00265: val_loss did not improve from 10.64666
Epoch 266/10000
4/4 - 0s - loss: 19.6071 - val_loss: 10.7231

Epoch 00266: val_loss did not improve from 10.64666
Epoch 267/10000
4/4 - 0s - loss: 19.6370 - val_loss: 10.6701

Epoch 00267: val_loss did not improve from 10.64666
Epoch 268/10000
4/4 - 0s - loss: 19.6212 - val_loss: 10.7489

Epoch 00268: val_loss did not improve from 10.64666
Epoch 269/10000
4/4 - 0s - loss: 19.6194 - val_loss: 10.7888

Epoch 00269: val_loss did not improve from 10.64666
Epoch 270/10000
4/4 - 0s - loss: 19.6138 - val_loss: 10.7104

Epoch 00270: val_loss did not improve from 10.64666
Epoch 271/10000
4/4 - 0s - loss: 19.6254 - val_loss: 10.7019

Epoch 00271: val_loss did not improve from 10.64666
Epoch 272/10000
4/4 - 0s - loss: 19.6155 - val_loss: 10.8348

Epoch 00272: val_loss did not improve from 10.64666
Epoch 273/10000
4/4 - 0s - loss: 19.6219 - val_loss: 10.8034

Epoch 00273: val_loss did not improve from 10.64666
Epoch 274/10000
4/4 - 0s - loss: 19.6315 - val_loss: 10.7516

Epoch 00274: val_loss did not improve from 10.64666
Epoch 275/10000
4/4 - 0s - loss: 19.6049 - val_loss: 10.7843

Epoch 00275: val_loss did not improve from 10.64666
Epoch 276/10000
4/4 - 0s - loss: 19.6190 - val_loss: 10.8538

Epoch 00276: val_loss did not improve from 10.64666
Epoch 277/10000
4/4 - 0s - loss: 19.6256 - val_loss: 10.7647

Epoch 00277: val_loss did not improve from 10.64666
Epoch 278/10000
4/4 - 0s - loss: 19.6073 - val_loss: 10.7277

Epoch 00278: val_loss did not improve from 10.64666
Epoch 279/10000
4/4 - 0s - loss: 19.6062 - val_loss: 10.7066

Epoch 00279: val_loss did not improve from 10.64666
Epoch 280/10000
4/4 - 0s - loss: 19.6102 - val_loss: 10.7208

Epoch 00280: val_loss did not improve from 10.64666
Epoch 281/10000
4/4 - 0s - loss: 19.6115 - val_loss: 10.7452

Epoch 00281: val_loss did not improve from 10.64666
Epoch 282/10000
4/4 - 0s - loss: 19.6222 - val_loss: 10.7662

Epoch 00282: val_loss did not improve from 10.64666
Epoch 283/10000
4/4 - 0s - loss: 19.6045 - val_loss: 10.7217

Epoch 00283: val_loss did not improve from 10.64666
Epoch 284/10000
4/4 - 0s - loss: 19.6096 - val_loss: 10.7283

Epoch 00284: val_loss did not improve from 10.64666
Epoch 285/10000
4/4 - 0s - loss: 19.6072 - val_loss: 10.7598

Epoch 00285: val_loss did not improve from 10.64666
Epoch 286/10000
4/4 - 0s - loss: 19.6012 - val_loss: 10.8619

Epoch 00286: val_loss did not improve from 10.64666
Epoch 287/10000
4/4 - 0s - loss: 19.6485 - val_loss: 10.8755

Epoch 00287: val_loss did not improve from 10.64666
Epoch 288/10000
4/4 - 0s - loss: 19.6246 - val_loss: 10.7806

Epoch 00288: val_loss did not improve from 10.64666
Epoch 289/10000
4/4 - 0s - loss: 19.6108 - val_loss: 10.7471

Epoch 00289: val_loss did not improve from 10.64666
Epoch 290/10000
4/4 - 0s - loss: 19.6322 - val_loss: 10.6866

Epoch 00290: val_loss did not improve from 10.64666
Epoch 291/10000
4/4 - 0s - loss: 19.6128 - val_loss: 10.7589

Epoch 00291: val_loss did not improve from 10.64666
Epoch 292/10000
4/4 - 0s - loss: 19.6455 - val_loss: 10.8361

Epoch 00292: val_loss did not improve from 10.64666
Epoch 293/10000
4/4 - 0s - loss: 19.6297 - val_loss: 10.6913

Epoch 00293: val_loss did not improve from 10.64666
Epoch 294/10000
4/4 - 0s - loss: 19.6527 - val_loss: 10.6771

Epoch 00294: val_loss did not improve from 10.64666
Epoch 295/10000
4/4 - 0s - loss: 19.5901 - val_loss: 10.8147

Epoch 00295: val_loss did not improve from 10.64666
Epoch 296/10000
4/4 - 0s - loss: 19.6078 - val_loss: 10.9386

Epoch 00296: val_loss did not improve from 10.64666
Epoch 297/10000
4/4 - 0s - loss: 19.6451 - val_loss: 10.8326

Epoch 00297: val_loss did not improve from 10.64666
Epoch 298/10000
4/4 - 0s - loss: 19.6081 - val_loss: 10.7532

Epoch 00298: val_loss did not improve from 10.64666
Epoch 299/10000
4/4 - 0s - loss: 19.6168 - val_loss: 10.7378

Epoch 00299: val_loss did not improve from 10.64666
Epoch 300/10000
4/4 - 0s - loss: 19.6102 - val_loss: 10.7361

Epoch 00300: val_loss did not improve from 10.64666
Epoch 301/10000
4/4 - 0s - loss: 19.6026 - val_loss: 10.7132

Epoch 00301: val_loss did not improve from 10.64666
Epoch 302/10000
4/4 - 0s - loss: 19.6060 - val_loss: 10.7023

Epoch 00302: val_loss did not improve from 10.64666
Epoch 303/10000
4/4 - 0s - loss: 19.6078 - val_loss: 10.7189

Epoch 00303: val_loss did not improve from 10.64666
Epoch 304/10000
4/4 - 0s - loss: 19.6067 - val_loss: 10.7659

Epoch 00304: val_loss did not improve from 10.64666
Epoch 305/10000
4/4 - 0s - loss: 19.6140 - val_loss: 10.7407

Epoch 00305: val_loss did not improve from 10.64666
Epoch 306/10000
4/4 - 0s - loss: 19.6053 - val_loss: 10.7610

Epoch 00306: val_loss did not improve from 10.64666
Epoch 307/10000
4/4 - 0s - loss: 19.6048 - val_loss: 10.7837

Epoch 00307: val_loss did not improve from 10.64666
Epoch 308/10000
4/4 - 0s - loss: 19.6213 - val_loss: 10.7630

Epoch 00308: val_loss did not improve from 10.64666
Epoch 309/10000
4/4 - 0s - loss: 19.6220 - val_loss: 10.6693

Epoch 00309: val_loss did not improve from 10.64666
Epoch 310/10000
4/4 - 0s - loss: 19.6350 - val_loss: 10.6762

Epoch 00310: val_loss did not improve from 10.64666
Epoch 311/10000
4/4 - 0s - loss: 19.6092 - val_loss: 10.7277

Epoch 00311: val_loss did not improve from 10.64666
Epoch 00311: early stopping
*************************** Fold #: 9 ***************************
Model: "sequential_48"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_528 (Dense)            (None, 30)                210       
_________________________________________________________________
dense_529 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_530 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_531 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_532 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_533 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_534 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_535 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_536 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_537 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_538 (Dense)            (None, 1)                 31        
=================================================================
Total params: 8,611
Trainable params: 8,611
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
4/4 - 0s - loss: 32.3259 - val_loss: 22.2379

Epoch 00001: val_loss improved from inf to 22.23790, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 2/10000
4/4 - 0s - loss: 32.2900 - val_loss: 22.2031

Epoch 00002: val_loss improved from 22.23790 to 22.20306, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 3/10000
4/4 - 0s - loss: 32.2514 - val_loss: 22.1652

Epoch 00003: val_loss improved from 22.20306 to 22.16519, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 4/10000
4/4 - 0s - loss: 32.2094 - val_loss: 22.1236

Epoch 00004: val_loss improved from 22.16519 to 22.12365, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 5/10000
4/4 - 0s - loss: 32.1627 - val_loss: 22.0777

Epoch 00005: val_loss improved from 22.12365 to 22.07774, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 6/10000
4/4 - 0s - loss: 32.1107 - val_loss: 22.0262

Epoch 00006: val_loss improved from 22.07774 to 22.02620, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 7/10000
4/4 - 0s - loss: 32.0521 - val_loss: 21.9672

Epoch 00007: val_loss improved from 22.02620 to 21.96722, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 8/10000
4/4 - 0s - loss: 31.9856 - val_loss: 21.8988

Epoch 00008: val_loss improved from 21.96722 to 21.89875, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 9/10000
4/4 - 0s - loss: 31.9078 - val_loss: 21.8183

Epoch 00009: val_loss improved from 21.89875 to 21.81832, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 10/10000
4/4 - 0s - loss: 31.8151 - val_loss: 21.7221

Epoch 00010: val_loss improved from 21.81832 to 21.72210, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 11/10000
4/4 - 0s - loss: 31.7055 - val_loss: 21.6058

Epoch 00011: val_loss improved from 21.72210 to 21.60575, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 12/10000
4/4 - 0s - loss: 31.5680 - val_loss: 21.4632

Epoch 00012: val_loss improved from 21.60575 to 21.46321, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 13/10000
4/4 - 0s - loss: 31.4011 - val_loss: 21.2840

Epoch 00013: val_loss improved from 21.46321 to 21.28395, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 14/10000
4/4 - 0s - loss: 31.1890 - val_loss: 21.0544

Epoch 00014: val_loss improved from 21.28395 to 21.05441, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 15/10000
4/4 - 0s - loss: 30.9156 - val_loss: 20.7528

Epoch 00015: val_loss improved from 21.05441 to 20.75280, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 16/10000
4/4 - 0s - loss: 30.5634 - val_loss: 20.3472

Epoch 00016: val_loss improved from 20.75280 to 20.34716, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 17/10000
4/4 - 0s - loss: 30.0489 - val_loss: 19.7873

Epoch 00017: val_loss improved from 20.34716 to 19.78728, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 18/10000
4/4 - 0s - loss: 29.3725 - val_loss: 18.9794

Epoch 00018: val_loss improved from 19.78728 to 18.97940, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 19/10000
4/4 - 0s - loss: 28.3502 - val_loss: 17.8023

Epoch 00019: val_loss improved from 18.97940 to 17.80230, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 20/10000
4/4 - 0s - loss: 26.8172 - val_loss: 16.2416

Epoch 00020: val_loss improved from 17.80230 to 16.24158, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 21/10000
4/4 - 0s - loss: 25.0117 - val_loss: 15.3659

Epoch 00021: val_loss improved from 16.24158 to 15.36586, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 22/10000
4/4 - 0s - loss: 24.3683 - val_loss: 16.2918

Epoch 00022: val_loss did not improve from 15.36586
Epoch 23/10000
4/4 - 0s - loss: 24.3931 - val_loss: 15.3034

Epoch 00023: val_loss improved from 15.36586 to 15.30338, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 24/10000
4/4 - 0s - loss: 23.8509 - val_loss: 15.0310

Epoch 00024: val_loss improved from 15.30338 to 15.03102, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 25/10000
4/4 - 0s - loss: 23.9075 - val_loss: 14.9942

Epoch 00025: val_loss improved from 15.03102 to 14.99422, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 26/10000
4/4 - 0s - loss: 23.8245 - val_loss: 14.8738

Epoch 00026: val_loss improved from 14.99422 to 14.87377, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 27/10000
4/4 - 0s - loss: 23.5913 - val_loss: 14.8548

Epoch 00027: val_loss improved from 14.87377 to 14.85482, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 28/10000
4/4 - 0s - loss: 23.4395 - val_loss: 14.9306

Epoch 00028: val_loss did not improve from 14.85482
Epoch 29/10000
4/4 - 0s - loss: 23.3768 - val_loss: 14.7761

Epoch 00029: val_loss improved from 14.85482 to 14.77605, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 30/10000
4/4 - 0s - loss: 23.1956 - val_loss: 14.5256

Epoch 00030: val_loss improved from 14.77605 to 14.52565, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 31/10000
4/4 - 0s - loss: 23.0501 - val_loss: 14.3655

Epoch 00031: val_loss improved from 14.52565 to 14.36547, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 32/10000
4/4 - 0s - loss: 22.9177 - val_loss: 14.2373

Epoch 00032: val_loss improved from 14.36547 to 14.23726, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 33/10000
4/4 - 0s - loss: 22.6748 - val_loss: 14.0902

Epoch 00033: val_loss improved from 14.23726 to 14.09017, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 34/10000
4/4 - 0s - loss: 22.4613 - val_loss: 13.9551

Epoch 00034: val_loss improved from 14.09017 to 13.95510, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 35/10000
4/4 - 0s - loss: 22.2349 - val_loss: 13.7752

Epoch 00035: val_loss improved from 13.95510 to 13.77517, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 36/10000
4/4 - 0s - loss: 21.9926 - val_loss: 13.5398

Epoch 00036: val_loss improved from 13.77517 to 13.53979, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 37/10000
4/4 - 0s - loss: 21.7394 - val_loss: 13.3110

Epoch 00037: val_loss improved from 13.53979 to 13.31101, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 38/10000
4/4 - 0s - loss: 21.4930 - val_loss: 13.1239

Epoch 00038: val_loss improved from 13.31101 to 13.12391, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 39/10000
4/4 - 0s - loss: 21.2655 - val_loss: 13.0451

Epoch 00039: val_loss improved from 13.12391 to 13.04506, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 40/10000
4/4 - 0s - loss: 21.1231 - val_loss: 12.8717

Epoch 00040: val_loss improved from 13.04506 to 12.87169, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 41/10000
4/4 - 0s - loss: 20.9104 - val_loss: 12.6738

Epoch 00041: val_loss improved from 12.87169 to 12.67378, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 42/10000
4/4 - 0s - loss: 20.7848 - val_loss: 12.5585

Epoch 00042: val_loss improved from 12.67378 to 12.55846, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 43/10000
4/4 - 0s - loss: 20.6577 - val_loss: 12.4879

Epoch 00043: val_loss improved from 12.55846 to 12.48789, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 44/10000
4/4 - 0s - loss: 20.5242 - val_loss: 12.4437

Epoch 00044: val_loss improved from 12.48789 to 12.44365, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 45/10000
4/4 - 0s - loss: 20.4108 - val_loss: 12.3503

Epoch 00045: val_loss improved from 12.44365 to 12.35029, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 46/10000
4/4 - 0s - loss: 20.3233 - val_loss: 12.2314

Epoch 00046: val_loss improved from 12.35029 to 12.23143, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 47/10000
4/4 - 0s - loss: 20.1887 - val_loss: 12.2474

Epoch 00047: val_loss did not improve from 12.23143
Epoch 48/10000
4/4 - 0s - loss: 20.1531 - val_loss: 12.2539

Epoch 00048: val_loss did not improve from 12.23143
Epoch 49/10000
4/4 - 0s - loss: 20.0362 - val_loss: 12.0521

Epoch 00049: val_loss improved from 12.23143 to 12.05206, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 50/10000
4/4 - 0s - loss: 20.0083 - val_loss: 12.0092

Epoch 00050: val_loss improved from 12.05206 to 12.00921, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 51/10000
4/4 - 0s - loss: 19.9591 - val_loss: 12.1212

Epoch 00051: val_loss did not improve from 12.00921
Epoch 52/10000
4/4 - 0s - loss: 19.8995 - val_loss: 12.0174

Epoch 00052: val_loss did not improve from 12.00921
Epoch 53/10000
4/4 - 0s - loss: 19.8544 - val_loss: 11.9575

Epoch 00053: val_loss improved from 12.00921 to 11.95750, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 54/10000
4/4 - 0s - loss: 19.8320 - val_loss: 11.9968

Epoch 00054: val_loss did not improve from 11.95750
Epoch 55/10000
4/4 - 0s - loss: 19.8076 - val_loss: 11.9515

Epoch 00055: val_loss improved from 11.95750 to 11.95153, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 56/10000
4/4 - 0s - loss: 19.7836 - val_loss: 11.8888

Epoch 00056: val_loss improved from 11.95153 to 11.88877, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 57/10000
4/4 - 0s - loss: 19.7763 - val_loss: 11.9177

Epoch 00057: val_loss did not improve from 11.88877
Epoch 58/10000
4/4 - 0s - loss: 19.7513 - val_loss: 12.0321

Epoch 00058: val_loss did not improve from 11.88877
Epoch 59/10000
4/4 - 0s - loss: 19.7400 - val_loss: 11.9043

Epoch 00059: val_loss did not improve from 11.88877
Epoch 60/10000
4/4 - 0s - loss: 19.7006 - val_loss: 11.8769

Epoch 00060: val_loss improved from 11.88877 to 11.87693, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 61/10000
4/4 - 0s - loss: 19.6896 - val_loss: 11.9099

Epoch 00061: val_loss did not improve from 11.87693
Epoch 62/10000
4/4 - 0s - loss: 19.6785 - val_loss: 11.8818

Epoch 00062: val_loss did not improve from 11.87693
Epoch 63/10000
4/4 - 0s - loss: 19.6661 - val_loss: 11.8924

Epoch 00063: val_loss did not improve from 11.87693
Epoch 64/10000
4/4 - 0s - loss: 19.6679 - val_loss: 11.8520

Epoch 00064: val_loss improved from 11.87693 to 11.85200, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 65/10000
4/4 - 0s - loss: 19.6915 - val_loss: 11.9398

Epoch 00065: val_loss did not improve from 11.85200
Epoch 66/10000
4/4 - 0s - loss: 19.6405 - val_loss: 11.8309

Epoch 00066: val_loss improved from 11.85200 to 11.83093, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 67/10000
4/4 - 0s - loss: 19.6330 - val_loss: 11.8376

Epoch 00067: val_loss did not improve from 11.83093
Epoch 68/10000
4/4 - 0s - loss: 19.6101 - val_loss: 11.8793

Epoch 00068: val_loss did not improve from 11.83093
Epoch 69/10000
4/4 - 0s - loss: 19.6066 - val_loss: 11.9115

Epoch 00069: val_loss did not improve from 11.83093
Epoch 70/10000
4/4 - 0s - loss: 19.6037 - val_loss: 11.8885

Epoch 00070: val_loss did not improve from 11.83093
Epoch 71/10000
4/4 - 0s - loss: 19.6292 - val_loss: 11.8268

Epoch 00071: val_loss improved from 11.83093 to 11.82680, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 72/10000
4/4 - 0s - loss: 19.5864 - val_loss: 11.8833

Epoch 00072: val_loss did not improve from 11.82680
Epoch 73/10000
4/4 - 0s - loss: 19.5799 - val_loss: 11.8504

Epoch 00073: val_loss did not improve from 11.82680
Epoch 74/10000
4/4 - 0s - loss: 19.5706 - val_loss: 11.8432

Epoch 00074: val_loss did not improve from 11.82680
Epoch 75/10000
4/4 - 0s - loss: 19.5720 - val_loss: 11.8663

Epoch 00075: val_loss did not improve from 11.82680
Epoch 76/10000
4/4 - 0s - loss: 19.5697 - val_loss: 11.8387

Epoch 00076: val_loss did not improve from 11.82680
Epoch 77/10000
4/4 - 0s - loss: 19.5635 - val_loss: 11.8474

Epoch 00077: val_loss did not improve from 11.82680
Epoch 78/10000
4/4 - 0s - loss: 19.5726 - val_loss: 11.8439

Epoch 00078: val_loss did not improve from 11.82680
Epoch 79/10000
4/4 - 0s - loss: 19.5605 - val_loss: 11.8548

Epoch 00079: val_loss did not improve from 11.82680
Epoch 80/10000
4/4 - 0s - loss: 19.5694 - val_loss: 11.9135

Epoch 00080: val_loss did not improve from 11.82680
Epoch 81/10000
4/4 - 0s - loss: 19.5522 - val_loss: 11.8331

Epoch 00081: val_loss did not improve from 11.82680
Epoch 82/10000
4/4 - 0s - loss: 19.5806 - val_loss: 11.7923

Epoch 00082: val_loss improved from 11.82680 to 11.79227, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 83/10000
4/4 - 0s - loss: 19.5683 - val_loss: 11.8510

Epoch 00083: val_loss did not improve from 11.79227
Epoch 84/10000
4/4 - 0s - loss: 19.5519 - val_loss: 11.9120

Epoch 00084: val_loss did not improve from 11.79227
Epoch 85/10000
4/4 - 0s - loss: 19.6290 - val_loss: 11.8033

Epoch 00085: val_loss did not improve from 11.79227
Epoch 86/10000
4/4 - 0s - loss: 19.5646 - val_loss: 11.8234

Epoch 00086: val_loss did not improve from 11.79227
Epoch 87/10000
4/4 - 0s - loss: 19.5372 - val_loss: 11.8762

Epoch 00087: val_loss did not improve from 11.79227
Epoch 88/10000
4/4 - 0s - loss: 19.5456 - val_loss: 11.9418

Epoch 00088: val_loss did not improve from 11.79227
Epoch 89/10000
4/4 - 0s - loss: 19.5481 - val_loss: 11.8576

Epoch 00089: val_loss did not improve from 11.79227
Epoch 90/10000
4/4 - 0s - loss: 19.5738 - val_loss: 11.7887

Epoch 00090: val_loss improved from 11.79227 to 11.78870, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 91/10000
4/4 - 0s - loss: 19.5731 - val_loss: 11.8344

Epoch 00091: val_loss did not improve from 11.78870
Epoch 92/10000
4/4 - 0s - loss: 19.5429 - val_loss: 11.8860

Epoch 00092: val_loss did not improve from 11.78870
Epoch 93/10000
4/4 - 0s - loss: 19.5489 - val_loss: 11.8641

Epoch 00093: val_loss did not improve from 11.78870
Epoch 94/10000
4/4 - 0s - loss: 19.5261 - val_loss: 11.7939

Epoch 00094: val_loss did not improve from 11.78870
Epoch 95/10000
4/4 - 0s - loss: 19.5585 - val_loss: 11.8038

Epoch 00095: val_loss did not improve from 11.78870
Epoch 96/10000
4/4 - 0s - loss: 19.5273 - val_loss: 11.9178

Epoch 00096: val_loss did not improve from 11.78870
Epoch 97/10000
4/4 - 0s - loss: 19.5999 - val_loss: 12.0038

Epoch 00097: val_loss did not improve from 11.78870
Epoch 98/10000
4/4 - 0s - loss: 19.5432 - val_loss: 11.8263

Epoch 00098: val_loss did not improve from 11.78870
Epoch 99/10000
4/4 - 0s - loss: 19.5414 - val_loss: 11.8041

Epoch 00099: val_loss did not improve from 11.78870
Epoch 100/10000
4/4 - 0s - loss: 19.5534 - val_loss: 11.8815

Epoch 00100: val_loss did not improve from 11.78870
Epoch 101/10000
4/4 - 0s - loss: 19.5395 - val_loss: 11.8802

Epoch 00101: val_loss did not improve from 11.78870
Epoch 102/10000
4/4 - 0s - loss: 19.5478 - val_loss: 11.8007

Epoch 00102: val_loss did not improve from 11.78870
Epoch 103/10000
4/4 - 0s - loss: 19.5516 - val_loss: 11.8729

Epoch 00103: val_loss did not improve from 11.78870
Epoch 104/10000
4/4 - 0s - loss: 19.5478 - val_loss: 11.8282

Epoch 00104: val_loss did not improve from 11.78870
Epoch 105/10000
4/4 - 0s - loss: 19.5572 - val_loss: 11.9038

Epoch 00105: val_loss did not improve from 11.78870
Epoch 106/10000
4/4 - 0s - loss: 19.5369 - val_loss: 11.8008

Epoch 00106: val_loss did not improve from 11.78870
Epoch 107/10000
4/4 - 0s - loss: 19.5493 - val_loss: 11.7929

Epoch 00107: val_loss did not improve from 11.78870
Epoch 108/10000
4/4 - 0s - loss: 19.5421 - val_loss: 11.8282

Epoch 00108: val_loss did not improve from 11.78870
Epoch 109/10000
4/4 - 0s - loss: 19.5109 - val_loss: 11.9518

Epoch 00109: val_loss did not improve from 11.78870
Epoch 110/10000
4/4 - 0s - loss: 19.5531 - val_loss: 11.9186

Epoch 00110: val_loss did not improve from 11.78870
Epoch 111/10000
4/4 - 0s - loss: 19.5412 - val_loss: 11.8402

Epoch 00111: val_loss did not improve from 11.78870
Epoch 112/10000
4/4 - 0s - loss: 19.5288 - val_loss: 11.8289

Epoch 00112: val_loss did not improve from 11.78870
Epoch 113/10000
4/4 - 0s - loss: 19.5306 - val_loss: 11.8455

Epoch 00113: val_loss did not improve from 11.78870
Epoch 114/10000
4/4 - 0s - loss: 19.5229 - val_loss: 11.8209

Epoch 00114: val_loss did not improve from 11.78870
Epoch 115/10000
4/4 - 0s - loss: 19.5171 - val_loss: 11.8168

Epoch 00115: val_loss did not improve from 11.78870
Epoch 116/10000
4/4 - 0s - loss: 19.5136 - val_loss: 11.8553

Epoch 00116: val_loss did not improve from 11.78870
Epoch 117/10000
4/4 - 0s - loss: 19.5284 - val_loss: 11.9271

Epoch 00117: val_loss did not improve from 11.78870
Epoch 118/10000
4/4 - 0s - loss: 19.5309 - val_loss: 11.8142

Epoch 00118: val_loss did not improve from 11.78870
Epoch 119/10000
4/4 - 0s - loss: 19.5157 - val_loss: 11.8021

Epoch 00119: val_loss did not improve from 11.78870
Epoch 120/10000
4/4 - 0s - loss: 19.5200 - val_loss: 11.8221

Epoch 00120: val_loss did not improve from 11.78870
Epoch 121/10000
4/4 - 0s - loss: 19.5134 - val_loss: 11.8495

Epoch 00121: val_loss did not improve from 11.78870
Epoch 122/10000
4/4 - 0s - loss: 19.5148 - val_loss: 11.8610

Epoch 00122: val_loss did not improve from 11.78870
Epoch 123/10000
4/4 - 0s - loss: 19.5107 - val_loss: 11.8592

Epoch 00123: val_loss did not improve from 11.78870
Epoch 124/10000
4/4 - 0s - loss: 19.5248 - val_loss: 11.8445

Epoch 00124: val_loss did not improve from 11.78870
Epoch 125/10000
4/4 - 0s - loss: 19.5112 - val_loss: 11.7979

Epoch 00125: val_loss did not improve from 11.78870
Epoch 126/10000
4/4 - 0s - loss: 19.5381 - val_loss: 11.7830

Epoch 00126: val_loss improved from 11.78870 to 11.78301, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 127/10000
4/4 - 0s - loss: 19.5066 - val_loss: 11.8702

Epoch 00127: val_loss did not improve from 11.78301
Epoch 128/10000
4/4 - 0s - loss: 19.5246 - val_loss: 11.9627

Epoch 00128: val_loss did not improve from 11.78301
Epoch 129/10000
4/4 - 0s - loss: 19.5266 - val_loss: 11.8387

Epoch 00129: val_loss did not improve from 11.78301
Epoch 130/10000
4/4 - 0s - loss: 19.5136 - val_loss: 11.8016

Epoch 00130: val_loss did not improve from 11.78301
Epoch 131/10000
4/4 - 0s - loss: 19.5220 - val_loss: 11.8399

Epoch 00131: val_loss did not improve from 11.78301
Epoch 132/10000
4/4 - 0s - loss: 19.5073 - val_loss: 11.8646

Epoch 00132: val_loss did not improve from 11.78301
Epoch 133/10000
4/4 - 0s - loss: 19.5090 - val_loss: 11.8617

Epoch 00133: val_loss did not improve from 11.78301
Epoch 134/10000
4/4 - 0s - loss: 19.5066 - val_loss: 11.8073

Epoch 00134: val_loss did not improve from 11.78301
Epoch 135/10000
4/4 - 0s - loss: 19.5285 - val_loss: 11.8059

Epoch 00135: val_loss did not improve from 11.78301
Epoch 136/10000
4/4 - 0s - loss: 19.5460 - val_loss: 11.9233

Epoch 00136: val_loss did not improve from 11.78301
Epoch 137/10000
4/4 - 0s - loss: 19.5167 - val_loss: 11.8369

Epoch 00137: val_loss did not improve from 11.78301
Epoch 138/10000
4/4 - 0s - loss: 19.5183 - val_loss: 11.8113

Epoch 00138: val_loss did not improve from 11.78301
Epoch 139/10000
4/4 - 0s - loss: 19.5300 - val_loss: 11.8857

Epoch 00139: val_loss did not improve from 11.78301
Epoch 140/10000
4/4 - 0s - loss: 19.5025 - val_loss: 11.8322

Epoch 00140: val_loss did not improve from 11.78301
Epoch 141/10000
4/4 - 0s - loss: 19.4993 - val_loss: 11.7967

Epoch 00141: val_loss did not improve from 11.78301
Epoch 142/10000
4/4 - 0s - loss: 19.5290 - val_loss: 11.8012

Epoch 00142: val_loss did not improve from 11.78301
Epoch 143/10000
4/4 - 0s - loss: 19.4955 - val_loss: 11.9101

Epoch 00143: val_loss did not improve from 11.78301
Epoch 144/10000
4/4 - 0s - loss: 19.5407 - val_loss: 11.9370

Epoch 00144: val_loss did not improve from 11.78301
Epoch 145/10000
4/4 - 0s - loss: 19.5151 - val_loss: 11.7941

Epoch 00145: val_loss did not improve from 11.78301
Epoch 146/10000
4/4 - 0s - loss: 19.5204 - val_loss: 11.8071

Epoch 00146: val_loss did not improve from 11.78301
Epoch 147/10000
4/4 - 0s - loss: 19.5279 - val_loss: 11.8965

Epoch 00147: val_loss did not improve from 11.78301
Epoch 148/10000
4/4 - 0s - loss: 19.5156 - val_loss: 11.8249

Epoch 00148: val_loss did not improve from 11.78301
Epoch 149/10000
4/4 - 0s - loss: 19.5158 - val_loss: 11.8650

Epoch 00149: val_loss did not improve from 11.78301
Epoch 150/10000
4/4 - 0s - loss: 19.5279 - val_loss: 11.8201

Epoch 00150: val_loss did not improve from 11.78301
Epoch 151/10000
4/4 - 0s - loss: 19.5008 - val_loss: 11.8600

Epoch 00151: val_loss did not improve from 11.78301
Epoch 152/10000
4/4 - 0s - loss: 19.5128 - val_loss: 11.8599

Epoch 00152: val_loss did not improve from 11.78301
Epoch 153/10000
4/4 - 0s - loss: 19.5014 - val_loss: 11.9382

Epoch 00153: val_loss did not improve from 11.78301
Epoch 154/10000
4/4 - 0s - loss: 19.5283 - val_loss: 11.9118

Epoch 00154: val_loss did not improve from 11.78301
Epoch 155/10000
4/4 - 0s - loss: 19.5140 - val_loss: 11.7970

Epoch 00155: val_loss did not improve from 11.78301
Epoch 156/10000
4/4 - 0s - loss: 19.5262 - val_loss: 11.8083

Epoch 00156: val_loss did not improve from 11.78301
Epoch 157/10000
4/4 - 0s - loss: 19.5096 - val_loss: 11.8983

Epoch 00157: val_loss did not improve from 11.78301
Epoch 158/10000
4/4 - 0s - loss: 19.5315 - val_loss: 11.8684

Epoch 00158: val_loss did not improve from 11.78301
Epoch 159/10000
4/4 - 0s - loss: 19.4917 - val_loss: 11.7859

Epoch 00159: val_loss did not improve from 11.78301
Epoch 160/10000
4/4 - 0s - loss: 19.5371 - val_loss: 11.7913

Epoch 00160: val_loss did not improve from 11.78301
Epoch 161/10000
4/4 - 0s - loss: 19.4742 - val_loss: 11.9401

Epoch 00161: val_loss did not improve from 11.78301
Epoch 162/10000
4/4 - 0s - loss: 19.5422 - val_loss: 12.0383

Epoch 00162: val_loss did not improve from 11.78301
Epoch 163/10000
4/4 - 0s - loss: 19.5571 - val_loss: 11.8079

Epoch 00163: val_loss did not improve from 11.78301
Epoch 164/10000
4/4 - 0s - loss: 19.5193 - val_loss: 11.8145

Epoch 00164: val_loss did not improve from 11.78301
Epoch 165/10000
4/4 - 0s - loss: 19.5590 - val_loss: 11.8148

Epoch 00165: val_loss did not improve from 11.78301
Epoch 166/10000
4/4 - 0s - loss: 19.5239 - val_loss: 12.0168

Epoch 00166: val_loss did not improve from 11.78301
Epoch 167/10000
4/4 - 0s - loss: 19.5615 - val_loss: 11.8708

Epoch 00167: val_loss did not improve from 11.78301
Epoch 168/10000
4/4 - 0s - loss: 19.5097 - val_loss: 11.8014

Epoch 00168: val_loss did not improve from 11.78301
Epoch 169/10000
4/4 - 0s - loss: 19.5076 - val_loss: 11.8537

Epoch 00169: val_loss did not improve from 11.78301
Epoch 170/10000
4/4 - 0s - loss: 19.4993 - val_loss: 11.9696

Epoch 00170: val_loss did not improve from 11.78301
Epoch 171/10000
4/4 - 0s - loss: 19.5212 - val_loss: 11.9343

Epoch 00171: val_loss did not improve from 11.78301
Epoch 172/10000
4/4 - 0s - loss: 19.5088 - val_loss: 11.8473

Epoch 00172: val_loss did not improve from 11.78301
Epoch 173/10000
4/4 - 0s - loss: 19.4978 - val_loss: 11.8165

Epoch 00173: val_loss did not improve from 11.78301
Epoch 174/10000
4/4 - 0s - loss: 19.5008 - val_loss: 11.8449

Epoch 00174: val_loss did not improve from 11.78301
Epoch 175/10000
4/4 - 0s - loss: 19.5213 - val_loss: 11.8422

Epoch 00175: val_loss did not improve from 11.78301
Epoch 176/10000
4/4 - 0s - loss: 19.5446 - val_loss: 11.9777

Epoch 00176: val_loss did not improve from 11.78301
Epoch 177/10000
4/4 - 0s - loss: 19.5438 - val_loss: 11.8153

Epoch 00177: val_loss did not improve from 11.78301
Epoch 178/10000
4/4 - 0s - loss: 19.4978 - val_loss: 11.8371

Epoch 00178: val_loss did not improve from 11.78301
Epoch 179/10000
4/4 - 0s - loss: 19.4867 - val_loss: 11.9036

Epoch 00179: val_loss did not improve from 11.78301
Epoch 180/10000
4/4 - 0s - loss: 19.5104 - val_loss: 11.9165

Epoch 00180: val_loss did not improve from 11.78301
Epoch 181/10000
4/4 - 0s - loss: 19.5436 - val_loss: 11.8081

Epoch 00181: val_loss did not improve from 11.78301
Epoch 182/10000
4/4 - 0s - loss: 19.5218 - val_loss: 11.8611

Epoch 00182: val_loss did not improve from 11.78301
Epoch 183/10000
4/4 - 0s - loss: 19.4895 - val_loss: 11.8181

Epoch 00183: val_loss did not improve from 11.78301
Epoch 184/10000
4/4 - 0s - loss: 19.5080 - val_loss: 11.7867

Epoch 00184: val_loss did not improve from 11.78301
Epoch 185/10000
4/4 - 0s - loss: 19.5104 - val_loss: 11.8287

Epoch 00185: val_loss did not improve from 11.78301
Epoch 186/10000
4/4 - 0s - loss: 19.4830 - val_loss: 12.0187

Epoch 00186: val_loss did not improve from 11.78301
Epoch 187/10000
4/4 - 0s - loss: 19.5781 - val_loss: 11.9588

Epoch 00187: val_loss did not improve from 11.78301
Epoch 188/10000
4/4 - 0s - loss: 19.5291 - val_loss: 11.7912

Epoch 00188: val_loss did not improve from 11.78301
Epoch 189/10000
4/4 - 0s - loss: 19.5730 - val_loss: 11.7835

Epoch 00189: val_loss did not improve from 11.78301
Epoch 190/10000
4/4 - 0s - loss: 19.5384 - val_loss: 11.9036

Epoch 00190: val_loss did not improve from 11.78301
Epoch 191/10000
4/4 - 0s - loss: 19.5212 - val_loss: 11.9518

Epoch 00191: val_loss did not improve from 11.78301
Epoch 192/10000
4/4 - 0s - loss: 19.4980 - val_loss: 11.8251

Epoch 00192: val_loss did not improve from 11.78301
Epoch 193/10000
4/4 - 0s - loss: 19.4946 - val_loss: 11.7840

Epoch 00193: val_loss did not improve from 11.78301
Epoch 194/10000
4/4 - 0s - loss: 19.5117 - val_loss: 11.8097

Epoch 00194: val_loss did not improve from 11.78301
Epoch 195/10000
4/4 - 0s - loss: 19.4994 - val_loss: 11.8807

Epoch 00195: val_loss did not improve from 11.78301
Epoch 196/10000
4/4 - 0s - loss: 19.4996 - val_loss: 11.8399

Epoch 00196: val_loss did not improve from 11.78301
Epoch 197/10000
4/4 - 0s - loss: 19.5095 - val_loss: 11.8325

Epoch 00197: val_loss did not improve from 11.78301
Epoch 198/10000
4/4 - 0s - loss: 19.5395 - val_loss: 11.9095

Epoch 00198: val_loss did not improve from 11.78301
Epoch 199/10000
4/4 - 0s - loss: 19.5002 - val_loss: 11.8105

Epoch 00199: val_loss did not improve from 11.78301
Epoch 200/10000
4/4 - 0s - loss: 19.5395 - val_loss: 11.7844

Epoch 00200: val_loss did not improve from 11.78301
Epoch 201/10000
4/4 - 0s - loss: 19.5151 - val_loss: 11.8807

Epoch 00201: val_loss did not improve from 11.78301
Epoch 202/10000
4/4 - 0s - loss: 19.4976 - val_loss: 11.8909

Epoch 00202: val_loss did not improve from 11.78301
Epoch 203/10000
4/4 - 0s - loss: 19.5019 - val_loss: 11.8321

Epoch 00203: val_loss did not improve from 11.78301
Epoch 204/10000
4/4 - 0s - loss: 19.5256 - val_loss: 11.8177

Epoch 00204: val_loss did not improve from 11.78301
Epoch 205/10000
4/4 - 0s - loss: 19.4996 - val_loss: 11.9792

Epoch 00205: val_loss did not improve from 11.78301
Epoch 206/10000
4/4 - 0s - loss: 19.5230 - val_loss: 11.9519

Epoch 00206: val_loss did not improve from 11.78301
Epoch 207/10000
4/4 - 0s - loss: 19.5120 - val_loss: 11.8360

Epoch 00207: val_loss did not improve from 11.78301
Epoch 208/10000
4/4 - 0s - loss: 19.5063 - val_loss: 11.8456

Epoch 00208: val_loss did not improve from 11.78301
Epoch 209/10000
4/4 - 0s - loss: 19.4933 - val_loss: 11.8252

Epoch 00209: val_loss did not improve from 11.78301
Epoch 210/10000
4/4 - 0s - loss: 19.4893 - val_loss: 11.8548

Epoch 00210: val_loss did not improve from 11.78301
Epoch 211/10000
4/4 - 0s - loss: 19.4929 - val_loss: 11.8923

Epoch 00211: val_loss did not improve from 11.78301
Epoch 212/10000
4/4 - 0s - loss: 19.4952 - val_loss: 11.8508

Epoch 00212: val_loss did not improve from 11.78301
Epoch 213/10000
4/4 - 0s - loss: 19.5112 - val_loss: 11.8138

Epoch 00213: val_loss did not improve from 11.78301
Epoch 214/10000
4/4 - 0s - loss: 19.5116 - val_loss: 11.8889

Epoch 00214: val_loss did not improve from 11.78301
Epoch 215/10000
4/4 - 0s - loss: 19.5042 - val_loss: 11.8394

Epoch 00215: val_loss did not improve from 11.78301
Epoch 216/10000
4/4 - 0s - loss: 19.4922 - val_loss: 11.8240

Epoch 00216: val_loss did not improve from 11.78301
Epoch 217/10000
4/4 - 0s - loss: 19.4906 - val_loss: 11.8062

Epoch 00217: val_loss did not improve from 11.78301
Epoch 218/10000
4/4 - 0s - loss: 19.5019 - val_loss: 11.8118

Epoch 00218: val_loss did not improve from 11.78301
Epoch 219/10000
4/4 - 0s - loss: 19.5094 - val_loss: 11.9064

Epoch 00219: val_loss did not improve from 11.78301
Epoch 220/10000
4/4 - 0s - loss: 19.5173 - val_loss: 11.8973

Epoch 00220: val_loss did not improve from 11.78301
Epoch 221/10000
4/4 - 0s - loss: 19.5063 - val_loss: 11.7901

Epoch 00221: val_loss did not improve from 11.78301
Epoch 222/10000
4/4 - 0s - loss: 19.5281 - val_loss: 11.8052

Epoch 00222: val_loss did not improve from 11.78301
Epoch 223/10000
4/4 - 0s - loss: 19.5244 - val_loss: 11.9607

Epoch 00223: val_loss did not improve from 11.78301
Epoch 224/10000
4/4 - 0s - loss: 19.5272 - val_loss: 11.8732

Epoch 00224: val_loss did not improve from 11.78301
Epoch 225/10000
4/4 - 0s - loss: 19.4911 - val_loss: 11.8471

Epoch 00225: val_loss did not improve from 11.78301
Epoch 226/10000
4/4 - 0s - loss: 19.4880 - val_loss: 11.8135

Epoch 00226: val_loss did not improve from 11.78301
Epoch 227/10000
4/4 - 0s - loss: 19.4943 - val_loss: 11.8263

Epoch 00227: val_loss did not improve from 11.78301
Epoch 228/10000
4/4 - 0s - loss: 19.4926 - val_loss: 11.8426

Epoch 00228: val_loss did not improve from 11.78301
Epoch 229/10000
4/4 - 0s - loss: 19.5024 - val_loss: 11.9203

Epoch 00229: val_loss did not improve from 11.78301
Epoch 230/10000
4/4 - 0s - loss: 19.4960 - val_loss: 11.8376

Epoch 00230: val_loss did not improve from 11.78301
Epoch 231/10000
4/4 - 0s - loss: 19.5026 - val_loss: 11.8197

Epoch 00231: val_loss did not improve from 11.78301
Epoch 232/10000
4/4 - 0s - loss: 19.4974 - val_loss: 11.8340

Epoch 00232: val_loss did not improve from 11.78301
Epoch 233/10000
4/4 - 0s - loss: 19.4931 - val_loss: 11.8952

Epoch 00233: val_loss did not improve from 11.78301
Epoch 234/10000
4/4 - 0s - loss: 19.4975 - val_loss: 11.8828

Epoch 00234: val_loss did not improve from 11.78301
Epoch 235/10000
4/4 - 0s - loss: 19.4905 - val_loss: 11.8311

Epoch 00235: val_loss did not improve from 11.78301
Epoch 236/10000
4/4 - 0s - loss: 19.4962 - val_loss: 11.8056

Epoch 00236: val_loss did not improve from 11.78301
Epoch 237/10000
4/4 - 0s - loss: 19.5239 - val_loss: 11.8486

Epoch 00237: val_loss did not improve from 11.78301
Epoch 238/10000
4/4 - 0s - loss: 19.5126 - val_loss: 11.7938

Epoch 00238: val_loss did not improve from 11.78301
Epoch 239/10000
4/4 - 0s - loss: 19.5002 - val_loss: 11.8101

Epoch 00239: val_loss did not improve from 11.78301
Epoch 240/10000
4/4 - 0s - loss: 19.5003 - val_loss: 11.8802

Epoch 00240: val_loss did not improve from 11.78301
Epoch 241/10000
4/4 - 0s - loss: 19.5007 - val_loss: 11.8527

Epoch 00241: val_loss did not improve from 11.78301
Epoch 242/10000
4/4 - 0s - loss: 19.5355 - val_loss: 11.7803

Epoch 00242: val_loss improved from 11.78301 to 11.78034, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 243/10000
4/4 - 0s - loss: 19.5093 - val_loss: 11.8153

Epoch 00243: val_loss did not improve from 11.78034
Epoch 244/10000
4/4 - 0s - loss: 19.4797 - val_loss: 11.9603

Epoch 00244: val_loss did not improve from 11.78034
Epoch 245/10000
4/4 - 0s - loss: 19.5183 - val_loss: 11.9396

Epoch 00245: val_loss did not improve from 11.78034
Epoch 246/10000
4/4 - 0s - loss: 19.5111 - val_loss: 11.8168

Epoch 00246: val_loss did not improve from 11.78034
Epoch 247/10000
4/4 - 0s - loss: 19.5096 - val_loss: 11.8260

Epoch 00247: val_loss did not improve from 11.78034
Epoch 248/10000
4/4 - 0s - loss: 19.4909 - val_loss: 11.9323

Epoch 00248: val_loss did not improve from 11.78034
Epoch 249/10000
4/4 - 0s - loss: 19.4991 - val_loss: 11.8895

Epoch 00249: val_loss did not improve from 11.78034
Epoch 250/10000
4/4 - 0s - loss: 19.4958 - val_loss: 11.8244

Epoch 00250: val_loss did not improve from 11.78034
Epoch 251/10000
4/4 - 0s - loss: 19.4901 - val_loss: 11.8169

Epoch 00251: val_loss did not improve from 11.78034
Epoch 252/10000
4/4 - 0s - loss: 19.4877 - val_loss: 11.8411

Epoch 00252: val_loss did not improve from 11.78034
Epoch 253/10000
4/4 - 0s - loss: 19.5240 - val_loss: 11.8879

Epoch 00253: val_loss did not improve from 11.78034
Epoch 254/10000
4/4 - 0s - loss: 19.4807 - val_loss: 11.8010

Epoch 00254: val_loss did not improve from 11.78034
Epoch 255/10000
4/4 - 0s - loss: 19.5224 - val_loss: 11.7748

Epoch 00255: val_loss improved from 11.78034 to 11.77481, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 256/10000
4/4 - 0s - loss: 19.5016 - val_loss: 11.8460

Epoch 00256: val_loss did not improve from 11.77481
Epoch 257/10000
4/4 - 0s - loss: 19.4920 - val_loss: 11.9000

Epoch 00257: val_loss did not improve from 11.77481
Epoch 258/10000
4/4 - 0s - loss: 19.5031 - val_loss: 11.8244

Epoch 00258: val_loss did not improve from 11.77481
Epoch 259/10000
4/4 - 0s - loss: 19.4858 - val_loss: 11.8140

Epoch 00259: val_loss did not improve from 11.77481
Epoch 260/10000
4/4 - 0s - loss: 19.4915 - val_loss: 11.8333

Epoch 00260: val_loss did not improve from 11.77481
Epoch 261/10000
4/4 - 0s - loss: 19.4898 - val_loss: 11.8105

Epoch 00261: val_loss did not improve from 11.77481
Epoch 262/10000
4/4 - 0s - loss: 19.5188 - val_loss: 11.8101

Epoch 00262: val_loss did not improve from 11.77481
Epoch 263/10000
4/4 - 0s - loss: 19.5163 - val_loss: 11.9450

Epoch 00263: val_loss did not improve from 11.77481
Epoch 264/10000
4/4 - 0s - loss: 19.5041 - val_loss: 11.8532

Epoch 00264: val_loss did not improve from 11.77481
Epoch 265/10000
4/4 - 0s - loss: 19.5107 - val_loss: 11.8161

Epoch 00265: val_loss did not improve from 11.77481
Epoch 266/10000
4/4 - 0s - loss: 19.5022 - val_loss: 11.8748

Epoch 00266: val_loss did not improve from 11.77481
Epoch 267/10000
4/4 - 0s - loss: 19.4866 - val_loss: 11.8400

Epoch 00267: val_loss did not improve from 11.77481
Epoch 268/10000
4/4 - 0s - loss: 19.4840 - val_loss: 11.8080

Epoch 00268: val_loss did not improve from 11.77481
Epoch 269/10000
4/4 - 0s - loss: 19.5084 - val_loss: 11.8186

Epoch 00269: val_loss did not improve from 11.77481
Epoch 270/10000
4/4 - 0s - loss: 19.4793 - val_loss: 11.9470

Epoch 00270: val_loss did not improve from 11.77481
Epoch 271/10000
4/4 - 0s - loss: 19.5197 - val_loss: 11.9315

Epoch 00271: val_loss did not improve from 11.77481
Epoch 272/10000
4/4 - 0s - loss: 19.4833 - val_loss: 11.8029

Epoch 00272: val_loss did not improve from 11.77481
Epoch 273/10000
4/4 - 0s - loss: 19.5373 - val_loss: 11.8008

Epoch 00273: val_loss did not improve from 11.77481
Epoch 274/10000
4/4 - 0s - loss: 19.4676 - val_loss: 11.9554

Epoch 00274: val_loss did not improve from 11.77481
Epoch 275/10000
4/4 - 0s - loss: 19.5246 - val_loss: 12.0836

Epoch 00275: val_loss did not improve from 11.77481
Epoch 276/10000
4/4 - 0s - loss: 19.5359 - val_loss: 11.8765

Epoch 00276: val_loss did not improve from 11.77481
Epoch 277/10000
4/4 - 0s - loss: 19.4754 - val_loss: 11.8187

Epoch 00277: val_loss did not improve from 11.77481
Epoch 278/10000
4/4 - 0s - loss: 19.5201 - val_loss: 11.8061

Epoch 00278: val_loss did not improve from 11.77481
Epoch 279/10000
4/4 - 0s - loss: 19.4903 - val_loss: 11.8777

Epoch 00279: val_loss did not improve from 11.77481
Epoch 280/10000
4/4 - 0s - loss: 19.4853 - val_loss: 11.9507

Epoch 00280: val_loss did not improve from 11.77481
Epoch 281/10000
4/4 - 0s - loss: 19.6925 - val_loss: 12.0590

Epoch 00281: val_loss did not improve from 11.77481
Epoch 282/10000
4/4 - 0s - loss: 19.5276 - val_loss: 11.7990

Epoch 00282: val_loss did not improve from 11.77481
Epoch 283/10000
4/4 - 0s - loss: 19.5285 - val_loss: 11.7965

Epoch 00283: val_loss did not improve from 11.77481
Epoch 284/10000
4/4 - 0s - loss: 19.5191 - val_loss: 11.8456

Epoch 00284: val_loss did not improve from 11.77481
Epoch 285/10000
4/4 - 0s - loss: 19.5555 - val_loss: 11.9389

Epoch 00285: val_loss did not improve from 11.77481
Epoch 286/10000
4/4 - 0s - loss: 19.5617 - val_loss: 11.8168

Epoch 00286: val_loss did not improve from 11.77481
Epoch 287/10000
4/4 - 0s - loss: 19.4804 - val_loss: 11.9013

Epoch 00287: val_loss did not improve from 11.77481
Epoch 288/10000
4/4 - 0s - loss: 19.5076 - val_loss: 11.9351

Epoch 00288: val_loss did not improve from 11.77481
Epoch 289/10000
4/4 - 0s - loss: 19.5469 - val_loss: 11.9372

Epoch 00289: val_loss did not improve from 11.77481
Epoch 290/10000
4/4 - 0s - loss: 19.5059 - val_loss: 11.7949

Epoch 00290: val_loss did not improve from 11.77481
Epoch 291/10000
4/4 - 0s - loss: 19.5142 - val_loss: 11.8094

Epoch 00291: val_loss did not improve from 11.77481
Epoch 292/10000
4/4 - 0s - loss: 19.4853 - val_loss: 11.8706

Epoch 00292: val_loss did not improve from 11.77481
Epoch 293/10000
4/4 - 0s - loss: 19.4931 - val_loss: 11.9250

Epoch 00293: val_loss did not improve from 11.77481
Epoch 294/10000
4/4 - 0s - loss: 19.4940 - val_loss: 11.8321

Epoch 00294: val_loss did not improve from 11.77481
Epoch 295/10000
4/4 - 0s - loss: 19.4945 - val_loss: 11.8094

Epoch 00295: val_loss did not improve from 11.77481
Epoch 296/10000
4/4 - 0s - loss: 19.4966 - val_loss: 11.8834

Epoch 00296: val_loss did not improve from 11.77481
Epoch 297/10000
4/4 - 0s - loss: 19.4931 - val_loss: 11.8355

Epoch 00297: val_loss did not improve from 11.77481
Epoch 298/10000
4/4 - 0s - loss: 19.5294 - val_loss: 11.7947

Epoch 00298: val_loss did not improve from 11.77481
Epoch 299/10000
4/4 - 0s - loss: 19.5255 - val_loss: 11.9064

Epoch 00299: val_loss did not improve from 11.77481
Epoch 300/10000
4/4 - 0s - loss: 19.4846 - val_loss: 11.8395

Epoch 00300: val_loss did not improve from 11.77481
Epoch 301/10000
4/4 - 0s - loss: 19.4814 - val_loss: 11.7919

Epoch 00301: val_loss did not improve from 11.77481
Epoch 302/10000
4/4 - 0s - loss: 19.5057 - val_loss: 11.8135

Epoch 00302: val_loss did not improve from 11.77481
Epoch 303/10000
4/4 - 0s - loss: 19.4981 - val_loss: 11.8431

Epoch 00303: val_loss did not improve from 11.77481
Epoch 304/10000
4/4 - 0s - loss: 19.4851 - val_loss: 11.8814

Epoch 00304: val_loss did not improve from 11.77481
Epoch 305/10000
4/4 - 0s - loss: 19.4840 - val_loss: 11.8567

Epoch 00305: val_loss did not improve from 11.77481
Epoch 306/10000
4/4 - 0s - loss: 19.5232 - val_loss: 11.8058

Epoch 00306: val_loss did not improve from 11.77481
Epoch 307/10000
4/4 - 0s - loss: 19.4764 - val_loss: 11.8884

Epoch 00307: val_loss did not improve from 11.77481
Epoch 308/10000
4/4 - 0s - loss: 19.5177 - val_loss: 12.0251

Epoch 00308: val_loss did not improve from 11.77481
Epoch 309/10000
4/4 - 0s - loss: 19.5229 - val_loss: 11.8827

Epoch 00309: val_loss did not improve from 11.77481
Epoch 310/10000
4/4 - 0s - loss: 19.4688 - val_loss: 11.7982

Epoch 00310: val_loss did not improve from 11.77481
Epoch 311/10000
4/4 - 0s - loss: 19.5633 - val_loss: 11.7867

Epoch 00311: val_loss did not improve from 11.77481
Epoch 312/10000
4/4 - 0s - loss: 19.5123 - val_loss: 11.9111

Epoch 00312: val_loss did not improve from 11.77481
Epoch 313/10000
4/4 - 0s - loss: 19.5286 - val_loss: 12.0162

Epoch 00313: val_loss did not improve from 11.77481
Epoch 314/10000
4/4 - 0s - loss: 19.5169 - val_loss: 11.8313

Epoch 00314: val_loss did not improve from 11.77481
Epoch 315/10000
4/4 - 0s - loss: 19.5115 - val_loss: 11.8013

Epoch 00315: val_loss did not improve from 11.77481
Epoch 316/10000
4/4 - 0s - loss: 19.4932 - val_loss: 11.9213

Epoch 00316: val_loss did not improve from 11.77481
Epoch 317/10000
4/4 - 0s - loss: 19.5039 - val_loss: 11.9155

Epoch 00317: val_loss did not improve from 11.77481
Epoch 318/10000
4/4 - 0s - loss: 19.5094 - val_loss: 11.8271

Epoch 00318: val_loss did not improve from 11.77481
Epoch 319/10000
4/4 - 0s - loss: 19.4865 - val_loss: 11.8086

Epoch 00319: val_loss did not improve from 11.77481
Epoch 320/10000
4/4 - 0s - loss: 19.4925 - val_loss: 11.8061

Epoch 00320: val_loss did not improve from 11.77481
Epoch 321/10000
4/4 - 0s - loss: 19.4888 - val_loss: 11.7913

Epoch 00321: val_loss did not improve from 11.77481
Epoch 322/10000
4/4 - 0s - loss: 19.4984 - val_loss: 11.8142

Epoch 00322: val_loss did not improve from 11.77481
Epoch 323/10000
4/4 - 0s - loss: 19.4841 - val_loss: 11.8517

Epoch 00323: val_loss did not improve from 11.77481
Epoch 324/10000
4/4 - 0s - loss: 19.4811 - val_loss: 11.9131

Epoch 00324: val_loss did not improve from 11.77481
Epoch 325/10000
4/4 - 0s - loss: 19.4906 - val_loss: 11.8585

Epoch 00325: val_loss did not improve from 11.77481
Epoch 326/10000
4/4 - 0s - loss: 19.4815 - val_loss: 11.8152

Epoch 00326: val_loss did not improve from 11.77481
Epoch 327/10000
4/4 - 0s - loss: 19.4973 - val_loss: 11.8288

Epoch 00327: val_loss did not improve from 11.77481
Epoch 328/10000
4/4 - 0s - loss: 19.4870 - val_loss: 11.8255

Epoch 00328: val_loss did not improve from 11.77481
Epoch 329/10000
4/4 - 0s - loss: 19.4990 - val_loss: 11.8657

Epoch 00329: val_loss did not improve from 11.77481
Epoch 330/10000
4/4 - 0s - loss: 19.5042 - val_loss: 11.7902

Epoch 00330: val_loss did not improve from 11.77481
Epoch 331/10000
4/4 - 0s - loss: 19.4941 - val_loss: 11.8437

Epoch 00331: val_loss did not improve from 11.77481
Epoch 332/10000
4/4 - 0s - loss: 19.5053 - val_loss: 11.8079

Epoch 00332: val_loss did not improve from 11.77481
Epoch 333/10000
4/4 - 0s - loss: 19.4865 - val_loss: 11.8557

Epoch 00333: val_loss did not improve from 11.77481
Epoch 334/10000
4/4 - 0s - loss: 19.4923 - val_loss: 11.8485

Epoch 00334: val_loss did not improve from 11.77481
Epoch 335/10000
4/4 - 0s - loss: 19.4891 - val_loss: 11.8168

Epoch 00335: val_loss did not improve from 11.77481
Epoch 336/10000
4/4 - 0s - loss: 19.4801 - val_loss: 11.7860

Epoch 00336: val_loss did not improve from 11.77481
Epoch 337/10000
4/4 - 0s - loss: 19.5132 - val_loss: 11.7868

Epoch 00337: val_loss did not improve from 11.77481
Epoch 338/10000
4/4 - 0s - loss: 19.4756 - val_loss: 11.9038

Epoch 00338: val_loss did not improve from 11.77481
Epoch 339/10000
4/4 - 0s - loss: 19.5309 - val_loss: 11.9687

Epoch 00339: val_loss did not improve from 11.77481
Epoch 340/10000
4/4 - 0s - loss: 19.5389 - val_loss: 11.8267

Epoch 00340: val_loss did not improve from 11.77481
Epoch 341/10000
4/4 - 0s - loss: 19.4825 - val_loss: 11.8403

Epoch 00341: val_loss did not improve from 11.77481
Epoch 342/10000
4/4 - 0s - loss: 19.5003 - val_loss: 11.9119

Epoch 00342: val_loss did not improve from 11.77481
Epoch 343/10000
4/4 - 0s - loss: 19.4997 - val_loss: 11.8411

Epoch 00343: val_loss did not improve from 11.77481
Epoch 344/10000
4/4 - 0s - loss: 19.4919 - val_loss: 11.8175

Epoch 00344: val_loss did not improve from 11.77481
Epoch 345/10000
4/4 - 0s - loss: 19.4843 - val_loss: 11.8039

Epoch 00345: val_loss did not improve from 11.77481
Epoch 346/10000
4/4 - 0s - loss: 19.4817 - val_loss: 11.8516

Epoch 00346: val_loss did not improve from 11.77481
Epoch 347/10000
4/4 - 0s - loss: 19.4885 - val_loss: 11.8651

Epoch 00347: val_loss did not improve from 11.77481
Epoch 348/10000
4/4 - 0s - loss: 19.5234 - val_loss: 11.7906

Epoch 00348: val_loss did not improve from 11.77481
Epoch 349/10000
4/4 - 0s - loss: 19.4909 - val_loss: 11.8546

Epoch 00349: val_loss did not improve from 11.77481
Epoch 350/10000
4/4 - 0s - loss: 19.4808 - val_loss: 11.8794

Epoch 00350: val_loss did not improve from 11.77481
Epoch 351/10000
4/4 - 0s - loss: 19.4869 - val_loss: 11.8788

Epoch 00351: val_loss did not improve from 11.77481
Epoch 352/10000
4/4 - 0s - loss: 19.4905 - val_loss: 11.8353

Epoch 00352: val_loss did not improve from 11.77481
Epoch 353/10000
4/4 - 0s - loss: 19.4819 - val_loss: 11.7710

Epoch 00353: val_loss improved from 11.77481 to 11.77103, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 354/10000
4/4 - 0s - loss: 19.5101 - val_loss: 11.7801

Epoch 00354: val_loss did not improve from 11.77103
Epoch 355/10000
4/4 - 0s - loss: 19.4964 - val_loss: 11.8804

Epoch 00355: val_loss did not improve from 11.77103
Epoch 356/10000
4/4 - 0s - loss: 19.4922 - val_loss: 11.8523

Epoch 00356: val_loss did not improve from 11.77103
Epoch 357/10000
4/4 - 0s - loss: 19.4832 - val_loss: 11.8249

Epoch 00357: val_loss did not improve from 11.77103
Epoch 358/10000
4/4 - 0s - loss: 19.4843 - val_loss: 11.8106

Epoch 00358: val_loss did not improve from 11.77103
Epoch 359/10000
4/4 - 0s - loss: 19.4812 - val_loss: 11.8020

Epoch 00359: val_loss did not improve from 11.77103
Epoch 360/10000
4/4 - 0s - loss: 19.4873 - val_loss: 11.8257

Epoch 00360: val_loss did not improve from 11.77103
Epoch 361/10000
4/4 - 0s - loss: 19.4816 - val_loss: 11.8403

Epoch 00361: val_loss did not improve from 11.77103
Epoch 362/10000
4/4 - 0s - loss: 19.4922 - val_loss: 11.8223

Epoch 00362: val_loss did not improve from 11.77103
Epoch 363/10000
4/4 - 0s - loss: 19.4870 - val_loss: 11.8331

Epoch 00363: val_loss did not improve from 11.77103
Epoch 364/10000
4/4 - 0s - loss: 19.4850 - val_loss: 11.8610

Epoch 00364: val_loss did not improve from 11.77103
Epoch 365/10000
4/4 - 0s - loss: 19.5074 - val_loss: 11.8717

Epoch 00365: val_loss did not improve from 11.77103
Epoch 366/10000
4/4 - 0s - loss: 19.4806 - val_loss: 11.8234

Epoch 00366: val_loss did not improve from 11.77103
Epoch 367/10000
4/4 - 0s - loss: 19.5069 - val_loss: 11.7773

Epoch 00367: val_loss did not improve from 11.77103
Epoch 368/10000
4/4 - 0s - loss: 19.5100 - val_loss: 11.8062

Epoch 00368: val_loss did not improve from 11.77103
Epoch 369/10000
4/4 - 0s - loss: 19.4816 - val_loss: 11.8520

Epoch 00369: val_loss did not improve from 11.77103
Epoch 370/10000
4/4 - 0s - loss: 19.4970 - val_loss: 11.8622

Epoch 00370: val_loss did not improve from 11.77103
Epoch 371/10000
4/4 - 0s - loss: 19.4910 - val_loss: 11.7983

Epoch 00371: val_loss did not improve from 11.77103
Epoch 372/10000
4/4 - 0s - loss: 19.4855 - val_loss: 11.8534

Epoch 00372: val_loss did not improve from 11.77103
Epoch 373/10000
4/4 - 0s - loss: 19.4936 - val_loss: 11.8762

Epoch 00373: val_loss did not improve from 11.77103
Epoch 374/10000
4/4 - 0s - loss: 19.4956 - val_loss: 11.8097

Epoch 00374: val_loss did not improve from 11.77103
Epoch 375/10000
4/4 - 0s - loss: 19.4835 - val_loss: 11.8670

Epoch 00375: val_loss did not improve from 11.77103
Epoch 376/10000
4/4 - 0s - loss: 19.5076 - val_loss: 11.9360

Epoch 00376: val_loss did not improve from 11.77103
Epoch 377/10000
4/4 - 0s - loss: 19.4830 - val_loss: 11.8252

Epoch 00377: val_loss did not improve from 11.77103
Epoch 378/10000
4/4 - 0s - loss: 19.4964 - val_loss: 11.8025

Epoch 00378: val_loss did not improve from 11.77103
Epoch 379/10000
4/4 - 0s - loss: 19.4899 - val_loss: 11.8299

Epoch 00379: val_loss did not improve from 11.77103
Epoch 380/10000
4/4 - 0s - loss: 19.4942 - val_loss: 11.9334

Epoch 00380: val_loss did not improve from 11.77103
Epoch 381/10000
4/4 - 0s - loss: 19.4942 - val_loss: 11.8522

Epoch 00381: val_loss did not improve from 11.77103
Epoch 382/10000
4/4 - 0s - loss: 19.5046 - val_loss: 11.7709

Epoch 00382: val_loss improved from 11.77103 to 11.77093, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 383/10000
4/4 - 0s - loss: 19.5095 - val_loss: 11.7773

Epoch 00383: val_loss did not improve from 11.77093
Epoch 384/10000
4/4 - 0s - loss: 19.4970 - val_loss: 11.8214

Epoch 00384: val_loss did not improve from 11.77093
Epoch 385/10000
4/4 - 0s - loss: 19.4829 - val_loss: 11.8209

Epoch 00385: val_loss did not improve from 11.77093
Epoch 386/10000
4/4 - 0s - loss: 19.4848 - val_loss: 11.8298

Epoch 00386: val_loss did not improve from 11.77093
Epoch 387/10000
4/4 - 0s - loss: 19.4911 - val_loss: 11.8812

Epoch 00387: val_loss did not improve from 11.77093
Epoch 388/10000
4/4 - 0s - loss: 19.4831 - val_loss: 11.8251

Epoch 00388: val_loss did not improve from 11.77093
Epoch 389/10000
4/4 - 0s - loss: 19.4981 - val_loss: 11.7928

Epoch 00389: val_loss did not improve from 11.77093
Epoch 390/10000
4/4 - 0s - loss: 19.4943 - val_loss: 11.8349

Epoch 00390: val_loss did not improve from 11.77093
Epoch 391/10000
4/4 - 0s - loss: 19.5139 - val_loss: 11.9002

Epoch 00391: val_loss did not improve from 11.77093
Epoch 392/10000
4/4 - 0s - loss: 19.4889 - val_loss: 11.7865

Epoch 00392: val_loss did not improve from 11.77093
Epoch 393/10000
4/4 - 0s - loss: 19.4945 - val_loss: 11.7804

Epoch 00393: val_loss did not improve from 11.77093
Epoch 394/10000
4/4 - 0s - loss: 19.5230 - val_loss: 11.8540

Epoch 00394: val_loss did not improve from 11.77093
Epoch 395/10000
4/4 - 0s - loss: 19.4765 - val_loss: 11.7985

Epoch 00395: val_loss did not improve from 11.77093
Epoch 396/10000
4/4 - 0s - loss: 19.4907 - val_loss: 11.7647

Epoch 00396: val_loss improved from 11.77093 to 11.76470, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 397/10000
4/4 - 0s - loss: 19.5079 - val_loss: 11.7794

Epoch 00397: val_loss did not improve from 11.76470
Epoch 398/10000
4/4 - 0s - loss: 19.4933 - val_loss: 11.9441

Epoch 00398: val_loss did not improve from 11.76470
Epoch 399/10000
4/4 - 0s - loss: 19.5242 - val_loss: 11.9211

Epoch 00399: val_loss did not improve from 11.76470
Epoch 400/10000
4/4 - 0s - loss: 19.4943 - val_loss: 11.8668

Epoch 00400: val_loss did not improve from 11.76470
Epoch 401/10000
4/4 - 0s - loss: 19.4843 - val_loss: 11.8174

Epoch 00401: val_loss did not improve from 11.76470
Epoch 402/10000
4/4 - 0s - loss: 19.4876 - val_loss: 11.8017

Epoch 00402: val_loss did not improve from 11.76470
Epoch 403/10000
4/4 - 0s - loss: 19.4811 - val_loss: 11.8359

Epoch 00403: val_loss did not improve from 11.76470
Epoch 404/10000
4/4 - 0s - loss: 19.5157 - val_loss: 11.9230

Epoch 00404: val_loss did not improve from 11.76470
Epoch 405/10000
4/4 - 0s - loss: 19.4775 - val_loss: 11.7852

Epoch 00405: val_loss did not improve from 11.76470
Epoch 406/10000
4/4 - 0s - loss: 19.5285 - val_loss: 11.7610

Epoch 00406: val_loss improved from 11.76470 to 11.76104, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 407/10000
4/4 - 0s - loss: 19.4975 - val_loss: 11.8378

Epoch 00407: val_loss did not improve from 11.76104
Epoch 408/10000
4/4 - 0s - loss: 19.4836 - val_loss: 11.9208

Epoch 00408: val_loss did not improve from 11.76104
Epoch 409/10000
4/4 - 0s - loss: 19.4956 - val_loss: 11.8347

Epoch 00409: val_loss did not improve from 11.76104
Epoch 410/10000
4/4 - 0s - loss: 19.5081 - val_loss: 11.7721

Epoch 00410: val_loss did not improve from 11.76104
Epoch 411/10000
4/4 - 0s - loss: 19.4839 - val_loss: 11.8431

Epoch 00411: val_loss did not improve from 11.76104
Epoch 412/10000
4/4 - 0s - loss: 19.4761 - val_loss: 11.9294

Epoch 00412: val_loss did not improve from 11.76104
Epoch 413/10000
4/4 - 0s - loss: 19.5020 - val_loss: 11.8929

Epoch 00413: val_loss did not improve from 11.76104
Epoch 414/10000
4/4 - 0s - loss: 19.5022 - val_loss: 11.8200

Epoch 00414: val_loss did not improve from 11.76104
Epoch 415/10000
4/4 - 0s - loss: 19.4861 - val_loss: 11.7998

Epoch 00415: val_loss did not improve from 11.76104
Epoch 416/10000
4/4 - 0s - loss: 19.4881 - val_loss: 11.8434

Epoch 00416: val_loss did not improve from 11.76104
Epoch 417/10000
4/4 - 0s - loss: 19.4743 - val_loss: 11.9011

Epoch 00417: val_loss did not improve from 11.76104
Epoch 418/10000
4/4 - 0s - loss: 19.4945 - val_loss: 11.9027

Epoch 00418: val_loss did not improve from 11.76104
Epoch 419/10000
4/4 - 0s - loss: 19.4915 - val_loss: 11.8031

Epoch 00419: val_loss did not improve from 11.76104
Epoch 420/10000
4/4 - 0s - loss: 19.4820 - val_loss: 11.7977

Epoch 00420: val_loss did not improve from 11.76104
Epoch 421/10000
4/4 - 0s - loss: 19.4838 - val_loss: 11.8162

Epoch 00421: val_loss did not improve from 11.76104
Epoch 422/10000
4/4 - 0s - loss: 19.4807 - val_loss: 11.8573

Epoch 00422: val_loss did not improve from 11.76104
Epoch 423/10000
4/4 - 0s - loss: 19.4842 - val_loss: 11.8364

Epoch 00423: val_loss did not improve from 11.76104
Epoch 424/10000
4/4 - 0s - loss: 19.4786 - val_loss: 11.7974

Epoch 00424: val_loss did not improve from 11.76104
Epoch 425/10000
4/4 - 0s - loss: 19.5017 - val_loss: 11.7732

Epoch 00425: val_loss did not improve from 11.76104
Epoch 426/10000
4/4 - 0s - loss: 19.4809 - val_loss: 11.8695

Epoch 00426: val_loss did not improve from 11.76104
Epoch 427/10000
4/4 - 0s - loss: 19.5192 - val_loss: 11.9330

Epoch 00427: val_loss did not improve from 11.76104
Epoch 428/10000
4/4 - 0s - loss: 19.5006 - val_loss: 11.8630

Epoch 00428: val_loss did not improve from 11.76104
Epoch 429/10000
4/4 - 0s - loss: 19.4543 - val_loss: 11.7696

Epoch 00429: val_loss did not improve from 11.76104
Epoch 430/10000
4/4 - 0s - loss: 19.5271 - val_loss: 11.7644

Epoch 00430: val_loss did not improve from 11.76104
Epoch 431/10000
4/4 - 0s - loss: 19.4986 - val_loss: 11.8141

Epoch 00431: val_loss did not improve from 11.76104
Epoch 432/10000
4/4 - 0s - loss: 19.5057 - val_loss: 11.9835

Epoch 00432: val_loss did not improve from 11.76104
Epoch 433/10000
4/4 - 0s - loss: 19.5256 - val_loss: 11.8890

Epoch 00433: val_loss did not improve from 11.76104
Epoch 434/10000
4/4 - 0s - loss: 19.5441 - val_loss: 11.7735

Epoch 00434: val_loss did not improve from 11.76104
Epoch 435/10000
4/4 - 0s - loss: 19.4804 - val_loss: 11.8502

Epoch 00435: val_loss did not improve from 11.76104
Epoch 436/10000
4/4 - 0s - loss: 19.4789 - val_loss: 11.9790

Epoch 00436: val_loss did not improve from 11.76104
Epoch 437/10000
4/4 - 0s - loss: 19.5107 - val_loss: 11.8907

Epoch 00437: val_loss did not improve from 11.76104
Epoch 438/10000
4/4 - 0s - loss: 19.4760 - val_loss: 11.7983

Epoch 00438: val_loss did not improve from 11.76104
Epoch 439/10000
4/4 - 0s - loss: 19.5106 - val_loss: 11.7745

Epoch 00439: val_loss did not improve from 11.76104
Epoch 440/10000
4/4 - 0s - loss: 19.5061 - val_loss: 11.8053

Epoch 00440: val_loss did not improve from 11.76104
Epoch 441/10000
4/4 - 0s - loss: 19.5316 - val_loss: 11.9307

Epoch 00441: val_loss did not improve from 11.76104
Epoch 442/10000
4/4 - 0s - loss: 19.5012 - val_loss: 11.8384

Epoch 00442: val_loss did not improve from 11.76104
Epoch 443/10000
4/4 - 0s - loss: 19.5109 - val_loss: 11.7584

Epoch 00443: val_loss improved from 11.76104 to 11.75842, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 444/10000
4/4 - 0s - loss: 19.5132 - val_loss: 11.7953

Epoch 00444: val_loss did not improve from 11.75842
Epoch 445/10000
4/4 - 0s - loss: 19.4757 - val_loss: 11.9647

Epoch 00445: val_loss did not improve from 11.75842
Epoch 446/10000
4/4 - 0s - loss: 19.5225 - val_loss: 11.8672

Epoch 00446: val_loss did not improve from 11.75842
Epoch 447/10000
4/4 - 0s - loss: 19.4977 - val_loss: 11.7942

Epoch 00447: val_loss did not improve from 11.75842
Epoch 448/10000
4/4 - 0s - loss: 19.4807 - val_loss: 11.8297

Epoch 00448: val_loss did not improve from 11.75842
Epoch 449/10000
4/4 - 0s - loss: 19.4764 - val_loss: 11.8569

Epoch 00449: val_loss did not improve from 11.75842
Epoch 450/10000
4/4 - 0s - loss: 19.4800 - val_loss: 11.8716

Epoch 00450: val_loss did not improve from 11.75842
Epoch 451/10000
4/4 - 0s - loss: 19.5099 - val_loss: 11.8394

Epoch 00451: val_loss did not improve from 11.75842
Epoch 452/10000
4/4 - 0s - loss: 19.4855 - val_loss: 11.9339

Epoch 00452: val_loss did not improve from 11.75842
Epoch 453/10000
4/4 - 0s - loss: 19.5048 - val_loss: 11.8538

Epoch 00453: val_loss did not improve from 11.75842
Epoch 454/10000
4/4 - 0s - loss: 19.5082 - val_loss: 11.7685

Epoch 00454: val_loss did not improve from 11.75842
Epoch 455/10000
4/4 - 0s - loss: 19.5224 - val_loss: 11.7925

Epoch 00455: val_loss did not improve from 11.75842
Epoch 456/10000
4/4 - 0s - loss: 19.4819 - val_loss: 11.8527

Epoch 00456: val_loss did not improve from 11.75842
Epoch 457/10000
4/4 - 0s - loss: 19.4901 - val_loss: 11.8457

Epoch 00457: val_loss did not improve from 11.75842
Epoch 458/10000
4/4 - 0s - loss: 19.4823 - val_loss: 11.8576

Epoch 00458: val_loss did not improve from 11.75842
Epoch 459/10000
4/4 - 0s - loss: 19.4793 - val_loss: 11.8296

Epoch 00459: val_loss did not improve from 11.75842
Epoch 460/10000
4/4 - 0s - loss: 19.4929 - val_loss: 11.7953

Epoch 00460: val_loss did not improve from 11.75842
Epoch 461/10000
4/4 - 0s - loss: 19.4929 - val_loss: 11.8231

Epoch 00461: val_loss did not improve from 11.75842
Epoch 462/10000
4/4 - 0s - loss: 19.4763 - val_loss: 11.9369

Epoch 00462: val_loss did not improve from 11.75842
Epoch 463/10000
4/4 - 0s - loss: 19.5554 - val_loss: 11.9268

Epoch 00463: val_loss did not improve from 11.75842
Epoch 464/10000
4/4 - 0s - loss: 19.4816 - val_loss: 11.7848

Epoch 00464: val_loss did not improve from 11.75842
Epoch 465/10000
4/4 - 0s - loss: 19.5147 - val_loss: 11.8012

Epoch 00465: val_loss did not improve from 11.75842
Epoch 466/10000
4/4 - 0s - loss: 19.4994 - val_loss: 11.8537

Epoch 00466: val_loss did not improve from 11.75842
Epoch 467/10000
4/4 - 0s - loss: 19.4784 - val_loss: 11.8467

Epoch 00467: val_loss did not improve from 11.75842
Epoch 468/10000
4/4 - 0s - loss: 19.5093 - val_loss: 11.8084

Epoch 00468: val_loss did not improve from 11.75842
Epoch 469/10000
4/4 - 0s - loss: 19.5018 - val_loss: 11.8892

Epoch 00469: val_loss did not improve from 11.75842
Epoch 470/10000
4/4 - 0s - loss: 19.4816 - val_loss: 11.8414

Epoch 00470: val_loss did not improve from 11.75842
Epoch 471/10000
4/4 - 0s - loss: 19.4840 - val_loss: 11.8137

Epoch 00471: val_loss did not improve from 11.75842
Epoch 472/10000
4/4 - 0s - loss: 19.4856 - val_loss: 11.8540

Epoch 00472: val_loss did not improve from 11.75842
Epoch 473/10000
4/4 - 0s - loss: 19.4921 - val_loss: 11.8311

Epoch 00473: val_loss did not improve from 11.75842
Epoch 474/10000
4/4 - 0s - loss: 19.4760 - val_loss: 11.8751

Epoch 00474: val_loss did not improve from 11.75842
Epoch 475/10000
4/4 - 0s - loss: 19.5136 - val_loss: 11.9293

Epoch 00475: val_loss did not improve from 11.75842
Epoch 476/10000
4/4 - 0s - loss: 19.4799 - val_loss: 11.8116

Epoch 00476: val_loss did not improve from 11.75842
Epoch 477/10000
4/4 - 0s - loss: 19.4888 - val_loss: 11.7970

Epoch 00477: val_loss did not improve from 11.75842
Epoch 478/10000
4/4 - 0s - loss: 19.4935 - val_loss: 11.8606

Epoch 00478: val_loss did not improve from 11.75842
Epoch 479/10000
4/4 - 0s - loss: 19.4827 - val_loss: 11.8699

Epoch 00479: val_loss did not improve from 11.75842
Epoch 480/10000
4/4 - 0s - loss: 19.4748 - val_loss: 11.8107

Epoch 00480: val_loss did not improve from 11.75842
Epoch 481/10000
4/4 - 0s - loss: 19.5231 - val_loss: 11.7895

Epoch 00481: val_loss did not improve from 11.75842
Epoch 482/10000
4/4 - 0s - loss: 19.4806 - val_loss: 11.8401

Epoch 00482: val_loss did not improve from 11.75842
Epoch 483/10000
4/4 - 0s - loss: 19.4906 - val_loss: 11.9265

Epoch 00483: val_loss did not improve from 11.75842
Epoch 484/10000
4/4 - 0s - loss: 19.4866 - val_loss: 11.8484

Epoch 00484: val_loss did not improve from 11.75842
Epoch 485/10000
4/4 - 0s - loss: 19.5234 - val_loss: 11.7708

Epoch 00485: val_loss did not improve from 11.75842
Epoch 486/10000
4/4 - 0s - loss: 19.4965 - val_loss: 11.8434

Epoch 00486: val_loss did not improve from 11.75842
Epoch 487/10000
4/4 - 0s - loss: 19.4963 - val_loss: 11.8992

Epoch 00487: val_loss did not improve from 11.75842
Epoch 488/10000
4/4 - 0s - loss: 19.4900 - val_loss: 11.8010

Epoch 00488: val_loss did not improve from 11.75842
Epoch 489/10000
4/4 - 0s - loss: 19.4869 - val_loss: 11.8113

Epoch 00489: val_loss did not improve from 11.75842
Epoch 490/10000
4/4 - 0s - loss: 19.5209 - val_loss: 11.7945

Epoch 00490: val_loss did not improve from 11.75842
Epoch 491/10000
4/4 - 0s - loss: 19.4665 - val_loss: 11.9394

Epoch 00491: val_loss did not improve from 11.75842
Epoch 492/10000
4/4 - 0s - loss: 19.5400 - val_loss: 11.9279

Epoch 00492: val_loss did not improve from 11.75842
Epoch 493/10000
4/4 - 0s - loss: 19.4850 - val_loss: 11.8049

Epoch 00493: val_loss did not improve from 11.75842
Epoch 494/10000
4/4 - 0s - loss: 19.4961 - val_loss: 11.8056

Epoch 00494: val_loss did not improve from 11.75842
Epoch 495/10000
4/4 - 0s - loss: 19.4868 - val_loss: 11.9029

Epoch 00495: val_loss did not improve from 11.75842
Epoch 496/10000
4/4 - 0s - loss: 19.5004 - val_loss: 11.8856

Epoch 00496: val_loss did not improve from 11.75842
Epoch 497/10000
4/4 - 0s - loss: 19.4978 - val_loss: 11.7838

Epoch 00497: val_loss did not improve from 11.75842
Epoch 498/10000
4/4 - 0s - loss: 19.5032 - val_loss: 11.7988

Epoch 00498: val_loss did not improve from 11.75842
Epoch 499/10000
4/4 - 0s - loss: 19.5342 - val_loss: 11.8897

Epoch 00499: val_loss did not improve from 11.75842
Epoch 500/10000
4/4 - 0s - loss: 19.4811 - val_loss: 11.8407

Epoch 00500: val_loss did not improve from 11.75842
Epoch 501/10000
4/4 - 0s - loss: 19.4831 - val_loss: 11.7822

Epoch 00501: val_loss did not improve from 11.75842
Epoch 502/10000
4/4 - 0s - loss: 19.5016 - val_loss: 11.8164

Epoch 00502: val_loss did not improve from 11.75842
Epoch 503/10000
4/4 - 0s - loss: 19.4829 - val_loss: 11.8512

Epoch 00503: val_loss did not improve from 11.75842
Epoch 504/10000
4/4 - 0s - loss: 19.4804 - val_loss: 11.8687

Epoch 00504: val_loss did not improve from 11.75842
Epoch 505/10000
4/4 - 0s - loss: 19.4810 - val_loss: 11.8534

Epoch 00505: val_loss did not improve from 11.75842
Epoch 506/10000
4/4 - 0s - loss: 19.4863 - val_loss: 11.8019

Epoch 00506: val_loss did not improve from 11.75842
Epoch 507/10000
4/4 - 0s - loss: 19.4927 - val_loss: 11.8075

Epoch 00507: val_loss did not improve from 11.75842
Epoch 508/10000
4/4 - 0s - loss: 19.4737 - val_loss: 11.8654

Epoch 00508: val_loss did not improve from 11.75842
Epoch 509/10000
4/4 - 0s - loss: 19.4938 - val_loss: 11.8658

Epoch 00509: val_loss did not improve from 11.75842
Epoch 510/10000
4/4 - 0s - loss: 19.5010 - val_loss: 11.9058

Epoch 00510: val_loss did not improve from 11.75842
Epoch 511/10000
4/4 - 0s - loss: 19.4914 - val_loss: 11.8426

Epoch 00511: val_loss did not improve from 11.75842
Epoch 512/10000
4/4 - 0s - loss: 19.4939 - val_loss: 11.7744

Epoch 00512: val_loss did not improve from 11.75842
Epoch 513/10000
4/4 - 0s - loss: 19.5340 - val_loss: 11.7832

Epoch 00513: val_loss did not improve from 11.75842
Epoch 514/10000
4/4 - 0s - loss: 19.4761 - val_loss: 11.9351

Epoch 00514: val_loss did not improve from 11.75842
Epoch 515/10000
4/4 - 0s - loss: 19.5376 - val_loss: 11.9559

Epoch 00515: val_loss did not improve from 11.75842
Epoch 516/10000
4/4 - 0s - loss: 19.4835 - val_loss: 11.7882

Epoch 00516: val_loss did not improve from 11.75842
Epoch 517/10000
4/4 - 0s - loss: 19.4888 - val_loss: 11.7670

Epoch 00517: val_loss did not improve from 11.75842
Epoch 518/10000
4/4 - 0s - loss: 19.5269 - val_loss: 11.7710

Epoch 00518: val_loss did not improve from 11.75842
Epoch 519/10000
4/4 - 0s - loss: 19.4717 - val_loss: 11.8945

Epoch 00519: val_loss did not improve from 11.75842
Epoch 520/10000
4/4 - 0s - loss: 19.5372 - val_loss: 11.9763

Epoch 00520: val_loss did not improve from 11.75842
Epoch 521/10000
4/4 - 0s - loss: 19.5181 - val_loss: 11.7971

Epoch 00521: val_loss did not improve from 11.75842
Epoch 522/10000
4/4 - 0s - loss: 19.5104 - val_loss: 11.8223

Epoch 00522: val_loss did not improve from 11.75842
Epoch 523/10000
4/4 - 0s - loss: 19.4946 - val_loss: 11.7917

Epoch 00523: val_loss did not improve from 11.75842
Epoch 524/10000
4/4 - 0s - loss: 19.5138 - val_loss: 11.8677

Epoch 00524: val_loss did not improve from 11.75842
Epoch 525/10000
4/4 - 0s - loss: 19.5015 - val_loss: 11.8621

Epoch 00525: val_loss did not improve from 11.75842
Epoch 526/10000
4/4 - 0s - loss: 19.5080 - val_loss: 11.7666

Epoch 00526: val_loss did not improve from 11.75842
Epoch 527/10000
4/4 - 0s - loss: 19.5027 - val_loss: 11.8183

Epoch 00527: val_loss did not improve from 11.75842
Epoch 528/10000
4/4 - 0s - loss: 19.4857 - val_loss: 11.8215

Epoch 00528: val_loss did not improve from 11.75842
Epoch 529/10000
4/4 - 0s - loss: 19.4767 - val_loss: 11.8462

Epoch 00529: val_loss did not improve from 11.75842
Epoch 530/10000
4/4 - 0s - loss: 19.4762 - val_loss: 11.8538

Epoch 00530: val_loss did not improve from 11.75842
Epoch 531/10000
4/4 - 0s - loss: 19.4785 - val_loss: 11.8455

Epoch 00531: val_loss did not improve from 11.75842
Epoch 532/10000
4/4 - 0s - loss: 19.4729 - val_loss: 11.8024

Epoch 00532: val_loss did not improve from 11.75842
Epoch 533/10000
4/4 - 0s - loss: 19.5017 - val_loss: 11.7818

Epoch 00533: val_loss did not improve from 11.75842
Epoch 534/10000
4/4 - 0s - loss: 19.5134 - val_loss: 11.8322

Epoch 00534: val_loss did not improve from 11.75842
Epoch 535/10000
4/4 - 0s - loss: 19.5076 - val_loss: 11.8039

Epoch 00535: val_loss did not improve from 11.75842
Epoch 536/10000
4/4 - 0s - loss: 19.4680 - val_loss: 11.9224

Epoch 00536: val_loss did not improve from 11.75842
Epoch 537/10000
4/4 - 0s - loss: 19.4949 - val_loss: 11.9498

Epoch 00537: val_loss did not improve from 11.75842
Epoch 538/10000
4/4 - 0s - loss: 19.4937 - val_loss: 11.8421

Epoch 00538: val_loss did not improve from 11.75842
Epoch 539/10000
4/4 - 0s - loss: 19.4782 - val_loss: 11.7985

Epoch 00539: val_loss did not improve from 11.75842
Epoch 540/10000
4/4 - 0s - loss: 19.4920 - val_loss: 11.7969

Epoch 00540: val_loss did not improve from 11.75842
Epoch 541/10000
4/4 - 0s - loss: 19.4911 - val_loss: 11.8205

Epoch 00541: val_loss did not improve from 11.75842
Epoch 542/10000
4/4 - 0s - loss: 19.4901 - val_loss: 11.8215

Epoch 00542: val_loss did not improve from 11.75842
Epoch 543/10000
4/4 - 0s - loss: 19.4826 - val_loss: 11.8500

Epoch 00543: val_loss did not improve from 11.75842
Epoch 544/10000
4/4 - 0s - loss: 19.4861 - val_loss: 11.8520

Epoch 00544: val_loss did not improve from 11.75842
Epoch 545/10000
4/4 - 0s - loss: 19.4867 - val_loss: 11.8101

Epoch 00545: val_loss did not improve from 11.75842
Epoch 546/10000
4/4 - 0s - loss: 19.4820 - val_loss: 11.8736

Epoch 00546: val_loss did not improve from 11.75842
Epoch 547/10000
4/4 - 0s - loss: 19.4975 - val_loss: 11.8625

Epoch 00547: val_loss did not improve from 11.75842
Epoch 548/10000
4/4 - 0s - loss: 19.5431 - val_loss: 11.8180

Epoch 00548: val_loss did not improve from 11.75842
Epoch 549/10000
4/4 - 0s - loss: 19.4525 - val_loss: 11.9771

Epoch 00549: val_loss did not improve from 11.75842
Epoch 550/10000
4/4 - 0s - loss: 19.5592 - val_loss: 12.0114

Epoch 00550: val_loss did not improve from 11.75842
Epoch 551/10000
4/4 - 0s - loss: 19.5939 - val_loss: 11.7959

Epoch 00551: val_loss did not improve from 11.75842
Epoch 552/10000
4/4 - 0s - loss: 19.4896 - val_loss: 11.8364

Epoch 00552: val_loss did not improve from 11.75842
Epoch 553/10000
4/4 - 0s - loss: 19.4759 - val_loss: 11.8644

Epoch 00553: val_loss did not improve from 11.75842
Epoch 554/10000
4/4 - 0s - loss: 19.4802 - val_loss: 11.8560

Epoch 00554: val_loss did not improve from 11.75842
Epoch 555/10000
4/4 - 0s - loss: 19.4737 - val_loss: 11.8246

Epoch 00555: val_loss did not improve from 11.75842
Epoch 556/10000
4/4 - 0s - loss: 19.4928 - val_loss: 11.8106

Epoch 00556: val_loss did not improve from 11.75842
Epoch 557/10000
4/4 - 0s - loss: 19.4778 - val_loss: 11.8429

Epoch 00557: val_loss did not improve from 11.75842
Epoch 558/10000
4/4 - 0s - loss: 19.4736 - val_loss: 11.9210

Epoch 00558: val_loss did not improve from 11.75842
Epoch 559/10000
4/4 - 0s - loss: 19.5087 - val_loss: 11.8748

Epoch 00559: val_loss did not improve from 11.75842
Epoch 560/10000
4/4 - 0s - loss: 19.5456 - val_loss: 11.7649

Epoch 00560: val_loss did not improve from 11.75842
Epoch 561/10000
4/4 - 0s - loss: 19.5025 - val_loss: 11.7859

Epoch 00561: val_loss did not improve from 11.75842
Epoch 562/10000
4/4 - 0s - loss: 19.4773 - val_loss: 11.8317

Epoch 00562: val_loss did not improve from 11.75842
Epoch 563/10000
4/4 - 0s - loss: 19.5051 - val_loss: 11.8604

Epoch 00563: val_loss did not improve from 11.75842
Epoch 564/10000
4/4 - 0s - loss: 19.4588 - val_loss: 11.7745

Epoch 00564: val_loss did not improve from 11.75842
Epoch 565/10000
4/4 - 0s - loss: 19.5069 - val_loss: 11.7574

Epoch 00565: val_loss improved from 11.75842 to 11.75737, saving model to ./results/dataset/trial_5/ckpt_9
Epoch 566/10000
4/4 - 0s - loss: 19.4879 - val_loss: 11.8264

Epoch 00566: val_loss did not improve from 11.75737
Epoch 567/10000
4/4 - 0s - loss: 19.4984 - val_loss: 11.9409

Epoch 00567: val_loss did not improve from 11.75737
Epoch 568/10000
4/4 - 0s - loss: 19.4885 - val_loss: 11.8212

Epoch 00568: val_loss did not improve from 11.75737
Epoch 569/10000
4/4 - 0s - loss: 19.4752 - val_loss: 11.7631

Epoch 00569: val_loss did not improve from 11.75737
Epoch 570/10000
4/4 - 0s - loss: 19.5077 - val_loss: 11.7878

Epoch 00570: val_loss did not improve from 11.75737
Epoch 571/10000
4/4 - 0s - loss: 19.4838 - val_loss: 11.8666

Epoch 00571: val_loss did not improve from 11.75737
Epoch 572/10000
4/4 - 0s - loss: 19.4869 - val_loss: 11.8708

Epoch 00572: val_loss did not improve from 11.75737
Epoch 573/10000
4/4 - 0s - loss: 19.4917 - val_loss: 11.7807

Epoch 00573: val_loss did not improve from 11.75737
Epoch 574/10000
4/4 - 0s - loss: 19.5004 - val_loss: 11.7800

Epoch 00574: val_loss did not improve from 11.75737
Epoch 575/10000
4/4 - 0s - loss: 19.4784 - val_loss: 11.9019

Epoch 00575: val_loss did not improve from 11.75737
Epoch 576/10000
4/4 - 0s - loss: 19.5215 - val_loss: 11.8975

Epoch 00576: val_loss did not improve from 11.75737
Epoch 577/10000
4/4 - 0s - loss: 19.4907 - val_loss: 11.8004

Epoch 00577: val_loss did not improve from 11.75737
Epoch 578/10000
4/4 - 0s - loss: 19.4842 - val_loss: 11.8151

Epoch 00578: val_loss did not improve from 11.75737
Epoch 579/10000
4/4 - 0s - loss: 19.4850 - val_loss: 11.8260

Epoch 00579: val_loss did not improve from 11.75737
Epoch 580/10000
4/4 - 0s - loss: 19.4758 - val_loss: 11.8260

Epoch 00580: val_loss did not improve from 11.75737
Epoch 581/10000
4/4 - 0s - loss: 19.4774 - val_loss: 11.8501

Epoch 00581: val_loss did not improve from 11.75737
Epoch 582/10000
4/4 - 0s - loss: 19.4793 - val_loss: 11.8881

Epoch 00582: val_loss did not improve from 11.75737
Epoch 583/10000
4/4 - 0s - loss: 19.4987 - val_loss: 11.8485

Epoch 00583: val_loss did not improve from 11.75737
Epoch 584/10000
4/4 - 0s - loss: 19.4918 - val_loss: 11.7942

Epoch 00584: val_loss did not improve from 11.75737
Epoch 585/10000
4/4 - 0s - loss: 19.4859 - val_loss: 11.8116

Epoch 00585: val_loss did not improve from 11.75737
Epoch 586/10000
4/4 - 0s - loss: 19.4679 - val_loss: 11.8886

Epoch 00586: val_loss did not improve from 11.75737
Epoch 587/10000
4/4 - 0s - loss: 19.5003 - val_loss: 11.9149

Epoch 00587: val_loss did not improve from 11.75737
Epoch 588/10000
4/4 - 0s - loss: 19.4756 - val_loss: 11.8094

Epoch 00588: val_loss did not improve from 11.75737
Epoch 589/10000
4/4 - 0s - loss: 19.4963 - val_loss: 11.7757

Epoch 00589: val_loss did not improve from 11.75737
Epoch 590/10000
4/4 - 0s - loss: 19.4989 - val_loss: 11.7939

Epoch 00590: val_loss did not improve from 11.75737
Epoch 591/10000
4/4 - 0s - loss: 19.4761 - val_loss: 11.8913

Epoch 00591: val_loss did not improve from 11.75737
Epoch 592/10000
4/4 - 0s - loss: 19.4896 - val_loss: 11.8790

Epoch 00592: val_loss did not improve from 11.75737
Epoch 593/10000
4/4 - 0s - loss: 19.4966 - val_loss: 11.7857

Epoch 00593: val_loss did not improve from 11.75737
Epoch 594/10000
4/4 - 0s - loss: 19.4911 - val_loss: 11.8377

Epoch 00594: val_loss did not improve from 11.75737
Epoch 595/10000
4/4 - 0s - loss: 19.5003 - val_loss: 11.8522

Epoch 00595: val_loss did not improve from 11.75737
Epoch 596/10000
4/4 - 0s - loss: 19.5024 - val_loss: 11.7744

Epoch 00596: val_loss did not improve from 11.75737
Epoch 597/10000
4/4 - 0s - loss: 19.4981 - val_loss: 11.7974

Epoch 00597: val_loss did not improve from 11.75737
Epoch 598/10000
4/4 - 0s - loss: 19.4848 - val_loss: 11.8545

Epoch 00598: val_loss did not improve from 11.75737
Epoch 599/10000
4/4 - 0s - loss: 19.4711 - val_loss: 11.9218

Epoch 00599: val_loss did not improve from 11.75737
Epoch 600/10000
4/4 - 0s - loss: 19.4985 - val_loss: 11.8945

Epoch 00600: val_loss did not improve from 11.75737
Epoch 601/10000
4/4 - 0s - loss: 19.4822 - val_loss: 11.8565

Epoch 00601: val_loss did not improve from 11.75737
Epoch 602/10000
4/4 - 0s - loss: 19.4817 - val_loss: 11.8264

Epoch 00602: val_loss did not improve from 11.75737
Epoch 603/10000
4/4 - 0s - loss: 19.4821 - val_loss: 11.8235

Epoch 00603: val_loss did not improve from 11.75737
Epoch 604/10000
4/4 - 0s - loss: 19.4760 - val_loss: 11.8252

Epoch 00604: val_loss did not improve from 11.75737
Epoch 605/10000
4/4 - 0s - loss: 19.4965 - val_loss: 11.8187

Epoch 00605: val_loss did not improve from 11.75737
Epoch 606/10000
4/4 - 0s - loss: 19.4667 - val_loss: 11.8970

Epoch 00606: val_loss did not improve from 11.75737
Epoch 607/10000
4/4 - 0s - loss: 19.4974 - val_loss: 11.9870

Epoch 00607: val_loss did not improve from 11.75737
Epoch 608/10000
4/4 - 0s - loss: 19.5092 - val_loss: 11.8862

Epoch 00608: val_loss did not improve from 11.75737
Epoch 609/10000
4/4 - 0s - loss: 19.4997 - val_loss: 11.7963

Epoch 00609: val_loss did not improve from 11.75737
Epoch 610/10000
4/4 - 0s - loss: 19.4884 - val_loss: 11.8424

Epoch 00610: val_loss did not improve from 11.75737
Epoch 611/10000
4/4 - 0s - loss: 19.4763 - val_loss: 11.8981

Epoch 00611: val_loss did not improve from 11.75737
Epoch 612/10000
4/4 - 0s - loss: 19.4800 - val_loss: 11.8686

Epoch 00612: val_loss did not improve from 11.75737
Epoch 613/10000
4/4 - 0s - loss: 19.4865 - val_loss: 11.8098

Epoch 00613: val_loss did not improve from 11.75737
Epoch 614/10000
4/4 - 0s - loss: 19.5002 - val_loss: 11.8608

Epoch 00614: val_loss did not improve from 11.75737
Epoch 615/10000
4/4 - 0s - loss: 19.5056 - val_loss: 11.8205

Epoch 00615: val_loss did not improve from 11.75737
Epoch 616/10000
4/4 - 0s - loss: 19.4768 - val_loss: 11.8503

Epoch 00616: val_loss did not improve from 11.75737
Epoch 617/10000
4/4 - 0s - loss: 19.4789 - val_loss: 11.8522

Epoch 00617: val_loss did not improve from 11.75737
Epoch 618/10000
4/4 - 0s - loss: 19.4709 - val_loss: 11.8056

Epoch 00618: val_loss did not improve from 11.75737
Epoch 619/10000
4/4 - 0s - loss: 19.5360 - val_loss: 11.7678

Epoch 00619: val_loss did not improve from 11.75737
Epoch 620/10000
4/4 - 0s - loss: 19.4925 - val_loss: 11.8362

Epoch 00620: val_loss did not improve from 11.75737
Epoch 621/10000
4/4 - 0s - loss: 19.5053 - val_loss: 11.9655

Epoch 00621: val_loss did not improve from 11.75737
Epoch 622/10000
4/4 - 0s - loss: 19.5048 - val_loss: 11.8715

Epoch 00622: val_loss did not improve from 11.75737
Epoch 623/10000
4/4 - 0s - loss: 19.4770 - val_loss: 11.8190

Epoch 00623: val_loss did not improve from 11.75737
Epoch 624/10000
4/4 - 0s - loss: 19.5215 - val_loss: 11.7754

Epoch 00624: val_loss did not improve from 11.75737
Epoch 625/10000
4/4 - 0s - loss: 19.4985 - val_loss: 11.8152

Epoch 00625: val_loss did not improve from 11.75737
Epoch 626/10000
4/4 - 0s - loss: 19.4968 - val_loss: 11.9164

Epoch 00626: val_loss did not improve from 11.75737
Epoch 627/10000
4/4 - 0s - loss: 19.4862 - val_loss: 11.8250

Epoch 00627: val_loss did not improve from 11.75737
Epoch 628/10000
4/4 - 0s - loss: 19.4784 - val_loss: 11.8047

Epoch 00628: val_loss did not improve from 11.75737
Epoch 629/10000
4/4 - 0s - loss: 19.4819 - val_loss: 11.8301

Epoch 00629: val_loss did not improve from 11.75737
Epoch 630/10000
4/4 - 0s - loss: 19.4731 - val_loss: 11.8653

Epoch 00630: val_loss did not improve from 11.75737
Epoch 631/10000
4/4 - 0s - loss: 19.4717 - val_loss: 11.9055

Epoch 00631: val_loss did not improve from 11.75737
Epoch 632/10000
4/4 - 0s - loss: 19.4820 - val_loss: 11.8834

Epoch 00632: val_loss did not improve from 11.75737
Epoch 633/10000
4/4 - 0s - loss: 19.4831 - val_loss: 11.8203

Epoch 00633: val_loss did not improve from 11.75737
Epoch 634/10000
4/4 - 0s - loss: 19.4853 - val_loss: 11.8394

Epoch 00634: val_loss did not improve from 11.75737
Epoch 635/10000
4/4 - 0s - loss: 19.4751 - val_loss: 11.8260

Epoch 00635: val_loss did not improve from 11.75737
Epoch 636/10000
4/4 - 0s - loss: 19.4797 - val_loss: 11.8473

Epoch 00636: val_loss did not improve from 11.75737
Epoch 637/10000
4/4 - 0s - loss: 19.4792 - val_loss: 11.8557

Epoch 00637: val_loss did not improve from 11.75737
Epoch 638/10000
4/4 - 0s - loss: 19.4744 - val_loss: 11.8086

Epoch 00638: val_loss did not improve from 11.75737
Epoch 639/10000
4/4 - 0s - loss: 19.4831 - val_loss: 11.8122

Epoch 00639: val_loss did not improve from 11.75737
Epoch 640/10000
4/4 - 0s - loss: 19.4814 - val_loss: 11.8202

Epoch 00640: val_loss did not improve from 11.75737
Epoch 641/10000
4/4 - 0s - loss: 19.4779 - val_loss: 11.8180

Epoch 00641: val_loss did not improve from 11.75737
Epoch 642/10000
4/4 - 0s - loss: 19.4769 - val_loss: 11.8441

Epoch 00642: val_loss did not improve from 11.75737
Epoch 643/10000
4/4 - 0s - loss: 19.4824 - val_loss: 11.8339

Epoch 00643: val_loss did not improve from 11.75737
Epoch 644/10000
4/4 - 0s - loss: 19.4704 - val_loss: 11.8821

Epoch 00644: val_loss did not improve from 11.75737
Epoch 645/10000
4/4 - 0s - loss: 19.4785 - val_loss: 11.9152

Epoch 00645: val_loss did not improve from 11.75737
Epoch 646/10000
4/4 - 0s - loss: 19.4882 - val_loss: 11.8616

Epoch 00646: val_loss did not improve from 11.75737
Epoch 647/10000
4/4 - 0s - loss: 19.4959 - val_loss: 11.8404

Epoch 00647: val_loss did not improve from 11.75737
Epoch 648/10000
4/4 - 0s - loss: 19.4891 - val_loss: 11.7837

Epoch 00648: val_loss did not improve from 11.75737
Epoch 649/10000
4/4 - 0s - loss: 19.4887 - val_loss: 11.8469

Epoch 00649: val_loss did not improve from 11.75737
Epoch 650/10000
4/4 - 0s - loss: 19.4715 - val_loss: 11.8961

Epoch 00650: val_loss did not improve from 11.75737
Epoch 651/10000
4/4 - 0s - loss: 19.4899 - val_loss: 11.8720

Epoch 00651: val_loss did not improve from 11.75737
Epoch 652/10000
4/4 - 0s - loss: 19.4797 - val_loss: 11.7947

Epoch 00652: val_loss did not improve from 11.75737
Epoch 653/10000
4/4 - 0s - loss: 19.4908 - val_loss: 11.8149

Epoch 00653: val_loss did not improve from 11.75737
Epoch 654/10000
4/4 - 0s - loss: 19.4736 - val_loss: 11.8020

Epoch 00654: val_loss did not improve from 11.75737
Epoch 655/10000
4/4 - 0s - loss: 19.4823 - val_loss: 11.8004

Epoch 00655: val_loss did not improve from 11.75737
Epoch 656/10000
4/4 - 0s - loss: 19.4976 - val_loss: 11.7709

Epoch 00656: val_loss did not improve from 11.75737
Epoch 657/10000
4/4 - 0s - loss: 19.5018 - val_loss: 11.8362

Epoch 00657: val_loss did not improve from 11.75737
Epoch 658/10000
4/4 - 0s - loss: 19.4792 - val_loss: 11.8316

Epoch 00658: val_loss did not improve from 11.75737
Epoch 659/10000
4/4 - 0s - loss: 19.4729 - val_loss: 11.8075

Epoch 00659: val_loss did not improve from 11.75737
Epoch 660/10000
4/4 - 0s - loss: 19.4847 - val_loss: 11.7907

Epoch 00660: val_loss did not improve from 11.75737
Epoch 661/10000
4/4 - 0s - loss: 19.4848 - val_loss: 11.8136

Epoch 00661: val_loss did not improve from 11.75737
Epoch 662/10000
4/4 - 0s - loss: 19.4682 - val_loss: 11.8984

Epoch 00662: val_loss did not improve from 11.75737
Epoch 663/10000
4/4 - 0s - loss: 19.5119 - val_loss: 11.8836

Epoch 00663: val_loss did not improve from 11.75737
Epoch 664/10000
4/4 - 0s - loss: 19.6331 - val_loss: 11.7611

Epoch 00664: val_loss did not improve from 11.75737
Epoch 665/10000
4/4 - 0s - loss: 19.5083 - val_loss: 11.8493

Epoch 00665: val_loss did not improve from 11.75737
Epoch 666/10000
4/4 - 0s - loss: 19.4732 - val_loss: 11.9199

Epoch 00666: val_loss did not improve from 11.75737
Epoch 667/10000
4/4 - 0s - loss: 19.5097 - val_loss: 11.8857

Epoch 00667: val_loss did not improve from 11.75737
Epoch 668/10000
4/4 - 0s - loss: 19.5086 - val_loss: 11.7682

Epoch 00668: val_loss did not improve from 11.75737
Epoch 669/10000
4/4 - 0s - loss: 19.5073 - val_loss: 11.7862

Epoch 00669: val_loss did not improve from 11.75737
Epoch 670/10000
4/4 - 0s - loss: 19.5123 - val_loss: 11.9132

Epoch 00670: val_loss did not improve from 11.75737
Epoch 671/10000
4/4 - 0s - loss: 19.5268 - val_loss: 11.7965

Epoch 00671: val_loss did not improve from 11.75737
Epoch 672/10000
4/4 - 0s - loss: 19.4793 - val_loss: 11.8182

Epoch 00672: val_loss did not improve from 11.75737
Epoch 673/10000
4/4 - 0s - loss: 19.4749 - val_loss: 11.8462

Epoch 00673: val_loss did not improve from 11.75737
Epoch 674/10000
4/4 - 0s - loss: 19.4982 - val_loss: 11.8654

Epoch 00674: val_loss did not improve from 11.75737
Epoch 675/10000
4/4 - 0s - loss: 19.4705 - val_loss: 11.7884

Epoch 00675: val_loss did not improve from 11.75737
Epoch 676/10000
4/4 - 0s - loss: 19.4907 - val_loss: 11.8071

Epoch 00676: val_loss did not improve from 11.75737
Epoch 677/10000
4/4 - 0s - loss: 19.4873 - val_loss: 11.8436

Epoch 00677: val_loss did not improve from 11.75737
Epoch 678/10000
4/4 - 0s - loss: 19.4768 - val_loss: 11.8123

Epoch 00678: val_loss did not improve from 11.75737
Epoch 679/10000
4/4 - 0s - loss: 19.5193 - val_loss: 11.7832

Epoch 00679: val_loss did not improve from 11.75737
Epoch 680/10000
4/4 - 0s - loss: 19.5049 - val_loss: 11.9301

Epoch 00680: val_loss did not improve from 11.75737
Epoch 681/10000
4/4 - 0s - loss: 19.4945 - val_loss: 11.8786

Epoch 00681: val_loss did not improve from 11.75737
Epoch 682/10000
4/4 - 0s - loss: 19.4829 - val_loss: 11.8070

Epoch 00682: val_loss did not improve from 11.75737
Epoch 683/10000
4/4 - 0s - loss: 19.5348 - val_loss: 11.7890

Epoch 00683: val_loss did not improve from 11.75737
Epoch 684/10000
4/4 - 0s - loss: 19.4693 - val_loss: 11.9285

Epoch 00684: val_loss did not improve from 11.75737
Epoch 685/10000
4/4 - 0s - loss: 19.5389 - val_loss: 11.9649

Epoch 00685: val_loss did not improve from 11.75737
Epoch 686/10000
4/4 - 0s - loss: 19.4976 - val_loss: 11.7948

Epoch 00686: val_loss did not improve from 11.75737
Epoch 687/10000
4/4 - 0s - loss: 19.5148 - val_loss: 11.7896

Epoch 00687: val_loss did not improve from 11.75737
Epoch 688/10000
4/4 - 0s - loss: 19.5064 - val_loss: 11.8946

Epoch 00688: val_loss did not improve from 11.75737
Epoch 689/10000
4/4 - 0s - loss: 19.4963 - val_loss: 11.8792

Epoch 00689: val_loss did not improve from 11.75737
Epoch 690/10000
4/4 - 0s - loss: 19.4582 - val_loss: 11.7882

Epoch 00690: val_loss did not improve from 11.75737
Epoch 691/10000
4/4 - 0s - loss: 19.5331 - val_loss: 11.7768

Epoch 00691: val_loss did not improve from 11.75737
Epoch 692/10000
4/4 - 0s - loss: 19.4889 - val_loss: 11.8712

Epoch 00692: val_loss did not improve from 11.75737
Epoch 693/10000
4/4 - 0s - loss: 19.4979 - val_loss: 11.9487

Epoch 00693: val_loss did not improve from 11.75737
Epoch 694/10000
4/4 - 0s - loss: 19.4854 - val_loss: 11.8287

Epoch 00694: val_loss did not improve from 11.75737
Epoch 695/10000
4/4 - 0s - loss: 19.4856 - val_loss: 11.7805

Epoch 00695: val_loss did not improve from 11.75737
Epoch 696/10000
4/4 - 0s - loss: 19.5073 - val_loss: 11.8300

Epoch 00696: val_loss did not improve from 11.75737
Epoch 697/10000
4/4 - 0s - loss: 19.4840 - val_loss: 11.8782

Epoch 00697: val_loss did not improve from 11.75737
Epoch 698/10000
4/4 - 0s - loss: 19.4767 - val_loss: 11.8480

Epoch 00698: val_loss did not improve from 11.75737
Epoch 699/10000
4/4 - 0s - loss: 19.4901 - val_loss: 11.7858

Epoch 00699: val_loss did not improve from 11.75737
Epoch 700/10000
4/4 - 0s - loss: 19.4901 - val_loss: 11.8164

Epoch 00700: val_loss did not improve from 11.75737
Epoch 701/10000
4/4 - 0s - loss: 19.4777 - val_loss: 11.9323

Epoch 00701: val_loss did not improve from 11.75737
Epoch 702/10000
4/4 - 0s - loss: 19.5032 - val_loss: 11.8755

Epoch 00702: val_loss did not improve from 11.75737
Epoch 703/10000
4/4 - 0s - loss: 19.4738 - val_loss: 11.8059

Epoch 00703: val_loss did not improve from 11.75737
Epoch 704/10000
4/4 - 0s - loss: 19.4809 - val_loss: 11.8153

Epoch 00704: val_loss did not improve from 11.75737
Epoch 705/10000
4/4 - 0s - loss: 19.4781 - val_loss: 11.8293

Epoch 00705: val_loss did not improve from 11.75737
Epoch 706/10000
4/4 - 0s - loss: 19.4843 - val_loss: 11.8096

Epoch 00706: val_loss did not improve from 11.75737
Epoch 707/10000
4/4 - 0s - loss: 19.4705 - val_loss: 11.8630

Epoch 00707: val_loss did not improve from 11.75737
Epoch 708/10000
4/4 - 0s - loss: 19.4757 - val_loss: 11.8796

Epoch 00708: val_loss did not improve from 11.75737
Epoch 709/10000
4/4 - 0s - loss: 19.4795 - val_loss: 11.8516

Epoch 00709: val_loss did not improve from 11.75737
Epoch 710/10000
4/4 - 0s - loss: 19.5180 - val_loss: 11.8005

Epoch 00710: val_loss did not improve from 11.75737
Epoch 711/10000
4/4 - 0s - loss: 19.4739 - val_loss: 11.8627

Epoch 00711: val_loss did not improve from 11.75737
Epoch 712/10000
4/4 - 0s - loss: 19.5003 - val_loss: 11.8870

Epoch 00712: val_loss did not improve from 11.75737
Epoch 713/10000
4/4 - 0s - loss: 19.4693 - val_loss: 11.8098

Epoch 00713: val_loss did not improve from 11.75737
Epoch 714/10000
4/4 - 0s - loss: 19.4985 - val_loss: 11.7701

Epoch 00714: val_loss did not improve from 11.75737
Epoch 715/10000
4/4 - 0s - loss: 19.4981 - val_loss: 11.8277

Epoch 00715: val_loss did not improve from 11.75737
Epoch 716/10000
4/4 - 0s - loss: 19.4851 - val_loss: 11.9056

Epoch 00716: val_loss did not improve from 11.75737
Epoch 717/10000
4/4 - 0s - loss: 19.4939 - val_loss: 11.8567

Epoch 00717: val_loss did not improve from 11.75737
Epoch 718/10000
4/4 - 0s - loss: 19.4723 - val_loss: 11.8361

Epoch 00718: val_loss did not improve from 11.75737
Epoch 719/10000
4/4 - 0s - loss: 19.4744 - val_loss: 11.8367

Epoch 00719: val_loss did not improve from 11.75737
Epoch 720/10000
4/4 - 0s - loss: 19.4750 - val_loss: 11.8347

Epoch 00720: val_loss did not improve from 11.75737
Epoch 721/10000
4/4 - 0s - loss: 19.4794 - val_loss: 11.8116

Epoch 00721: val_loss did not improve from 11.75737
Epoch 722/10000
4/4 - 0s - loss: 19.4889 - val_loss: 11.8503

Epoch 00722: val_loss did not improve from 11.75737
Epoch 723/10000
4/4 - 0s - loss: 19.4842 - val_loss: 11.9234

Epoch 00723: val_loss did not improve from 11.75737
Epoch 724/10000
4/4 - 0s - loss: 19.4876 - val_loss: 11.8480

Epoch 00724: val_loss did not improve from 11.75737
Epoch 725/10000
4/4 - 0s - loss: 19.4783 - val_loss: 11.8005

Epoch 00725: val_loss did not improve from 11.75737
Epoch 726/10000
4/4 - 0s - loss: 19.4788 - val_loss: 11.8446

Epoch 00726: val_loss did not improve from 11.75737
Epoch 727/10000
4/4 - 0s - loss: 19.4861 - val_loss: 11.8995

Epoch 00727: val_loss did not improve from 11.75737
Epoch 728/10000
4/4 - 0s - loss: 19.4895 - val_loss: 11.8386

Epoch 00728: val_loss did not improve from 11.75737
Epoch 729/10000
4/4 - 0s - loss: 19.4736 - val_loss: 11.8436

Epoch 00729: val_loss did not improve from 11.75737
Epoch 730/10000
4/4 - 0s - loss: 19.4804 - val_loss: 11.8109

Epoch 00730: val_loss did not improve from 11.75737
Epoch 731/10000
4/4 - 0s - loss: 19.4756 - val_loss: 11.8273

Epoch 00731: val_loss did not improve from 11.75737
Epoch 732/10000
4/4 - 0s - loss: 19.4705 - val_loss: 11.8567

Epoch 00732: val_loss did not improve from 11.75737
Epoch 733/10000
4/4 - 0s - loss: 19.4767 - val_loss: 11.8597

Epoch 00733: val_loss did not improve from 11.75737
Epoch 734/10000
4/4 - 0s - loss: 19.4706 - val_loss: 11.8114

Epoch 00734: val_loss did not improve from 11.75737
Epoch 735/10000
4/4 - 0s - loss: 19.4835 - val_loss: 11.8030

Epoch 00735: val_loss did not improve from 11.75737
Epoch 736/10000
4/4 - 0s - loss: 19.4913 - val_loss: 11.8586

Epoch 00736: val_loss did not improve from 11.75737
Epoch 737/10000
4/4 - 0s - loss: 19.4752 - val_loss: 11.8419

Epoch 00737: val_loss did not improve from 11.75737
Epoch 738/10000
4/4 - 0s - loss: 19.4993 - val_loss: 11.7956

Epoch 00738: val_loss did not improve from 11.75737
Epoch 739/10000
4/4 - 0s - loss: 19.4923 - val_loss: 11.8592

Epoch 00739: val_loss did not improve from 11.75737
Epoch 740/10000
4/4 - 0s - loss: 19.4763 - val_loss: 11.8822

Epoch 00740: val_loss did not improve from 11.75737
Epoch 741/10000
4/4 - 0s - loss: 19.4756 - val_loss: 11.8270

Epoch 00741: val_loss did not improve from 11.75737
Epoch 742/10000
4/4 - 0s - loss: 19.4818 - val_loss: 11.8254

Epoch 00742: val_loss did not improve from 11.75737
Epoch 743/10000
4/4 - 0s - loss: 19.4780 - val_loss: 11.8153

Epoch 00743: val_loss did not improve from 11.75737
Epoch 744/10000
4/4 - 0s - loss: 19.4811 - val_loss: 11.8135

Epoch 00744: val_loss did not improve from 11.75737
Epoch 745/10000
4/4 - 0s - loss: 19.5020 - val_loss: 11.7919

Epoch 00745: val_loss did not improve from 11.75737
Epoch 746/10000
4/4 - 0s - loss: 19.4912 - val_loss: 11.8623

Epoch 00746: val_loss did not improve from 11.75737
Epoch 747/10000
4/4 - 0s - loss: 19.4743 - val_loss: 11.8860

Epoch 00747: val_loss did not improve from 11.75737
Epoch 748/10000
4/4 - 0s - loss: 19.4903 - val_loss: 11.8375

Epoch 00748: val_loss did not improve from 11.75737
Epoch 749/10000
4/4 - 0s - loss: 19.4752 - val_loss: 11.8437

Epoch 00749: val_loss did not improve from 11.75737
Epoch 750/10000
4/4 - 0s - loss: 19.4769 - val_loss: 11.8500

Epoch 00750: val_loss did not improve from 11.75737
Epoch 751/10000
4/4 - 0s - loss: 19.4738 - val_loss: 11.8568

Epoch 00751: val_loss did not improve from 11.75737
Epoch 752/10000
4/4 - 0s - loss: 19.4720 - val_loss: 11.8282

Epoch 00752: val_loss did not improve from 11.75737
Epoch 753/10000
4/4 - 0s - loss: 19.4847 - val_loss: 11.8322

Epoch 00753: val_loss did not improve from 11.75737
Epoch 754/10000
4/4 - 0s - loss: 19.4700 - val_loss: 11.8814

Epoch 00754: val_loss did not improve from 11.75737
Epoch 755/10000
4/4 - 0s - loss: 19.5288 - val_loss: 11.9709

Epoch 00755: val_loss did not improve from 11.75737
Epoch 756/10000
4/4 - 0s - loss: 19.5046 - val_loss: 11.8051

Epoch 00756: val_loss did not improve from 11.75737
Epoch 757/10000
4/4 - 0s - loss: 19.5042 - val_loss: 11.8098

Epoch 00757: val_loss did not improve from 11.75737
Epoch 758/10000
4/4 - 0s - loss: 19.4709 - val_loss: 11.9602

Epoch 00758: val_loss did not improve from 11.75737
Epoch 759/10000
4/4 - 0s - loss: 19.5858 - val_loss: 11.9450

Epoch 00759: val_loss did not improve from 11.75737
Epoch 760/10000
4/4 - 0s - loss: 19.4965 - val_loss: 11.7707

Epoch 00760: val_loss did not improve from 11.75737
Epoch 761/10000
4/4 - 0s - loss: 19.5792 - val_loss: 11.7657

Epoch 00761: val_loss did not improve from 11.75737
Epoch 762/10000
4/4 - 0s - loss: 19.4920 - val_loss: 11.8604

Epoch 00762: val_loss did not improve from 11.75737
Epoch 763/10000
4/4 - 0s - loss: 19.5034 - val_loss: 12.0499

Epoch 00763: val_loss did not improve from 11.75737
Epoch 764/10000
4/4 - 0s - loss: 19.5166 - val_loss: 11.8353

Epoch 00764: val_loss did not improve from 11.75737
Epoch 765/10000
4/4 - 0s - loss: 19.5033 - val_loss: 11.7658

Epoch 00765: val_loss did not improve from 11.75737
Epoch 00765: early stopping
*************************** Fold #: 10 ***************************
Model: "sequential_49"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_539 (Dense)            (None, 30)                210       
_________________________________________________________________
dense_540 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_541 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_542 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_543 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_544 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_545 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_546 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_547 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_548 (Dense)            (None, 30)                930       
_________________________________________________________________
dense_549 (Dense)            (None, 1)                 31        
=================================================================
Total params: 8,611
Trainable params: 8,611
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10000
4/4 - 0s - loss: 33.0150 - val_loss: 16.0431

Epoch 00001: val_loss improved from inf to 16.04308, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 2/10000
4/4 - 0s - loss: 32.9813 - val_loss: 16.0109

Epoch 00002: val_loss improved from 16.04308 to 16.01094, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 3/10000
4/4 - 0s - loss: 32.9437 - val_loss: 15.9753

Epoch 00003: val_loss improved from 16.01094 to 15.97527, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 4/10000
4/4 - 0s - loss: 32.9023 - val_loss: 15.9348

Epoch 00004: val_loss improved from 15.97527 to 15.93485, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 5/10000
4/4 - 0s - loss: 32.8545 - val_loss: 15.8884

Epoch 00005: val_loss improved from 15.93485 to 15.88842, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 6/10000
4/4 - 0s - loss: 32.8001 - val_loss: 15.8340

Epoch 00006: val_loss improved from 15.88842 to 15.83401, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 7/10000
4/4 - 0s - loss: 32.7337 - val_loss: 15.7694

Epoch 00007: val_loss improved from 15.83401 to 15.76941, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 8/10000
4/4 - 0s - loss: 32.6582 - val_loss: 15.6903

Epoch 00008: val_loss improved from 15.76941 to 15.69034, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 9/10000
4/4 - 0s - loss: 32.5622 - val_loss: 15.5921

Epoch 00009: val_loss improved from 15.69034 to 15.59207, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 10/10000
4/4 - 0s - loss: 32.4435 - val_loss: 15.4677

Epoch 00010: val_loss improved from 15.59207 to 15.46768, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 11/10000
4/4 - 0s - loss: 32.2894 - val_loss: 15.3067

Epoch 00011: val_loss improved from 15.46768 to 15.30671, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 12/10000
4/4 - 0s - loss: 32.0882 - val_loss: 15.0927

Epoch 00012: val_loss improved from 15.30671 to 15.09274, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 13/10000
4/4 - 0s - loss: 31.8212 - val_loss: 14.8011

Epoch 00013: val_loss improved from 15.09274 to 14.80111, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 14/10000
4/4 - 0s - loss: 31.4550 - val_loss: 14.3898

Epoch 00014: val_loss improved from 14.80111 to 14.38980, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 15/10000
4/4 - 0s - loss: 30.9109 - val_loss: 13.7903

Epoch 00015: val_loss improved from 14.38980 to 13.79033, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 16/10000
4/4 - 0s - loss: 30.1281 - val_loss: 12.8887

Epoch 00016: val_loss improved from 13.79033 to 12.88874, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 17/10000
4/4 - 0s - loss: 28.9384 - val_loss: 11.5488

Epoch 00017: val_loss improved from 12.88874 to 11.54877, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 18/10000
4/4 - 0s - loss: 27.1738 - val_loss: 9.8995

Epoch 00018: val_loss improved from 11.54877 to 9.89950, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 19/10000
4/4 - 0s - loss: 25.2514 - val_loss: 9.7713

Epoch 00019: val_loss improved from 9.89950 to 9.77129, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 20/10000
4/4 - 0s - loss: 25.2828 - val_loss: 10.3630

Epoch 00020: val_loss did not improve from 9.77129
Epoch 21/10000
4/4 - 0s - loss: 24.8600 - val_loss: 9.2768

Epoch 00021: val_loss improved from 9.77129 to 9.27683, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 22/10000
4/4 - 0s - loss: 24.4701 - val_loss: 9.1138

Epoch 00022: val_loss improved from 9.27683 to 9.11379, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 23/10000
4/4 - 0s - loss: 24.5104 - val_loss: 9.0412

Epoch 00023: val_loss improved from 9.11379 to 9.04121, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 24/10000
4/4 - 0s - loss: 24.3480 - val_loss: 8.9341

Epoch 00024: val_loss improved from 9.04121 to 8.93415, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 25/10000
4/4 - 0s - loss: 24.0664 - val_loss: 8.9751

Epoch 00025: val_loss did not improve from 8.93415
Epoch 26/10000
4/4 - 0s - loss: 23.9427 - val_loss: 8.9994

Epoch 00026: val_loss did not improve from 8.93415
Epoch 27/10000
4/4 - 0s - loss: 23.8325 - val_loss: 8.7962

Epoch 00027: val_loss improved from 8.93415 to 8.79621, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 28/10000
4/4 - 0s - loss: 23.6253 - val_loss: 8.5211

Epoch 00028: val_loss improved from 8.79621 to 8.52110, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 29/10000
4/4 - 0s - loss: 23.4342 - val_loss: 8.3397

Epoch 00029: val_loss improved from 8.52110 to 8.33970, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 30/10000
4/4 - 0s - loss: 23.2197 - val_loss: 8.2054

Epoch 00030: val_loss improved from 8.33970 to 8.20542, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 31/10000
4/4 - 0s - loss: 22.9717 - val_loss: 8.0942

Epoch 00031: val_loss improved from 8.20542 to 8.09420, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 32/10000
4/4 - 0s - loss: 22.7310 - val_loss: 7.8889

Epoch 00032: val_loss improved from 8.09420 to 7.88887, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 33/10000
4/4 - 0s - loss: 22.4562 - val_loss: 7.6340

Epoch 00033: val_loss improved from 7.88887 to 7.63404, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 34/10000
4/4 - 0s - loss: 22.1916 - val_loss: 7.4515

Epoch 00034: val_loss improved from 7.63404 to 7.45150, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 35/10000
4/4 - 0s - loss: 21.9104 - val_loss: 7.3756

Epoch 00035: val_loss improved from 7.45150 to 7.37560, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 36/10000
4/4 - 0s - loss: 21.6991 - val_loss: 7.2775

Epoch 00036: val_loss improved from 7.37560 to 7.27747, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 37/10000
4/4 - 0s - loss: 21.4964 - val_loss: 7.0622

Epoch 00037: val_loss improved from 7.27747 to 7.06216, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 38/10000
4/4 - 0s - loss: 21.3340 - val_loss: 7.0174

Epoch 00038: val_loss improved from 7.06216 to 7.01736, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 39/10000
4/4 - 0s - loss: 21.1390 - val_loss: 6.8999

Epoch 00039: val_loss improved from 7.01736 to 6.89989, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 40/10000
4/4 - 0s - loss: 21.0299 - val_loss: 6.8801

Epoch 00040: val_loss improved from 6.89989 to 6.88011, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 41/10000
4/4 - 0s - loss: 20.9244 - val_loss: 6.8743

Epoch 00041: val_loss improved from 6.88011 to 6.87430, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 42/10000
4/4 - 0s - loss: 20.8052 - val_loss: 7.0350

Epoch 00042: val_loss did not improve from 6.87430
Epoch 43/10000
4/4 - 0s - loss: 20.8160 - val_loss: 7.0134

Epoch 00043: val_loss did not improve from 6.87430
Epoch 44/10000
4/4 - 0s - loss: 20.6585 - val_loss: 6.7545

Epoch 00044: val_loss improved from 6.87430 to 6.75450, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 45/10000
4/4 - 0s - loss: 20.6396 - val_loss: 6.7874

Epoch 00045: val_loss did not improve from 6.75450
Epoch 46/10000
4/4 - 0s - loss: 20.5605 - val_loss: 6.8693

Epoch 00046: val_loss did not improve from 6.75450
Epoch 47/10000
4/4 - 0s - loss: 20.5068 - val_loss: 6.7887

Epoch 00047: val_loss did not improve from 6.75450
Epoch 48/10000
4/4 - 0s - loss: 20.4730 - val_loss: 6.7952

Epoch 00048: val_loss did not improve from 6.75450
Epoch 49/10000
4/4 - 0s - loss: 20.3983 - val_loss: 6.7485

Epoch 00049: val_loss improved from 6.75450 to 6.74853, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 50/10000
4/4 - 0s - loss: 20.3758 - val_loss: 6.7892

Epoch 00050: val_loss did not improve from 6.74853
Epoch 51/10000
4/4 - 0s - loss: 20.3476 - val_loss: 6.8289

Epoch 00051: val_loss did not improve from 6.74853
Epoch 52/10000
4/4 - 0s - loss: 20.3047 - val_loss: 6.7316

Epoch 00052: val_loss improved from 6.74853 to 6.73158, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 53/10000
4/4 - 0s - loss: 20.2964 - val_loss: 6.7373

Epoch 00053: val_loss did not improve from 6.73158
Epoch 54/10000
4/4 - 0s - loss: 20.2690 - val_loss: 6.7728

Epoch 00054: val_loss did not improve from 6.73158
Epoch 55/10000
4/4 - 0s - loss: 20.2521 - val_loss: 6.7256

Epoch 00055: val_loss improved from 6.73158 to 6.72563, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 56/10000
4/4 - 0s - loss: 20.2156 - val_loss: 6.8421

Epoch 00056: val_loss did not improve from 6.72563
Epoch 57/10000
4/4 - 0s - loss: 20.2061 - val_loss: 6.8216

Epoch 00057: val_loss did not improve from 6.72563
Epoch 58/10000
4/4 - 0s - loss: 20.1920 - val_loss: 6.7568

Epoch 00058: val_loss did not improve from 6.72563
Epoch 59/10000
4/4 - 0s - loss: 20.1933 - val_loss: 6.7595

Epoch 00059: val_loss did not improve from 6.72563
Epoch 60/10000
4/4 - 0s - loss: 20.1699 - val_loss: 6.6701

Epoch 00060: val_loss improved from 6.72563 to 6.67011, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 61/10000
4/4 - 0s - loss: 20.1720 - val_loss: 6.7132

Epoch 00061: val_loss did not improve from 6.67011
Epoch 62/10000
4/4 - 0s - loss: 20.1464 - val_loss: 6.9112

Epoch 00062: val_loss did not improve from 6.67011
Epoch 63/10000
4/4 - 0s - loss: 20.1886 - val_loss: 6.9234

Epoch 00063: val_loss did not improve from 6.67011
Epoch 64/10000
4/4 - 0s - loss: 20.1573 - val_loss: 6.6905

Epoch 00064: val_loss did not improve from 6.67011
Epoch 65/10000
4/4 - 0s - loss: 20.1624 - val_loss: 6.6510

Epoch 00065: val_loss improved from 6.67011 to 6.65097, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 66/10000
4/4 - 0s - loss: 20.1450 - val_loss: 6.7460

Epoch 00066: val_loss did not improve from 6.65097
Epoch 67/10000
4/4 - 0s - loss: 20.1421 - val_loss: 6.8604

Epoch 00067: val_loss did not improve from 6.65097
Epoch 68/10000
4/4 - 0s - loss: 20.1531 - val_loss: 6.7021

Epoch 00068: val_loss did not improve from 6.65097
Epoch 69/10000
4/4 - 0s - loss: 20.1452 - val_loss: 6.6652

Epoch 00069: val_loss did not improve from 6.65097
Epoch 70/10000
4/4 - 0s - loss: 20.1294 - val_loss: 6.7319

Epoch 00070: val_loss did not improve from 6.65097
Epoch 71/10000
4/4 - 0s - loss: 20.1412 - val_loss: 6.7448

Epoch 00071: val_loss did not improve from 6.65097
Epoch 72/10000
4/4 - 0s - loss: 20.1446 - val_loss: 6.6430

Epoch 00072: val_loss improved from 6.65097 to 6.64297, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 73/10000
4/4 - 0s - loss: 20.1563 - val_loss: 6.5740

Epoch 00073: val_loss improved from 6.64297 to 6.57405, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 74/10000
4/4 - 0s - loss: 20.1404 - val_loss: 6.7477

Epoch 00074: val_loss did not improve from 6.57405
Epoch 75/10000
4/4 - 0s - loss: 20.1384 - val_loss: 6.7826

Epoch 00075: val_loss did not improve from 6.57405
Epoch 76/10000
4/4 - 0s - loss: 20.1350 - val_loss: 6.6102

Epoch 00076: val_loss did not improve from 6.57405
Epoch 77/10000
4/4 - 0s - loss: 20.1990 - val_loss: 6.6017

Epoch 00077: val_loss did not improve from 6.57405
Epoch 78/10000
4/4 - 0s - loss: 20.1647 - val_loss: 6.9849

Epoch 00078: val_loss did not improve from 6.57405
Epoch 79/10000
4/4 - 0s - loss: 20.1926 - val_loss: 6.7618

Epoch 00079: val_loss did not improve from 6.57405
Epoch 80/10000
4/4 - 0s - loss: 20.0956 - val_loss: 6.4993

Epoch 00080: val_loss improved from 6.57405 to 6.49927, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 81/10000
4/4 - 0s - loss: 20.2816 - val_loss: 6.4921

Epoch 00081: val_loss improved from 6.49927 to 6.49210, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 82/10000
4/4 - 0s - loss: 20.1262 - val_loss: 6.7677

Epoch 00082: val_loss did not improve from 6.49210
Epoch 83/10000
4/4 - 0s - loss: 20.1989 - val_loss: 7.2258

Epoch 00083: val_loss did not improve from 6.49210
Epoch 84/10000
4/4 - 0s - loss: 20.2074 - val_loss: 6.6125

Epoch 00084: val_loss did not improve from 6.49210
Epoch 85/10000
4/4 - 0s - loss: 20.1676 - val_loss: 6.5148

Epoch 00085: val_loss did not improve from 6.49210
Epoch 86/10000
4/4 - 0s - loss: 20.1542 - val_loss: 6.6827

Epoch 00086: val_loss did not improve from 6.49210
Epoch 87/10000
4/4 - 0s - loss: 20.1934 - val_loss: 6.9728

Epoch 00087: val_loss did not improve from 6.49210
Epoch 88/10000
4/4 - 0s - loss: 20.1703 - val_loss: 6.6694

Epoch 00088: val_loss did not improve from 6.49210
Epoch 89/10000
4/4 - 0s - loss: 20.1411 - val_loss: 6.5940

Epoch 00089: val_loss did not improve from 6.49210
Epoch 90/10000
4/4 - 0s - loss: 20.1117 - val_loss: 6.7330

Epoch 00090: val_loss did not improve from 6.49210
Epoch 91/10000
4/4 - 0s - loss: 20.1398 - val_loss: 6.8298

Epoch 00091: val_loss did not improve from 6.49210
Epoch 92/10000
4/4 - 0s - loss: 20.1189 - val_loss: 6.6675

Epoch 00092: val_loss did not improve from 6.49210
Epoch 93/10000
4/4 - 0s - loss: 20.1254 - val_loss: 6.5657

Epoch 00093: val_loss did not improve from 6.49210
Epoch 94/10000
4/4 - 0s - loss: 20.1272 - val_loss: 6.7048

Epoch 00094: val_loss did not improve from 6.49210
Epoch 95/10000
4/4 - 0s - loss: 20.1227 - val_loss: 6.7326

Epoch 00095: val_loss did not improve from 6.49210
Epoch 96/10000
4/4 - 0s - loss: 20.1395 - val_loss: 6.8582

Epoch 00096: val_loss did not improve from 6.49210
Epoch 97/10000
4/4 - 0s - loss: 20.1170 - val_loss: 6.6465

Epoch 00097: val_loss did not improve from 6.49210
Epoch 98/10000
4/4 - 0s - loss: 20.1194 - val_loss: 6.5957

Epoch 00098: val_loss did not improve from 6.49210
Epoch 99/10000
4/4 - 0s - loss: 20.1385 - val_loss: 6.7308

Epoch 00099: val_loss did not improve from 6.49210
Epoch 100/10000
4/4 - 0s - loss: 20.1283 - val_loss: 6.6270

Epoch 00100: val_loss did not improve from 6.49210
Epoch 101/10000
4/4 - 0s - loss: 20.1194 - val_loss: 6.7451

Epoch 00101: val_loss did not improve from 6.49210
Epoch 102/10000
4/4 - 0s - loss: 20.1108 - val_loss: 6.6285

Epoch 00102: val_loss did not improve from 6.49210
Epoch 103/10000
4/4 - 0s - loss: 20.1079 - val_loss: 6.5981

Epoch 00103: val_loss did not improve from 6.49210
Epoch 104/10000
4/4 - 0s - loss: 20.1336 - val_loss: 6.6221

Epoch 00104: val_loss did not improve from 6.49210
Epoch 105/10000
4/4 - 0s - loss: 20.0948 - val_loss: 6.8682

Epoch 00105: val_loss did not improve from 6.49210
Epoch 106/10000
4/4 - 0s - loss: 20.1350 - val_loss: 6.7808

Epoch 00106: val_loss did not improve from 6.49210
Epoch 107/10000
4/4 - 0s - loss: 20.1183 - val_loss: 6.6464

Epoch 00107: val_loss did not improve from 6.49210
Epoch 108/10000
4/4 - 0s - loss: 20.1126 - val_loss: 6.6876

Epoch 00108: val_loss did not improve from 6.49210
Epoch 109/10000
4/4 - 0s - loss: 20.1155 - val_loss: 6.7036

Epoch 00109: val_loss did not improve from 6.49210
Epoch 110/10000
4/4 - 0s - loss: 20.1212 - val_loss: 6.8130

Epoch 00110: val_loss did not improve from 6.49210
Epoch 111/10000
4/4 - 0s - loss: 20.1099 - val_loss: 6.6256

Epoch 00111: val_loss did not improve from 6.49210
Epoch 112/10000
4/4 - 0s - loss: 20.1033 - val_loss: 6.5645

Epoch 00112: val_loss did not improve from 6.49210
Epoch 113/10000
4/4 - 0s - loss: 20.1673 - val_loss: 6.5290

Epoch 00113: val_loss did not improve from 6.49210
Epoch 114/10000
4/4 - 0s - loss: 20.1891 - val_loss: 6.9304

Epoch 00114: val_loss did not improve from 6.49210
Epoch 115/10000
4/4 - 0s - loss: 20.1603 - val_loss: 6.6740

Epoch 00115: val_loss did not improve from 6.49210
Epoch 116/10000
4/4 - 0s - loss: 20.1062 - val_loss: 6.6775

Epoch 00116: val_loss did not improve from 6.49210
Epoch 117/10000
4/4 - 0s - loss: 20.1032 - val_loss: 6.6500

Epoch 00117: val_loss did not improve from 6.49210
Epoch 118/10000
4/4 - 0s - loss: 20.1062 - val_loss: 6.7033

Epoch 00118: val_loss did not improve from 6.49210
Epoch 119/10000
4/4 - 0s - loss: 20.1229 - val_loss: 6.7424

Epoch 00119: val_loss did not improve from 6.49210
Epoch 120/10000
4/4 - 0s - loss: 20.1169 - val_loss: 6.6123

Epoch 00120: val_loss did not improve from 6.49210
Epoch 121/10000
4/4 - 0s - loss: 20.1109 - val_loss: 6.6680

Epoch 00121: val_loss did not improve from 6.49210
Epoch 122/10000
4/4 - 0s - loss: 20.1012 - val_loss: 6.6952

Epoch 00122: val_loss did not improve from 6.49210
Epoch 123/10000
4/4 - 0s - loss: 20.1071 - val_loss: 6.6814

Epoch 00123: val_loss did not improve from 6.49210
Epoch 124/10000
4/4 - 0s - loss: 20.1093 - val_loss: 6.5874

Epoch 00124: val_loss did not improve from 6.49210
Epoch 125/10000
4/4 - 0s - loss: 20.1141 - val_loss: 6.6062

Epoch 00125: val_loss did not improve from 6.49210
Epoch 126/10000
4/4 - 0s - loss: 20.1074 - val_loss: 6.6008

Epoch 00126: val_loss did not improve from 6.49210
Epoch 127/10000
4/4 - 0s - loss: 20.1101 - val_loss: 6.6492

Epoch 00127: val_loss did not improve from 6.49210
Epoch 128/10000
4/4 - 0s - loss: 20.1036 - val_loss: 6.6149

Epoch 00128: val_loss did not improve from 6.49210
Epoch 129/10000
4/4 - 0s - loss: 20.1058 - val_loss: 6.6947

Epoch 00129: val_loss did not improve from 6.49210
Epoch 130/10000
4/4 - 0s - loss: 20.1293 - val_loss: 6.5931

Epoch 00130: val_loss did not improve from 6.49210
Epoch 131/10000
4/4 - 0s - loss: 20.1052 - val_loss: 6.7230

Epoch 00131: val_loss did not improve from 6.49210
Epoch 132/10000
4/4 - 0s - loss: 20.1059 - val_loss: 6.6945

Epoch 00132: val_loss did not improve from 6.49210
Epoch 133/10000
4/4 - 0s - loss: 20.1087 - val_loss: 6.6901

Epoch 00133: val_loss did not improve from 6.49210
Epoch 134/10000
4/4 - 0s - loss: 20.0889 - val_loss: 6.5692

Epoch 00134: val_loss did not improve from 6.49210
Epoch 135/10000
4/4 - 0s - loss: 20.1359 - val_loss: 6.5490

Epoch 00135: val_loss did not improve from 6.49210
Epoch 136/10000
4/4 - 0s - loss: 20.1157 - val_loss: 6.8319

Epoch 00136: val_loss did not improve from 6.49210
Epoch 137/10000
4/4 - 0s - loss: 20.1254 - val_loss: 6.7652

Epoch 00137: val_loss did not improve from 6.49210
Epoch 138/10000
4/4 - 0s - loss: 20.1244 - val_loss: 6.6600

Epoch 00138: val_loss did not improve from 6.49210
Epoch 139/10000
4/4 - 0s - loss: 20.1007 - val_loss: 6.7229

Epoch 00139: val_loss did not improve from 6.49210
Epoch 140/10000
4/4 - 0s - loss: 20.1235 - val_loss: 6.6865

Epoch 00140: val_loss did not improve from 6.49210
Epoch 141/10000
4/4 - 0s - loss: 20.1389 - val_loss: 6.8761

Epoch 00141: val_loss did not improve from 6.49210
Epoch 142/10000
4/4 - 0s - loss: 20.1004 - val_loss: 6.5912

Epoch 00142: val_loss did not improve from 6.49210
Epoch 143/10000
4/4 - 0s - loss: 20.1292 - val_loss: 6.5022

Epoch 00143: val_loss did not improve from 6.49210
Epoch 144/10000
4/4 - 0s - loss: 20.1327 - val_loss: 6.5663

Epoch 00144: val_loss did not improve from 6.49210
Epoch 145/10000
4/4 - 0s - loss: 20.1037 - val_loss: 6.7160

Epoch 00145: val_loss did not improve from 6.49210
Epoch 146/10000
4/4 - 0s - loss: 20.1116 - val_loss: 6.8393

Epoch 00146: val_loss did not improve from 6.49210
Epoch 147/10000
4/4 - 0s - loss: 20.1416 - val_loss: 6.6469

Epoch 00147: val_loss did not improve from 6.49210
Epoch 148/10000
4/4 - 0s - loss: 20.0982 - val_loss: 6.6424

Epoch 00148: val_loss did not improve from 6.49210
Epoch 149/10000
4/4 - 0s - loss: 20.1190 - val_loss: 6.7448

Epoch 00149: val_loss did not improve from 6.49210
Epoch 150/10000
4/4 - 0s - loss: 20.1266 - val_loss: 6.5857

Epoch 00150: val_loss did not improve from 6.49210
Epoch 151/10000
4/4 - 0s - loss: 20.1043 - val_loss: 6.6291

Epoch 00151: val_loss did not improve from 6.49210
Epoch 152/10000
4/4 - 0s - loss: 20.0981 - val_loss: 6.6568

Epoch 00152: val_loss did not improve from 6.49210
Epoch 153/10000
4/4 - 0s - loss: 20.1342 - val_loss: 6.8002

Epoch 00153: val_loss did not improve from 6.49210
Epoch 154/10000
4/4 - 0s - loss: 20.1142 - val_loss: 6.5757

Epoch 00154: val_loss did not improve from 6.49210
Epoch 155/10000
4/4 - 0s - loss: 20.1246 - val_loss: 6.5251

Epoch 00155: val_loss did not improve from 6.49210
Epoch 156/10000
4/4 - 0s - loss: 20.1154 - val_loss: 6.6679

Epoch 00156: val_loss did not improve from 6.49210
Epoch 157/10000
4/4 - 0s - loss: 20.1021 - val_loss: 6.6790

Epoch 00157: val_loss did not improve from 6.49210
Epoch 158/10000
4/4 - 0s - loss: 20.1037 - val_loss: 6.7551

Epoch 00158: val_loss did not improve from 6.49210
Epoch 159/10000
4/4 - 0s - loss: 20.1261 - val_loss: 6.6084

Epoch 00159: val_loss did not improve from 6.49210
Epoch 160/10000
4/4 - 0s - loss: 20.0965 - val_loss: 6.6690

Epoch 00160: val_loss did not improve from 6.49210
Epoch 161/10000
4/4 - 0s - loss: 20.0978 - val_loss: 6.7587

Epoch 00161: val_loss did not improve from 6.49210
Epoch 162/10000
4/4 - 0s - loss: 20.1208 - val_loss: 6.7060

Epoch 00162: val_loss did not improve from 6.49210
Epoch 163/10000
4/4 - 0s - loss: 20.0926 - val_loss: 6.5420

Epoch 00163: val_loss did not improve from 6.49210
Epoch 164/10000
4/4 - 0s - loss: 20.1233 - val_loss: 6.5108

Epoch 00164: val_loss did not improve from 6.49210
Epoch 165/10000
4/4 - 0s - loss: 20.1261 - val_loss: 6.5544

Epoch 00165: val_loss did not improve from 6.49210
Epoch 166/10000
4/4 - 0s - loss: 20.0994 - val_loss: 6.7638

Epoch 00166: val_loss did not improve from 6.49210
Epoch 167/10000
4/4 - 0s - loss: 20.1082 - val_loss: 6.7070

Epoch 00167: val_loss did not improve from 6.49210
Epoch 168/10000
4/4 - 0s - loss: 20.1012 - val_loss: 6.6045

Epoch 00168: val_loss did not improve from 6.49210
Epoch 169/10000
4/4 - 0s - loss: 20.1505 - val_loss: 6.5535

Epoch 00169: val_loss did not improve from 6.49210
Epoch 170/10000
4/4 - 0s - loss: 20.1330 - val_loss: 6.8621

Epoch 00170: val_loss did not improve from 6.49210
Epoch 171/10000
4/4 - 0s - loss: 20.1095 - val_loss: 6.6655

Epoch 00171: val_loss did not improve from 6.49210
Epoch 172/10000
4/4 - 0s - loss: 20.0820 - val_loss: 6.5581

Epoch 00172: val_loss did not improve from 6.49210
Epoch 173/10000
4/4 - 0s - loss: 20.1294 - val_loss: 6.5253

Epoch 00173: val_loss did not improve from 6.49210
Epoch 174/10000
4/4 - 0s - loss: 20.1317 - val_loss: 6.7555

Epoch 00174: val_loss did not improve from 6.49210
Epoch 175/10000
4/4 - 0s - loss: 20.0987 - val_loss: 6.6636

Epoch 00175: val_loss did not improve from 6.49210
Epoch 176/10000
4/4 - 0s - loss: 20.0892 - val_loss: 6.5430

Epoch 00176: val_loss did not improve from 6.49210
Epoch 177/10000
4/4 - 0s - loss: 20.1062 - val_loss: 6.5583

Epoch 00177: val_loss did not improve from 6.49210
Epoch 178/10000
4/4 - 0s - loss: 20.1288 - val_loss: 6.6387

Epoch 00178: val_loss did not improve from 6.49210
Epoch 179/10000
4/4 - 0s - loss: 20.0934 - val_loss: 6.5880

Epoch 00179: val_loss did not improve from 6.49210
Epoch 180/10000
4/4 - 0s - loss: 20.0941 - val_loss: 6.5828

Epoch 00180: val_loss did not improve from 6.49210
Epoch 181/10000
4/4 - 0s - loss: 20.1108 - val_loss: 6.5817

Epoch 00181: val_loss did not improve from 6.49210
Epoch 182/10000
4/4 - 0s - loss: 20.0935 - val_loss: 6.6168

Epoch 00182: val_loss did not improve from 6.49210
Epoch 183/10000
4/4 - 0s - loss: 20.1387 - val_loss: 6.6317

Epoch 00183: val_loss did not improve from 6.49210
Epoch 184/10000
4/4 - 0s - loss: 20.1820 - val_loss: 6.4474

Epoch 00184: val_loss improved from 6.49210 to 6.44741, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 185/10000
4/4 - 0s - loss: 20.1443 - val_loss: 6.6044

Epoch 00185: val_loss did not improve from 6.44741
Epoch 186/10000
4/4 - 0s - loss: 20.0876 - val_loss: 6.7067

Epoch 00186: val_loss did not improve from 6.44741
Epoch 187/10000
4/4 - 0s - loss: 20.1075 - val_loss: 6.6588

Epoch 00187: val_loss did not improve from 6.44741
Epoch 188/10000
4/4 - 0s - loss: 20.0904 - val_loss: 6.7210

Epoch 00188: val_loss did not improve from 6.44741
Epoch 189/10000
4/4 - 0s - loss: 20.0900 - val_loss: 6.6438

Epoch 00189: val_loss did not improve from 6.44741
Epoch 190/10000
4/4 - 0s - loss: 20.1026 - val_loss: 6.5744

Epoch 00190: val_loss did not improve from 6.44741
Epoch 191/10000
4/4 - 0s - loss: 20.1025 - val_loss: 6.6695

Epoch 00191: val_loss did not improve from 6.44741
Epoch 192/10000
4/4 - 0s - loss: 20.0957 - val_loss: 6.6435

Epoch 00192: val_loss did not improve from 6.44741
Epoch 193/10000
4/4 - 0s - loss: 20.0905 - val_loss: 6.5654

Epoch 00193: val_loss did not improve from 6.44741
Epoch 194/10000
4/4 - 0s - loss: 20.0980 - val_loss: 6.5813

Epoch 00194: val_loss did not improve from 6.44741
Epoch 195/10000
4/4 - 0s - loss: 20.1080 - val_loss: 6.5628

Epoch 00195: val_loss did not improve from 6.44741
Epoch 196/10000
4/4 - 0s - loss: 20.1134 - val_loss: 6.7440

Epoch 00196: val_loss did not improve from 6.44741
Epoch 197/10000
4/4 - 0s - loss: 20.0989 - val_loss: 6.5701

Epoch 00197: val_loss did not improve from 6.44741
Epoch 198/10000
4/4 - 0s - loss: 20.0999 - val_loss: 6.5287

Epoch 00198: val_loss did not improve from 6.44741
Epoch 199/10000
4/4 - 0s - loss: 20.1042 - val_loss: 6.5866

Epoch 00199: val_loss did not improve from 6.44741
Epoch 200/10000
4/4 - 0s - loss: 20.0828 - val_loss: 6.7299

Epoch 00200: val_loss did not improve from 6.44741
Epoch 201/10000
4/4 - 0s - loss: 20.1172 - val_loss: 6.7047

Epoch 00201: val_loss did not improve from 6.44741
Epoch 202/10000
4/4 - 0s - loss: 20.0828 - val_loss: 6.5161

Epoch 00202: val_loss did not improve from 6.44741
Epoch 203/10000
4/4 - 0s - loss: 20.1297 - val_loss: 6.5351

Epoch 00203: val_loss did not improve from 6.44741
Epoch 204/10000
4/4 - 0s - loss: 20.1196 - val_loss: 6.8238

Epoch 00204: val_loss did not improve from 6.44741
Epoch 205/10000
4/4 - 0s - loss: 20.1048 - val_loss: 6.6705

Epoch 00205: val_loss did not improve from 6.44741
Epoch 206/10000
4/4 - 0s - loss: 20.0861 - val_loss: 6.6012

Epoch 00206: val_loss did not improve from 6.44741
Epoch 207/10000
4/4 - 0s - loss: 20.1064 - val_loss: 6.5757

Epoch 00207: val_loss did not improve from 6.44741
Epoch 208/10000
4/4 - 0s - loss: 20.0807 - val_loss: 6.6772

Epoch 00208: val_loss did not improve from 6.44741
Epoch 209/10000
4/4 - 0s - loss: 20.0912 - val_loss: 6.7532

Epoch 00209: val_loss did not improve from 6.44741
Epoch 210/10000
4/4 - 0s - loss: 20.1151 - val_loss: 6.6176

Epoch 00210: val_loss did not improve from 6.44741
Epoch 211/10000
4/4 - 0s - loss: 20.0895 - val_loss: 6.6784

Epoch 00211: val_loss did not improve from 6.44741
Epoch 212/10000
4/4 - 0s - loss: 20.1015 - val_loss: 6.6747

Epoch 00212: val_loss did not improve from 6.44741
Epoch 213/10000
4/4 - 0s - loss: 20.0785 - val_loss: 6.7798

Epoch 00213: val_loss did not improve from 6.44741
Epoch 214/10000
4/4 - 0s - loss: 20.1029 - val_loss: 6.7288

Epoch 00214: val_loss did not improve from 6.44741
Epoch 215/10000
4/4 - 0s - loss: 20.0844 - val_loss: 6.5557

Epoch 00215: val_loss did not improve from 6.44741
Epoch 216/10000
4/4 - 0s - loss: 20.1423 - val_loss: 6.5333

Epoch 00216: val_loss did not improve from 6.44741
Epoch 217/10000
4/4 - 0s - loss: 20.1080 - val_loss: 6.9191

Epoch 00217: val_loss did not improve from 6.44741
Epoch 218/10000
4/4 - 0s - loss: 20.1395 - val_loss: 6.7170

Epoch 00218: val_loss did not improve from 6.44741
Epoch 219/10000
4/4 - 0s - loss: 20.1002 - val_loss: 6.5828

Epoch 00219: val_loss did not improve from 6.44741
Epoch 220/10000
4/4 - 0s - loss: 20.0967 - val_loss: 6.6527

Epoch 00220: val_loss did not improve from 6.44741
Epoch 221/10000
4/4 - 0s - loss: 20.0850 - val_loss: 6.6920

Epoch 00221: val_loss did not improve from 6.44741
Epoch 222/10000
4/4 - 0s - loss: 20.0856 - val_loss: 6.6348

Epoch 00222: val_loss did not improve from 6.44741
Epoch 223/10000
4/4 - 0s - loss: 20.0784 - val_loss: 6.5661

Epoch 00223: val_loss did not improve from 6.44741
Epoch 224/10000
4/4 - 0s - loss: 20.1054 - val_loss: 6.5513

Epoch 00224: val_loss did not improve from 6.44741
Epoch 225/10000
4/4 - 0s - loss: 20.0644 - val_loss: 6.7638

Epoch 00225: val_loss did not improve from 6.44741
Epoch 226/10000
4/4 - 0s - loss: 20.1121 - val_loss: 6.8894

Epoch 00226: val_loss did not improve from 6.44741
Epoch 227/10000
4/4 - 0s - loss: 20.1192 - val_loss: 6.6931

Epoch 00227: val_loss did not improve from 6.44741
Epoch 228/10000
4/4 - 0s - loss: 20.0885 - val_loss: 6.4957

Epoch 00228: val_loss did not improve from 6.44741
Epoch 229/10000
4/4 - 0s - loss: 20.1218 - val_loss: 6.5641

Epoch 00229: val_loss did not improve from 6.44741
Epoch 230/10000
4/4 - 0s - loss: 20.1783 - val_loss: 6.8732

Epoch 00230: val_loss did not improve from 6.44741
Epoch 231/10000
4/4 - 0s - loss: 20.1173 - val_loss: 6.5595

Epoch 00231: val_loss did not improve from 6.44741
Epoch 232/10000
4/4 - 0s - loss: 20.0883 - val_loss: 6.5392

Epoch 00232: val_loss did not improve from 6.44741
Epoch 233/10000
4/4 - 0s - loss: 20.0885 - val_loss: 6.5766

Epoch 00233: val_loss did not improve from 6.44741
Epoch 234/10000
4/4 - 0s - loss: 20.0840 - val_loss: 6.6209

Epoch 00234: val_loss did not improve from 6.44741
Epoch 235/10000
4/4 - 0s - loss: 20.1054 - val_loss: 6.6788

Epoch 00235: val_loss did not improve from 6.44741
Epoch 236/10000
4/4 - 0s - loss: 20.0938 - val_loss: 6.4869

Epoch 00236: val_loss did not improve from 6.44741
Epoch 237/10000
4/4 - 0s - loss: 20.1077 - val_loss: 6.4923

Epoch 00237: val_loss did not improve from 6.44741
Epoch 238/10000
4/4 - 0s - loss: 20.0864 - val_loss: 6.6417

Epoch 00238: val_loss did not improve from 6.44741
Epoch 239/10000
4/4 - 0s - loss: 20.0972 - val_loss: 6.7830

Epoch 00239: val_loss did not improve from 6.44741
Epoch 240/10000
4/4 - 0s - loss: 20.0909 - val_loss: 6.5639

Epoch 00240: val_loss did not improve from 6.44741
Epoch 241/10000
4/4 - 0s - loss: 20.0895 - val_loss: 6.4988

Epoch 00241: val_loss did not improve from 6.44741
Epoch 242/10000
4/4 - 0s - loss: 20.1094 - val_loss: 6.6417

Epoch 00242: val_loss did not improve from 6.44741
Epoch 243/10000
4/4 - 0s - loss: 20.0803 - val_loss: 6.6559

Epoch 00243: val_loss did not improve from 6.44741
Epoch 244/10000
4/4 - 0s - loss: 20.0862 - val_loss: 6.6633

Epoch 00244: val_loss did not improve from 6.44741
Epoch 245/10000
4/4 - 0s - loss: 20.0927 - val_loss: 6.6286

Epoch 00245: val_loss did not improve from 6.44741
Epoch 246/10000
4/4 - 0s - loss: 20.1014 - val_loss: 6.6495

Epoch 00246: val_loss did not improve from 6.44741
Epoch 247/10000
4/4 - 0s - loss: 20.0767 - val_loss: 6.5465

Epoch 00247: val_loss did not improve from 6.44741
Epoch 248/10000
4/4 - 0s - loss: 20.1057 - val_loss: 6.5930

Epoch 00248: val_loss did not improve from 6.44741
Epoch 249/10000
4/4 - 0s - loss: 20.0854 - val_loss: 6.5509

Epoch 00249: val_loss did not improve from 6.44741
Epoch 250/10000
4/4 - 0s - loss: 20.0867 - val_loss: 6.6440

Epoch 00250: val_loss did not improve from 6.44741
Epoch 251/10000
4/4 - 0s - loss: 20.0873 - val_loss: 6.5865

Epoch 00251: val_loss did not improve from 6.44741
Epoch 252/10000
4/4 - 0s - loss: 20.0838 - val_loss: 6.6080

Epoch 00252: val_loss did not improve from 6.44741
Epoch 253/10000
4/4 - 0s - loss: 20.0818 - val_loss: 6.5440

Epoch 00253: val_loss did not improve from 6.44741
Epoch 254/10000
4/4 - 0s - loss: 20.0860 - val_loss: 6.5557

Epoch 00254: val_loss did not improve from 6.44741
Epoch 255/10000
4/4 - 0s - loss: 20.1086 - val_loss: 6.5319

Epoch 00255: val_loss did not improve from 6.44741
Epoch 256/10000
4/4 - 0s - loss: 20.1163 - val_loss: 6.7875

Epoch 00256: val_loss did not improve from 6.44741
Epoch 257/10000
4/4 - 0s - loss: 20.1009 - val_loss: 6.6049

Epoch 00257: val_loss did not improve from 6.44741
Epoch 258/10000
4/4 - 0s - loss: 20.0773 - val_loss: 6.5641

Epoch 00258: val_loss did not improve from 6.44741
Epoch 259/10000
4/4 - 0s - loss: 20.0906 - val_loss: 6.5867

Epoch 00259: val_loss did not improve from 6.44741
Epoch 260/10000
4/4 - 0s - loss: 20.1180 - val_loss: 6.5219

Epoch 00260: val_loss did not improve from 6.44741
Epoch 261/10000
4/4 - 0s - loss: 20.0620 - val_loss: 6.7252

Epoch 00261: val_loss did not improve from 6.44741
Epoch 262/10000
4/4 - 0s - loss: 20.1275 - val_loss: 6.8723

Epoch 00262: val_loss did not improve from 6.44741
Epoch 263/10000
4/4 - 0s - loss: 20.1197 - val_loss: 6.5631

Epoch 00263: val_loss did not improve from 6.44741
Epoch 264/10000
4/4 - 0s - loss: 20.0808 - val_loss: 6.5415

Epoch 00264: val_loss did not improve from 6.44741
Epoch 265/10000
4/4 - 0s - loss: 20.0814 - val_loss: 6.6310

Epoch 00265: val_loss did not improve from 6.44741
Epoch 266/10000
4/4 - 0s - loss: 20.0800 - val_loss: 6.7465

Epoch 00266: val_loss did not improve from 6.44741
Epoch 267/10000
4/4 - 0s - loss: 20.0920 - val_loss: 6.6835

Epoch 00267: val_loss did not improve from 6.44741
Epoch 268/10000
4/4 - 0s - loss: 20.0724 - val_loss: 6.5463

Epoch 00268: val_loss did not improve from 6.44741
Epoch 269/10000
4/4 - 0s - loss: 20.0993 - val_loss: 6.5517

Epoch 00269: val_loss did not improve from 6.44741
Epoch 270/10000
4/4 - 0s - loss: 20.1112 - val_loss: 6.8147

Epoch 00270: val_loss did not improve from 6.44741
Epoch 271/10000
4/4 - 0s - loss: 20.1029 - val_loss: 6.6334

Epoch 00271: val_loss did not improve from 6.44741
Epoch 272/10000
4/4 - 0s - loss: 20.0714 - val_loss: 6.5292

Epoch 00272: val_loss did not improve from 6.44741
Epoch 273/10000
4/4 - 0s - loss: 20.1018 - val_loss: 6.5732

Epoch 00273: val_loss did not improve from 6.44741
Epoch 274/10000
4/4 - 0s - loss: 20.0944 - val_loss: 6.6402

Epoch 00274: val_loss did not improve from 6.44741
Epoch 275/10000
4/4 - 0s - loss: 20.0812 - val_loss: 6.6030

Epoch 00275: val_loss did not improve from 6.44741
Epoch 276/10000
4/4 - 0s - loss: 20.0893 - val_loss: 6.5770

Epoch 00276: val_loss did not improve from 6.44741
Epoch 277/10000
4/4 - 0s - loss: 20.0812 - val_loss: 6.6866

Epoch 00277: val_loss did not improve from 6.44741
Epoch 278/10000
4/4 - 0s - loss: 20.0766 - val_loss: 6.6106

Epoch 00278: val_loss did not improve from 6.44741
Epoch 279/10000
4/4 - 0s - loss: 20.0837 - val_loss: 6.5678

Epoch 00279: val_loss did not improve from 6.44741
Epoch 280/10000
4/4 - 0s - loss: 20.0745 - val_loss: 6.6210

Epoch 00280: val_loss did not improve from 6.44741
Epoch 281/10000
4/4 - 0s - loss: 20.0728 - val_loss: 6.6923

Epoch 00281: val_loss did not improve from 6.44741
Epoch 282/10000
4/4 - 0s - loss: 20.0838 - val_loss: 6.6961

Epoch 00282: val_loss did not improve from 6.44741
Epoch 283/10000
4/4 - 0s - loss: 20.0920 - val_loss: 6.6122

Epoch 00283: val_loss did not improve from 6.44741
Epoch 284/10000
4/4 - 0s - loss: 20.0788 - val_loss: 6.6178

Epoch 00284: val_loss did not improve from 6.44741
Epoch 285/10000
4/4 - 0s - loss: 20.1002 - val_loss: 6.5649

Epoch 00285: val_loss did not improve from 6.44741
Epoch 286/10000
4/4 - 0s - loss: 20.0810 - val_loss: 6.6443

Epoch 00286: val_loss did not improve from 6.44741
Epoch 287/10000
4/4 - 0s - loss: 20.0739 - val_loss: 6.5972

Epoch 00287: val_loss did not improve from 6.44741
Epoch 288/10000
4/4 - 0s - loss: 20.0774 - val_loss: 6.5362

Epoch 00288: val_loss did not improve from 6.44741
Epoch 289/10000
4/4 - 0s - loss: 20.0779 - val_loss: 6.6063

Epoch 00289: val_loss did not improve from 6.44741
Epoch 290/10000
4/4 - 0s - loss: 20.0751 - val_loss: 6.6265

Epoch 00290: val_loss did not improve from 6.44741
Epoch 291/10000
4/4 - 0s - loss: 20.0818 - val_loss: 6.6585

Epoch 00291: val_loss did not improve from 6.44741
Epoch 292/10000
4/4 - 0s - loss: 20.0913 - val_loss: 6.6407

Epoch 00292: val_loss did not improve from 6.44741
Epoch 293/10000
4/4 - 0s - loss: 20.0978 - val_loss: 6.7538

Epoch 00293: val_loss did not improve from 6.44741
Epoch 294/10000
4/4 - 0s - loss: 20.0744 - val_loss: 6.5877

Epoch 00294: val_loss did not improve from 6.44741
Epoch 295/10000
4/4 - 0s - loss: 20.1163 - val_loss: 6.4807

Epoch 00295: val_loss did not improve from 6.44741
Epoch 296/10000
4/4 - 0s - loss: 20.1092 - val_loss: 6.6754

Epoch 00296: val_loss did not improve from 6.44741
Epoch 297/10000
4/4 - 0s - loss: 20.0817 - val_loss: 6.6728

Epoch 00297: val_loss did not improve from 6.44741
Epoch 298/10000
4/4 - 0s - loss: 20.0706 - val_loss: 6.5665

Epoch 00298: val_loss did not improve from 6.44741
Epoch 299/10000
4/4 - 0s - loss: 20.0778 - val_loss: 6.4907

Epoch 00299: val_loss did not improve from 6.44741
Epoch 300/10000
4/4 - 0s - loss: 20.0895 - val_loss: 6.5557

Epoch 00300: val_loss did not improve from 6.44741
Epoch 301/10000
4/4 - 0s - loss: 20.0890 - val_loss: 6.7383

Epoch 00301: val_loss did not improve from 6.44741
Epoch 302/10000
4/4 - 0s - loss: 20.0913 - val_loss: 6.6801

Epoch 00302: val_loss did not improve from 6.44741
Epoch 303/10000
4/4 - 0s - loss: 20.0715 - val_loss: 6.5369

Epoch 00303: val_loss did not improve from 6.44741
Epoch 304/10000
4/4 - 0s - loss: 20.0826 - val_loss: 6.5066

Epoch 00304: val_loss did not improve from 6.44741
Epoch 305/10000
4/4 - 0s - loss: 20.0947 - val_loss: 6.6546

Epoch 00305: val_loss did not improve from 6.44741
Epoch 306/10000
4/4 - 0s - loss: 20.0760 - val_loss: 6.6105

Epoch 00306: val_loss did not improve from 6.44741
Epoch 307/10000
4/4 - 0s - loss: 20.0774 - val_loss: 6.5937

Epoch 00307: val_loss did not improve from 6.44741
Epoch 308/10000
4/4 - 0s - loss: 20.1492 - val_loss: 6.4743

Epoch 00308: val_loss did not improve from 6.44741
Epoch 309/10000
4/4 - 0s - loss: 20.0695 - val_loss: 6.7344

Epoch 00309: val_loss did not improve from 6.44741
Epoch 310/10000
4/4 - 0s - loss: 20.0950 - val_loss: 6.7444

Epoch 00310: val_loss did not improve from 6.44741
Epoch 311/10000
4/4 - 0s - loss: 20.0970 - val_loss: 6.6550

Epoch 00311: val_loss did not improve from 6.44741
Epoch 312/10000
4/4 - 0s - loss: 20.0751 - val_loss: 6.6322

Epoch 00312: val_loss did not improve from 6.44741
Epoch 313/10000
4/4 - 0s - loss: 20.0939 - val_loss: 6.6311

Epoch 00313: val_loss did not improve from 6.44741
Epoch 314/10000
4/4 - 0s - loss: 20.0861 - val_loss: 6.7141

Epoch 00314: val_loss did not improve from 6.44741
Epoch 315/10000
4/4 - 0s - loss: 20.0871 - val_loss: 6.5657

Epoch 00315: val_loss did not improve from 6.44741
Epoch 316/10000
4/4 - 0s - loss: 20.0924 - val_loss: 6.5132

Epoch 00316: val_loss did not improve from 6.44741
Epoch 317/10000
4/4 - 0s - loss: 20.0971 - val_loss: 6.6215

Epoch 00317: val_loss did not improve from 6.44741
Epoch 318/10000
4/4 - 0s - loss: 20.0733 - val_loss: 6.5894

Epoch 00318: val_loss did not improve from 6.44741
Epoch 319/10000
4/4 - 0s - loss: 20.0762 - val_loss: 6.6060

Epoch 00319: val_loss did not improve from 6.44741
Epoch 320/10000
4/4 - 0s - loss: 20.0689 - val_loss: 6.6585

Epoch 00320: val_loss did not improve from 6.44741
Epoch 321/10000
4/4 - 0s - loss: 20.0803 - val_loss: 6.6624

Epoch 00321: val_loss did not improve from 6.44741
Epoch 322/10000
4/4 - 0s - loss: 20.0729 - val_loss: 6.5399

Epoch 00322: val_loss did not improve from 6.44741
Epoch 323/10000
4/4 - 0s - loss: 20.0858 - val_loss: 6.5461

Epoch 00323: val_loss did not improve from 6.44741
Epoch 324/10000
4/4 - 0s - loss: 20.0686 - val_loss: 6.7110

Epoch 00324: val_loss did not improve from 6.44741
Epoch 325/10000
4/4 - 0s - loss: 20.0818 - val_loss: 6.6592

Epoch 00325: val_loss did not improve from 6.44741
Epoch 326/10000
4/4 - 0s - loss: 20.0714 - val_loss: 6.5947

Epoch 00326: val_loss did not improve from 6.44741
Epoch 327/10000
4/4 - 0s - loss: 20.0712 - val_loss: 6.5531

Epoch 00327: val_loss did not improve from 6.44741
Epoch 328/10000
4/4 - 0s - loss: 20.0824 - val_loss: 6.5864

Epoch 00328: val_loss did not improve from 6.44741
Epoch 329/10000
4/4 - 0s - loss: 20.1042 - val_loss: 6.7254

Epoch 00329: val_loss did not improve from 6.44741
Epoch 330/10000
4/4 - 0s - loss: 20.0831 - val_loss: 6.5360

Epoch 00330: val_loss did not improve from 6.44741
Epoch 331/10000
4/4 - 0s - loss: 20.0814 - val_loss: 6.5471

Epoch 00331: val_loss did not improve from 6.44741
Epoch 332/10000
4/4 - 0s - loss: 20.0752 - val_loss: 6.6928

Epoch 00332: val_loss did not improve from 6.44741
Epoch 333/10000
4/4 - 0s - loss: 20.0981 - val_loss: 6.6263

Epoch 00333: val_loss did not improve from 6.44741
Epoch 334/10000
4/4 - 0s - loss: 20.0627 - val_loss: 6.5108

Epoch 00334: val_loss did not improve from 6.44741
Epoch 335/10000
4/4 - 0s - loss: 20.0861 - val_loss: 6.4873

Epoch 00335: val_loss did not improve from 6.44741
Epoch 336/10000
4/4 - 0s - loss: 20.0827 - val_loss: 6.5772

Epoch 00336: val_loss did not improve from 6.44741
Epoch 337/10000
4/4 - 0s - loss: 20.0689 - val_loss: 6.6652

Epoch 00337: val_loss did not improve from 6.44741
Epoch 338/10000
4/4 - 0s - loss: 20.0958 - val_loss: 6.6652

Epoch 00338: val_loss did not improve from 6.44741
Epoch 339/10000
4/4 - 0s - loss: 20.0688 - val_loss: 6.4778

Epoch 00339: val_loss did not improve from 6.44741
Epoch 340/10000
4/4 - 0s - loss: 20.1343 - val_loss: 6.4498

Epoch 00340: val_loss did not improve from 6.44741
Epoch 341/10000
4/4 - 0s - loss: 20.0607 - val_loss: 6.7172

Epoch 00341: val_loss did not improve from 6.44741
Epoch 342/10000
4/4 - 0s - loss: 20.0965 - val_loss: 6.8331

Epoch 00342: val_loss did not improve from 6.44741
Epoch 343/10000
4/4 - 0s - loss: 20.1001 - val_loss: 6.6202

Epoch 00343: val_loss did not improve from 6.44741
Epoch 344/10000
4/4 - 0s - loss: 20.0936 - val_loss: 6.4239

Epoch 00344: val_loss improved from 6.44741 to 6.42386, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 345/10000
4/4 - 0s - loss: 20.1322 - val_loss: 6.5203

Epoch 00345: val_loss did not improve from 6.42386
Epoch 346/10000
4/4 - 0s - loss: 20.1375 - val_loss: 6.9155

Epoch 00346: val_loss did not improve from 6.42386
Epoch 347/10000
4/4 - 0s - loss: 20.1231 - val_loss: 6.5977

Epoch 00347: val_loss did not improve from 6.42386
Epoch 348/10000
4/4 - 0s - loss: 20.0712 - val_loss: 6.4115

Epoch 00348: val_loss improved from 6.42386 to 6.41153, saving model to ./results/dataset/trial_5/ckpt_10
Epoch 349/10000
4/4 - 0s - loss: 20.1401 - val_loss: 6.4726

Epoch 00349: val_loss did not improve from 6.41153
Epoch 350/10000
4/4 - 0s - loss: 20.0825 - val_loss: 6.5649

Epoch 00350: val_loss did not improve from 6.41153
Epoch 351/10000
4/4 - 0s - loss: 20.0665 - val_loss: 6.7490

Epoch 00351: val_loss did not improve from 6.41153
Epoch 352/10000
4/4 - 0s - loss: 20.1430 - val_loss: 6.7066

Epoch 00352: val_loss did not improve from 6.41153
Epoch 353/10000
4/4 - 0s - loss: 20.0728 - val_loss: 6.4808

Epoch 00353: val_loss did not improve from 6.41153
Epoch 354/10000
4/4 - 0s - loss: 20.0925 - val_loss: 6.5152

Epoch 00354: val_loss did not improve from 6.41153
Epoch 355/10000
4/4 - 0s - loss: 20.0773 - val_loss: 6.6557

Epoch 00355: val_loss did not improve from 6.41153
Epoch 356/10000
4/4 - 0s - loss: 20.0751 - val_loss: 6.6981

Epoch 00356: val_loss did not improve from 6.41153
Epoch 357/10000
4/4 - 0s - loss: 20.1147 - val_loss: 6.7261

Epoch 00357: val_loss did not improve from 6.41153
Epoch 358/10000
4/4 - 0s - loss: 20.0637 - val_loss: 6.4836

Epoch 00358: val_loss did not improve from 6.41153
Epoch 359/10000
4/4 - 0s - loss: 20.1159 - val_loss: 6.4815

Epoch 00359: val_loss did not improve from 6.41153
Epoch 360/10000
4/4 - 0s - loss: 20.0738 - val_loss: 6.6665

Epoch 00360: val_loss did not improve from 6.41153
Epoch 361/10000
4/4 - 0s - loss: 20.0803 - val_loss: 6.7273

Epoch 00361: val_loss did not improve from 6.41153
Epoch 362/10000
4/4 - 0s - loss: 20.1074 - val_loss: 6.7536

Epoch 00362: val_loss did not improve from 6.41153
Epoch 363/10000
4/4 - 0s - loss: 20.0698 - val_loss: 6.4806

Epoch 00363: val_loss did not improve from 6.41153
Epoch 364/10000
4/4 - 0s - loss: 20.1191 - val_loss: 6.4765

Epoch 00364: val_loss did not improve from 6.41153
Epoch 365/10000
4/4 - 0s - loss: 20.0990 - val_loss: 6.8226

Epoch 00365: val_loss did not improve from 6.41153
Epoch 366/10000
4/4 - 0s - loss: 20.1120 - val_loss: 6.7500

Epoch 00366: val_loss did not improve from 6.41153
Epoch 367/10000
4/4 - 0s - loss: 20.1143 - val_loss: 6.4546

Epoch 00367: val_loss did not improve from 6.41153
Epoch 368/10000
4/4 - 0s - loss: 20.1103 - val_loss: 6.5421

Epoch 00368: val_loss did not improve from 6.41153
Epoch 369/10000
4/4 - 0s - loss: 20.0960 - val_loss: 6.5738

Epoch 00369: val_loss did not improve from 6.41153
Epoch 370/10000
4/4 - 0s - loss: 20.0803 - val_loss: 6.8376

Epoch 00370: val_loss did not improve from 6.41153
Epoch 371/10000
4/4 - 0s - loss: 20.1158 - val_loss: 6.6054

Epoch 00371: val_loss did not improve from 6.41153
Epoch 372/10000
4/4 - 0s - loss: 20.1334 - val_loss: 6.4643

Epoch 00372: val_loss did not improve from 6.41153
Epoch 373/10000
4/4 - 0s - loss: 20.1141 - val_loss: 6.7259

Epoch 00373: val_loss did not improve from 6.41153
Epoch 374/10000
4/4 - 0s - loss: 20.0849 - val_loss: 6.7265

Epoch 00374: val_loss did not improve from 6.41153
Epoch 375/10000
4/4 - 0s - loss: 20.0978 - val_loss: 6.5502

Epoch 00375: val_loss did not improve from 6.41153
Epoch 376/10000
4/4 - 0s - loss: 20.0734 - val_loss: 6.6114

Epoch 00376: val_loss did not improve from 6.41153
Epoch 377/10000
4/4 - 0s - loss: 20.0670 - val_loss: 6.6020

Epoch 00377: val_loss did not improve from 6.41153
Epoch 378/10000
4/4 - 0s - loss: 20.0689 - val_loss: 6.6170

Epoch 00378: val_loss did not improve from 6.41153
Epoch 379/10000
4/4 - 0s - loss: 20.0793 - val_loss: 6.5875

Epoch 00379: val_loss did not improve from 6.41153
Epoch 380/10000
4/4 - 0s - loss: 20.0894 - val_loss: 6.7143

Epoch 00380: val_loss did not improve from 6.41153
Epoch 381/10000
4/4 - 0s - loss: 20.0732 - val_loss: 6.5714

Epoch 00381: val_loss did not improve from 6.41153
Epoch 382/10000
4/4 - 0s - loss: 20.0728 - val_loss: 6.5183

Epoch 00382: val_loss did not improve from 6.41153
Epoch 383/10000
4/4 - 0s - loss: 20.0919 - val_loss: 6.6180

Epoch 00383: val_loss did not improve from 6.41153
Epoch 384/10000
4/4 - 0s - loss: 20.0956 - val_loss: 6.5796

Epoch 00384: val_loss did not improve from 6.41153
Epoch 385/10000
4/4 - 0s - loss: 20.0641 - val_loss: 6.4891

Epoch 00385: val_loss did not improve from 6.41153
Epoch 386/10000
4/4 - 0s - loss: 20.1540 - val_loss: 6.4174

Epoch 00386: val_loss did not improve from 6.41153
Epoch 387/10000
4/4 - 0s - loss: 20.1022 - val_loss: 6.7891

Epoch 00387: val_loss did not improve from 6.41153
Epoch 388/10000
4/4 - 0s - loss: 20.1135 - val_loss: 6.7536

Epoch 00388: val_loss did not improve from 6.41153
Epoch 389/10000
4/4 - 0s - loss: 20.1464 - val_loss: 6.4424

Epoch 00389: val_loss did not improve from 6.41153
Epoch 390/10000
4/4 - 0s - loss: 20.1089 - val_loss: 6.5636

Epoch 00390: val_loss did not improve from 6.41153
Epoch 391/10000
4/4 - 0s - loss: 20.0662 - val_loss: 6.6305

Epoch 00391: val_loss did not improve from 6.41153
Epoch 392/10000
4/4 - 0s - loss: 20.0732 - val_loss: 6.6380

Epoch 00392: val_loss did not improve from 6.41153
Epoch 393/10000
4/4 - 0s - loss: 20.0798 - val_loss: 6.5362

Epoch 00393: val_loss did not improve from 6.41153
Epoch 394/10000
4/4 - 0s - loss: 20.0702 - val_loss: 6.6026

Epoch 00394: val_loss did not improve from 6.41153
Epoch 395/10000
4/4 - 0s - loss: 20.0683 - val_loss: 6.6016

Epoch 00395: val_loss did not improve from 6.41153
Epoch 396/10000
4/4 - 0s - loss: 20.0802 - val_loss: 6.5160

Epoch 00396: val_loss did not improve from 6.41153
Epoch 397/10000
4/4 - 0s - loss: 20.0918 - val_loss: 6.4964

Epoch 00397: val_loss did not improve from 6.41153
Epoch 398/10000
4/4 - 0s - loss: 20.0851 - val_loss: 6.7672

Epoch 00398: val_loss did not improve from 6.41153
Epoch 399/10000
4/4 - 0s - loss: 20.1117 - val_loss: 6.6291

Epoch 00399: val_loss did not improve from 6.41153
Epoch 400/10000
4/4 - 0s - loss: 20.0713 - val_loss: 6.5770

Epoch 00400: val_loss did not improve from 6.41153
Epoch 401/10000
4/4 - 0s - loss: 20.0666 - val_loss: 6.5827

Epoch 00401: val_loss did not improve from 6.41153
Epoch 402/10000
4/4 - 0s - loss: 20.0638 - val_loss: 6.6362

Epoch 00402: val_loss did not improve from 6.41153
Epoch 403/10000
4/4 - 0s - loss: 20.0769 - val_loss: 6.6572

Epoch 00403: val_loss did not improve from 6.41153
Epoch 404/10000
4/4 - 0s - loss: 20.0643 - val_loss: 6.5185

Epoch 00404: val_loss did not improve from 6.41153
Epoch 405/10000
4/4 - 0s - loss: 20.0766 - val_loss: 6.5216

Epoch 00405: val_loss did not improve from 6.41153
Epoch 406/10000
4/4 - 0s - loss: 20.1272 - val_loss: 6.6783

Epoch 00406: val_loss did not improve from 6.41153
Epoch 407/10000
4/4 - 0s - loss: 20.0641 - val_loss: 6.4987

Epoch 00407: val_loss did not improve from 6.41153
Epoch 408/10000
4/4 - 0s - loss: 20.1048 - val_loss: 6.4526

Epoch 00408: val_loss did not improve from 6.41153
Epoch 409/10000
4/4 - 0s - loss: 20.1277 - val_loss: 6.6097

Epoch 00409: val_loss did not improve from 6.41153
Epoch 410/10000
4/4 - 0s - loss: 20.0856 - val_loss: 6.5115

Epoch 00410: val_loss did not improve from 6.41153
Epoch 411/10000
4/4 - 0s - loss: 20.0696 - val_loss: 6.6124

Epoch 00411: val_loss did not improve from 6.41153
Epoch 412/10000
4/4 - 0s - loss: 20.0748 - val_loss: 6.7173

Epoch 00412: val_loss did not improve from 6.41153
Epoch 413/10000
4/4 - 0s - loss: 20.1139 - val_loss: 6.5320

Epoch 00413: val_loss did not improve from 6.41153
Epoch 414/10000
4/4 - 0s - loss: 20.0806 - val_loss: 6.5473

Epoch 00414: val_loss did not improve from 6.41153
Epoch 415/10000
4/4 - 0s - loss: 20.0694 - val_loss: 6.6312

Epoch 00415: val_loss did not improve from 6.41153
Epoch 416/10000
4/4 - 0s - loss: 20.0666 - val_loss: 6.7118

Epoch 00416: val_loss did not improve from 6.41153
Epoch 417/10000
4/4 - 0s - loss: 20.1341 - val_loss: 6.7836

Epoch 00417: val_loss did not improve from 6.41153
Epoch 418/10000
4/4 - 0s - loss: 20.0572 - val_loss: 6.4654

Epoch 00418: val_loss did not improve from 6.41153
Epoch 419/10000
4/4 - 0s - loss: 20.1214 - val_loss: 6.4331

Epoch 00419: val_loss did not improve from 6.41153
Epoch 420/10000
4/4 - 0s - loss: 20.1059 - val_loss: 6.6487

Epoch 00420: val_loss did not improve from 6.41153
Epoch 421/10000
4/4 - 0s - loss: 20.0759 - val_loss: 6.6925

Epoch 00421: val_loss did not improve from 6.41153
Epoch 422/10000
4/4 - 0s - loss: 20.1360 - val_loss: 6.5194

Epoch 00422: val_loss did not improve from 6.41153
Epoch 423/10000
4/4 - 0s - loss: 20.0781 - val_loss: 6.6987

Epoch 00423: val_loss did not improve from 6.41153
Epoch 424/10000
4/4 - 0s - loss: 20.0841 - val_loss: 6.5550

Epoch 00424: val_loss did not improve from 6.41153
Epoch 425/10000
4/4 - 0s - loss: 20.0638 - val_loss: 6.5907

Epoch 00425: val_loss did not improve from 6.41153
Epoch 426/10000
4/4 - 0s - loss: 20.1062 - val_loss: 6.6645

Epoch 00426: val_loss did not improve from 6.41153
Epoch 427/10000
4/4 - 0s - loss: 20.0664 - val_loss: 6.5073

Epoch 00427: val_loss did not improve from 6.41153
Epoch 428/10000
4/4 - 0s - loss: 20.0839 - val_loss: 6.5533

Epoch 00428: val_loss did not improve from 6.41153
Epoch 429/10000
4/4 - 0s - loss: 20.0902 - val_loss: 6.5893

Epoch 00429: val_loss did not improve from 6.41153
Epoch 430/10000
4/4 - 0s - loss: 20.0801 - val_loss: 6.6750

Epoch 00430: val_loss did not improve from 6.41153
Epoch 431/10000
4/4 - 0s - loss: 20.0703 - val_loss: 6.5785

Epoch 00431: val_loss did not improve from 6.41153
Epoch 432/10000
4/4 - 0s - loss: 20.0662 - val_loss: 6.5883

Epoch 00432: val_loss did not improve from 6.41153
Epoch 433/10000
4/4 - 0s - loss: 20.0671 - val_loss: 6.5957

Epoch 00433: val_loss did not improve from 6.41153
Epoch 434/10000
4/4 - 0s - loss: 20.0657 - val_loss: 6.5664

Epoch 00434: val_loss did not improve from 6.41153
Epoch 435/10000
4/4 - 0s - loss: 20.0651 - val_loss: 6.5643

Epoch 00435: val_loss did not improve from 6.41153
Epoch 436/10000
4/4 - 0s - loss: 20.0864 - val_loss: 6.5565

Epoch 00436: val_loss did not improve from 6.41153
Epoch 437/10000
4/4 - 0s - loss: 20.0953 - val_loss: 6.7549

Epoch 00437: val_loss did not improve from 6.41153
Epoch 438/10000
4/4 - 0s - loss: 20.0828 - val_loss: 6.5728

Epoch 00438: val_loss did not improve from 6.41153
Epoch 439/10000
4/4 - 0s - loss: 20.1240 - val_loss: 6.4518

Epoch 00439: val_loss did not improve from 6.41153
Epoch 440/10000
4/4 - 0s - loss: 20.1202 - val_loss: 6.6221

Epoch 00440: val_loss did not improve from 6.41153
Epoch 441/10000
4/4 - 0s - loss: 20.0663 - val_loss: 6.5085

Epoch 00441: val_loss did not improve from 6.41153
Epoch 442/10000
4/4 - 0s - loss: 20.1040 - val_loss: 6.4886

Epoch 00442: val_loss did not improve from 6.41153
Epoch 443/10000
4/4 - 0s - loss: 20.0550 - val_loss: 6.7976

Epoch 00443: val_loss did not improve from 6.41153
Epoch 444/10000
4/4 - 0s - loss: 20.1175 - val_loss: 6.8275

Epoch 00444: val_loss did not improve from 6.41153
Epoch 445/10000
4/4 - 0s - loss: 20.0704 - val_loss: 6.5169

Epoch 00445: val_loss did not improve from 6.41153
Epoch 446/10000
4/4 - 0s - loss: 20.1325 - val_loss: 6.4134

Epoch 00446: val_loss did not improve from 6.41153
Epoch 447/10000
4/4 - 0s - loss: 20.1432 - val_loss: 6.6282

Epoch 00447: val_loss did not improve from 6.41153
Epoch 448/10000
4/4 - 0s - loss: 20.0661 - val_loss: 6.6450

Epoch 00448: val_loss did not improve from 6.41153
Epoch 449/10000
4/4 - 0s - loss: 20.0669 - val_loss: 6.5741

Epoch 00449: val_loss did not improve from 6.41153
Epoch 450/10000
4/4 - 0s - loss: 20.0651 - val_loss: 6.5550

Epoch 00450: val_loss did not improve from 6.41153
Epoch 451/10000
4/4 - 0s - loss: 20.0638 - val_loss: 6.5707

Epoch 00451: val_loss did not improve from 6.41153
Epoch 452/10000
4/4 - 0s - loss: 20.0631 - val_loss: 6.5989

Epoch 00452: val_loss did not improve from 6.41153
Epoch 453/10000
4/4 - 0s - loss: 20.0640 - val_loss: 6.6772

Epoch 00453: val_loss did not improve from 6.41153
Epoch 454/10000
4/4 - 0s - loss: 20.0699 - val_loss: 6.5829

Epoch 00454: val_loss did not improve from 6.41153
Epoch 455/10000
4/4 - 0s - loss: 20.0704 - val_loss: 6.5316

Epoch 00455: val_loss did not improve from 6.41153
Epoch 456/10000
4/4 - 0s - loss: 20.0781 - val_loss: 6.5958

Epoch 00456: val_loss did not improve from 6.41153
Epoch 457/10000
4/4 - 0s - loss: 20.0627 - val_loss: 6.5852

Epoch 00457: val_loss did not improve from 6.41153
Epoch 458/10000
4/4 - 0s - loss: 20.0688 - val_loss: 6.5935

Epoch 00458: val_loss did not improve from 6.41153
Epoch 459/10000
4/4 - 0s - loss: 20.0693 - val_loss: 6.6971

Epoch 00459: val_loss did not improve from 6.41153
Epoch 460/10000
4/4 - 0s - loss: 20.0863 - val_loss: 6.8917

Epoch 00460: val_loss did not improve from 6.41153
Epoch 461/10000
4/4 - 0s - loss: 20.1150 - val_loss: 6.7423

Epoch 00461: val_loss did not improve from 6.41153
Epoch 462/10000
4/4 - 0s - loss: 20.1200 - val_loss: 6.5040

Epoch 00462: val_loss did not improve from 6.41153
Epoch 463/10000
4/4 - 0s - loss: 20.0883 - val_loss: 6.5895

Epoch 00463: val_loss did not improve from 6.41153
Epoch 464/10000
4/4 - 0s - loss: 20.0743 - val_loss: 6.8689

Epoch 00464: val_loss did not improve from 6.41153
Epoch 465/10000
4/4 - 0s - loss: 20.1218 - val_loss: 6.7158

Epoch 00465: val_loss did not improve from 6.41153
Epoch 466/10000
4/4 - 0s - loss: 20.0971 - val_loss: 6.6022

Epoch 00466: val_loss did not improve from 6.41153
Epoch 467/10000
4/4 - 0s - loss: 20.0906 - val_loss: 6.7258

Epoch 00467: val_loss did not improve from 6.41153
Epoch 468/10000
4/4 - 0s - loss: 20.1137 - val_loss: 6.5669

Epoch 00468: val_loss did not improve from 6.41153
Epoch 469/10000
4/4 - 0s - loss: 20.0884 - val_loss: 6.7240

Epoch 00469: val_loss did not improve from 6.41153
Epoch 470/10000
4/4 - 0s - loss: 20.0804 - val_loss: 6.5590

Epoch 00470: val_loss did not improve from 6.41153
Epoch 471/10000
4/4 - 0s - loss: 20.0757 - val_loss: 6.5181

Epoch 00471: val_loss did not improve from 6.41153
Epoch 472/10000
4/4 - 0s - loss: 20.0852 - val_loss: 6.6336

Epoch 00472: val_loss did not improve from 6.41153
Epoch 473/10000
4/4 - 0s - loss: 20.0589 - val_loss: 6.5597

Epoch 00473: val_loss did not improve from 6.41153
Epoch 474/10000
4/4 - 0s - loss: 20.0648 - val_loss: 6.5311

Epoch 00474: val_loss did not improve from 6.41153
Epoch 475/10000
4/4 - 0s - loss: 20.0686 - val_loss: 6.5617

Epoch 00475: val_loss did not improve from 6.41153
Epoch 476/10000
4/4 - 0s - loss: 20.1055 - val_loss: 6.7404

Epoch 00476: val_loss did not improve from 6.41153
Epoch 477/10000
4/4 - 0s - loss: 20.0702 - val_loss: 6.5667

Epoch 00477: val_loss did not improve from 6.41153
Epoch 478/10000
4/4 - 0s - loss: 20.0695 - val_loss: 6.5002

Epoch 00478: val_loss did not improve from 6.41153
Epoch 479/10000
4/4 - 0s - loss: 20.0820 - val_loss: 6.5616

Epoch 00479: val_loss did not improve from 6.41153
Epoch 480/10000
4/4 - 0s - loss: 20.0659 - val_loss: 6.5710

Epoch 00480: val_loss did not improve from 6.41153
Epoch 481/10000
4/4 - 0s - loss: 20.0733 - val_loss: 6.5725

Epoch 00481: val_loss did not improve from 6.41153
Epoch 482/10000
4/4 - 0s - loss: 20.0834 - val_loss: 6.5019

Epoch 00482: val_loss did not improve from 6.41153
Epoch 483/10000
4/4 - 0s - loss: 20.0803 - val_loss: 6.5940

Epoch 00483: val_loss did not improve from 6.41153
Epoch 484/10000
4/4 - 0s - loss: 20.0743 - val_loss: 6.5222

Epoch 00484: val_loss did not improve from 6.41153
Epoch 485/10000
4/4 - 0s - loss: 20.0612 - val_loss: 6.5974

Epoch 00485: val_loss did not improve from 6.41153
Epoch 486/10000
4/4 - 0s - loss: 20.0809 - val_loss: 6.6533

Epoch 00486: val_loss did not improve from 6.41153
Epoch 487/10000
4/4 - 0s - loss: 20.0743 - val_loss: 6.4823

Epoch 00487: val_loss did not improve from 6.41153
Epoch 488/10000
4/4 - 0s - loss: 20.0729 - val_loss: 6.5755

Epoch 00488: val_loss did not improve from 6.41153
Epoch 489/10000
4/4 - 0s - loss: 20.0588 - val_loss: 6.6435

Epoch 00489: val_loss did not improve from 6.41153
Epoch 490/10000
4/4 - 0s - loss: 20.0704 - val_loss: 6.6607

Epoch 00490: val_loss did not improve from 6.41153
Epoch 491/10000
4/4 - 0s - loss: 20.0949 - val_loss: 6.5039

Epoch 00491: val_loss did not improve from 6.41153
Epoch 492/10000
4/4 - 0s - loss: 20.0932 - val_loss: 6.5562

Epoch 00492: val_loss did not improve from 6.41153
Epoch 493/10000
4/4 - 0s - loss: 20.0745 - val_loss: 6.5070

Epoch 00493: val_loss did not improve from 6.41153
Epoch 494/10000
4/4 - 0s - loss: 20.0569 - val_loss: 6.6377

Epoch 00494: val_loss did not improve from 6.41153
Epoch 495/10000
4/4 - 0s - loss: 20.0579 - val_loss: 6.7843

Epoch 00495: val_loss did not improve from 6.41153
Epoch 496/10000
4/4 - 0s - loss: 20.0975 - val_loss: 6.6668

Epoch 00496: val_loss did not improve from 6.41153
Epoch 497/10000
4/4 - 0s - loss: 20.0616 - val_loss: 6.5708

Epoch 00497: val_loss did not improve from 6.41153
Epoch 498/10000
4/4 - 0s - loss: 20.0901 - val_loss: 6.4954

Epoch 00498: val_loss did not improve from 6.41153
Epoch 499/10000
4/4 - 0s - loss: 20.1176 - val_loss: 6.6545

Epoch 00499: val_loss did not improve from 6.41153
Epoch 500/10000
4/4 - 0s - loss: 20.0567 - val_loss: 6.5011

Epoch 00500: val_loss did not improve from 6.41153
Epoch 501/10000
4/4 - 0s - loss: 20.0862 - val_loss: 6.4826

Epoch 00501: val_loss did not improve from 6.41153
Epoch 502/10000
4/4 - 0s - loss: 20.0928 - val_loss: 6.6946

Epoch 00502: val_loss did not improve from 6.41153
Epoch 503/10000
4/4 - 0s - loss: 20.0662 - val_loss: 6.5778

Epoch 00503: val_loss did not improve from 6.41153
Epoch 504/10000
4/4 - 0s - loss: 20.0826 - val_loss: 6.4497

Epoch 00504: val_loss did not improve from 6.41153
Epoch 505/10000
4/4 - 0s - loss: 20.0881 - val_loss: 6.5530

Epoch 00505: val_loss did not improve from 6.41153
Epoch 506/10000
4/4 - 0s - loss: 20.0698 - val_loss: 6.6288

Epoch 00506: val_loss did not improve from 6.41153
Epoch 507/10000
4/4 - 0s - loss: 20.0878 - val_loss: 6.5313

Epoch 00507: val_loss did not improve from 6.41153
Epoch 508/10000
4/4 - 0s - loss: 20.0688 - val_loss: 6.6630

Epoch 00508: val_loss did not improve from 6.41153
Epoch 509/10000
4/4 - 0s - loss: 20.0880 - val_loss: 6.5973

Epoch 00509: val_loss did not improve from 6.41153
Epoch 510/10000
4/4 - 0s - loss: 20.0526 - val_loss: 6.4179

Epoch 00510: val_loss did not improve from 6.41153
Epoch 511/10000
4/4 - 0s - loss: 20.1131 - val_loss: 6.4565

Epoch 00511: val_loss did not improve from 6.41153
Epoch 512/10000
4/4 - 0s - loss: 20.0651 - val_loss: 6.6814

Epoch 00512: val_loss did not improve from 6.41153
Epoch 513/10000
4/4 - 0s - loss: 20.0811 - val_loss: 6.7024

Epoch 00513: val_loss did not improve from 6.41153
Epoch 514/10000
4/4 - 0s - loss: 20.0786 - val_loss: 6.4851

Epoch 00514: val_loss did not improve from 6.41153
Epoch 515/10000
4/4 - 0s - loss: 20.0958 - val_loss: 6.5076

Epoch 00515: val_loss did not improve from 6.41153
Epoch 516/10000
4/4 - 0s - loss: 20.0664 - val_loss: 6.5839

Epoch 00516: val_loss did not improve from 6.41153
Epoch 517/10000
4/4 - 0s - loss: 20.0590 - val_loss: 6.5792

Epoch 00517: val_loss did not improve from 6.41153
Epoch 518/10000
4/4 - 0s - loss: 20.0592 - val_loss: 6.6228

Epoch 00518: val_loss did not improve from 6.41153
Epoch 519/10000
4/4 - 0s - loss: 20.0626 - val_loss: 6.5961

Epoch 00519: val_loss did not improve from 6.41153
Epoch 520/10000
4/4 - 0s - loss: 20.0569 - val_loss: 6.5464

Epoch 00520: val_loss did not improve from 6.41153
Epoch 521/10000
4/4 - 0s - loss: 20.0619 - val_loss: 6.5354

Epoch 00521: val_loss did not improve from 6.41153
Epoch 522/10000
4/4 - 0s - loss: 20.0762 - val_loss: 6.6259

Epoch 00522: val_loss did not improve from 6.41153
Epoch 523/10000
4/4 - 0s - loss: 20.0562 - val_loss: 6.5357

Epoch 00523: val_loss did not improve from 6.41153
Epoch 524/10000
4/4 - 0s - loss: 20.0711 - val_loss: 6.4632

Epoch 00524: val_loss did not improve from 6.41153
Epoch 525/10000
4/4 - 0s - loss: 20.0800 - val_loss: 6.5631

Epoch 00525: val_loss did not improve from 6.41153
Epoch 526/10000
4/4 - 0s - loss: 20.0706 - val_loss: 6.5589

Epoch 00526: val_loss did not improve from 6.41153
Epoch 527/10000
4/4 - 0s - loss: 20.0577 - val_loss: 6.4929

Epoch 00527: val_loss did not improve from 6.41153
Epoch 528/10000
4/4 - 0s - loss: 20.0947 - val_loss: 6.4649

Epoch 00528: val_loss did not improve from 6.41153
Epoch 529/10000
4/4 - 0s - loss: 20.0734 - val_loss: 6.6634

Epoch 00529: val_loss did not improve from 6.41153
Epoch 530/10000
4/4 - 0s - loss: 20.0713 - val_loss: 6.6374

Epoch 00530: val_loss did not improve from 6.41153
Epoch 531/10000
4/4 - 0s - loss: 20.0650 - val_loss: 6.5105

Epoch 00531: val_loss did not improve from 6.41153
Epoch 532/10000
4/4 - 0s - loss: 20.0640 - val_loss: 6.5490

Epoch 00532: val_loss did not improve from 6.41153
Epoch 533/10000
4/4 - 0s - loss: 20.0803 - val_loss: 6.6996

Epoch 00533: val_loss did not improve from 6.41153
Epoch 534/10000
4/4 - 0s - loss: 20.0587 - val_loss: 6.5391

Epoch 00534: val_loss did not improve from 6.41153
Epoch 535/10000
4/4 - 0s - loss: 20.0671 - val_loss: 6.4773

Epoch 00535: val_loss did not improve from 6.41153
Epoch 536/10000
4/4 - 0s - loss: 20.0817 - val_loss: 6.4254

Epoch 00536: val_loss did not improve from 6.41153
Epoch 537/10000
4/4 - 0s - loss: 20.0779 - val_loss: 6.5750

Epoch 00537: val_loss did not improve from 6.41153
Epoch 538/10000
4/4 - 0s - loss: 20.0970 - val_loss: 6.6583

Epoch 00538: val_loss did not improve from 6.41153
Epoch 539/10000
4/4 - 0s - loss: 20.0880 - val_loss: 6.4498

Epoch 00539: val_loss did not improve from 6.41153
Epoch 540/10000
4/4 - 0s - loss: 20.0794 - val_loss: 6.5055

Epoch 00540: val_loss did not improve from 6.41153
Epoch 541/10000
4/4 - 0s - loss: 20.0672 - val_loss: 6.6984

Epoch 00541: val_loss did not improve from 6.41153
Epoch 542/10000
4/4 - 0s - loss: 20.0711 - val_loss: 6.5693

Epoch 00542: val_loss did not improve from 6.41153
Epoch 543/10000
4/4 - 0s - loss: 20.0606 - val_loss: 6.5105

Epoch 00543: val_loss did not improve from 6.41153
Epoch 544/10000
4/4 - 0s - loss: 20.0758 - val_loss: 6.5364

Epoch 00544: val_loss did not improve from 6.41153
Epoch 545/10000
4/4 - 0s - loss: 20.0480 - val_loss: 6.7465

Epoch 00545: val_loss did not improve from 6.41153
Epoch 546/10000
4/4 - 0s - loss: 20.0861 - val_loss: 6.6806

Epoch 00546: val_loss did not improve from 6.41153
Epoch 547/10000
4/4 - 0s - loss: 20.0891 - val_loss: 6.5429

Epoch 00547: val_loss did not improve from 6.41153
Epoch 548/10000
4/4 - 0s - loss: 20.0611 - val_loss: 6.5908

Epoch 00548: val_loss did not improve from 6.41153
Epoch 00548: early stopping
